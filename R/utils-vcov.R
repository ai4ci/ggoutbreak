# identity matrix:
# tmp  = matrix(nrow=4,ncol=4,data = 0)
# diag(tmp) = 1
# t(tmp * c(1,2,3,4)) * c(1,2,3,4) - would give us vcov matrix

# Create distance matrix:
# time_matrix <- outer(time_points, time_points, function(x, y) abs(x - y))
# Exponential decay covariance function
# Correlation decays exponentially with distance
# correlation_matrix <- exp(-time_matrix / bandwidth)

# GAMs
predict_derivative = function(model, newdata, dimension = "time") {
  dimension = rlang::ensym(dimension)
  eps = 1e-7 ## finite difference interval
  X0 = stats::predict(
    model,
    newdata %>% dplyr::mutate(!!dimension := !!dimension - eps),
    type = "lpmatrix"
  )
  X1 = stats::predict(
    model,
    newdata %>% dplyr::mutate(!!dimension := !!dimension + eps),
    type = "lpmatrix"
  )
  Xp = (X1 - X0) / (2 * eps) ## maps coefficients to (fd approx.) derivatives
  fit = Xp %*% stats::coef(model)
  # this is doing a Xp %*% vcov(model) %*% t(Xp) where we only need sequential
  # values (i.e. the diagonals)
  se.fit = sqrt(rowSums(Xp %*% stats::vcov(model) * Xp))

  return(list(
    fit = as.numeric(fit),
    se.fit = as.numeric(se.fit)
  ))
}

# Example usage
# deriv_result <- predict_derivative(best_model, newdata)

.gam_glm_cor = function(model, newdata) {
  Xp <- stats::predict(model, newdata, type = "lpmatrix")
  pred_vcov <- Xp %*% stats::vcov(model) %*% t(Xp)
  return(stats::cov2cor(pred_vcov))
}

# generate a vcov matrix for locfit based on time difference alone.
# .locfit_vcov = function(
#   model,
#   newdata,
#   bw = model$dp$h,
#   decay = c("exponential", "gaussian", "power")
# ) {
#   tmp = stats::preplot(
#     fit,
#     newdata = newdata,
#     se.fit = TRUE,
#     band = "local",
#     maxit = 5000,
#     maxk = 5000
#   )
#   .ts_vcov(tmp$se.fit, bw = bw, decay = decay)
# }
#
# .ts_vcov = function(se.fit, bw, decay = c("exponential", "gaussian", "power")) {
#   correlation_matrix = .time_based_correlation(
#     seq_along(se.fit),
#     bw = bw,
#     decay = decay
#   )
#   se_matrix = outer(tmp$se.fit, tmp$se.fit)
#   cov_matrix = correlation_matrix * se_matrix
# }

#' Estimate Parametric VCOV Matrix from Residuals
#'
#' Estimates the variance-covariance matrix of log-incidence estimates
#' by modelling residual autocorrelation with an exponential decay model.
#'
#' This function was generated by Qwen3-235B-A22B-2507
#'
#' @param data Numeric vector: observed case counts I_t
#' @param mu Numeric vector: estimated log-incidence (log lambda_t)
#' @param sigma Numeric vector: estimated standard error of log lambda_t
#' @param max_lag Integer: maximum lag for ACF estimation (default: 10)
#' @param min_alpha Positive number: minimum decay rate (default: 0.01)
#' @param max_alpha Positive number: maximum decay rate (default: 2.0)
#'
#' @return List with:
#'   - vcov_matrix: T x T estimated VCOV matrix for log lambda_t
#'   - alpha: fitted decay parameter
#'   - acf_obs: observed ACF of Pearson residuals
#'   - acf_fit: fitted ACF values
#'   - residuals: Pearson residuals used
#'   - times: time indices
#' @export
#'
#' @examples
#' T <- 50
#' mu <- 5 + 0.05 * (1:T) + stats::arima.sim(list(ar = 0.8), n = T, sd = 0.3)
#' sigma <- rep(0.2, T)
#' lambda <- exp(mu)
#' data <- stats::rpois(T, lambda)
#'
#' result <- vcov_from_residuals(data, mu, sigma, max_lag = 8)
#' dim(result$vcov_matrix)  # Should be T x T
#'
vcov_from_residuals = function(
  data,
  mu,
  sigma,
  max_lag = 10,
  min_alpha = 0.01,
  max_alpha = 2.0
) {
  # Input validation
  if (!all(c(length(data), length(mu), length(sigma)) == length(data))) {
    stop("All inputs must have the same length.")
  }
  if (any(stats::na.omit(data) < 0)) {
    stop("Data must be non-negative counts.")
  }
  if (any(stats::na.omit(sigma) <= 0)) {
    stop("sigma must be positive.")
  }
  if (max_lag >= length(data)) {
    stop("max_lag must be less than length of data.")
  }

  T <- length(data)
  times <- 1:T

  # Step 1: Compute fitted values
  lambda_hat <- exp(mu + sigma^2 / 2)

  # Step 2: Compute Pearson residuals
  residuals <- (data - lambda_hat) / sqrt(lambda_hat)

  # Remove any NaNs (e.g., if lambda_hat = 0)
  valid <- !is.na(residuals) & is.finite(residuals)
  if (!all(valid)) {
    #warning("Some residuals are NaN/Inf; using only valid time points for ACF.")
    residuals <- residuals[valid]
  }

  # Step 3: Estimate empirical autocorrelation
  acf_fit <- stats::acf(
    residuals,
    lag.max = max_lag,
    type = "correlation",
    plot = FALSE,
    na.action = stats::na.pass
  )
  lags <- acf_fit$lag
  acf_obs <- acf_fit$acf

  # Only use non-zero lags
  lag_vals <- lags[,, 1] # Extract from 3D array
  acf_vals <- acf_obs[,, 1]

  # Step 4: Fit exponential decay model: rho(tau) = exp(-alpha * tau)
  # Use non-linear least squares
  keep <- lag_vals > 0 & lag_vals <= max_lag
  if (sum(keep) < 2) {
    stop("Not enough valid lags to fit model.")
  }

  objective <- function(alpha) {
    rho_hat <- exp(-alpha * lag_vals[keep])
    sum((acf_vals[keep] - rho_hat)^2)
  }

  fit <- stats::optim(
    par = 0.5,
    fn = objective,
    method = "L-BFGS-B",
    lower = min_alpha,
    upper = max_alpha
  )

  alpha <- fit$par
  acf_fit_vals <- exp(-alpha * lag_vals)

  # Step 5: Build VCOV matrix
  vcov_matrix <- abs(outer(1:T, 1:T, "-")) # lags
  vcov_matrix <- exp(-alpha * vcov_matrix) # exponential correlation
  vcov_matrix <- vcov_matrix * outer(sigma, sigma) # covariance

  # Return results
  list(
    vcov_matrix = vcov_matrix,
    alpha = alpha,
    acf_obs = data.frame(lag = lag_vals, acf = acf_vals),
    acf_fit = data.frame(lag = lag_vals, acf = exp(-alpha * lag_vals)),
    residuals = residuals,
    times = times,
    call = match.call()
  )
}
