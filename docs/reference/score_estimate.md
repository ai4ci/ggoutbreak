# Calculate scoring statistics from predictions.

This performs a range of continuous scoring metrics for each estimate
time-point using cumulative distribution functions for each estimate.
Point quality metrics are calculated for each estimate provided and
summarised. Summarisation is performed using bootstrap resampling to
generate confidence intervals for summary statistics, which are
presented as median +/1 95% CI.

## Usage

``` r
score_estimate(
  est,
  obs,
  lags = NULL,
  summarise_by = est %>% dplyr::groups(),
  bootstraps = 1000,
  raw_bootstraps = FALSE,
  seed = 100
)
```

## Arguments

- est:

  a dataframe of estimates of incidence, growth rate of reproduction
  number based off a simulation or data with known parameters. Each
  group in `est` is expected to contain multiple estimates and each
  group is scored separately. Estimates in `est` must be in the form of
  a column named `XXX.cdf` containing a cumulative distribution function
  for the estimate and `XXX.link` containing a link function
  specification (one if `identity`,`log` or `logit`). These are not
  generated by default by the `ggoutbreak` estimators but are triggered
  by setting the option: `options("ggoutbreak.keep_cdf"=TRUE)` before
  running the estimator. The CDFs generated will be analytical, if the
  estimator generates a parametrised output (or a mixture thereof),
  empirical if the estimator uses resampling, or inferred if the
  estimator produces quantiles only.

- obs:

  a dataframe of the ground truth, sharing the same grouping and columns
  as `est` with at least one column(s) named `XXX.obs` with `XXX` being
  e.g. `rt`,`growth` or `incidence` or any other column group predicted
  in `est` (i.e. if `obs` has a column `XXX.obs`, `est` must have one
  called `XXX.cdf`).

- lags:

  a data frame of estimate types and lags as output by
  [`quantify_lag()`](https://ai4ci.github.io/ggoutbreak/reference/quantify_lag.md)
  if multiple models are included then the columns must match those in
  `obs`. It must have 2 columns, one called `estimate` with values
  matching `incidence`,`rt`,`growth`,`proportion`,`relative.growth`, and
  a `lag` column, with (whole) number of days.

- summarise_by:

  by default every group is treated separately. This can be overridden
  with a `dplyr` specification of the groupings we want to see in the
  final summarised output (e.g. if we want to differentiate performance
  on a particular type of scenario or timeframe). If this is exactly
  `FALSE` the function will return all the raw point estimates.

- bootstraps:

  the number of bootstrap replicates to draw for assessing metric
  confidence. If FALSE then no bootstrapping will be done and the
  metrics returned will have no confidence intervals.

- raw_bootstraps:

  (defaults to FALSE) return the summary metrics for each bootstrap
  rather than the quantiles of the summary metrics.

- seed:

  a random seed for reproducibility

## Value

a dataframe of scoring metrics, with one row per group. This includes
the following columns:

- `mean_quantile_bias` - the average of the universal residuals. Lower
  values are better.

- `mean_trans_bias` - the bias on the link function scale.

- link - the link function

- `mean_bias` - the bias on the natural scale (which may be interpreted
  as additive or multiplicative depending on the link)

- `pit_was` - an unadjusted probability integral transform histogram
  Wasserstein distance from the uniform (lower values are better).

- `unbiased_pit_was` - an PIT Wasserstein distance from the uniform,
  adjusted for estimator bias (lower values are better). This is a
  measure of calibration.

- `directed_pit_was` - a PIT Wasserstein distance from the uniform,
  directed away from the centre, adjusted for estimator bias (values
  closer to zero are better, positive values indicate overconfidence,
  and negative values excessively conservative estimates).

- `percent_iqr_coverage` - the percentage of estimators that include the
  true value in their IQR. For a perfectly calibrated estimate this
  should be 0.5. Lower values reflect overconfidence, higher values
  reflect excessively conservative estimates. This is a measure of
  calibration but is influenced by bias.

- `unbiased_percent_iqr_coverage` - the percentage of estimators that
  include the true value in their IQR once adjusted for bias. This
  should be 0.5. This is a measure of calibration, and tells you which
  direction (smaller numbers are over-confident, larger values
  excessively conservative).

- `mean_prediction_interval_width_50` - the prediction interval width is
  a measure of sharpness (smaller values are sharper). Sharper
  estimators are superior if they are unbiased and well calibrated.

- `mean_crps` - the mean value of the continuous rank probability score
  for each point estimate (lower values are better)

- `mean_unbiased_crps` - the mean value of the continuous rank
  probability score for each point estimate assessed after adjustment
  for bias (lower values are better)

- `threshold_misclassification_probability` - if a metric has a natural
  threshold like 1 for Rt then this measures how probable it is that the
  estimate will propose the epidemic is shrinking when it is growing and
  vice versa. Lower is better

other outputs are possible if `summarise_by` is false.

## Examples

``` r
data = example_poisson_rt_smooth()

pipeline = ~ .x %>% poisson_locfit_model(ip = .y, quick=TRUE)
lags = quantify_lag(pipeline, ip = example_ip())
#> Rt estimation using Locfit (approx and assuming independence)

withr::with_options(list("ggoutbreak.keep_cdf"=TRUE),{
   est = data %>% poisson_locfit_model(ip = example_ip(), quick=TRUE)
})
#> Rt estimation using Locfit (approx and assuming independence)
#> Estimates were assumed to be independent, but more that 1% of estimates
#> are at risk of Rt underestimation by more that 0.05 (absolute).
#> We advise re-running supplying a full variance-covariance matrix, or
#> a value to the `raw` parameter, or setting `quick=FALSE`.

if (interactive()) plot_rt(est)+sim_geom_function(data, colour="red")

obs = data %>% dplyr::mutate(rt.obs = rt, incidence.obs = rate)
score_estimate(est,obs,lags) %>% dplyr::glimpse()
#> estimates match true observations using columns: statistic,time
#> matching ground truth observations for: rt,incidence
#> Rows: 2
#> Columns: 58
#> Groups: link, statistic, .type [2]
#> $ link                                          <chr> "log", "log"
#> $ statistic                                     <chr> "infections", "infection…
#> $ .type                                         <chr> "incidence", "rt"
#> $ mean_crps.0.025                               <dbl> 3.21782117, 0.04837831
#> $ mean_crps.0.25                                <dbl> 3.67838047, 0.05761117
#> $ mean_crps.0.5                                 <dbl> 3.94836855, 0.06306065
#> $ mean_crps.0.75                                <dbl> 4.25836841, 0.06896325
#> $ mean_crps.0.975                               <dbl> 4.85983296, 0.07941303
#> $ threshold_misclassification_probability.0.025 <dbl> NA, 0.003492902
#> $ threshold_misclassification_probability.0.25  <dbl> NA, 0.004801876
#> $ threshold_misclassification_probability.0.5   <dbl> NA, 0.005663844
#> $ threshold_misclassification_probability.0.75  <dbl> NA, 0.006601401
#> $ threshold_misclassification_probability.0.975 <dbl> NA, 0.008548549
#> $ mean_trans_bias.0.025                         <dbl> -0.03932336, -0.12444109
#> $ mean_trans_bias.0.25                          <dbl> -0.01635998, -0.09288908
#> $ mean_trans_bias.0.5                           <dbl> 0.0000477014, -0.0756842…
#> $ mean_trans_bias.0.75                          <dbl> 0.02091896, -0.05999008
#> $ mean_trans_bias.0.975                         <dbl> 0.06618486, -0.03284903
#> $ mean_bias.0.025                               <dbl> 0.9687548, 0.9276912
#> $ mean_bias.0.25                                <dbl> 1.0067972, 0.9457355
#> $ mean_bias.0.5                                 <dbl> 1.2837259, 0.9558659
#> $ mean_bias.0.75                                <dbl> 1.5640856, 0.9651901
#> $ mean_bias.0.975                               <dbl> 1.9461215, 0.9814167
#> $ mean_quantile_bias.0.025                      <dbl> -0.21723959, -0.09106206
#> $ mean_quantile_bias.0.25                       <dbl> -0.14910455, -0.04287315
#> $ mean_quantile_bias.0.5                        <dbl> -0.11461270, -0.01784693
#> $ mean_quantile_bias.0.75                       <dbl> -0.082103994, 0.007517602
#> $ mean_quantile_bias.0.975                      <dbl> -0.01704358, 0.05698413
#> $ mean_prediction_interval_width_50.0.025       <dbl> 4.8570437, 0.1233357
#> $ mean_prediction_interval_width_50.0.25        <dbl> 5.3252001, 0.1340493
#> $ mean_prediction_interval_width_50.0.5         <dbl> 5.5936187, 0.1397408
#> $ mean_prediction_interval_width_50.0.75        <dbl> 5.8583160, 0.1454413
#> $ mean_prediction_interval_width_50.0.975       <dbl> 6.3619715, 0.1560621
#> $ pit_was.0.025                                 <dbl> 0.04169608, 0.03916000
#> $ pit_was.0.25                                  <dbl> 0.06170105, 0.05120671
#> $ pit_was.0.5                                   <dbl> 0.07598819, 0.05811761
#> $ pit_was.0.75                                  <dbl> 0.08981801, 0.06470482
#> $ pit_was.0.975                                 <dbl> 0.11638225, 0.07897469
#> $ unbiased_pit_was.0.025                        <dbl> 0.1323706, 0.1399726
#> $ unbiased_pit_was.0.25                         <dbl> 0.1681051, 0.1669565
#> $ unbiased_pit_was.0.5                          <dbl> 0.1837494, 0.1798616
#> $ unbiased_pit_was.0.75                         <dbl> 0.1992547, 0.1936935
#> $ unbiased_pit_was.0.975                        <dbl> 0.227905, 0.222787
#> $ directed_pit_was.0.025                        <dbl> -0.02227773, -0.06882064
#> $ directed_pit_was.0.25                         <dbl> -0.001731458, -0.0470520…
#> $ directed_pit_was.0.5                          <dbl> 0.008796109, -0.034922490
#> $ directed_pit_was.0.75                         <dbl> 0.01837417, -0.02477326
#> $ directed_pit_was.0.975                        <dbl> 0.03782334, -0.00453361
#> $ percent_iqr_coverage.0.025                    <dbl> 0.3787267, 0.5900621
#> $ percent_iqr_coverage.0.25                     <dbl> 0.4285714, 0.6397516
#> $ percent_iqr_coverage.0.5                      <dbl> 0.4534161, 0.6645963
#> $ percent_iqr_coverage.0.75                     <dbl> 0.4782609, 0.6894410
#> $ percent_iqr_coverage.0.975                    <dbl> 0.5279503, 0.7329193
#> $ unbiased_percent_iqr_coverage.0.025           <dbl> 0.2360248, 0.2981366
#> $ unbiased_percent_iqr_coverage.0.25            <dbl> 0.2857143, 0.3478261
#> $ unbiased_percent_iqr_coverage.0.5             <dbl> 0.3105590, 0.3726708
#> $ unbiased_percent_iqr_coverage.0.75            <dbl> 0.3354037, 0.3975155
#> $ unbiased_percent_iqr_coverage.0.975           <dbl> 0.3788820, 0.4409938
```
