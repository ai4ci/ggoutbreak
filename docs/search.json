[{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2022 ggoutbreak authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"/articles/covid-timeseries.html","id":"incidence-and-growth-rate-from-case-positive-counts","dir":"Articles","previous_headings":"","what":"Incidence and growth rate from case positive counts","title":"England COVID-19 cases","text":"method uses case positive count dataset bundled growth rates age stratified (age grouping class column). look age stratification different vignettes instance want aggregate England wide rate. purpose time_aggregate() performs simple summarisation. raw covid case count log1p scale total detected cases per day.  Major events timeseries can plotted axes. ’ve focussed first 2 years pandemic:  incidence model assumes case rates result Poisson process rate estimated time varying locally fitted polynomial degree defined deg parameter, using log link function, according methods Loader et al. (see utils::citation(\"locfit\")). fitting process local maximum likelihood estimation uses bandwidth defined account data points within window time point estimated. gradient fitted polynomial log scale, exponential growth rate. scale independent view rate growth epidemic. estimation methodology compared consensus estimates SPI-M-O UK government advisory group red, shifted forward time 21 days. SPI-M-O estimates made pandemic retrospective whereas ones can use information time point now may better represent timing changes.  state epidemic described incidence growth, phase plots allow us see different time points. case epidemic state 10 weeks leading Christmas 2021, 2022 2023:","code":"england_covid %>% dplyr::glimpse() ## Rows: 26,790 ## Columns: 5 ## Groups: class [19] ## $ date  <date> 2023-12-09, 2023-12-09, 2023-12-09, 2023-12-09, 2023-12-09, 202… ## $ class <fct> 00_04, 05_09, 10_14, 15_19, 20_24, 25_29, 30_34, 35_39, 40_44, 4… ## $ count <dbl> 24, 8, 8, 4, 21, 20, 29, 36, 41, 59, 53, 54, 56, 54, 67, 72, 56,… ## $ denom <dbl> 771, 771, 771, 771, 771, 771, 771, 771, 771, 771, 771, 771, 771,… ## $ time  <time_prd> 1409, 1409, 1409, 1409, 1409, 1409, 1409, 1409, 1409, 1409,… tmp = ggoutbreak::england_covid %>%   time_aggregate(count=sum(count)) fit = tmp %>%    poisson_locfit_model()   plot_incidence(fit,raw = tmp, colour=\"blue\",size=0.025)+   scale_y_log1p(n=7) plot_incidence(fit, raw = tmp,events = england_events, colour=\"blue\",size=0.025)+   scale_y_log1p(n=7) + ggplot2::coord_cartesian(xlim=as.Date(c(\"2020-01-01\",\"2022-01-01\"))) plot_growth_rate(fit,events = england_events, colour=\"blue\")+   ggplot2::coord_cartesian(xlim=as.Date(c(\"2020-01-01\",\"2022-01-01\")), ylim=c(-0.15,0.15))+   ggplot2::geom_errorbar(data=england_consensus_growth_rate,ggplot2::aes(x=date-21,ymin=low,ymax=high),colour=\"red\") ## Coordinate system already present. Adding new coordinate system, which will ## replace the existing one. plot_growth_phase(fit,     timepoints = as.Date(c(\"Xmas 2020\"=\"2020-12-25\",\"Xmas 2021\"=\"2021-12-25\",\"Xmas 2022\"=\"2022-12-25\")),     duration = 70,      interval = 7,     colour=\"blue\" )"},{"path":"/articles/covid-timeseries.html","id":"reproduction-number-estimation-from-growth-rates","dir":"Articles","previous_headings":"","what":"Reproduction number estimation from growth rates","title":"England COVID-19 cases","text":"growth rate unit “per day” example. can derive reproduction number. Using methods Wallinga Lipsitch estimate infectivity profile COVID-19. describes probability infectee infected x days infector, includes temporal dimension rendering reproduction number dimensionless quantity reflecting average number infectees resulting infector. ggoutbreak estimate infectivity profile based meta-analysis serial interval estimates COVID-19. infectivity profile bootstrapped set discrete probability distributions. truncated 14 days.  growth rate estimate methods uses 1000 bootstraps propagate uncertainty hence somewhat slow. use memoise cache result. effective \\(R_t\\) estimates compared consensus values SPI-M-O group (red):  EpiEstim \\(R_t\\) fits comparison data, infectivity profile much certain exhibit oscillation due weekly periodicity underlying time series.","code":"ggplot2::ggplot()+   ggplot2::geom_errorbar(     data = ggoutbreak::covid_infectivity_profile %>% tidyr::complete(time=0:max(time), fill = list(probability=0)),     mapping = ggplot2::aes(x=as.factor(time),ymin=probability,ymax=probability),     width=1,     colour=\"blue\",     alpha=0.1   )+   ggplot2::geom_line(     data = ggoutbreak::covid_infectivity_profile %>%        dplyr::group_by(time) %>%       dplyr::summarise(m = mean(probability)) %>%        dplyr::ungroup(),     mapping = ggplot2::aes(x=as.factor(time),y=m, group=1),     inherit.aes = FALSE   ) # .cache = memoise::cache_filesystem(rappdirs::user_cache_dir(\"ggoutbreak\")) #  # cached_rt_from_growth_rate = memoise::memoise( #   ggoutbreak::rt_from_growth_rate, #   cache = .cache # )  rt_fit = fit %>% ggoutbreak::rt_from_growth_rate(ip = covid_infectivity_profile)  plot_rt(rt_fit, events = england_events, colour=\"blue\")+   ggplot2::coord_cartesian(xlim=as.Date(c(\"2020-01-01\",\"2022-01-01\")), ylim=c(0.6,1.6))+   ggplot2::geom_errorbar(data=england_consensus_rt,ggplot2::aes(x=date-21,ymin=low,ymax=high),colour=\"red\") ## Coordinate system already present. Adding new coordinate system, which will ## replace the existing one. rt_epi_fit = tmp %>% ggoutbreak::rt_epiestim(ip = covid_infectivity_profile)  plot_rt(rt_epi_fit, events = england_events, colour=\"blue\")+   ggplot2::coord_cartesian(xlim=as.Date(c(\"2020-01-01\",\"2022-01-01\")), ylim=c(0.6,1.6))+   ggplot2::geom_errorbar(data=england_consensus_rt,ggplot2::aes(x=date-7,ymin=low,ymax=high),colour=\"red\") ## Coordinate system already present. Adding new coordinate system, which will ## replace the existing one."},{"path":"/articles/covid-timeseries.html","id":"prevalence-and-growth-rate-from-test-positivity-rates","dir":"Articles","previous_headings":"","what":"Prevalence and growth rate from test positivity rates","title":"England COVID-19 cases","text":"Test availability consistent pandemic. early stages PCR tests difficult obtain case positive incidence estimates thought vast underestimate. certain parts pandemic targeted testing high risk groups occurred. Test positivity different view pandemic accounts biases introduces others . data must contain denom column case represents number tests conducted:  case gradient proportion logistic scale estimate growth rate. senses relative growth testing effort case produces answer similar incidence model.  similar growth rate estimates method can also theoretically used calculate estimates \\(R_t\\). Growth-proportion phase diagrams can also compare different points times see elsewhere, different populations.","code":"england_covid_pcr_positivity %>% dplyr::glimpse() ## Rows: 1,413 ## Columns: 4 ## $ date  <date> 2023-12-12, 2023-12-11, 2023-12-10, 2023-12-09, 2023-12-08, 202… ## $ time  <time_prd> 1444, 1443, 1442, 1441, 1440, 1439, 1438, 1437, 1436, 1435,… ## $ count <dbl> 375, 509, 381, 350, 445, 399, 430, 457, 413, 295, 252, 293, 343,… ## $ denom <dbl> 1707, 5884, 5514, 6001, 7840, 8333, 8946, 10139, 9805, 6445, 638… fit2 = england_covid_pcr_positivity %>%    ggoutbreak::proportion_locfit_model()  plot_proportion(fit2, england_covid_pcr_positivity, events = england_events, size=0.25, colour=\"blue\")+   ggplot2::coord_cartesian(xlim=as.Date(c(\"2020-01-01\",\"2022-01-01\"))) plot_growth_rate(fit2, events = england_events, colour=\"blue\")+   ggplot2::coord_cartesian(xlim=as.Date(c(\"2020-01-01\",\"2022-01-01\")), ylim=c(-0.15,0.15))+   ggplot2::geom_errorbar(data=england_consensus_growth_rate,ggplot2::aes(x=date-21,ymin=low,ymax=high),colour=\"red\") ## Coordinate system already present. Adding new coordinate system, which will ## replace the existing one. plot_growth_phase(fit2,     timepoints = as.Date(c(\"Xmas 2020\"=\"2020-12-25\",\"Xmas 2021\"=\"2021-12-25\",\"Xmas 2022\"=\"2022-12-25\")),     duration = 70,      interval = 7,     colour=\"blue\" )"},{"path":"/articles/covid-timeseries.html","id":"nhs-covid-app","dir":"Articles","previous_headings":"","what":"NHS COVID app","title":"England COVID-19 cases","text":"NHS COVID-19 app performed digital contact tracing. rate venue check-ins demonstrates levels high risk social contacts however became optional Aug 2021. Self isolation alerts peaked Aug / Sept 2021 Delta wave Dec 2021 / Jan 2022 Omicron wave. Periods rapid growth precede increases NHS app notifications. (N.B. data https://www.gov.uk/government/publications/nhs-covid-19-app-statistics)","code":"p1 = plot_incidence(fit,events = england_events, colour=\"blue\", date_breaks=\"3 months\")+   ggplot2::coord_cartesian(xlim=as.Date(c(\"2020-01-01\",\"2023-07-01\")))+   ggplot2::facet_wrap(~\"Cases\")+   ggplot2::theme(axis.text.x.bottom = ggplot2::element_blank())+   scale_y_log1p()  p2 = plot_growth_rate(fit,events = england_events, colour=\"blue\", date_breaks=\"3 months\")+   ggplot2::coord_cartesian(xlim=as.Date(c(\"2020-01-01\",\"2023-07-01\")), ylim=c(-0.15,0.15))+   ggplot2::geom_errorbar(data=england_consensus_growth_rate,ggplot2::aes(x=date-21,ymin=low,ymax=high),colour=\"red\")+   ggplot2::facet_wrap(~\"Growth rate\")+   ggplot2::theme(axis.text.x.bottom = ggplot2::element_blank(),axis.text.x.top = ggplot2::element_blank()) ## Coordinate system already present. Adding new coordinate system, which will ## replace the existing one. p3 = ggplot2::ggplot(ggoutbreak::england_nhs_app)+   geom_events(events=england_events,hide_labels = TRUE)+   ggplot2::geom_step(ggplot2::aes(x=date, y=alerts/mean(alerts, na.rm=TRUE),colour=\"alerts\"))+   ggplot2::geom_step(ggplot2::aes(x=date, y=visits/mean(visits, na.rm=TRUE),colour=\"venue visits\"))+   ggplot2::geom_rect(ggplot2::aes(xmin=date,xmax=dplyr::lead(date), ymin=0, ymax=alerts/mean(alerts, na.rm=TRUE),fill=\"alerts\"), linewidth=0, alpha=0.2)+   ggplot2::geom_rect(ggplot2::aes(xmin=date,xmax=dplyr::lead(date), ymin=0, ymax=visits/mean(visits, na.rm=TRUE),fill=\"venue visits\"), linewidth=0, alpha=0.2)+   ggplot2::coord_cartesian(xlim=as.Date(c(\"2020-01-01\",\"2023-07-01\")))+   ggplot2::ylab(\"relative frequency\")+   ggplot2::xlab(NULL)+   ggplot2::facet_wrap(~\"NHS app\")+   ggplot2::scale_color_brewer(palette=\"Dark2\", name=NULL, aesthetics = c(\"fill\",\"colour\"))+   ggplot2::scale_x_date(date_breaks=\"3 months\",date_labels = \"%b %y\")+   ggplot2::theme(legend.position = \"bottom\")  p1+p2+p3+patchwork::plot_layout(ncol=1) ## Warning: Removed 63 rows containing missing values or values outside the scale range ## (`geom_step()`). ## Warning: Removed 1 row containing missing values or values outside the scale range ## (`geom_rect()`). ## Warning: Removed 63 rows containing missing values or values outside the scale range ## (`geom_rect()`)."},{"path":[]},{"path":"/articles/estimators-example.html","id":"simple-incidence-test-with-a-poisson-model","dir":"Articles","previous_headings":"Locfit models","what":"Simple incidence test with a poisson model","title":"Simulation tests for growth rate estimators","text":"incidence mode based absolute counts:  Estimated absolute growth rate versus simulation (red)","code":"data = .test_poisson_model() data %>% dplyr::glimpse() #> Rows: 105 #> Columns: 5 #> $ time  <time_prd> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1… #> $ r     <dbl> 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,… #> $ rate  <dbl> 110.5171, 122.1403, 134.9859, 149.1825, 164.8721, 182.2119, 201.… #> $ count <int> 109, 117, 134, 153, 163, 167, 205, 233, 250, 297, 315, 302, 357,… #> $ denom <dbl> 2502, 2502, 2502, 2502, 2502, 2502, 2502, 2502, 2502, 2502, 2502… tmp = data %>% poisson_locfit_model(window=7, deg = 2)  plot_incidence(tmp, data)+ggplot2::geom_line(   mapping=ggplot2::aes(x=as.Date(time),y=rate), data=data, colour=\"red\",inherit.aes = FALSE) plot_growth_rate(tmp)+   ggplot2::geom_line(mapping=ggplot2::aes(x=as.Date(time),y=r), data=data, colour=\"red\",inherit.aes = FALSE) plot_growth_phase(tmp) #> Warning in .time_labels(x, ..., dfmt = dfmt, ifmt = ifmt, na.value = na.value): #> labelling applied to non-integer times."},{"path":"/articles/estimators-example.html","id":"multinomial-data","dir":"Articles","previous_headings":"Locfit models","what":"Multinomial data","title":"Simulation tests for growth rate estimators","text":"Multiple classes simulated 3 independent epdiemics (‘variant1’, ‘variant2’ ‘variant3’) known growth rates initial sample size resulting 3 parallel time series. combined give overall epidemic proportional distribution ‘variant’ fraction whole. relative growth rate calculated based set parameters.","code":"data2 = .test_multinomial() %>% dplyr::group_by(class) %>% dplyr::glimpse() #> Rows: 315 #> Columns: 9 #> Groups: class [3] #> $ time           <time_prd> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, … #> $ r              <dbl> 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, … #> $ rate           <dbl> 110.5171, 122.1403, 134.9859, 149.1825, 164.8721, 182.2… #> $ count          <int> 99, 129, 128, 144, 178, 186, 202, 215, 262, 250, 282, 3… #> $ denom          <dbl> 2344, 2344, 2344, 2344, 2344, 2344, 2344, 2344, 2344, 2… #> $ class          <chr> \"variant1\", \"variant1\", \"variant1\", \"variant1\", \"varian… #> $ proportion     <dbl> 0.3382826, 0.3420088, 0.3445125, 0.3458146, 0.3459542, … #> $ proportion.obs <dbl> 0.3378840, 0.3421751, 0.3450135, 0.3453237, 0.3456311, … #> $ relative.r     <dbl> 0.019385523, 0.013833622, 0.008404115, 0.003151554, -0.…"},{"path":"/articles/estimators-example.html","id":"poisson-model","dir":"Articles","previous_headings":"Locfit models > Multinomial data","what":"Poisson model","title":"Simulation tests for growth rate estimators","text":"Firstly fitting incidence model groupwise fashion:  absolute growth rates:","code":"tmp2 = data2 %>% poisson_locfit_model(window=7, deg = 1)  plot_incidence(tmp2, data2)+scale_y_log1p() plot_growth_rate(modelled = tmp2)+    ggplot2::geom_line(mapping=ggplot2::aes(x=as.Date(time),y=r, colour=class), data=data2, inherit.aes = FALSE)+    ggplot2::facet_wrap(dplyr::vars(class), ncol=1)"},{"path":"/articles/estimators-example.html","id":"one-versus-others-binomial-model","dir":"Articles","previous_headings":"Locfit models > Multinomial data","what":"One versus others Binomial model","title":"Simulation tests for growth rate estimators","text":"looks proportions three variants growth rate relative : Firstly proportions:  secondly relative growth rate:","code":"# This will reinterpret total to be the total of positives across all variants data3 = data2 %>%    dplyr::group_by(time) %>%    dplyr::mutate(denom = sum(count)) %>%   dplyr::group_by(class) %>%   dplyr::glimpse() #> Rows: 315 #> Columns: 9 #> Groups: class [3] #> $ time           <time_prd> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, … #> $ r              <dbl> 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, … #> $ rate           <dbl> 110.5171, 122.1403, 134.9859, 149.1825, 164.8721, 182.2… #> $ count          <int> 99, 129, 128, 144, 178, 186, 202, 215, 262, 250, 282, 3… #> $ denom          <int> 293, 377, 371, 417, 515, 538, 588, 633, 778, 756, 868, … #> $ class          <chr> \"variant1\", \"variant1\", \"variant1\", \"variant1\", \"varian… #> $ proportion     <dbl> 0.3382826, 0.3420088, 0.3445125, 0.3458146, 0.3459542, … #> $ proportion.obs <dbl> 0.3378840, 0.3421751, 0.3450135, 0.3453237, 0.3456311, … #> $ relative.r     <dbl> 0.019385523, 0.013833622, 0.008404115, 0.003151554, -0.… tmp3 = data3 %>% proportion_locfit_model(window=14, deg = 2)  plot_proportion(modelled = tmp3,raw = data3)+   ggplot2::facet_wrap(dplyr::vars(class), ncol=1) plot_growth_rate(modelled = tmp3)+    ggplot2::geom_line(mapping=ggplot2::aes(x=as.Date(time),y=relative.r, colour=class), data=data2, inherit.aes = FALSE)+    ggplot2::facet_wrap(dplyr::vars(class), ncol=1) plot_growth_phase(tmp3) #> Warning in .time_labels(x, ..., dfmt = dfmt, ifmt = ifmt, na.value = na.value): #> labelling applied to non-integer times."},{"path":"/articles/estimators-example.html","id":"multinomial-model","dir":"Articles","previous_headings":"Locfit models > Multinomial data","what":"Multinomial model","title":"Simulation tests for growth rate estimators","text":"multinomial model gives us absolute proportions (growth rates)","code":"# we don't need to calculate the denominator as it is done automatically by the  # multinomial model  tmp4 = data2 %>% multinomial_nnet_model() #> # weights:  30 (18 variable) #> initial  value 362008.129688  #> iter  10 value 182565.876936 #> iter  20 value 179596.437266 #> final  value 177261.175074  #> converged plot_multinomial(tmp4) # plot_multinomial(tmp3, events = event_test,normalise = TRUE)"},{"path":[]},{"path":"/articles/estimators-example.html","id":"poisson-model-1","dir":"Articles","previous_headings":"GLM models","what":"Poisson model","title":"Simulation tests for growth rate estimators","text":"Spline currently good incidence","code":"tmp5 = data %>% poisson_glm_model(window=7) plot_incidence(tmp5,data)"},{"path":"/articles/estimators-example.html","id":"binomial-model","dir":"Articles","previous_headings":"GLM models","what":"Binomial model","title":"Simulation tests for growth rate estimators","text":"Absolute proportions ","code":"tmp6 = data3 %>% proportion_glm_model(window=14, deg = 2) plot_proportion(tmp6,data3)"},{"path":"/articles/incidence-trends.html","id":"incidence-poisson-rate-model","dir":"Articles","previous_headings":"","what":"Incidence Poisson rate model","title":"Population comparisons and incidence","text":"plot normalised incidence rates COVID-19 population size, shows initially rate COVID cases highest elderly. late 2020 pattern changed rates uniform accross age groups. early 2021 vaccination took hold school testing rolled , younger age groups higher rates COVID positive tests, curious spike young age groups around November 2021. early 2022 pattern reversed elderly became age group highest rates, pattern persisted present.  use test positives proxy COVID incidence clearlly potentially biased testing (partilcularly first wave testing limited hospital). reliable comparison situation test positivie proportion, unfortunately testing rates published broken age. exponential growth rate already normalised population size. Comparisons growth rate populations gives idea tightly coupled . age groups epidemic growing shrinking sync apart possibly young. COVID detections age group particularly reliable though easy -interpret.  combination growth normalised incidence allows us compare epidemic state different time points, case Christmas day 2020, 2021 2022. shows data previous graphs.","code":"tmp = ggoutbreak::england_covid %>%    ggoutbreak::poisson_locfit_model(window=21) %>%    ggoutbreak::normalise_incidence(ggoutbreak::england_demographics)  raw_pop = ggoutbreak::england_covid %>% dplyr::inner_join(england_demographics, by=\"class\")  plot_incidence(tmp,raw = raw_pop, size=0.25)+scale_y_log1p(n=7)+   ggplot2::scale_colour_viridis_d(aesthetics = c(\"fill\",\"colour\")) plot_growth_rate(tmp)+   ggplot2::scale_fill_viridis_d(aesthetics = c(\"fill\",\"colour\"))+   ggplot2::coord_cartesian(ylim=c(-0.15,0.15)) #> Coordinate system already present. Adding new coordinate system, which will #> replace the existing one. plot_growth_phase(tmp,     timepoints = as.Date(c(\"Xmas 2020\"=\"2020-12-25\",\"Xmas 2021\"=\"2021-12-25\",\"Xmas 2022\"=\"2022-12-25\")),     duration = 70,      interval = 7 )+   ggplot2::scale_colour_viridis_d()"},{"path":"/articles/incidence-trends.html","id":"proportion-model","dir":"Articles","previous_headings":"","what":"Proportion model","title":"Population comparisons and incidence","text":"two possible proportions models woudl interest . mentioned proportion positive tests age group give us clearer picture whether differences age groups differential testing, unfortunately available data set. second potential use distribution ages test positive age group. age distribution gives us information burden disease population also biased test prioritisation. multinomial proportion shows similar patterns normalised incidence plot :  age distribution test positives can normalised age distribution population. give us relative proportion age groups people testing positive versus expected population. conceptually relative risk age group given COVID status .e. \\(\\frac{P(age = 80+|COVID+)}{P(age = 80+)}\\) point time given population quantity centred around 1 comparing growth rate gives us possibly clearer picture trajectory relative distribution COVID population. Xmas 2021 although majority cases young, relatively high growth elderly population meant catching , can see early 2022 elderly highest COVID positive rates. 2022 however, separation age groups established trajectories acting preserve separation.","code":"tmp2 = ggoutbreak::england_covid %>%    ggoutbreak::proportion_locfit_model(window=21)  p1 = plot_multinomial(tmp2,normalise = TRUE)+   ggplot2::scale_fill_viridis_d()  p2 = ggplot2::ggplot(england_demographics)+   ggplot2::geom_bar(ggplot2::aes(x=\"baseline\",y=population/sum(population)*100,fill=class), stat=\"identity\", position=\"stack\", colour=\"black\", linewidth=0.1)+   ggplot2::scale_fill_viridis_d(guide=\"none\")+   ggplot2::xlab(NULL)+   ggplot2::ylab(NULL)+   ggplot2::theme(axis.text.y = ggplot2::element_blank())+   ggplot2::coord_cartesian(expand=FALSE)  p1+p2+patchwork::plot_layout(nrow=1,widths = c(20,1),guides = \"collect\") tmp3 = tmp2 %>% normalise_proportion(england_demographics)  plot_growth_phase(tmp3,     timepoints = as.Date(c(\"Xmas 2020\"=\"2020-12-25\",\"Xmas 2021\"=\"2021-12-25\",\"Xmas 2022\"=\"2022-12-25\")),     duration = 70,      interval = 7 )+   ggplot2::scale_colour_viridis_d() #> Coordinate system already present. Adding new coordinate system, which will #> replace the existing one."},{"path":"/articles/incidence-trends.html","id":"todo","dir":"Articles","previous_headings":"","what":"TODO:","title":"Population comparisons and incidence","text":"Regional breakdown testing effort positivity age group published part test trace. -age -region breakdown, shut test trace. https://www.gov.uk/government/publications/weekly-statistics--nhs-test--trace-england-2--15-june-2022 look age group proportion incidence models look ascertainment bias age groups.","code":"prop = ggoutbreak::england_covid_proportion %>%   ggoutbreak::proportion_locfit_model(window=5)  plot_proportion(prop)+ggplot2::scale_fill_viridis_d(aesthetics = c(\"colour\",\"fill\")) tmp_pop = ggoutbreak::england_covid_proportion %>% dplyr::select(class,population) %>% dplyr::distinct() pois = ggoutbreak::england_covid_proportion %>%   ggoutbreak::poisson_locfit_model(window=5) %>%   ggoutbreak::normalise_incidence(tmp_pop)  plot_incidence(pois)+ggplot2::scale_fill_viridis_d(aesthetics = c(\"colour\",\"fill\"))"},{"path":"/articles/incidence-trends.html","id":"pre-test-probability","dir":"Articles","previous_headings":"TODO:","what":"Pre test probability","title":"Population comparisons and incidence","text":"Using covid infection survey can look population prevalence based random sampling versus estimates incidence based test positivity. relationship pre test probability testing, although need sort accounting fact one incidence prevalence. Likewise test positives per head population can compared prevalence. case ratio connection ascertainment rate although infectivity profile needs taken account (accurately probability test positive given sample taken specific day post infection patient infected), prevalence number represents people infectious given day, test positives closer incidence.","code":"p1 = ggoutbreak::plot_proportion(   ggoutbreak::england_ons_infection_survey %>%      dplyr::filter(geography == \"England\") %>%     dplyr::mutate(       proportion.fit = NA, proportion.se.fit=NA,   ),events = ggoutbreak::england_events)+   ggplot2::theme(     axis.title.x = ggplot2::element_blank(),      axis.text.x = ggplot2::element_blank(),      axis.text.x.bottom = ggplot2::element_blank()   )   p2 = ggoutbreak::england_covid_pcr_positivity %>%   proportion_locfit_model() %>%   dplyr::inner_join(ggoutbreak::england_ons_infection_survey %>%                        dplyr::filter(geography==\"England\") %>%                        dplyr::rename_with(.cols = starts_with(\"proportion\"), .fn = ~stringr::str_replace(.x,\"proportion\",\"ons\")), by=c(\"time\")   ) %>%   dplyr::transmute(date=date, pre_test_odds = proportion.0.5 / ons.0.5) %>%   ggplot2::ggplot(ggplot2::aes(x=date,y=pre_test_odds)) + ggplot2::geom_line() +   ggplot2::geom_hline(yintercept=1, colour=\"grey40\",linetype=\"dashed\") +   ggplot2::ylab(\"Pre-test odds ratio COVID\") +   ggoutbreak::geom_events(events = ggoutbreak::england_events,hide_labels = TRUE)+   ggplot2::theme(     axis.title.x = ggplot2::element_blank(),      axis.text.x = ggplot2::element_blank(),      axis.text.x.bottom = ggplot2::element_blank(),      axis.text.x.top = ggplot2::element_blank()   ) england_pop = sum(ggoutbreak::england_demographics$population)  p3 = ggoutbreak::england_covid_pcr_positivity %>%    dplyr::select(-denom) %>%    dplyr::mutate(denom = england_pop) %>%   proportion_locfit_model() %>%   dplyr::inner_join(england_ons_infection_survey %>%                        dplyr::filter(geography==\"England\") %>%                        dplyr::rename_with(.cols = starts_with(\"proportion\"), .fn = ~stringr::str_replace(.x,\"proportion\",\"ons\")), by=c(\"time\")   ) %>%   dplyr::transmute(date=date, ascertainment = proportion.0.5 / ons.0.5 * 100) %>%   ggplot2::ggplot(ggplot2::aes(x=date,y=ascertainment)) +    ggplot2::geom_line() +    ggplot2::ylab(\"Ascertainment rate (%)\") +   ggoutbreak::geom_events(events = ggoutbreak::england_events,hide_labels = TRUE)   p1+p2+p3+patchwork::plot_layout(ncol=1)"},{"path":"/articles/rt-from-incidence.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Estimating the reproduction number from modelled incidence","text":"estimated incidence disease \\(I_t\\) using poisson rate using maximum likelihood estimators, rate typically log-normally distributed parameters \\(\\mu\\) \\(\\sigma\\). fitted model shown log1p scale, COVID-19 epidemic England:  appealing use modelled incidence estimate calculate estimate reproduction number, \\(R_t\\). Incidence models can derived number ways, easily inspected error can made tolerant missing values outliers.","code":""},{"path":"/articles/rt-from-incidence.html","id":"methods","dir":"Articles","previous_headings":"","what":"Methods","title":"Estimating the reproduction number from modelled incidence","text":"use modelled estimate incidence predict \\(R_t\\) need propagate uncertainty incidence \\(R_t\\) estimates. calculate \\(R_t\\) can use backwards-looking renewal equations incorporate infectivity profile disease (\\(\\omega\\)) number days infection (\\(\\tau\\)): \\[ I_t \\sim Lognormal(\\mu_t,\\sigma_t) \\\\ R_t = \\frac{I_t}{\\sum_{\\tau}{\\omega_{\\tau}I_{t-\\tau}}} \\] giving us: \\[ R_t = \\frac{Lognormal(\\mu_t,\\sigma_t)}{\\sum_{\\tau}{   Lognormal( \\mu_{t-\\tau} + log(\\omega_{\\tau}) , \\sigma_{t-\\tau}) }} \\\\ \\] sum \\(\\) log normal distributions can approximated another log normal (Lo 2013) parameters \\(\\mu_Z\\) \\(\\sigma_Z\\). \\[ \\begin{align}     S_+ &= \\operatorname{E}\\left[\\sum_i X_i \\right] = \\sum_i     \\operatorname{E}[X_i] =     \\sum_i e^{\\mu_i + \\frac{1}{2}\\sigma_i^2}     \\\\     \\sigma^2_{Z} &= \\frac{1}{S_+^2} \\, \\sum_{,j}       \\operatorname{cor}_{ij} \\sigma_i \\sigma_j \\operatorname{E}[X_i] \\operatorname{E}[X_j] =       \\frac{1}{S_+^2} \\, \\sum_{,j}       \\operatorname{cor}_{ij} \\sigma_i \\sigma_j e^{\\mu_i+\\frac{1}{2}\\sigma_i^2}       e^{\\mu_j+\\frac{1}{2}\\sigma_j^2}     \\\\     \\mu_Z &= \\ln\\left( S_+ \\right) - \\frac{1}{2}\\sigma_{Z}^2 \\end{align} \\] sum term denominator renewal equations consists set correlated scaled log normal distributions scale correlation defined infectivity profile (\\(\\omega\\)). case \\(cor_{ij}\\) can equated infectivity profile (\\(\\omega_{|-j|}\\)) \\(\\neq j\\) 1 \\(= j\\). \\(\\mu_i\\) \\(\\mu_{t-\\tau} + ln(\\omega_{\\tau})\\). \\[ \\begin{align}     S_{t} &= \\sum_{s=1}^{|\\omega|} { \\omega_s e^{\\mu_{t-s} + \\frac{1}{2}\\sigma_{t-s}^2 }} \\\\     \\sigma_{Z,t} &= \\sqrt{       \\frac{         \\sum_{,j=1}^{|\\omega|} {         (\\omega_{|-j|}+(,j)) \\omega_i \\omega_j (\\sigma_{(t-)} e^{\\mu_{(t-)}+\\frac{1}{2}\\sigma_{(t-)}^2}) (\\sigma_{(t-j)} e^{\\mu_{(t-j)}+\\frac{1}{2}\\sigma_{(t-j)}^2})         }       }{S_{t}^2}     }   \\\\     \\mu_{Z,t} &= \\log\\left( S_{t} \\right) - \\frac{1}{2}\\sigma_{Z,t}^2 \\end{align} \\] \\(\\mu\\) central estimate case counts log scale, standard deviation can also large. numerical stability issues dealing terms involving \\(e^{(\\mu+\\sigma^2)}\\), however keeping everything log space using optimised log-sum-exp functions can made computationally tractable. \\[ \\begin{align}     \\log(S_{t}) &= \\log(\\sum_{s=1}^{|\\omega|} {  e^{\\mu_{t-s} + \\frac{1}{2}\\sigma_{t-s}^2 + \\log(\\omega_s) }}) \\\\     \\log(T_{t,\\tau}) &= \\log(\\omega_{\\tau}) + \\log(\\sigma_{(t-{\\tau})}) + \\mu_{(t-{\\tau})} + \\frac{1}{2}\\sigma_{(t-{\\tau})}^2) \\\\     \\log(cor_{,j}) &= \\log(\\omega_{|-j|}+(=j)) \\\\     \\log(\\sigma_{Z,t}^2) &= \\log(         \\sum_{,j=1}^{|\\omega|} {           e^{             \\log(cor_{,j}) + \\log(T_{t,}) + \\log(T_{t,j})           }         }) - 2 \\log(S_{t}) \\\\     \\mu_{Z,t} &= \\log( S_{t} ) - \\frac{1}{2}\\sigma_{Z,t}^2 \\end{align} \\] N.B. assume individual estimates incidence uncorrelated simplifies : \\[ \\begin{align} \\log(\\sigma_{Z,t}^2) &= \\log(         \\sum_{\\tau=1}^{|\\omega|} {           e^{             2 \\log(T_{t,\\tau})           }         }) - 2 \\log(S_{t}) \\end{align} \\] Empirically huge amount difference estimates two forms. infectivity profile \\(\\omega\\) spread large period correlation matrix \\(O(\\omega)^2\\) may predicate simpler order 1 formulation. \\(\\mu_{Z,t}\\) \\(\\sigma_{Z,t}\\) left final derivation \\(R_t\\), giving us distributional form \\(R_t\\) incorporating uncertainty modelled incidence estimates: \\[ \\begin{align} R_t &= \\frac{Lognormal(\\mu_t,\\sigma_t)} {Lognormal( \\mu_{Z,t}, \\sigma_{Z,t})} \\\\ \\mu_{R_t} &= \\mu_t - \\mu_{Z,t} \\\\ \\sigma_{R_t} &= \\sqrt{\\sigma_t^2+\\sigma_{z,t}^2} \\\\ R_t &= Lognormal(\\mu_{R_t}, \\sigma_{R_t}) \\end{align} \\] conditioned single known infectivity profile. reality also uncertainty infectivity profile, however assume particular distributional form . can use range empirical estimates infectivity profile calculate multiple distributional estimates \\(R_t\\) combine mixture distribution numerically. avoid computation involved however reasonable approximation mixture log normal mean variance mixture, likely individual \\(R_t\\) estimates similar. moment matching done using mean variance \\(R_t\\) distributions log transformed distribution parameters, \\(\\mu\\) \\(\\sigma\\): \\[ \\begin{align} E[R_t] &= e^{(\\mu_{R_t} - \\frac{1}{2}\\sigma_{R_t}^2)} \\\\ V[R_t] &= \\big[   e^{(\\sigma_{R_t}^2)} - 1 \\big] \\big[   e^{2 \\mu_{R_t} + \\sigma_{R_t}^2} \\big] \\\\ E[R_t^*] &= \\frac{1}{|\\Omega|}\\sum_{\\omega \\\\Omega} E[{R_t|\\omega}] \\\\ V[R_t^*] &= \\frac{1}{|\\Omega|} \\bigg(\\sum_{\\omega \\\\Omega}{V[R_t|\\omega]+E[R_t|\\omega]^2}\\bigg) - E[R_t^*]^2 \\\\ \\mu^* &= \\log\\Bigg(\\frac{E[R_t^*]}{\\sqrt{\\frac{V[R_t^*]}{E[R_t^*]^2}+1}}\\Bigg)  \\\\ \\sigma_*^2 &= \\log\\bigg(\\frac{V[R_t^*]}{E[R_t^*]^2}+1\\bigg)\\\\ R_t^* &= Lognormal(\\mu_*,\\sigma_*) \\end{align} \\]","code":""},{"path":"/articles/rt-from-incidence.html","id":"implementation","dir":"Articles","previous_headings":"","what":"Implementation","title":"Estimating the reproduction number from modelled incidence","text":"method implemented using following R function, designed numerical stability speed. Generating \\(R_t\\) estimates given modelled incidence typically occurring :","code":"#> function (mu, sigma, omega, mu_t, sigma_t, cor = TRUE)  #> { #>     omega_m = as.matrix(omega) #>     omega_m = apply(omega_m, MARGIN = 2, rev) #>     tmp = apply(omega_m, MARGIN = 2, function(omega) { #>         log_S_t = .logsumexp(mu_t + sigma_t^2/2 + log(omega)) #>         log_T_t_tau = mu_t + sigma_t^2/2 + log(omega) + log(sigma_t) #>         if (cor) { #>             n = length(omega) #>             idx = 0:(n^2 - 1) #>             i = idx%/%n #>             j = idx%%n #>             log_cor_ij = c(0, log(omega))[abs(i - j) + 1] #>             log_var_Zt_ij = log_cor_ij + log_T_t_tau[i + 1] +  #>                 log_T_t_tau[j + 1] #>         } #>         else { #>             log_var_Zt_ij = 2 * log_T_t_tau #>         } #>         log_var_Zt = .logsumexp(log_var_Zt_ij) - 2 * log_S_t #>         var_Zt = exp(log_var_Zt) #>         mu_Zt = log_S_t - var_Zt/2 #>         return(c(mu_Rt = mu - mu_Zt, var_Rt = sigma^2 + var_Zt)) #>     }) #>     if (ncol(tmp) == 1) { #>         mu_star = tmp[1] #>         sigma2_star = tmp[2] #>         mean_star = exp(mu_star + sigma2_star/2) #>         var_star = (exp(sigma2_star) - 1) * exp(2 * mu_star +  #>             sigma2_star) #>     } #>     else { #>         means = exp(tmp[1, ] + tmp[2, ]/2) #>         vars = (exp(tmp[2, ]) - 1) * exp(2 * tmp[1, ] + tmp[2,  #>             ]) #>         mean_star = mean(means) #>         var_star = mean(vars + means^2) - mean_star^2 #>         mu_star = log(mean_star/sqrt((var_star/mean_star^2) +  #>             1)) #>         sigma2_star = log((var_star/mean_star^2) + 1) #>     } #>     sigma_star = sqrt(sigma2_star) #>     return(tibble::tibble(rt.mu = mu_star, rt.sigma = sigma_star,  #>         rt.fit = mean_star, rt.se.fit = sqrt(var_star), rt.0.025 = stats::qlnorm(0.025,  #>             mu_star, sigma_star), rt.0.5 = stats::qlnorm(0.5,  #>             mu_star, sigma_star), rt.0.975 = stats::qlnorm(0.975,  #>             mu_star, sigma_star))) #> } #> <bytecode: 0x64bb506c3610> #> <environment: namespace:ggoutbreak>"},{"path":"/articles/rt-from-incidence.html","id":"results","dir":"Articles","previous_headings":"","what":"Results","title":"Estimating the reproduction number from modelled incidence","text":"Testing incidence model shown , comparing results SPI-M-O consensus \\(R_t\\) estimates gives us following time-series England. formally evaluated qualitatively good fit. single time series 1410 time points took around 3 seconds fit, opens possibility performing \\(R_t\\) estimates fine grained geographical demographic subgroups.","code":"#>    user  system elapsed  #>   2.772   0.002   2.774"},{"path":"/articles/rt-from-incidence.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Estimating the reproduction number from modelled incidence","text":"present methodology deriving \\(R_t\\) modelled estimates incidence propagating uncertainty. demonstrate produces satisfactory qualitative results COVID-19 data. method relatively quick, fully deterministic, can used top statistical models estimating incidence use logarithmic link functions.","code":""},{"path":"/articles/time-periods.html","id":"line-lists-vs--time-series","dir":"Articles","previous_headings":"","what":"Line lists vs. time series","title":"Data wrangling and working with `ggoutbreak`","text":"Infectious disease data usually either comes set observations individual infection time stamp (.e. line list) count events (e.g. positive tests, hospitalisations, deaths) happening within specific period (day, week, month etc.) time series. count data may also denominator known. testing number tests performed, number patients risk hospitalisation. data types may also class associated observation, defining subgroup infections interest. variant virus, age group, example. may make sense compare different subgroups . case denominator may total counts among groups per unit time. Additionally may information size population subgroup. ggoutbreak assumes part input data form set time series counts, unique set times, usually complete. create datasets like line lists ggoutbreak provides infrastructure dealing time series:","code":""},{"path":"/articles/time-periods.html","id":"time-periods","dir":"Articles","previous_headings":"","what":"Time periods","title":"Data wrangling and working with `ggoutbreak`","text":"weekly case rate represents time slice seven days start finish date. Dates continuous quantity, cut_dates() can used classify continuous dates periods equal duration, start date: Performing calculations using interval censored dates awkward. numeric version dates useful can keep track start date time series intrinsic duration, numeric. purpose time_period class: time_period defaults using date beginning COVID-19 pandemic origin calculating duration unit based data (case weekly). usual set S3 methods available formatting, printing, labelling, casting time_periods dates POSIXct classes: weekly time series can recast different frequency, start date: original dates recoverable: date_seq() can used make sure set periodic times complete: time_periods can used monthly yearly data data regular. handled irregular date periods generally OK use ggoutbreak functions like date_seq may work anticipated irregular dates. Two time series can aligned make comparable:","code":"random_dates = Sys.Date()+sample.int(21,50,replace = TRUE) cut_date( random_dates, unit = \"1 week\", anchor = \"start\", dfmt = \"%d %b\") #> 29 Aug — 04 Sep 29 Aug — 04 Sep 22 Aug — 28 Aug 22 Aug — 28 Aug 05 Sep — 11 Sep  #>    \"2024-08-29\"    \"2024-08-29\"    \"2024-08-22\"    \"2024-08-22\"    \"2024-09-05\"  #> 05 Sep — 11 Sep 22 Aug — 28 Aug 22 Aug — 28 Aug 29 Aug — 04 Sep 22 Aug — 28 Aug  #>    \"2024-09-05\"    \"2024-08-22\"    \"2024-08-22\"    \"2024-08-29\"    \"2024-08-22\"  #> 22 Aug — 28 Aug 05 Sep — 11 Sep 29 Aug — 04 Sep 22 Aug — 28 Aug 29 Aug — 04 Sep  #>    \"2024-08-22\"    \"2024-09-05\"    \"2024-08-29\"    \"2024-08-22\"    \"2024-08-29\"  #> 29 Aug — 04 Sep 22 Aug — 28 Aug 05 Sep — 11 Sep 29 Aug — 04 Sep 22 Aug — 28 Aug  #>    \"2024-08-29\"    \"2024-08-22\"    \"2024-09-05\"    \"2024-08-29\"    \"2024-08-22\"  #> 22 Aug — 28 Aug 22 Aug — 28 Aug 05 Sep — 11 Sep 22 Aug — 28 Aug 22 Aug — 28 Aug  #>    \"2024-08-22\"    \"2024-08-22\"    \"2024-09-05\"    \"2024-08-22\"    \"2024-08-22\"  #> 29 Aug — 04 Sep 22 Aug — 28 Aug 05 Sep — 11 Sep 22 Aug — 28 Aug 29 Aug — 04 Sep  #>    \"2024-08-29\"    \"2024-08-22\"    \"2024-09-05\"    \"2024-08-22\"    \"2024-08-29\"  #> 29 Aug — 04 Sep 05 Sep — 11 Sep 22 Aug — 28 Aug 05 Sep — 11 Sep 05 Sep — 11 Sep  #>    \"2024-08-29\"    \"2024-09-05\"    \"2024-08-22\"    \"2024-09-05\"    \"2024-09-05\"  #> 22 Aug — 28 Aug 22 Aug — 28 Aug 22 Aug — 28 Aug 05 Sep — 11 Sep 29 Aug — 04 Sep  #>    \"2024-08-22\"    \"2024-08-22\"    \"2024-08-22\"    \"2024-09-05\"    \"2024-08-29\"  #> 22 Aug — 28 Aug 05 Sep — 11 Sep 05 Sep — 11 Sep 22 Aug — 28 Aug 29 Aug — 04 Sep  #>    \"2024-08-22\"    \"2024-09-05\"    \"2024-09-05\"    \"2024-08-22\"    \"2024-08-29\"  #> 22 Aug — 28 Aug 29 Aug — 04 Sep 05 Sep — 11 Sep 05 Sep — 11 Sep 29 Aug — 04 Sep  #>    \"2024-08-22\"    \"2024-08-29\"    \"2024-09-05\"    \"2024-09-05\"    \"2024-08-29\" dates = seq(as.Date(\"2020-01-01\"),by=7,length.out = 5) tmp = as.time_period(dates) #> No `start_date` (or `anchor`) specified. Using default: 2019-12-29 #> No unit given. Guessing a sensible value from the dates gives: 7d 0H 0M 0S tmp #> time unit: week, origin: 2019-12-29 (a Sunday) #> [1] 0.4285714 1.4285714 2.4285714 3.4285714 4.4285714 suppressWarnings(labels(tmp)) #> 01/Jan — 07/Jan #> 08/Jan — 14/Jan #> 15/Jan — 21/Jan #> 22/Jan — 28/Jan #> 29/Jan — 04/Feb tmp2 = as.time_period(tmp, unit = \"2 days\", start_date = \"2020-01-01\") tmp2 #> time unit: 2 days, origin: 2020-01-01 (a Wednesday) #> [1]  0.0  3.5  7.0 10.5 14.0 as.Date(tmp2) #> [1] \"2020-01-01\" \"2020-01-08\" \"2020-01-15\" \"2020-01-22\" \"2020-01-29\" tmp3 = as.time_period(Sys.Date()+c(0:2,4:5)*7,anchor = \"start\") #> No unit given. Guessing a sensible value from the dates gives: 7d 0H 0M 0S as.Date(date_seq(tmp3)) #> [1] \"2024-08-21\" \"2024-08-28\" \"2024-09-04\" \"2024-09-11\" \"2024-09-18\" #> [6] \"2024-09-25\" orig_dates = Sys.Date()+1:10*7  # a 2 daily time series based on weekly dates t1 = as.time_period(orig_dates, unit = \"2 days\", start_date = \"2021-01-01\") t1 #> time unit: 2 days, origin: 2021-01-01 (a Friday) #>  [1] 667.5 671.0 674.5 678.0 681.5 685.0 688.5 692.0 695.5 699.0  # a weekly with different start date t2 = as.time_period(orig_dates, unit = \"1 week\", start_date = \"2022-01-01\") t2 #> time unit: week, origin: 2022-01-01 (a Saturday) #>  [1] 138.5714 139.5714 140.5714 141.5714 142.5714 143.5714 144.5714 145.5714 #>  [9] 146.5714 147.5714  # rebase t1 into the same format as t2 # as t1 and t2 based on the same original dates converting t2 onto the same # peridicty as t1 results in an identical set of times t3 = as.time_period(t1,t2) t3 #> time unit: week, origin: 2022-01-01 (a Saturday) #>  [1] 138.5714 139.5714 140.5714 141.5714 142.5714 143.5714 144.5714 145.5714 #>  [9] 146.5714 147.5714"},{"path":"/articles/time-periods.html","id":"times-in-ggoutbreak-and-conversion-of-line-lists","dir":"Articles","previous_headings":"","what":"Times in ggoutbreak and conversion of line-lists","title":"Data wrangling and working with `ggoutbreak`","text":"ggoutbreak uses time_period class internally extensively. Casting dates time_periods generally needs done using ggoutbreak. functions ggoutbreak operate time series data expect unique (usually complete) set data periodic time. help prepare line-list data time series time_summarise() function. minimal line-list date column nothing else. line-list contains class column interpreted complete record possible options can calculate denominator. case positive negative results test: specific example subsequent analysis ggoutbreak may focus positive subgroup , comparison positive negative test results trivial. another example class may test results, major subdivision e.g. variant disease. case comparison different groups may much relevant. use class major sub-group convenience. Additional grouping class columns also possible multi-facetted comparisons, grouping preserved included automatically denominator, may need manually calculated:","code":"random_dates = Sys.Date()+sample.int(21,50,replace = TRUE) linelist = tibble::tibble(date = random_dates) linelist %>% time_summarise(unit=\"1 week\") %>% dplyr::glimpse() #> Rows: 3 #> Columns: 2 #> $ time  <time_prd> 0, 1, 2 #> $ count <int> 27, 17, 6 random_dates = Sys.Date()+sample.int(21,200,replace = TRUE) linelist2 = tibble::tibble(   date = random_dates,   class = stats::rbinom(200, 1, 0.04) %>% ifelse(\"positive\",\"negative\") ) linelist2 %>% time_summarise(unit=\"1 week\") %>% dplyr::glimpse() #> Rows: 6 #> Columns: 4 #> Groups: class [2] #> $ class <chr> \"negative\", \"negative\", \"negative\", \"positive\", \"positive\", \"pos… #> $ time  <time_prd> 0, 1, 2, 0, 1, 2 #> $ count <int> 52, 66, 73, 4, 2, 3 #> $ denom <int> 56, 68, 76, 56, 68, 76 random_dates = Sys.Date()+sample.int(21,200,replace = TRUE) variant = apply(stats::rmultinom(200, 1, c(0.1,0.3,0.6)), MARGIN = 2, function(x) which(x==1))  linelist3 = tibble::tibble(   date = random_dates,   class = c(\"variant1\",\"variant2\",\"variant3\")[variant],   gender = ifelse(stats::rbinom(200,1,0.5),\"male\",\"female\") )    count_by_gender = linelist3 %>%    dplyr::group_by(gender) %>%    time_summarise(unit=\"1 week\") %>%    dplyr::arrange(time, gender, class) %>%   dplyr::glimpse() #> Rows: 18 #> Columns: 5 #> Groups: gender, class [6] #> $ gender <chr> \"female\", \"female\", \"female\", \"male\", \"male\", \"male\", \"female\",… #> $ class  <chr> \"variant1\", \"variant2\", \"variant3\", \"variant1\", \"variant2\", \"va… #> $ time   <time_prd> 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2 #> $ count  <int> 5, 12, 17, 2, 5, 26, 4, 8, 24, 1, 8, 25, 3, 10, 25, 7, 6, 12 #> $ denom  <int> 34, 34, 34, 33, 33, 33, 36, 36, 36, 34, 34, 34, 38, 38, 38…"},{"path":"/articles/time-periods.html","id":"aggregating-time-series-datasets-","dir":"Articles","previous_headings":"","what":"Aggregating time series datasets.","title":"Data wrangling and working with `ggoutbreak`","text":"case time series additional grouping present, removing level grouping whilst retaining time made easier time_aggregate(). case wish sum count denom gender, retaining class grouping. default time_aggregate sum count, denom population columns behaviour can specified passing dplyr::summarise style directives function.","code":"count_by_gender %>%    dplyr::group_by(class,gender) %>%    time_aggregate() %>%   dplyr::glimpse() #> Rows: 9 #> Columns: 4 #> Groups: class [3] #> $ class <chr> \"variant1\", \"variant1\", \"variant1\", \"variant2\", \"variant2\", \"var… #> $ time  <time_prd> 0, 1, 2, 0, 1, 2, 0, 1, 2 #> $ count <int> 7, 5, 10, 17, 16, 16, 43, 49, 37 #> $ denom <int> 67, 70, 63, 67, 70, 63, 67, 70, 63"},{"path":"/articles/variant-proportions.html","id":"covid-19-proportions-in-england","dir":"Articles","previous_headings":"","what":"COVID-19 proportions in England","title":"Multinomial proportions models for genomic variants","text":"Sanger Centre & COGUK performed large amount sequencing COVID-19 pandemic, identify emerging genomic variants. scaled second half 2021 continued beginning 2023. Lineages assigned using Pango lineage system important ones given nicknames . Sanger variants data discontinued, still available download. code download, process data sets determine full lineage data-raw/variants.R file, output bundled data set . many caveats data terms bias regarded definitive: data must class column defining main categorisation data (case main pango variant). time column time_period derived date (weekly). necessary column count column integer counts class. data must grouped class. Multiple models can fitted simultaneously data grouped columns.","code":"# tidy copy of the sanger weekly variants count data aggregated to England level ggoutbreak::england_variants %>% dplyr::glimpse() ## Rows: 479 ## Columns: 6 ## Groups: class [10] ## $ date      <date> 2020-09-05, 2020-09-05, 2020-09-12, 2020-09-12, 2020-09-19,… ## $ time      <time_prd> 0, 0, 7, 7, 14, 14, 21, 21, 28, 28, 35, 35, 42, 42, 49,… ## $ class     <fct> Other, Alpha (B.1.1.7), Other, Alpha (B.1.1.7), Other, Alpha… ## $ who_class <fct> Other, Alpha, Other, Alpha, Other, Alpha, Other, Alpha, Othe… ## $ count     <dbl> 1182, 371, 1439, 588, 837, 429, 1685, 1157, 1208, 823, 1501,… ## $ denom     <dbl> 1553, 1553, 2027, 2027, 1266, 1266, 2842, 2842, 2031, 2031, …"},{"path":"/articles/variant-proportions.html","id":"multinomial-proportions-model-","dir":"Articles","previous_headings":"","what":"Multinomial proportions model.","title":"Multinomial proportions models for genomic variants","text":"Genomic testing happened subset cases. testing effort varied significantly time. frequency variant time can determined multinomial model.","code":"probs = england_variants %>%    multinomial_nnet_model(window = 28) ## # weights:  40 (27 variable) ## initial  value 3583520.087982  ## iter  10 value 1562162.620103 ## iter  20 value 1380207.974678 ## iter  30 value 959088.555894 ## iter  40 value 742507.401941 ## iter  50 value 731767.878774 ## iter  60 value 729647.595794 ## iter  70 value 726795.599521 ## iter  80 value 716309.104988 ## iter  90 value 709310.965531 ## iter 100 value 707285.575109 ## final  value 707285.575109  ## stopped after 100 iterations plot_multinomial(probs)+   ggplot2::scale_fill_viridis_d(option=\"cividis\")"},{"path":"/articles/variant-proportions.html","id":"binomial-proportions-model","dir":"Articles","previous_headings":"","what":"Binomial proportions model","title":"Multinomial proportions models for genomic variants","text":"binomial proportions different multinomial probabilities calculated , come confidence intervals, however median values necessarily sum 1.  rate change proportion individual variant versus others logistic scale can used work exponential growth rate one variant relative others. relative growth rate taken togehter esimates variants given time centred around zero. one variant growth advantage, definition others growth disadvantage despite potentially causing larger disease burden increasing numbers growing epidemic.  binomial relative growth rate per day growth advantage existing variants. dependency unit time controlled time_period configuration. data provided time_period defined daily basis despite data provided weekly. Doubling time make strict sense describing relative growth rates shown .","code":"probs2 = england_variants %>% proportion_locfit_model(window = 14)  plot_proportion(probs2)+   ggplot2::scale_colour_viridis_d(option=\"cividis\",aesthetics = c(\"colour\",\"fill\")) plot_growth_rate(probs2) +   ggplot2::scale_fill_viridis_d(option=\"cividis\",aesthetics = c(\"colour\",\"fill\"))"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Robert Challen. Author, maintainer, copyright holder.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Challen R (2024). ggoutbreak: Estimate Incidence, Proportions Exponential Growth Rates. R package version 0.3.2,  https://github.com/ai4ci/ggoutbreak, https://doi.org/10.5281/zenodo.13165561, https://ai4ci.github.io/ggoutbreak/.","code":"@Manual{,   title = {ggoutbreak: Estimate Incidence, Proportions and Exponential Growth Rates},   author = {Robert Challen},   year = {2024},   note = {R package version 0.3.2,  https://github.com/ai4ci/ggoutbreak, https://doi.org/10.5281/zenodo.13165561},   url = {https://ai4ci.github.io/ggoutbreak/}, }"},{"path":"/index.html","id":"ggoutbreak","dir":"","previous_headings":"","what":"Estimate Incidence, Proportions and Exponential Growth Rates","title":"Estimate Incidence, Proportions and Exponential Growth Rates","text":"Simple statistical models visualisations calculating incidence, proportion, exponential growth rate, reproduction number infectious disease case time series. tool kit largely developed COVID-19 pandemic.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Estimate Incidence, Proportions and Exponential Growth Rates","text":"ggoutbreak hosted AI4CI r-universe. Installation follows: can install development version ggoutbreak GitHub :","code":"options(repos = c(   \"ai4ci\" = 'https://ai4ci.r-universe.dev/',   CRAN = 'https://cloud.r-project.org'))  # Download and install ggoutbreak in R install.packages(\"ggoutbreak\") # install.packages(\"devtools\") devtools::install_github(\"ai4ci/ggoutbreak\")"},{"path":"/index.html","id":"funding","dir":"","previous_headings":"","what":"Funding","title":"Estimate Incidence, Proportions and Exponential Growth Rates","text":"authors gratefully acknowledge support UK Research Innovation AI programme Engineering Physical Sciences Research Council EPSRC grant EP/Y028392/1.","code":""},{"path":"/reference/as.Date.time_period.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert time period to dates — as.Date.time_period","title":"Convert time period to dates — as.Date.time_period","text":"Convert time period dates","code":""},{"path":"/reference/as.Date.time_period.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert time period to dates — as.Date.time_period","text":"","code":"# S3 method for time_period as.Date(x, ...)  # S3 method for time_period as.POSIXct(x, ...)"},{"path":"/reference/as.Date.time_period.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert time period to dates — as.Date.time_period","text":"x time_period ... used","code":""},{"path":"/reference/as.Date.time_period.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert time period to dates — as.Date.time_period","text":"vector dates representing start input time_period entries","code":""},{"path":"/reference/as.Date.time_period.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Convert time period to dates — as.Date.time_period","text":".POSIXct(time_period): Convert vector POSIXct","code":""},{"path":"/reference/as.time_period.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert to a time period class — as.time_period","title":"Convert to a time period class — as.time_period","text":"Time periods just zero based numeric representation dates time unit baked . allows variable length periods (e.g. days weeks), fractional days represented consistent(ish) way","code":""},{"path":"/reference/as.time_period.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert to a time period class — as.time_period","text":"","code":"as.time_period(x, unit = NULL, start_date = NULL, anchor = NULL, ...)  # S3 method for time_period c(..., recursive = F)  # S3 method for time_period [(x, ...)  # S3 method for time_period [(x, ...) <- value  # S3 method for time_period [[(x, ...)  # S3 method for time_period [[(x, ...) <- value  is.time_period(x)  # S3 method for time_period print(x, ...)"},{"path":"/reference/as.time_period.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert to a time period class — as.time_period","text":"x vector numbers (may integer real) time_period unit length one unit time. either integer number days, specification \"1 week\", another time_period. x time_period, unit different x return new time_period using new units. start_date zero time date something can coerced date. x input already time_period different start_date recalibrated use new start date. anchor relevant x vector dates start_date specified, date, \"start\" \"end\" weekday name e.g. \"mon\". vector dates x find reference date time-series. NULL start_date also NULL fall back getOption(\"day_zero\",\"2019-12-29\") ... used subtype implementations recursive concatenate recursively value value","code":""},{"path":"/reference/as.time_period.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert to a time period class — as.time_period","text":"time_period class, consisting vector numbers, attributes time period start_date","code":""},{"path":"/reference/as.time_period.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Convert to a time period class — as.time_period","text":"c(time_period): Combine time_period [: Subset time_period `[`(time_period) <- value: Assign values subset time_period [[: Get value time_period `[[`(time_period) <- value: Assign value time_period .time_period(): Check time_period print(time_period): Print time_period","code":""},{"path":"/reference/as.time_period.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert to a time period class — as.time_period","text":"","code":"# 100 weeks from 2020-01-01  tmp = as.time_period(0:100, 7, \"2020-01-01\") as.Date(tmp) #>   [1] \"2020-01-01\" \"2020-01-08\" \"2020-01-15\" \"2020-01-22\" \"2020-01-29\" #>   [6] \"2020-02-05\" \"2020-02-12\" \"2020-02-19\" \"2020-02-26\" \"2020-03-04\" #>  [11] \"2020-03-11\" \"2020-03-18\" \"2020-03-25\" \"2020-04-01\" \"2020-04-08\" #>  [16] \"2020-04-15\" \"2020-04-22\" \"2020-04-29\" \"2020-05-06\" \"2020-05-13\" #>  [21] \"2020-05-20\" \"2020-05-27\" \"2020-06-03\" \"2020-06-10\" \"2020-06-17\" #>  [26] \"2020-06-24\" \"2020-07-01\" \"2020-07-08\" \"2020-07-15\" \"2020-07-22\" #>  [31] \"2020-07-29\" \"2020-08-05\" \"2020-08-12\" \"2020-08-19\" \"2020-08-26\" #>  [36] \"2020-09-02\" \"2020-09-09\" \"2020-09-16\" \"2020-09-23\" \"2020-09-30\" #>  [41] \"2020-10-07\" \"2020-10-14\" \"2020-10-21\" \"2020-10-28\" \"2020-11-04\" #>  [46] \"2020-11-11\" \"2020-11-18\" \"2020-11-25\" \"2020-12-02\" \"2020-12-09\" #>  [51] \"2020-12-16\" \"2020-12-23\" \"2020-12-30\" \"2021-01-06\" \"2021-01-13\" #>  [56] \"2021-01-20\" \"2021-01-27\" \"2021-02-03\" \"2021-02-10\" \"2021-02-17\" #>  [61] \"2021-02-24\" \"2021-03-03\" \"2021-03-10\" \"2021-03-17\" \"2021-03-24\" #>  [66] \"2021-03-31\" \"2021-04-07\" \"2021-04-14\" \"2021-04-21\" \"2021-04-28\" #>  [71] \"2021-05-05\" \"2021-05-12\" \"2021-05-19\" \"2021-05-26\" \"2021-06-02\" #>  [76] \"2021-06-09\" \"2021-06-16\" \"2021-06-23\" \"2021-06-30\" \"2021-07-07\" #>  [81] \"2021-07-14\" \"2021-07-21\" \"2021-07-28\" \"2021-08-04\" \"2021-08-11\" #>  [86] \"2021-08-18\" \"2021-08-25\" \"2021-09-01\" \"2021-09-08\" \"2021-09-15\" #>  [91] \"2021-09-22\" \"2021-09-29\" \"2021-10-06\" \"2021-10-13\" \"2021-10-20\" #>  [96] \"2021-10-27\" \"2021-11-03\" \"2021-11-10\" \"2021-11-17\" \"2021-11-24\" #> [101] \"2021-12-01\"  range(tmp) #> time unit: week, origin: 2020-01-01 (a Wednesday) #> [1]   0 100 min(tmp) #> time unit: week, origin: 2020-01-01 (a Wednesday) #> [1] 0 tmp2 = as.integer(as.Date(tmp)) # testthat::expect_true(all(na.omit(tmp2-lag(tmp2)) == 7))  tmp2 = as.time_period(0:23, 1/24, \"2020-01-01\") as.POSIXct(tmp2) #>  [1] \"2020-01-01 00:00:00 GMT\" \"2020-01-01 01:00:00 GMT\" #>  [3] \"2020-01-01 02:00:00 GMT\" \"2020-01-01 03:00:00 GMT\" #>  [5] \"2020-01-01 04:00:00 GMT\" \"2020-01-01 05:00:00 GMT\" #>  [7] \"2020-01-01 06:00:00 GMT\" \"2020-01-01 07:00:00 GMT\" #>  [9] \"2020-01-01 08:00:00 GMT\" \"2020-01-01 09:00:00 GMT\" #> [11] \"2020-01-01 10:00:00 GMT\" \"2020-01-01 11:00:00 GMT\" #> [13] \"2020-01-01 12:00:00 GMT\" \"2020-01-01 13:00:00 GMT\" #> [15] \"2020-01-01 14:00:00 GMT\" \"2020-01-01 15:00:00 GMT\" #> [17] \"2020-01-01 16:00:00 GMT\" \"2020-01-01 17:00:00 GMT\" #> [19] \"2020-01-01 18:00:00 GMT\" \"2020-01-01 19:00:00 GMT\" #> [21] \"2020-01-01 20:00:00 GMT\" \"2020-01-01 21:00:00 GMT\" #> [23] \"2020-01-01 22:00:00 GMT\" \"2020-01-01 23:00:00 GMT\"  # convert timeseries to new \"unit\" tmp = as.time_period(0:100, 7, \"2020-01-01\") tmp2 = as.time_period(tmp,1) testthat::expect_equal(as.numeric(tmp2), 0:100*7)"},{"path":"/reference/breaks_log1p.html","id":null,"dir":"Reference","previous_headings":"","what":"A scales breaks generator for log1p scales — breaks_log1p","title":"A scales breaks generator for log1p scales — breaks_log1p","text":"scales breaks generator log1p scales","code":""},{"path":"/reference/breaks_log1p.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A scales breaks generator for log1p scales — breaks_log1p","text":"","code":"breaks_log1p(n = 5, base = 10)"},{"path":"/reference/breaks_log1p.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A scales breaks generator for log1p scales — breaks_log1p","text":"n number breaks base base breaks","code":""},{"path":"/reference/breaks_log1p.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A scales breaks generator for log1p scales — breaks_log1p","text":"function ggplot scale breaks","code":""},{"path":"/reference/breaks_log1p.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A scales breaks generator for log1p scales — breaks_log1p","text":"","code":"ggplot2::ggplot(ggplot2::diamonds, ggplot2::aes(x=price))+   ggplot2::geom_density()+   ggplot2::scale_x_continuous(trans=\"log1p\", breaks=breaks_log1p())"},{"path":"/reference/covid_infectivity_profile.html","id":null,"dir":"Reference","previous_headings":"","what":"The covid_infectivity_profile dataframe structure specification — covid_infectivity_profile","title":"The covid_infectivity_profile dataframe structure specification — covid_infectivity_profile","text":"covid_infectivity_profile dataframe structure specification","code":""},{"path":"/reference/covid_infectivity_profile.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"The covid_infectivity_profile dataframe structure specification — covid_infectivity_profile","text":"dataframe containing following columns: boot (anything + default(1)) - bootstrap identifier time (positive_double) - end time period (days) probability (proportion) - probability infection previous time period time Must grouped : boot (exactly). default value defined.","code":""},{"path":"/reference/cut_date.html","id":null,"dir":"Reference","previous_headings":"","what":"Places a set of dates within a regular time series — cut_date","title":"Places a set of dates within a regular time series — cut_date","text":"counterpart date_seq_dates(). Take original set data place within regular time series periodicity time series may expressed numbers days, weeks, months quarters, years, periods defined anchoring date, day week reference start end input dates. can either return periods dates factors (e.g. plotting) time_period analysis relies numeric representation date duration anchor.","code":""},{"path":"/reference/cut_date.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Places a set of dates within a regular time series — cut_date","text":"","code":"cut_date(   dates,   unit,   anchor = \"start\",   output = c(\"date\", \"factor\", \"time_period\"),   dfmt = \"%d/%b/%y\",   ifmt = \"{start} — {end}\",   ... )"},{"path":"/reference/cut_date.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Places a set of dates within a regular time series — cut_date","text":"dates set dates unit period e.g. \"1 week\" anchor one date, \"start\" \"end\" weekday name e.g. \"mon\" always one start time periods cutting output return result either \"date\" (default), ordered \"factor\" date ranges label, \"time_period\". result named labels referring dfmt strptime format dates labels ifmt sprintf format period label containing %s exactly twice. ... ignored","code":""},{"path":"/reference/cut_date.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Places a set of dates within a regular time series — cut_date","text":"set dates, times factor level, representing start period date falls , period defined duration anchor","code":""},{"path":"/reference/cut_date.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Places a set of dates within a regular time series — cut_date","text":"","code":"dates = as.Date(c(\"2020-01-01\",\"2020-02-01\",\"2020-01-15\",\"2020-02-03\",NA)) fs = ggoutbreak::date_seq(dates, \"2 days\") dates - cut_date(dates, \"2 days\") #> Time differences in days #> 01/Jan/20 — 02/Jan/20 31/Jan/20 — 01/Feb/20 15/Jan/20 — 16/Jan/20  #>                     0                     1                     0  #> 02/Feb/20 — 03/Feb/20               Unknown  #>                     1                    NA  cut_date(dates,unit=\"2 days\", output=\"time_period\") #> time unit: 2 days, origin: 2020-01-01 (a Wednesday) #> [1]  0 15  7 16 NA  # A weekly set of dates: dates2 = Sys.Date() + floor(stats::runif(50,max=10))*7  # in this specific situation the final date is not truncated because the # input data is seen as an exact match for the whole output period. cut_date(dates2, \"1 week\", \"sun\", output=\"factor\") #>  [1] 18/Aug/24 — 24/Aug/24 13/Oct/24 — 19/Oct/24 29/Sep/24 — 05/Oct/24 #>  [4] 25/Aug/24 — 31/Aug/24 18/Aug/24 — 24/Aug/24 15/Sep/24 — 21/Sep/24 #>  [7] 15/Sep/24 — 21/Sep/24 01/Sep/24 — 07/Sep/24 06/Oct/24 — 12/Oct/24 #> [10] 06/Oct/24 — 12/Oct/24 13/Oct/24 — 19/Oct/24 25/Aug/24 — 31/Aug/24 #> [13] 18/Aug/24 — 24/Aug/24 08/Sep/24 — 14/Sep/24 15/Sep/24 — 21/Sep/24 #> [16] 25/Aug/24 — 31/Aug/24 15/Sep/24 — 21/Sep/24 18/Aug/24 — 24/Aug/24 #> [19] 08/Sep/24 — 14/Sep/24 20/Oct/24 — 26/Oct/24 01/Sep/24 — 07/Sep/24 #> [22] 29/Sep/24 — 05/Oct/24 06/Oct/24 — 12/Oct/24 25/Aug/24 — 31/Aug/24 #> [25] 20/Oct/24 — 26/Oct/24 06/Oct/24 — 12/Oct/24 18/Aug/24 — 24/Aug/24 #> [28] 22/Sep/24 — 28/Sep/24 29/Sep/24 — 05/Oct/24 29/Sep/24 — 05/Oct/24 #> [31] 18/Aug/24 — 24/Aug/24 01/Sep/24 — 07/Sep/24 08/Sep/24 — 14/Sep/24 #> [34] 29/Sep/24 — 05/Oct/24 15/Sep/24 — 21/Sep/24 15/Sep/24 — 21/Sep/24 #> [37] 06/Oct/24 — 12/Oct/24 20/Oct/24 — 26/Oct/24 25/Aug/24 — 31/Aug/24 #> [40] 01/Sep/24 — 07/Sep/24 29/Sep/24 — 05/Oct/24 15/Sep/24 — 21/Sep/24 #> [43] 29/Sep/24 — 05/Oct/24 29/Sep/24 — 05/Oct/24 18/Aug/24 — 24/Aug/24 #> [46] 06/Oct/24 — 12/Oct/24 06/Oct/24 — 12/Oct/24 20/Oct/24 — 26/Oct/24 #> [49] 20/Oct/24 — 26/Oct/24 08/Sep/24 — 14/Sep/24 #> 11 Levels: 18/Aug/24 — 24/Aug/24 < ... < 27/Oct/24 — 02/Nov/24 cut_date(dates2, dfmt = \"%d/%b\", output=\"factor\", unit = \"2 weeks\", anchor=\"sun\") #>  [1] 18/Aug — 31/Aug 13/Oct — 26/Oct 29/Sep — 12/Oct 18/Aug — 31/Aug #>  [5] 18/Aug — 31/Aug 15/Sep — 28/Sep 15/Sep — 28/Sep 01/Sep — 14/Sep #>  [9] 29/Sep — 12/Oct 29/Sep — 12/Oct 13/Oct — 26/Oct 18/Aug — 31/Aug #> [13] 18/Aug — 31/Aug 01/Sep — 14/Sep 15/Sep — 28/Sep 18/Aug — 31/Aug #> [17] 15/Sep — 28/Sep 18/Aug — 31/Aug 01/Sep — 14/Sep 13/Oct — 26/Oct #> [21] 01/Sep — 14/Sep 29/Sep — 12/Oct 29/Sep — 12/Oct 18/Aug — 31/Aug #> [25] 13/Oct — 26/Oct 29/Sep — 12/Oct 18/Aug — 31/Aug 15/Sep — 28/Sep #> [29] 29/Sep — 12/Oct 29/Sep — 12/Oct 18/Aug — 31/Aug 01/Sep — 14/Sep #> [33] 01/Sep — 14/Sep 29/Sep — 12/Oct 15/Sep — 28/Sep 15/Sep — 28/Sep #> [37] 29/Sep — 12/Oct 13/Oct — 26/Oct 18/Aug — 31/Aug 01/Sep — 14/Sep #> [41] 29/Sep — 12/Oct 15/Sep — 28/Sep 29/Sep — 12/Oct 29/Sep — 12/Oct #> [45] 18/Aug — 31/Aug 29/Sep — 12/Oct 29/Sep — 12/Oct 13/Oct — 26/Oct #> [49] 13/Oct — 26/Oct 01/Sep — 14/Sep #> 6 Levels: 18/Aug — 31/Aug < 01/Sep — 14/Sep < ... < 27/Oct — 09/Nov"},{"path":"/reference/date_seq.Date.html","id":null,"dir":"Reference","previous_headings":"","what":"Expand a date vector to the full range of possible dates — date_seq.Date","title":"Expand a date vector to the full range of possible dates — date_seq.Date","text":"Derive vector observation dates, complete ordered sequence periods regular time series, length periods specified, number od days, weeks, years etc. E.g. can convert random set dates ordered complete list 1 week intervals (2 month intervals) spanning range dates. interesting problems regarding put breaks within month week. Often either based specific date (e.g. yearly periods starting 2020-01-01) day week (e.g. 2 weekly periods staring sunday) maybe relative input time series (weekly ending last date data). also problem consider data may incomplete starting end periods, may comparable periods, may need exclude result.","code":""},{"path":"/reference/date_seq.Date.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expand a date vector to the full range of possible dates — date_seq.Date","text":"","code":"# S3 method for Date date_seq(x, period = .day_interval(x), anchor = \"start\", complete = FALSE, ...)"},{"path":"/reference/date_seq.Date.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expand a date vector to the full range of possible dates — date_seq.Date","text":"x vector dates, possibly including NA values period gap observations number days natural language definition period \"1 week\", '2 weeks', '1 month', etc. given derived dates. anchor defines day appears sequence (extend far). Given either date, \"start\", \"end\" day week, e.g. \"mon\". complete truncate incomplete start end periods ... ignored","code":""},{"path":"/reference/date_seq.Date.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expand a date vector to the full range of possible dates — date_seq.Date","text":"vector dates regular periods minimum maximum dates, boundaries defined anchor.","code":""},{"path":"/reference/date_seq.Date.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expand a date vector to the full range of possible dates — date_seq.Date","text":"","code":"date_seq(as.Date(c(\"2020-01-01\",\"2020-02-01\",\"2020-01-15\",\"2020-02-01\",NA)), \"2 days\") #>  [1] \"2020-01-01\" \"2020-01-03\" \"2020-01-05\" \"2020-01-07\" \"2020-01-09\" #>  [6] \"2020-01-11\" \"2020-01-13\" \"2020-01-15\" \"2020-01-17\" \"2020-01-19\" #> [11] \"2020-01-21\" \"2020-01-23\" \"2020-01-25\" \"2020-01-27\" \"2020-01-29\" #> [16] \"2020-01-31\""},{"path":"/reference/date_seq.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the full sequence of values in a vector — date_seq","title":"Create the full sequence of values in a vector — date_seq","text":"useful want fill missing values observed . example, date_seq(c(1, 2, 4, 6), 1) return 1:6.","code":""},{"path":"/reference/date_seq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the full sequence of values in a vector — date_seq","text":"","code":"date_seq(x, period, ...)"},{"path":"/reference/date_seq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the full sequence of values in a vector — date_seq","text":"x numeric date vector period Gap observation. existing data checked ensure actually periodicity. ... subtype methods","code":""},{"path":"/reference/date_seq.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create the full sequence of values in a vector — date_seq","text":"vector type input","code":""},{"path":"/reference/date_seq.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create the full sequence of values in a vector — date_seq","text":"","code":"date_seq(c(1, 2, 4, 5, 10), 1) #>  [1]  1  2  3  4  5  6  7  8  9 10"},{"path":"/reference/date_seq.numeric.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the full sequence of values in a vector — date_seq.numeric","title":"Create the full sequence of values in a vector — date_seq.numeric","text":"useful want fill missing values observed . example, date_seq(c(1, 2, 4, 6), 1) return 1:6.","code":""},{"path":"/reference/date_seq.numeric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the full sequence of values in a vector — date_seq.numeric","text":"","code":"# S3 method for numeric date_seq(x, period = 1, tol = 1e-06, ...)"},{"path":"/reference/date_seq.numeric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the full sequence of values in a vector — date_seq.numeric","text":"x numeric date vector period Gap observation. existing data checked ensure actually periodicity. tol Numerical tolerance checking periodicity. ... subtype methods","code":""},{"path":"/reference/date_seq.numeric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create the full sequence of values in a vector — date_seq.numeric","text":"vector type input","code":""},{"path":"/reference/date_seq.numeric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create the full sequence of values in a vector — date_seq.numeric","text":"","code":"date_seq(c(1, 2, 4, 5, 10), 1) #>  [1]  1  2  3  4  5  6  7  8  9 10"},{"path":"/reference/date_seq.time_period.html","id":null,"dir":"Reference","previous_headings":"","what":"Expand a time_period vector to the full range of possible times — date_seq.time_period","title":"Expand a time_period vector to the full range of possible times — date_seq.time_period","text":"Derive vector observation time_periods, complete ordered sequence periods regular time series, length periods specified, number days, weeks, years etc. E.g. can convert random set times ordered complete list 1 week intervals (2 month intervals) spanning range dates. interesting problems regarding put breaks within month week. Often either based specific date (e.g. yearly periods starting 2020-01-01) day week (e.g. 2 weekly periods staring sunday) maybe relative input time series (weekly ending last date data). also problem consider data may incomplete starting end periods, may comparable periods, may need exclude result.","code":""},{"path":"/reference/date_seq.time_period.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expand a time_period vector to the full range of possible times — date_seq.time_period","text":"","code":"# S3 method for time_period date_seq(x, period = attributes(x)$unit, complete = FALSE, ...)"},{"path":"/reference/date_seq.time_period.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expand a time_period vector to the full range of possible times — date_seq.time_period","text":"x time period vector period gap observations number days natural language definition period \"1 week\", '2 weeks', '1 month', etc. given derived dates. complete truncate incomplete start end periods ... ignored","code":""},{"path":"/reference/date_seq.time_period.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expand a time_period vector to the full range of possible times — date_seq.time_period","text":"vector time_periods regular periods minimum maximum dates, boundaries defined anchor.","code":""},{"path":"/reference/date_seq.time_period.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expand a time_period vector to the full range of possible times — date_seq.time_period","text":"","code":"tmp = as.time_period(c(0,10,100), 7, \"2020-01-01\") date_seq(tmp, \"7 days\") #> time unit: week, origin: 2020-01-01 (a Wednesday) #>  [1]   0  10  20  30  40  50  60  70  80  90 100 date_seq(tmp, \"1 day\") #> time unit: week, origin: 2020-01-01 (a Wednesday) #>   [1]  0.1428571  0.2857143  0.4285714  0.5714286  0.7142857  0.8571429 #>   [7]  1.0000000  1.1428571  1.2857143  1.4285714  1.5714286  1.7142857 #>  [13]  1.8571429  2.0000000  2.1428571  2.2857143  2.4285714  2.5714286 #>  [19]  2.7142857  2.8571429  3.0000000  3.1428571  3.2857143  3.4285714 #>  [25]  3.5714286  3.7142857  3.8571429  4.0000000  4.1428571  4.2857143 #>  [31]  4.4285714  4.5714286  4.7142857  4.8571429  5.0000000  5.1428571 #>  [37]  5.2857143  5.4285714  5.5714286  5.7142857  5.8571429  6.0000000 #>  [43]  6.1428571  6.2857143  6.4285714  6.5714286  6.7142857  6.8571429 #>  [49]  7.0000000  7.1428571  7.2857143  7.4285714  7.5714286  7.7142857 #>  [55]  7.8571429  8.0000000  8.1428571  8.2857143  8.4285714  8.5714286 #>  [61]  8.7142857  8.8571429  9.0000000  9.1428571  9.2857143  9.4285714 #>  [67]  9.5714286  9.7142857  9.8571429 10.0000000 10.1428571 10.2857143 #>  [73] 10.4285714 10.5714286 10.7142857 10.8571429 11.0000000 11.1428571 #>  [79] 11.2857143 11.4285714 11.5714286 11.7142857 11.8571429 12.0000000 #>  [85] 12.1428571 12.2857143 12.4285714 12.5714286 12.7142857 12.8571429 #>  [91] 13.0000000 13.1428571 13.2857143 13.4285714 13.5714286 13.7142857 #>  [97] 13.8571429 14.0000000 14.1428571 14.2857143 14.4285714 14.5714286 #> [103] 14.7142857 14.8571429 15.0000000 15.1428571 15.2857143 15.4285714 #> [109] 15.5714286 15.7142857 15.8571429 16.0000000 16.1428571 16.2857143 #> [115] 16.4285714 16.5714286 16.7142857 16.8571429 17.0000000 17.1428571 #> [121] 17.2857143 17.4285714 17.5714286 17.7142857 17.8571429 18.0000000 #> [127] 18.1428571 18.2857143 18.4285714 18.5714286 18.7142857 18.8571429 #> [133] 19.0000000 19.1428571 19.2857143 19.4285714 19.5714286 19.7142857 #> [139] 19.8571429 20.0000000 20.1428571 20.2857143 20.4285714 20.5714286 #> [145] 20.7142857 20.8571429 21.0000000 21.1428571 21.2857143 21.4285714 #> [151] 21.5714286 21.7142857 21.8571429 22.0000000 22.1428571 22.2857143 #> [157] 22.4285714 22.5714286 22.7142857 22.8571429 23.0000000 23.1428571 #> [163] 23.2857143 23.4285714 23.5714286 23.7142857 23.8571429 24.0000000 #> [169] 24.1428571 24.2857143 24.4285714 24.5714286 24.7142857 24.8571429 #> [175] 25.0000000 25.1428571 25.2857143 25.4285714 25.5714286 25.7142857 #> [181] 25.8571429 26.0000000 26.1428571 26.2857143 26.4285714 26.5714286 #> [187] 26.7142857 26.8571429 27.0000000 27.1428571 27.2857143 27.4285714 #> [193] 27.5714286 27.7142857 27.8571429 28.0000000 28.1428571 28.2857143 #> [199] 28.4285714 28.5714286 28.7142857 28.8571429 29.0000000 29.1428571 #> [205] 29.2857143 29.4285714 29.5714286 29.7142857 29.8571429 30.0000000 #> [211] 30.1428571 30.2857143 30.4285714 30.5714286 30.7142857 30.8571429 #> [217] 31.0000000 31.1428571 31.2857143 31.4285714 31.5714286 31.7142857 #> [223] 31.8571429 32.0000000 32.1428571 32.2857143 32.4285714 32.5714286 #> [229] 32.7142857 32.8571429 33.0000000 33.1428571 33.2857143 33.4285714 #> [235] 33.5714286 33.7142857 33.8571429 34.0000000 34.1428571 34.2857143 #> [241] 34.4285714 34.5714286 34.7142857 34.8571429 35.0000000 35.1428571 #> [247] 35.2857143 35.4285714 35.5714286 35.7142857 35.8571429 36.0000000 #> [253] 36.1428571 36.2857143 36.4285714 36.5714286 36.7142857 36.8571429 #> [259] 37.0000000 37.1428571 37.2857143 37.4285714 37.5714286 37.7142857 #> [265] 37.8571429 38.0000000 38.1428571 38.2857143 38.4285714 38.5714286 #> [271] 38.7142857 38.8571429 39.0000000 39.1428571 39.2857143 39.4285714 #> [277] 39.5714286 39.7142857 39.8571429 40.0000000 40.1428571 40.2857143 #> [283] 40.4285714 40.5714286 40.7142857 40.8571429 41.0000000 41.1428571 #> [289] 41.2857143 41.4285714 41.5714286 41.7142857 41.8571429 42.0000000 #> [295] 42.1428571 42.2857143 42.4285714 42.5714286 42.7142857 42.8571429 #> [301] 43.0000000 43.1428571 43.2857143 43.4285714 43.5714286 43.7142857 #> [307] 43.8571429 44.0000000 44.1428571 44.2857143 44.4285714 44.5714286 #> [313] 44.7142857 44.8571429 45.0000000 45.1428571 45.2857143 45.4285714 #> [319] 45.5714286 45.7142857 45.8571429 46.0000000 46.1428571 46.2857143 #> [325] 46.4285714 46.5714286 46.7142857 46.8571429 47.0000000 47.1428571 #> [331] 47.2857143 47.4285714 47.5714286 47.7142857 47.8571429 48.0000000 #> [337] 48.1428571 48.2857143 48.4285714 48.5714286 48.7142857 48.8571429 #> [343] 49.0000000 49.1428571 49.2857143 49.4285714 49.5714286 49.7142857 #> [349] 49.8571429 50.0000000 50.1428571 50.2857143 50.4285714 50.5714286 #> [355] 50.7142857 50.8571429 51.0000000 51.1428571 51.2857143 51.4285714 #> [361] 51.5714286 51.7142857 51.8571429 52.0000000 52.1428571 52.2857143 #> [367] 52.4285714 52.5714286 52.7142857 52.8571429 53.0000000 53.1428571 #> [373] 53.2857143 53.4285714 53.5714286 53.7142857 53.8571429 54.0000000 #> [379] 54.1428571 54.2857143 54.4285714 54.5714286 54.7142857 54.8571429 #> [385] 55.0000000 55.1428571 55.2857143 55.4285714 55.5714286 55.7142857 #> [391] 55.8571429 56.0000000 56.1428571 56.2857143 56.4285714 56.5714286 #> [397] 56.7142857 56.8571429 57.0000000 57.1428571 57.2857143 57.4285714 #> [403] 57.5714286 57.7142857 57.8571429 58.0000000 58.1428571 58.2857143 #> [409] 58.4285714 58.5714286 58.7142857 58.8571429 59.0000000 59.1428571 #> [415] 59.2857143 59.4285714 59.5714286 59.7142857 59.8571429 60.0000000 #> [421] 60.1428571 60.2857143 60.4285714 60.5714286 60.7142857 60.8571429 #> [427] 61.0000000 61.1428571 61.2857143 61.4285714 61.5714286 61.7142857 #> [433] 61.8571429 62.0000000 62.1428571 62.2857143 62.4285714 62.5714286 #> [439] 62.7142857 62.8571429 63.0000000 63.1428571 63.2857143 63.4285714 #> [445] 63.5714286 63.7142857 63.8571429 64.0000000 64.1428571 64.2857143 #> [451] 64.4285714 64.5714286 64.7142857 64.8571429 65.0000000 65.1428571 #> [457] 65.2857143 65.4285714 65.5714286 65.7142857 65.8571429 66.0000000 #> [463] 66.1428571 66.2857143 66.4285714 66.5714286 66.7142857 66.8571429 #> [469] 67.0000000 67.1428571 67.2857143 67.4285714 67.5714286 67.7142857 #> [475] 67.8571429 68.0000000 68.1428571 68.2857143 68.4285714 68.5714286 #> [481] 68.7142857 68.8571429 69.0000000 69.1428571 69.2857143 69.4285714 #> [487] 69.5714286 69.7142857 69.8571429 70.0000000 70.1428571 70.2857143 #> [493] 70.4285714 70.5714286 70.7142857 70.8571429 71.0000000 71.1428571 #> [499] 71.2857143 71.4285714 71.5714286 71.7142857 71.8571429 72.0000000 #> [505] 72.1428571 72.2857143 72.4285714 72.5714286 72.7142857 72.8571429 #> [511] 73.0000000 73.1428571 73.2857143 73.4285714 73.5714286 73.7142857 #> [517] 73.8571429 74.0000000 74.1428571 74.2857143 74.4285714 74.5714286 #> [523] 74.7142857 74.8571429 75.0000000 75.1428571 75.2857143 75.4285714 #> [529] 75.5714286 75.7142857 75.8571429 76.0000000 76.1428571 76.2857143 #> [535] 76.4285714 76.5714286 76.7142857 76.8571429 77.0000000 77.1428571 #> [541] 77.2857143 77.4285714 77.5714286 77.7142857 77.8571429 78.0000000 #> [547] 78.1428571 78.2857143 78.4285714 78.5714286 78.7142857 78.8571429 #> [553] 79.0000000 79.1428571 79.2857143 79.4285714 79.5714286 79.7142857 #> [559] 79.8571429 80.0000000 80.1428571 80.2857143 80.4285714 80.5714286 #> [565] 80.7142857 80.8571429 81.0000000 81.1428571 81.2857143 81.4285714 #> [571] 81.5714286 81.7142857 81.8571429 82.0000000 82.1428571 82.2857143 #> [577] 82.4285714 82.5714286 82.7142857 82.8571429 83.0000000 83.1428571 #> [583] 83.2857143 83.4285714 83.5714286 83.7142857 83.8571429 84.0000000 #> [589] 84.1428571 84.2857143 84.4285714 84.5714286 84.7142857 84.8571429 #> [595] 85.0000000 85.1428571 85.2857143 85.4285714 85.5714286 85.7142857 #> [601] 85.8571429 86.0000000 86.1428571 86.2857143 86.4285714 86.5714286 #> [607] 86.7142857 86.8571429 87.0000000 87.1428571 87.2857143 87.4285714 #> [613] 87.5714286 87.7142857 87.8571429 88.0000000 88.1428571 88.2857143 #> [619] 88.4285714 88.5714286 88.7142857 88.8571429 89.0000000 89.1428571 #> [625] 89.2857143 89.4285714 89.5714286 89.7142857 89.8571429 90.0000000 #> [631] 90.1428571 90.2857143 90.4285714 90.5714286 90.7142857 90.8571429 #> [637] 91.0000000 91.1428571 91.2857143 91.4285714 91.5714286 91.7142857 #> [643] 91.8571429 92.0000000 92.1428571 92.2857143 92.4285714 92.5714286 #> [649] 92.7142857 92.8571429 93.0000000 93.1428571 93.2857143 93.4285714 #> [655] 93.5714286 93.7142857 93.8571429 94.0000000 94.1428571 94.2857143 #> [661] 94.4285714 94.5714286 94.7142857 94.8571429 95.0000000 95.1428571 #> [667] 95.2857143 95.4285714 95.5714286 95.7142857 95.8571429 96.0000000 #> [673] 96.1428571 96.2857143 96.4285714 96.5714286 96.7142857 96.8571429 #> [679] 97.0000000 97.1428571 97.2857143 97.4285714 97.5714286 97.7142857 #> [685] 97.8571429 98.0000000 98.1428571 98.2857143 98.4285714 98.5714286 #> [691] 98.7142857 98.8571429 99.0000000 99.1428571 99.2857143 99.4285714 #> [697] 99.5714286 99.7142857 99.8571429"},{"path":"/reference/date_to_time.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a set of dates to numeric timepoints — date_to_time","title":"Convert a set of dates to numeric timepoints — date_to_time","text":"Using start_date unit specification","code":""},{"path":"/reference/date_to_time.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a set of dates to numeric timepoints — date_to_time","text":"","code":"date_to_time(   dates,   unit = .day_interval(dates),   start_date = getOption(\"day_zero\", \"2019-12-29\") )"},{"path":"/reference/date_to_time.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert a set of dates to numeric timepoints — date_to_time","text":"dates vector dates convert unit specification unit resulting time series. determined periodicity dates specified. another time_period given unit start_date origin conversion. Defaults beginning COVID pandemic","code":""},{"path":"/reference/date_to_time.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert a set of dates to numeric timepoints — date_to_time","text":"vector class time_period","code":""},{"path":"/reference/date_to_time.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert a set of dates to numeric timepoints — date_to_time","text":"","code":"times = date_to_time(as.Date(\"2019-12-29\")+0:100, \"1 week\") dates = time_to_date(times)"},{"path":"/reference/dot-epiestim_si.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a set of serial interval distributions using EpiEstim — .epiestim_si","title":"Generate a set of serial interval distributions using EpiEstim — .epiestim_si","text":"Generate set serial interval distributions using EpiEstim","code":""},{"path":"/reference/dot-epiestim_si.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a set of serial interval distributions using EpiEstim — .epiestim_si","text":"","code":".epiestim_si(   mean_of_mean,   sd_of_mean,   mean_of_sd,   sd_of_sd,   days = 14,   boots = 100,   seed = Sys.time() )"},{"path":"/reference/dot-epiestim_si.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a set of serial interval distributions using EpiEstim — .epiestim_si","text":"mean_of_mean mean si mean posteriors sd_of_mean sd si mean posteriors mean_of_sd mean si sd posteriors sd_of_sd sd si sd posteriors days length desired SI distribution boots number bootstraps generate","code":""},{"path":"/reference/dot-epiestim_si.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a set of serial interval distributions using EpiEstim — .epiestim_si","text":"dataframe containing following columns: boot (anything) - bootstrap identifier time (positive_double) - end time period (days) probability (proportion) - probability infection previous time period time Grouped : boot (exactly).","code":""},{"path":"/reference/dot-epiestim_si.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a set of serial interval distributions using EpiEstim — .epiestim_si","text":"","code":"# N.B. EpiEstim cannot reconstruct an accurate set of distributions that # match the inputs parameters due to truncation of the SI distribution.  if (interactive()) {  ggplot2::ggplot(     .epiestim_si(5,1,3,1,boots = 100, days = 14),     ggplot2::aes(x=time,ymin=probability,ymax=probability,group=time)   )+ggplot2::geom_errorbar(alpha=0.2)  .epiestim_si(5,1,3,1,boots = 1000, days = 14) %>%   dplyr::summarise(     E = sum(probability*time),     E2 = sum(probability*time^2)   ) %>%   dplyr::summarise(     mean_of_mean = mean(E), sd_of_mean = stats::sd(E),     mean_of_sd = mean(sqrt(E2 - E^2)),     sd_of_sd = stats::sd(sqrt(E2 - E^2))   )  }  # This becomes less of an issue with larger SI days parameter."},{"path":"/reference/dot-summarise_with_ascertainment.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarise a line list with daily case ascertainment variability — .summarise_with_ascertainment","title":"Summarise a line list with daily case ascertainment variability — .summarise_with_ascertainment","text":"function introduces additional noise case series ensuing random proportion cases detected day. randomness defined logit-normal distribution parametrised baseline probability p.asc day day variability terms dispersion parameter kappa.asc.","code":""},{"path":"/reference/dot-summarise_with_ascertainment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarise a line list with daily case ascertainment variability — .summarise_with_ascertainment","text":"","code":".summarise_with_ascertainment(df, p.asc = 1, kappa.asc = 1, seed = Sys.time())"},{"path":"/reference/dot-summarise_with_ascertainment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarise a line list with daily case ascertainment variability — .summarise_with_ascertainment","text":"df line list p.asc background probability case detected kappa.asc dispersion parameter controlling day day variability ascertainment 0 (dispersion) Inf (maximum) seed random seed","code":""},{"path":"/reference/dot-summarise_with_ascertainment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarise a line list with daily case ascertainment variability — .summarise_with_ascertainment","text":"count data frame.","code":""},{"path":"/reference/dot-summarise_with_ascertainment.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarise a line list with daily case ascertainment variability — .summarise_with_ascertainment","text":"","code":"if (interactive()) {  tmp = .test_branching_process(   changes = tibble::tibble(t = c(0,20,40,60,80,110), R_t = c(1.8,1.5,0.9,1.5,0.8,1.2)),   kappa = 2,   max_time = 120,   p.asc= 0.8,   kappa.asc = 1.01,   seed = 100,   summarise = FALSE )  tmp2 = dplyr::bind_rows(lapply(c(0,0.5,1,2), function(d) {   tmp %>% .summarise_with_ascertainment(0.7,d) %>% dplyr::mutate(kappa = d) }))  ggplot2::ggplot(   tmp2,   ggplot2::aes(x=time,y=count, colour=as.factor(kappa)) )+ ggplot2::geom_line()+ ggplot2::geom_point()  }"},{"path":"/reference/dot-test_branching_process.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a line list from a branching process model parameterised by reproduction number — .test_branching_process","title":"Generate a line list from a branching process model parameterised by reproduction number — .test_branching_process","text":"Generate line list branching process model parameterised reproduction number","code":""},{"path":"/reference/dot-test_branching_process.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a line list from a branching process model parameterised by reproduction number — .test_branching_process","text":"","code":".test_branching_process(   changes = tibble::tibble(t = c(0, 40), R_t = c(2.5, 0.8)),   kappa = 1,   ip = ggoutbreak::covid_infectivity_profile,   max_time = 80,   initial = 30,   seed = Sys.time(),   summarise = TRUE,   ... )"},{"path":"/reference/dot-test_branching_process.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a line list from a branching process model parameterised by reproduction number — .test_branching_process","text":"changes dataframe containing t time column R_t reproduction number parameter. kappa dispersion parameter controlling likelihood individual super-spreading. must 1 Inf 1 standard poisson dispersion large values representing dispersion. ip data frame time, probability columns max_time maximum duration simulation initial initial outbreak size seed random seen summarise FALSE return line list one entry per person ... Arguments passed .summarise_with_ascertainment p.asc background probability case detected kappa.asc dispersion parameter controlling day day variability ascertainment 0 (dispersion) Inf (maximum)","code":""},{"path":"/reference/dot-test_branching_process.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a line list from a branching process model parameterised by reproduction number — .test_branching_process","text":"either line list cases, individual ids, infection times, infector ids summary case count time series,","code":""},{"path":"/reference/dot-test_branching_process.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a line list from a branching process model parameterised by reproduction number — .test_branching_process","text":"","code":"if (interactive()) {  tmp = .test_branching_process(   changes = tibble::tibble(t = c(0,20,40,60,80,110), R_t = c(1.8,1.5,0.9,1.5,0.8,1.2)),   kappa = 2,   max_time = 120,   p.asc= 0.8,   kappa.asc = 1.01,   seed = 100 )  mean(tmp$dispersion) ggplot2::ggplot(tmp, ggplot2::aes(x=time,y=count))+ggplot2::geom_point()  }"},{"path":"/reference/dot-test_multinomial.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a multinomial outbreak defined by per class growth rates and a poisson model — .test_multinomial","title":"Generate a multinomial outbreak defined by per class growth rates and a poisson model — .test_multinomial","text":"Generate multinomial outbreak defined per class growth rates poisson model","code":""},{"path":"/reference/dot-test_multinomial.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a multinomial outbreak defined by per class growth rates and a poisson model — .test_multinomial","text":"","code":".test_multinomial(   changes = tibble::tibble(time = c(0, 20, 40, 60, 80), variant1 = c(0.1, 0, -0.1, 0,     0.1), variant2 = c(0.15, 0.05, -0.05, -0.01, 0.05), variant3 = c(0, 0.05, -0.05,     +0.05, -0.05), ),   initial = c(100, 1, 100),   ... )"},{"path":"/reference/dot-test_multinomial.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a multinomial outbreak defined by per class growth rates and a poisson model — .test_multinomial","text":"changes list time points growth rates per week per class. initial size inital outbreak per class ... Arguments passed .test_poisson_model seed random seed kappa dispersion parameter. 1 dispersion, smaller values mean dispersion. max_time desired length time series","code":""},{"path":"/reference/dot-test_multinomial.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a multinomial outbreak defined by per class growth rates and a poisson model — .test_multinomial","text":"case count time series including class, count time columns","code":""},{"path":"/reference/dot-test_multinomial.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a multinomial outbreak defined by per class growth rates and a poisson model — .test_multinomial","text":"","code":"if (interactive()) {  ggplot2::ggplot(   .test_multinomial(),   ggplot2::aes(x=time,y=count,colour=class) )+ggplot2::geom_point()  }"},{"path":"/reference/dot-test_poisson_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate an outbreak case count series defined by growth rates using a poisson model. — .test_poisson_model","title":"Generate an outbreak case count series defined by growth rates using a poisson model. — .test_poisson_model","text":"Generate outbreak case count series defined growth rates using poisson model.","code":""},{"path":"/reference/dot-test_poisson_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate an outbreak case count series defined by growth rates using a poisson model. — .test_poisson_model","text":"","code":".test_poisson_model(   changes = tibble::tibble(time = c(0, 20, 40, 60, 80), r = c(0.1, 0, -0.1, 0, 0.1)),   kappa = 1,   initial = 100,   max_time = 104,   seed = Sys.time() )"},{"path":"/reference/dot-test_poisson_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate an outbreak case count series defined by growth rates using a poisson model. — .test_poisson_model","text":"changes dataframe holding change time points (time) growth rate per week (r) columns kappa dispersion parameter. 1 dispersion, smaller values mean dispersion. initial size initial outbreak max_time desired length time series seed random seed","code":""},{"path":"/reference/dot-test_poisson_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate an outbreak case count series defined by growth rates using a poisson model. — .test_poisson_model","text":"dataframe containing following columns: count (positive_integer) - Positive case counts associated specified timeframe time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period Ungrouped.","code":""},{"path":"/reference/dot-test_poisson_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate an outbreak case count series defined by growth rates using a poisson model. — .test_poisson_model","text":"","code":"if (interactive()) {  ggplot2::ggplot(   .test_poisson_model(kappa=0.1, seed=100),   ggplot2::aes(x=time,y=count) )+ ggplot2::geom_point()  }"},{"path":"/reference/doubling_time.html","id":null,"dir":"Reference","previous_headings":"","what":"Doubling time from growth rate — doubling_time","title":"Doubling time from growth rate — doubling_time","text":"unit doubling times always days.","code":""},{"path":"/reference/doubling_time.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Doubling time from growth rate — doubling_time","text":"","code":"doubling_time(x, ...)"},{"path":"/reference/doubling_time.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Doubling time from growth rate — doubling_time","text":"x dataframe calculated either proportion incidence growth rate calculations: e.g. dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period incidence.fit (double) - estimate incidence rate log scale incidence.se.fit (double) - standard error incidence rate estimate log scale incidence.0.025 (positive_double) - lower confidence limit incidence rate (true scale) incidence.0.5 (positive_double) - median estimate incidence rate (true scale) incidence.0.975 (positive_double) - upper confidence limit incidence rate (true scale) growth.fit (double) - estimate growth rate growth.se.fit (double) - standard error growth rate growth.0.025 (double) - lower confidence limit growth rate growth.0.5 (double) - median estimate growth rate growth.0.975 (double) - upper confidence limit growth rate mandatory groupings. default value. dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period proportion.fit (double) - estimate proportion logit scale proportion.se.fit (double) - standard error proportion estimate logit scale proportion.0.025 (proportion) - lower confidence limit proportion (true scale) proportion.0.5 (proportion) - median estimate proportion (true scale) proportion.0.975 (proportion) - upper confidence limit proportion (true scale) relative.growth.fit (double) - estimate relative growth rate relative.growth.se.fit (double) - standard error relative growth rate relative.growth.0.025 (double) - lower confidence limit relative growth rate relative.growth.0.5 (double) - median estimate relative growth rate relative.growth.0.975 (double) - upper confidence limit relative growth rate mandatory groupings. default value. ... used","code":""},{"path":"/reference/doubling_time.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Doubling time from growth rate — doubling_time","text":"dataframe additional columns doubling time relative doubling time plus confidence intervals.","code":""},{"path":"/reference/doubling_time.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Doubling time from growth rate — doubling_time","text":"","code":"ggoutbreak::england_covid %>%   ggoutbreak::poisson_locfit_model(window=21) %>%   ggoutbreak::doubling_time() %>%   dplyr::glimpse() #> Rows: 26,790 #> Columns: 15 #> Groups: class [19] #> $ class               <fct> 00_04, 00_04, 00_04, 00_04, 00_04, 00_04, 00_04, 0… #> $ time                <time_prd> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,… #> $ incidence.fit       <dbl> -17.891227, -17.395804, -16.873590, -16.331042, -1… #> $ incidence.se.fit    <dbl> 1.9111699, 1.9238465, 1.9194060, 1.9000358, 1.8681… #> $ incidence.0.025     <dbl> 4.010032e-10, 6.419738e-10, 1.091671e-09, 1.950766… #> $ incidence.0.5       <dbl> 1.698004e-08, 2.786752e-08, 4.697785e-08, 8.081996… #> $ incidence.0.975     <dbl> 7.190010e-07, 1.209705e-06, 2.021596e-06, 3.348359… #> $ growth.fit          <dbl> 0.4798757, 0.4792888, 0.4776793, 0.4752744, 0.4723… #> $ growth.se.fit       <dbl> 0.05395200, 0.05584978, 0.05729669, 0.05835042, 0.… #> $ growth.0.025        <dbl> 0.3741317, 0.3698252, 0.3653799, 0.3609097, 0.3565… #> $ growth.0.5          <dbl> 0.4798757, 0.4792888, 0.4776793, 0.4752744, 0.4723… #> $ growth.0.975        <dbl> 0.5856197, 0.5887523, 0.5899788, 0.5896391, 0.5880… #> $ doubling_time.0.5   <dbl> 1.444431, 1.446200, 1.451072, 1.458415, 1.467596, … #> $ doubling_time.0.025 <dbl> 1.183613, 1.177315, 1.174868, 1.175545, 1.178641, … #> $ doubling_time.0.975 <dbl> 1.852682, 1.874256, 1.897059, 1.920556, 1.944248, …"},{"path":"/reference/england_consensus_growth_rate.html","id":null,"dir":"Reference","previous_headings":"","what":"The SPI-M-O England consensus growth rate — england_consensus_growth_rate","title":"The SPI-M-O England consensus growth rate — england_consensus_growth_rate","text":"SPI-M-O used range different statistical mechanistic models produce estimates growth rate epidemic various data sources (including early version ggoutbreak).","code":""},{"path":"/reference/england_consensus_growth_rate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The SPI-M-O England consensus growth rate — england_consensus_growth_rate","text":"","code":"data(england_consensus_growth_rate)"},{"path":"/reference/england_consensus_growth_rate.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"The SPI-M-O England consensus growth rate — england_consensus_growth_rate","text":"dataframe containing following columns: date (date) - date estimate low (numeric) - lower published estimate growth rate high (numeric) - higher published estimate growth rate mandatory groupings. default value. 111 rows 3 columns","code":""},{"path":"/reference/england_consensus_rt.html","id":null,"dir":"Reference","previous_headings":"","what":"The SPI-M-O England consensus reproduction number — england_consensus_rt","title":"The SPI-M-O England consensus reproduction number — england_consensus_rt","text":"SPI-M-O used range different statistical mechanistic models produce estimates  reproduction number epidemic various data sources.","code":""},{"path":"/reference/england_consensus_rt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The SPI-M-O England consensus reproduction number — england_consensus_rt","text":"","code":"data(england_consensus_rt)"},{"path":"/reference/england_consensus_rt.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"The SPI-M-O England consensus reproduction number — england_consensus_rt","text":"dataframe containing following columns: date (date) - date estimate low (numeric) - lower published estimate reproduction number high (numeric) - higher published estimate reproduction number mandatory groupings. default value. 113 rows 3 columns","code":""},{"path":"/reference/england_covid.html","id":null,"dir":"Reference","previous_headings":"","what":"Daily COVID-19 case counts by age group in England — england_covid","title":"Daily COVID-19 case counts by age group in England — england_covid","text":"dataset daily count covid cases age group England downloaded UKHSA coronavirus API, formatted use ggoutbreak. denominator calculated overall positive count age groups. data set can used calculate group-wise incidence absolute growth rates group wise proportions relative growth rates.","code":""},{"path":"/reference/england_covid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Daily COVID-19 case counts by age group in England — england_covid","text":"","code":"data(england_covid)"},{"path":"/reference/england_covid.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Daily COVID-19 case counts by age group in England — england_covid","text":"dataframe containing following columns: date (.Date) - date column class (enum(00_04,05_09,10_14,15_19,20_24,25_29,30_34,35_39,40_44,45_49,50_54,55_59,60_64,65_69,70_74,75_79,80_84,85_89,90+)) - class column count (numeric) - test positives age group denom (numeric) - test positives age groups time (time_period) - time column Must grouped : class (groupings allowed). default value. 26790 rows 5 columns","code":""},{"path":"/reference/england_covid_pcr_positivity.html","id":null,"dir":"Reference","previous_headings":"","what":"England COVID-19 PCR test positivity — england_covid_pcr_positivity","title":"England COVID-19 PCR test positivity — england_covid_pcr_positivity","text":"coronavirus.gov.uk dashboard published tests conducted positive results separate data sets range geographies. case data combined testing rate denominator, positives count England.","code":""},{"path":"/reference/england_covid_pcr_positivity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"England COVID-19 PCR test positivity — england_covid_pcr_positivity","text":"","code":"data(england_covid_pcr_positivity)"},{"path":"/reference/england_covid_pcr_positivity.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"England COVID-19 PCR test positivity — england_covid_pcr_positivity","text":"dataframe containing following columns: date (date) - daily time series time (time_period) - time column count (numeric) - test positives England day denom (numeric) - total tests conducted day mandatory groupings. default value. 1413 rows 4 columns","code":""},{"path":"/reference/england_covid_proportion.html","id":null,"dir":"Reference","previous_headings":"","what":"England COVID by age group for ascertainment — england_covid_proportion","title":"England COVID by age group for ascertainment — england_covid_proportion","text":"age group stratified dataset ","code":""},{"path":"/reference/england_covid_proportion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"England COVID by age group for ascertainment — england_covid_proportion","text":"","code":"data(england_covid_proportion)"},{"path":"/reference/england_covid_proportion.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"England COVID by age group for ascertainment — england_covid_proportion","text":"dataframe containing following columns: class (character) - age group date (date) - start date week count (numeric) - count COVID positives denom (numeric) - number COVID tests performed population (numeric) - size population age group time (time_period) - time column (weekly) Must grouped : class (groupings allowed). default value. 1050 rows 6 columns","code":""},{"path":"/reference/england_covid_proportion.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"England COVID by age group for ascertainment — england_covid_proportion","text":"coronavirus.gov.uk site positive cases aggregated 10 year age groups weekly time. NHS test trace date reported regional age group testing effort aggregated country level. ONS 2021 census population aggregated 10 year age groups.","code":""},{"path":"/reference/england_demographics.html","id":null,"dir":"Reference","previous_headings":"","what":"England demographics — england_demographics","title":"England demographics — england_demographics","text":"Population counts 5 year age group England 2021 census.","code":""},{"path":"/reference/england_demographics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"England demographics — england_demographics","text":"","code":"data(england_demographics)"},{"path":"/reference/england_demographics.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"England demographics — england_demographics","text":"dataframe containing following columns: class (enum(00_04,05_09,10_14,15_19,20_24,25_29,30_34,35_39,40_44,45_49,50_54,55_59,60_64,65_69,70_74,75_79,80_84,85_89,90+)) - class column population (numeric) - population count column baseline_proportion (numeric) - baseline proportion proportion age group makes total. Must grouped : class (groupings allowed). default value. 19 rows 3 columns","code":""},{"path":"/reference/england_demographics.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"England demographics — england_demographics","text":"https://www.ons.gov.uk/file?uri=/peoplepopulationandcommunity/populationandmigration/populationestimates/datasets/populationandhouseholdestimatesenglandandwalescensus2021/census2021/census2021firstresultsenglandwales1.xlsx","code":""},{"path":"/reference/england_events.html","id":null,"dir":"Reference","previous_headings":"","what":"Key dated in the COVID-19 response in England — england_events","title":"Key dated in the COVID-19 response in England — england_events","text":"includes mainly dates lockdowns, releases social distancing measures dates new variants first detected.","code":""},{"path":"/reference/england_events.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Key dated in the COVID-19 response in England — england_events","text":"","code":"data(england_events)"},{"path":"/reference/england_events.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Key dated in the COVID-19 response in England — england_events","text":"dataframe containing following columns: label (character) - event label start (date) - event start date end (date) - (optional) event end date mandatory groupings. default value. 13 rows 3 columns","code":""},{"path":"/reference/england_nhs_app.html","id":null,"dir":"Reference","previous_headings":"","what":"NHS COVID-19 app data — england_nhs_app","title":"NHS COVID-19 app data — england_nhs_app","text":"check-(social activity) alerts (self isolation instruction) data NHS COVID-19 app, aggregated country level week week basis.","code":""},{"path":"/reference/england_nhs_app.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"NHS COVID-19 app data — england_nhs_app","text":"","code":"data(england_nhs_app)"},{"path":"/reference/england_nhs_app.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"NHS COVID-19 app data — england_nhs_app","text":"dataframe containing following columns: date (date) - start date week alerts (integer) - count self-isolation alerts visits (integer) - number venue check-ins representing visits social venues. time (time_period) - time column mandatory groupings. default value. 137 rows 4 columns","code":""},{"path":"/reference/england_ons_infection_survey.html","id":null,"dir":"Reference","previous_headings":"","what":"The england_ons_infection_survey dataset — england_ons_infection_survey","title":"The england_ons_infection_survey dataset — england_ons_infection_survey","text":"COVID-19 ONS infection survey took random sample population provides estimate prevalence COVID-19 supposedly free ascertainment bias.","code":""},{"path":"/reference/england_ons_infection_survey.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The england_ons_infection_survey dataset — england_ons_infection_survey","text":"","code":"data(england_ons_infection_survey)"},{"path":"/reference/england_ons_infection_survey.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"The england_ons_infection_survey dataset — england_ons_infection_survey","text":"dataframe containing following columns: date (date) - date column geography (character) - geography column proportion.0.5 (numeric) - median proportion people region testing positive COVID-19 proportion.0.025 (numeric) - lower CI proportion people region testing positive COVID-19 proportion.0.975 (numeric) - upper CI proportion people region testing positive COVID-19 denom (integer) - sample size estimate made (daily rate inferred weekly sample sizes.) time (time_period) - time column mandatory groupings. default value. 9820 rows 7 columns","code":""},{"path":"/reference/england_ons_infection_survey.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The england_ons_infection_survey dataset — england_ons_infection_survey","text":"data available : https://www.ons.gov.uk/file?uri=/peoplepopulationandcommunity/healthandsocialcare/conditionsanddiseases/datasets/coronaviruscovid19infectionsurveydata/2023/20230310covid19infectionsurveydatasetsengland.xlsx","code":""},{"path":"/reference/england_variants.html","id":null,"dir":"Reference","previous_headings":"","what":"Counts of COVID-19 variants — england_variants","title":"Counts of COVID-19 variants — england_variants","text":"Data COG-UK Sanger centre sequencing programme. data made available Welcome foundation Lower tier local authority level, weekly timeseries counts per variant. Variants assigned using tree structure Pango lineage. Different sub-lineages aggregated major variants concern.","code":""},{"path":"/reference/england_variants.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Counts of COVID-19 variants — england_variants","text":"","code":"data(england_variants)"},{"path":"/reference/england_variants.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Counts of COVID-19 variants — england_variants","text":"dataframe containing following columns: date (date) - end date week time (time_period) - time column class (enum(,Alpha (B.1.1.7),Delta (B.1.617.2),Delta (AY.4),Omicron (),Omicron (BA.2),Omicron (BA.4),Omicron (BA.5),XBB (),Kraken (XBB.1.5),Arcturus (XBB.1.16),Eris (EG.5.1))) - class column who_class (enum(,Alpha,Delta,Omicron,Kraken,Arcturus,Eris)) - who_class column count (numeric) - weekly count column denom (numeric) - number sequences performed week Must grouped : class (groupings allowed). default value. 479 rows 6 columns","code":""},{"path":"/reference/fdmy.html","id":null,"dir":"Reference","previous_headings":"","what":"Format date as dmy — fdmy","title":"Format date as dmy — fdmy","text":"Format date dmy","code":""},{"path":"/reference/fdmy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format date as dmy — fdmy","text":"","code":"fdmy(date)"},{"path":"/reference/fdmy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format date as dmy — fdmy","text":"date date convert","code":""},{"path":"/reference/fdmy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Format date as dmy — fdmy","text":"formatted date","code":""},{"path":"/reference/fdmy.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Format date as dmy — fdmy","text":"","code":"fdmy(Sys.Date()) #> [1] \"21 Aug 2024\""},{"path":"/reference/full_seq.Date.html","id":null,"dir":"Reference","previous_headings":"","what":"Expand a date vector to the full range of possible dates — date_seq.Date","title":"Expand a date vector to the full range of possible dates — date_seq.Date","text":"Derive vector observation dates, complete ordered sequence periods regular time series, length periods specified, number od days, weeks, years etc. E.g. can convert random set dates ordered complete list 1 week intervals (2 month intervals) spanning range dates. interesting problems regarding put breaks within month week. Often either based specific date (e.g. yearly periods starting 2020-01-01) day week (e.g. 2 weekly periods staring sunday) maybe relative input time series (weekly ending last date data). also problem consider data may incomplete starting end periods, may comparable periods, may need exclude result.","code":""},{"path":"/reference/full_seq.Date.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expand a date vector to the full range of possible dates — date_seq.Date","text":"","code":"# S3 method for Date date_seq(x, period = .day_interval(x), anchor = \"start\", complete = FALSE, ...)"},{"path":"/reference/full_seq.Date.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expand a date vector to the full range of possible dates — date_seq.Date","text":"x vector dates, possibly including NA values period gap observations number days natural language definition period \"1 week\", '2 weeks', '1 month', etc. given derived dates. anchor defines day appears sequence (extend far). Given either date, \"start\", \"end\" day week, e.g. \"mon\". complete truncate incomplete start end periods ... ignored","code":""},{"path":"/reference/full_seq.Date.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expand a date vector to the full range of possible dates — date_seq.Date","text":"vector dates regular periods minimum maximum dates, boundaries defined anchor.","code":""},{"path":"/reference/full_seq.Date.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expand a date vector to the full range of possible dates — date_seq.Date","text":"","code":"date_seq(as.Date(c(\"2020-01-01\",\"2020-02-01\",\"2020-01-15\",\"2020-02-01\",NA)), \"2 days\") #>  [1] \"2020-01-01\" \"2020-01-03\" \"2020-01-05\" \"2020-01-07\" \"2020-01-09\" #>  [6] \"2020-01-11\" \"2020-01-13\" \"2020-01-15\" \"2020-01-17\" \"2020-01-19\" #> [11] \"2020-01-21\" \"2020-01-23\" \"2020-01-25\" \"2020-01-27\" \"2020-01-29\" #> [16] \"2020-01-31\""},{"path":"/reference/full_seq.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the full sequence of values in a vector — full_seq","title":"Create the full sequence of values in a vector — full_seq","text":"useful want fill missing values observed . example, date_seq(c(1, 2, 4, 6), 1) return 1:6.","code":""},{"path":"/reference/full_seq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the full sequence of values in a vector — full_seq","text":"","code":"date_seq(x, period, ...)"},{"path":"/reference/full_seq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the full sequence of values in a vector — full_seq","text":"x numeric date vector period Gap observation. existing data checked ensure actually periodicity. ... subtype methods","code":""},{"path":"/reference/full_seq.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create the full sequence of values in a vector — full_seq","text":"vector type input","code":""},{"path":"/reference/full_seq.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create the full sequence of values in a vector — full_seq","text":"","code":"date_seq(c(1, 2, 4, 5, 10), 1) #>  [1]  1  2  3  4  5  6  7  8  9 10"},{"path":"/reference/full_seq.numeric.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the full sequence of values in a vector — full_seq.numeric","title":"Create the full sequence of values in a vector — full_seq.numeric","text":"useful want fill missing values observed . example, date_seq(c(1, 2, 4, 6), 1) return 1:6.","code":""},{"path":"/reference/full_seq.numeric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the full sequence of values in a vector — full_seq.numeric","text":"","code":"# S3 method for numeric date_seq(x, period = 1, tol = 1e-06, ...)"},{"path":"/reference/full_seq.numeric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the full sequence of values in a vector — full_seq.numeric","text":"x numeric date vector period Gap observation. existing data checked ensure actually periodicity. tol Numerical tolerance checking periodicity. ... subtype methods","code":""},{"path":"/reference/full_seq.numeric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create the full sequence of values in a vector — full_seq.numeric","text":"vector type input","code":""},{"path":"/reference/full_seq.numeric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create the full sequence of values in a vector — full_seq.numeric","text":"","code":"date_seq(c(1, 2, 4, 5, 10), 1) #>  [1]  1  2  3  4  5  6  7  8  9 10"},{"path":"/reference/full_seq.time_period.html","id":null,"dir":"Reference","previous_headings":"","what":"Expand a time_period vector to the full range of possible times — date_seq.time_period","title":"Expand a time_period vector to the full range of possible times — date_seq.time_period","text":"Derive vector observation time_periods, complete ordered sequence periods regular time series, length periods specified, number days, weeks, years etc. E.g. can convert random set times ordered complete list 1 week intervals (2 month intervals) spanning range dates. interesting problems regarding put breaks within month week. Often either based specific date (e.g. yearly periods starting 2020-01-01) day week (e.g. 2 weekly periods staring sunday) maybe relative input time series (weekly ending last date data). also problem consider data may incomplete starting end periods, may comparable periods, may need exclude result.","code":""},{"path":"/reference/full_seq.time_period.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expand a time_period vector to the full range of possible times — date_seq.time_period","text":"","code":"# S3 method for time_period date_seq(x, period = attributes(x)$unit, complete = FALSE, ...)"},{"path":"/reference/full_seq.time_period.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expand a time_period vector to the full range of possible times — date_seq.time_period","text":"x time period vector period gap observations number days natural language definition period \"1 week\", '2 weeks', '1 month', etc. given derived dates. complete truncate incomplete start end periods ... ignored","code":""},{"path":"/reference/full_seq.time_period.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expand a time_period vector to the full range of possible times — date_seq.time_period","text":"vector time_periods regular periods minimum maximum dates, boundaries defined anchor.","code":""},{"path":"/reference/full_seq.time_period.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expand a time_period vector to the full range of possible times — date_seq.time_period","text":"","code":"tmp = as.time_period(c(0,10,100), 7, \"2020-01-01\") date_seq(tmp, \"7 days\") #> time unit: week, origin: 2020-01-01 (a Wednesday) #>  [1]   0  10  20  30  40  50  60  70  80  90 100"},{"path":"/reference/geom_events.html","id":null,"dir":"Reference","previous_headings":"","what":"Add time series event markers to a timeseries plot. — geom_events","title":"Add time series event markers to a timeseries plot. — geom_events","text":"x axis must date.","code":""},{"path":"/reference/geom_events.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add time series event markers to a timeseries plot. — geom_events","text":"","code":"geom_events(   events = i_events,   event_label_size = 7,   event_label_colour = \"black\",   event_label_angle = -30,   event_line_colour = \"grey50\",   event_fill_colour = \"grey50\",   hide_labels = FALSE,   guide_axis = ggplot2::derive(),   ... )"},{"path":"/reference/geom_events.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add time series event markers to a timeseries plot. — geom_events","text":"events Significant events time spans dataframe containing following columns: label (character) - event label start (date) - start date, date event end (date) - end date NA single event mandatory groupings. default value defined. event_label_size big make event label event_label_colour event label colour event_label_angle event label colour event_line_colour event line colour event_fill_colour event area fill hide_labels show labels guide_axis guide axis configuration labels (see ggplot2::guide_axis ggplot2::dup_axis). can used specify position amongst things. ... Arguments passed ggplot2::scale_x_date name name scale. Used axis legend title. waiver(), default, name scale taken first mapping used aesthetic. NULL, legend title omitted. breaks One : NULL breaks waiver() breaks specified date_breaks Date/POSIXct vector giving positions breaks function takes limits input returns breaks output date_breaks string giving distance breaks like \"2 weeks\", \"10 years\". breaks date_breaks specified, date_breaks wins. Valid specifications 'sec', 'min', 'hour', 'day', 'week', 'month' 'year', optionally followed 's'. labels One : NULL labels waiver() default labels computed transformation object character vector giving labels (must length breaks) expression vector (must length breaks). See ?plotmath details. function takes breaks input returns labels output. Also accepts rlang lambda function notation. date_labels string giving formatting specification labels. Codes defined strftime(). labels date_labels specified, date_labels wins. minor_breaks One : NULL breaks waiver() breaks specified date_minor_breaks Date/POSIXct vector giving positions minor breaks function takes limits input returns minor breaks output date_minor_breaks string giving distance minor breaks like \"2 weeks\", \"10 years\". minor_breaks date_minor_breaks specified, date_minor_breaks wins. Valid specifications 'sec', 'min', 'hour', 'day', 'week', 'month' 'year', optionally followed 's'. limits One : NULL use default scale range numeric vector length two providing limits scale. Use NA refer existing minimum maximum function accepts existing (automatic) limits returns new limits. Also accepts rlang lambda function notation. Note setting limits positional scales remove data outside limits. purpose zoom, use limit argument coordinate system (see coord_cartesian()). expand position scales, vector range expansion constants used add padding around data ensure placed distance away axes. Use convenience function expansion() generate values expand argument. defaults expand scale 5% side continuous variables, 0.6 units side discrete variables. oob One : Function handles limits outside scale limits (bounds). Also accepts rlang lambda function notation. default (scales::censor()) replaces bounds values NA. scales::squish() squishing bounds values range. scales::squish_infinite() squishing infinite values range. guide function used create guide name. See guides() information. position position scales, position axis. left right y axes, top bottom x axes.","code":""},{"path":"/reference/geom_events.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add time series event markers to a timeseries plot. — geom_events","text":"set geoms timeseries.","code":""},{"path":"/reference/germany_covid.html","id":null,"dir":"Reference","previous_headings":"","what":"Weekly COVID-19 case counts by age group in Germany — germany_covid","title":"Weekly COVID-19 case counts by age group in Germany — germany_covid","text":"dataset weekly count covid cases age group Germany downloaded Robert Koch Institute Survstat service, formatted use growth rates. denominator calculated overall positive count age groups. data set can used calculate group-wise incidence absolute growth rates group wise proportions relative growth rates.","code":""},{"path":"/reference/germany_covid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Weekly COVID-19 case counts by age group in Germany — germany_covid","text":"","code":"data(germany_covid)"},{"path":"/reference/germany_covid.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Weekly COVID-19 case counts by age group in Germany — germany_covid","text":"dataframe containing following columns: class (enum(0–14,15–19,20–24,25–29,30–39,40–49,50–59,60–69,70–79,80+,Unknown, .ordered=TRUE)) - age group date (.Date) - date column count (integer) - test positives age group time (time_period) - time column denom (integer) - test positives age groups Must grouped : class (groupings allowed). default value. 2070 rows 6 columns","code":""},{"path":"/reference/germany_demographics.html","id":null,"dir":"Reference","previous_headings":"","what":"Germany demographics — germany_demographics","title":"Germany demographics — germany_demographics","text":"Derived Robert Koch Survstat service comparing counts incidence rates.","code":""},{"path":"/reference/germany_demographics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Germany demographics — germany_demographics","text":"","code":"data(germany_demographics)"},{"path":"/reference/germany_demographics.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Germany demographics — germany_demographics","text":"dataframe containing following columns: class (enum(0–14,15–19,20–24,25–29,30–39,40–49,50–59,60–69,70–79,80+, .ordered=TRUE)) - class column population (integer) - population column Must grouped : class (groupings allowed). default value. 10 rows 2 columns","code":""},{"path":"/reference/is.Date.html","id":null,"dir":"Reference","previous_headings":"","what":"Check whether vector is a date — is.Date","title":"Check whether vector is a date — is.Date","text":"Check whether vector date","code":""},{"path":"/reference/is.Date.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check whether vector is a date — is.Date","text":"","code":"is.Date(x)"},{"path":"/reference/is.Date.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check whether vector is a date — is.Date","text":"x vector check","code":""},{"path":"/reference/is.Date.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check whether vector is a date — is.Date","text":"TRUE dates, FALSE otherwise","code":""},{"path":"/reference/is.Date.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check whether vector is a date — is.Date","text":"","code":"is.Date(Sys.Date()) #> [1] TRUE"},{"path":"/reference/labels.time_period.html","id":null,"dir":"Reference","previous_headings":"","what":"Label a time period — labels.time_period","title":"Label a time period — labels.time_period","text":"Create set labels time period based start duration period. format configurable using start end dates dfmt ifmt parameters, however time period names used preference.","code":""},{"path":"/reference/labels.time_period.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Label a time period — labels.time_period","text":"","code":"# S3 method for time_period labels(   object,   ...,   dfmt = \"%d/%b\",   ifmt = \"{start} — {end}\",   na.value = \"Unknown\" )"},{"path":"/reference/labels.time_period.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Label a time period — labels.time_period","text":"object set decimal times time_period ... used dfmt strptime format specification format date ifmt glue spec referring start end period formatted date na.value label NA times","code":""},{"path":"/reference/labels.time_period.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Label a time period — labels.time_period","text":"set character labels time","code":""},{"path":"/reference/labels.time_period.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Label a time period — labels.time_period","text":"","code":"eg = as.time_period(Sys.Date()+0:10*7, anchor=\"start\") #> No unit given. Guessing a sensible value from the dates gives: 7d 0H 0M 0S labels(eg) #> 21/Aug — 27/Aug #> 28/Aug — 03/Sep #> 04/Sep — 10/Sep #> 11/Sep — 17/Sep #> 18/Sep — 24/Sep #> 25/Sep — 01/Oct #> 02/Oct — 08/Oct #> 09/Oct — 15/Oct #> 16/Oct — 22/Oct #> 23/Oct — 29/Oct #> 30/Oct — 05/Nov labels(eg, ifmt=\"{start}\", dfmt=\"%d/%b/%y\") #> 21/Aug/24 #> 28/Aug/24 #> 04/Sep/24 #> 11/Sep/24 #> 18/Sep/24 #> 25/Sep/24 #> 02/Oct/24 #> 09/Oct/24 #> 16/Oct/24 #> 23/Oct/24 #> 30/Oct/24 labels(eg, ifmt=\"until {end}\", dfmt=\"%d %b %Y\") #> until 27 Aug 2024 #> until 03 Sep 2024 #> until 10 Sep 2024 #> until 17 Sep 2024 #> until 24 Sep 2024 #> until 01 Oct 2024 #> until 08 Oct 2024 #> until 15 Oct 2024 #> until 22 Oct 2024 #> until 29 Oct 2024 #> until 05 Nov 2024  # labels retained in constructor: eg2 = Sys.Date()+0:10*7 names(eg2) = paste0(\"week \",0:10) labels(eg2) #>  [1] \"week 0\"  \"week 1\"  \"week 2\"  \"week 3\"  \"week 4\"  \"week 5\"  \"week 6\"  #>  [8] \"week 7\"  \"week 8\"  \"week 9\"  \"week 10\" labels(as.time_period(eg2, anchor=\"start\")) #> No unit given. Guessing a sensible value from the dates gives: 7d 0H 0M 0S #>  [1] \"week 0\"  \"week 1\"  \"week 2\"  \"week 3\"  \"week 4\"  \"week 5\"  \"week 6\"  #>  [8] \"week 7\"  \"week 8\"  \"week 9\"  \"week 10\""},{"path":"/reference/logit_trans.html","id":null,"dir":"Reference","previous_headings":"","what":"logit scale — logit_trans","title":"logit scale — logit_trans","text":"Perform logit scaling correct axis formatting. used directly ggplot (e.g. ggplot2::scale_y_continuous(trans = \"logit\") )","code":""},{"path":"/reference/logit_trans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"logit scale — logit_trans","text":"","code":"logit_trans(n = 5, ...)"},{"path":"/reference/logit_trans.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"logit scale — logit_trans","text":"n number breaks ... used, compatibility","code":""},{"path":"/reference/logit_trans.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"logit scale — logit_trans","text":"scales object","code":""},{"path":"/reference/logit_trans.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"logit scale — logit_trans","text":"","code":"library(ggplot2) library(tibble)  tibble::tibble(pvalue = c(0.001, 0.05, 0.1), fold_change = 1:3) %>%  ggplot2::ggplot(aes(fold_change , pvalue)) +  ggplot2::geom_point() +  ggplot2::scale_y_continuous(trans = \"logit\")"},{"path":"/reference/max_date.html","id":null,"dir":"Reference","previous_headings":"","what":"The maximum of a set of dates — max_date","title":"The maximum of a set of dates — max_date","text":"max.Date returns integer -Inf set NA dates. usually inconvenient.","code":""},{"path":"/reference/max_date.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The maximum of a set of dates — max_date","text":"","code":"max_date(x, ...)"},{"path":"/reference/max_date.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The maximum of a set of dates — max_date","text":"x vector dates ... ignored","code":""},{"path":"/reference/max_date.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The maximum of a set of dates — max_date","text":"date. `0001-01-01`` well defined minimum.","code":""},{"path":"/reference/max_date.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The maximum of a set of dates — max_date","text":"","code":"max_date(NA) #> [1] \"1-01-01\""},{"path":"/reference/min_date.html","id":null,"dir":"Reference","previous_headings":"","what":"The minimum of a set of dates — min_date","title":"The minimum of a set of dates — min_date","text":"min.Date returns integer Inf set NA dates. usually inconvenient.","code":""},{"path":"/reference/min_date.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The minimum of a set of dates — min_date","text":"","code":"min_date(x, ...)"},{"path":"/reference/min_date.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The minimum of a set of dates — min_date","text":"x vector dates ... ignored","code":""},{"path":"/reference/min_date.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The minimum of a set of dates — min_date","text":"date. 9999-12-31 well defined minimum.","code":""},{"path":"/reference/min_date.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The minimum of a set of dates — min_date","text":"","code":"min_date(NA) #> [1] \"9999-12-31\""},{"path":"/reference/multinomial_nnet_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Multinomial time-series model. — multinomial_nnet_model","title":"Multinomial time-series model. — multinomial_nnet_model","text":"Takes list times, classes counts, e.g. COGUK variant like data set time, (multinomial) class (e.g. variant) count count time period. Fits quadratic B-spline time proportion data using nnet::multinom, approx one degree freedom per class per window units time series","code":""},{"path":"/reference/multinomial_nnet_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multinomial time-series model. — multinomial_nnet_model","text":"","code":"multinomial_nnet_model(   d = i_multinomial_input,   ...,   window = 14,   frequency = \"1 day\",   predict = TRUE )"},{"path":"/reference/multinomial_nnet_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multinomial time-series model. — multinomial_nnet_model","text":"d Multiclass count input ... used present allow proportion model used group_modify window number data points knots, smaller values result less smoothing, large value . frequency density output estimates. predict result prediction. false return model.","code":""},{"path":"/reference/multinomial_nnet_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multinomial time-series model. — multinomial_nnet_model","text":"new dataframe time (time period), class, proportion.0.5, model object","code":""},{"path":"/reference/multinomial_nnet_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multinomial time-series model. — multinomial_nnet_model","text":"","code":"if (FALSE) {   # not run due to long running   tmp = ggoutbreak::england_covid %>%     dplyr::filter(date > \"2022-01-01\") %>%     ggoutbreak::multinomial_nnet_model(window=21) %>%     dplyr::glimpse() }"},{"path":"/reference/normalise_incidence.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate a normalised incidence rate per capita — normalise_incidence","title":"Calculate a normalised incidence rate per capita — normalise_incidence","text":"assumes positive disease counts stratified population grouping, e.g. geography age, estimates size population time period. Normalising population size allows us compare groups.","code":""},{"path":"/reference/normalise_incidence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate a normalised incidence rate per capita — normalise_incidence","text":"","code":"normalise_incidence(   modelled = i_timeseries,   ...,   population_unit = 1e+05,   normalise_time = FALSE )"},{"path":"/reference/normalise_incidence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate a normalised incidence rate per capita — normalise_incidence","text":"modelled Model output processing raw dataframe something like poission_locfit_model dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` mandatory groupings. default value. ... used population_unit population unit want incidence e.g. per 100K normalise_time default behaviour incidence keep time units input data. parameter set TRUE incidence rates calculated per year. given lubridate period string e.g. \"1 day\" incidence calculated time period.","code":""},{"path":"/reference/normalise_incidence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate a normalised incidence rate per capita — normalise_incidence","text":"dataframe incidence rates per unit capita. dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period incidence.per_capita.fit (double) - estimate incidence per capita rate log scale incidence.per_capita.se.fit (double) - standard error incidence per capita rate estimate log scale incidence.per_capita.0.025 (positive_double) - lower confidence limit incidence per capita rate (true scale) incidence.per_capita.0.5 (positive_double) - median estimate incidence per capita rate (true scale) incidence.per_capita.0.975 (positive_double) - upper confidence limit incidence per capita rate (true scale) population_unit (double) - population unit per capita incidence rate calculated mandatory groupings. default value.","code":""},{"path":"/reference/normalise_incidence.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate a normalised incidence rate per capita — normalise_incidence","text":"","code":"tmp = ggoutbreak::england_covid %>%   ggoutbreak::poisson_locfit_model(window=21) %>%   ggoutbreak::normalise_incidence(ggoutbreak::england_demographics) %>%   dplyr::glimpse() #> Rows: 26,790 #> Columns: 21 #> Groups: class [19] #> $ class                       <fct> 00_04, 00_04, 00_04, 00_04, 00_04, 00_04, … #> $ time                        <time_prd> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,… #> $ incidence.fit               <dbl> -17.891227, -17.395804, -16.873590, -16.33… #> $ incidence.se.fit            <dbl> 1.9111699, 1.9238465, 1.9194060, 1.9000358… #> $ incidence.0.025             <dbl> 4.010032e-10, 6.419738e-10, 1.091671e-09, … #> $ incidence.0.5               <dbl> 1.698004e-08, 2.786752e-08, 4.697785e-08, … #> $ incidence.0.975             <dbl> 7.190010e-07, 1.209705e-06, 2.021596e-06, … #> $ growth.fit                  <dbl> 0.4798757, 0.4792888, 0.4776793, 0.4752744… #> $ growth.se.fit               <dbl> 0.05395200, 0.05584978, 0.05729669, 0.0583… #> $ growth.0.025                <dbl> 0.3741317, 0.3698252, 0.3653799, 0.3609097… #> $ growth.0.5                  <dbl> 0.4798757, 0.4792888, 0.4776793, 0.4752744… #> $ growth.0.975                <dbl> 0.5856197, 0.5887523, 0.5899788, 0.5896391… #> $ population                  <int> 3077000, 3077000, 3077000, 3077000, 307700… #> $ baseline_proportion         <dbl> 0.05447011, 0.05447011, 0.05447011, 0.0544… #> $ incidence.per_capita.0.025  <dbl> 1.303228e-11, 2.086363e-11, 3.547843e-11, … #> $ incidence.per_capita.0.5    <dbl> 5.518375e-10, 9.056719e-10, 1.526742e-09, … #> $ incidence.per_capita.0.975  <dbl> 2.336695e-08, 3.931443e-08, 6.570024e-08, … #> $ incidence.per_capita.fit    <dbl> -21.317768, -20.822344, -20.300130, -19.75… #> $ incidence.per_capita.se.fit <dbl> -1.515370, -1.502694, -1.507134, -1.526504… #> $ population_unit             <dbl> 1e+05, 1e+05, 1e+05, 1e+05, 1e+05, 1e+05, … #> $ time_unit                   <Period> 1d 0H 0M 0S, 1d 0H 0M 0S, 1d 0H 0M 0S, …"},{"path":"/reference/normalise_incidence.incidence.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate a normalised incidence rate per capita — normalise_incidence.incidence","title":"Calculate a normalised incidence rate per capita — normalise_incidence.incidence","text":"assumes positive disease counts stratified population grouping, e.g. geography age, estimates size population time period. Normalising population size allows us compare groups.","code":""},{"path":"/reference/normalise_incidence.incidence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate a normalised incidence rate per capita — normalise_incidence.incidence","text":"","code":"normalise_incidence.incidence(   modelled = i_incidence_model,   pop = i_population_data,   ...,   population_unit = 1e+05,   normalise_time = FALSE )"},{"path":"/reference/normalise_incidence.incidence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate a normalised incidence rate per capita — normalise_incidence.incidence","text":"modelled Model output processing raw dataframe something like poission_locfit_model dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` incidence.fit (double) - estimate incidence rate log scale incidence.se.fit (double) - standard error incidence rate estimate log scale incidence.0.025 (positive_double) - lower confidence limit incidence rate (true scale) incidence.0.5 (positive_double) - median estimate incidence rate (true scale) incidence.0.975 (positive_double) - upper confidence limit incidence rate (true scale) mandatory groupings. default value. pop population data must grouped way modelled. dataframe containing following columns: population (positive_integer) - Size population mandatory groupings. default value. ... used population_unit population unit want incidence e.g. per 100K normalise_time default behaviour incidence keep time units input data. parameter set TRUE incidence rates calculated per year. given lubridate period string e.g. \"1 day\" incidence calculated time period.","code":""},{"path":"/reference/normalise_incidence.incidence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate a normalised incidence rate per capita — normalise_incidence.incidence","text":"dataframe incidence rates per unit capita. dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period incidence.per_capita.fit (double) - estimate incidence per capita rate log scale incidence.per_capita.se.fit (double) - standard error incidence per capita rate estimate log scale incidence.per_capita.0.025 (positive_double) - lower confidence limit incidence per capita rate (true scale) incidence.per_capita.0.5 (positive_double) - median estimate incidence per capita rate (true scale) incidence.per_capita.0.975 (positive_double) - upper confidence limit incidence per capita rate (true scale) population_unit (double) - population unit per capita incidence rate calculated mandatory groupings. default value.","code":""},{"path":"/reference/normalise_incidence.incidence.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate a normalised incidence rate per capita — normalise_incidence.incidence","text":"","code":"tmp = ggoutbreak::england_covid %>%   ggoutbreak::poisson_locfit_model(window=21) %>%   ggoutbreak::normalise_incidence(ggoutbreak::england_demographics) %>%   dplyr::glimpse() #> Rows: 26,790 #> Columns: 21 #> Groups: class [19] #> $ class                       <fct> 00_04, 00_04, 00_04, 00_04, 00_04, 00_04, … #> $ time                        <time_prd> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,… #> $ incidence.fit               <dbl> -17.891227, -17.395804, -16.873590, -16.33… #> $ incidence.se.fit            <dbl> 1.9111699, 1.9238465, 1.9194060, 1.9000358… #> $ incidence.0.025             <dbl> 4.010032e-10, 6.419738e-10, 1.091671e-09, … #> $ incidence.0.5               <dbl> 1.698004e-08, 2.786752e-08, 4.697785e-08, … #> $ incidence.0.975             <dbl> 7.190010e-07, 1.209705e-06, 2.021596e-06, … #> $ growth.fit                  <dbl> 0.4798757, 0.4792888, 0.4776793, 0.4752744… #> $ growth.se.fit               <dbl> 0.05395200, 0.05584978, 0.05729669, 0.0583… #> $ growth.0.025                <dbl> 0.3741317, 0.3698252, 0.3653799, 0.3609097… #> $ growth.0.5                  <dbl> 0.4798757, 0.4792888, 0.4776793, 0.4752744… #> $ growth.0.975                <dbl> 0.5856197, 0.5887523, 0.5899788, 0.5896391… #> $ population                  <int> 3077000, 3077000, 3077000, 3077000, 307700… #> $ baseline_proportion         <dbl> 0.05447011, 0.05447011, 0.05447011, 0.0544… #> $ incidence.per_capita.0.025  <dbl> 1.303228e-11, 2.086363e-11, 3.547843e-11, … #> $ incidence.per_capita.0.5    <dbl> 5.518375e-10, 9.056719e-10, 1.526742e-09, … #> $ incidence.per_capita.0.975  <dbl> 2.336695e-08, 3.931443e-08, 6.570024e-08, … #> $ incidence.per_capita.fit    <dbl> -21.317768, -20.822344, -20.300130, -19.75… #> $ incidence.per_capita.se.fit <dbl> -1.515370, -1.502694, -1.507134, -1.526504… #> $ population_unit             <dbl> 1e+05, 1e+05, 1e+05, 1e+05, 1e+05, 1e+05, … #> $ time_unit                   <Period> 1d 0H 0M 0S, 1d 0H 0M 0S, 1d 0H 0M 0S, …"},{"path":"/reference/normalise_incidence.proportion.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate a normalised incidence rate per capita — normalise_incidence.proportion","title":"Calculate a normalised incidence rate per capita — normalise_incidence.proportion","text":"assumes positive disease counts stratified population grouping, e.g. geography age, estimates size population time period. Normalising population size allows us compare groups.","code":""},{"path":"/reference/normalise_incidence.proportion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate a normalised incidence rate per capita — normalise_incidence.proportion","text":"","code":"normalise_incidence.proportion(   modelled = i_proportion_model,   ...,   population_unit = 1e+05,   normalise_time = FALSE )"},{"path":"/reference/normalise_incidence.proportion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate a normalised incidence rate per capita — normalise_incidence.proportion","text":"modelled Model output processing raw dataframe something like poission_locfit_model dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` proportion.fit (double) - estimate proportion logit scale proportion.se.fit (double) - standard error proportion estimate logit scale proportion.0.025 (proportion) - lower confidence limit proportion (true scale) proportion.0.5 (proportion) - median estimate proportion (true scale) proportion.0.975 (proportion) - upper confidence limit proportion (true scale) mandatory groupings. default value. ... used population_unit population unit want incidence e.g. per 100K normalise_time default behaviour incidence keep time units input data. parameter set TRUE incidence rates calculated per year. given lubridate period string e.g. \"1 day\" incidence calculated time period.","code":""},{"path":"/reference/normalise_incidence.proportion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate a normalised incidence rate per capita — normalise_incidence.proportion","text":"dataframe incidence rates per unit capita. dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period incidence.per_capita.fit (double) - estimate incidence per capita rate log scale incidence.per_capita.se.fit (double) - standard error incidence per capita rate estimate log scale incidence.per_capita.0.025 (positive_double) - lower confidence limit incidence per capita rate (true scale) incidence.per_capita.0.5 (positive_double) - median estimate incidence per capita rate (true scale) incidence.per_capita.0.975 (positive_double) - upper confidence limit incidence per capita rate (true scale) population_unit (double) - population unit per capita incidence rate calculated mandatory groupings. default value.","code":""},{"path":"/reference/normalise_incidence.proportion.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate a normalised incidence rate per capita — normalise_incidence.proportion","text":"scales proportion model population unit make comparable incidence model.","code":""},{"path":"/reference/normalise_incidence.proportion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate a normalised incidence rate per capita — normalise_incidence.proportion","text":"","code":"tmp = ggoutbreak::england_covid %>%   ggoutbreak::poisson_locfit_model(window=21) %>%   ggoutbreak::normalise_incidence(ggoutbreak::england_demographics) %>%   dplyr::glimpse() #> Rows: 26,790 #> Columns: 21 #> Groups: class [19] #> $ class                       <fct> 00_04, 00_04, 00_04, 00_04, 00_04, 00_04, … #> $ time                        <time_prd> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,… #> $ incidence.fit               <dbl> -17.891227, -17.395804, -16.873590, -16.33… #> $ incidence.se.fit            <dbl> 1.9111699, 1.9238465, 1.9194060, 1.9000358… #> $ incidence.0.025             <dbl> 4.010032e-10, 6.419738e-10, 1.091671e-09, … #> $ incidence.0.5               <dbl> 1.698004e-08, 2.786752e-08, 4.697785e-08, … #> $ incidence.0.975             <dbl> 7.190010e-07, 1.209705e-06, 2.021596e-06, … #> $ growth.fit                  <dbl> 0.4798757, 0.4792888, 0.4776793, 0.4752744… #> $ growth.se.fit               <dbl> 0.05395200, 0.05584978, 0.05729669, 0.0583… #> $ growth.0.025                <dbl> 0.3741317, 0.3698252, 0.3653799, 0.3609097… #> $ growth.0.5                  <dbl> 0.4798757, 0.4792888, 0.4776793, 0.4752744… #> $ growth.0.975                <dbl> 0.5856197, 0.5887523, 0.5899788, 0.5896391… #> $ population                  <int> 3077000, 3077000, 3077000, 3077000, 307700… #> $ baseline_proportion         <dbl> 0.05447011, 0.05447011, 0.05447011, 0.0544… #> $ incidence.per_capita.0.025  <dbl> 1.303228e-11, 2.086363e-11, 3.547843e-11, … #> $ incidence.per_capita.0.5    <dbl> 5.518375e-10, 9.056719e-10, 1.526742e-09, … #> $ incidence.per_capita.0.975  <dbl> 2.336695e-08, 3.931443e-08, 6.570024e-08, … #> $ incidence.per_capita.fit    <dbl> -21.317768, -20.822344, -20.300130, -19.75… #> $ incidence.per_capita.se.fit <dbl> -1.515370, -1.502694, -1.507134, -1.526504… #> $ population_unit             <dbl> 1e+05, 1e+05, 1e+05, 1e+05, 1e+05, 1e+05, … #> $ time_unit                   <Period> 1d 0H 0M 0S, 1d 0H 0M 0S, 1d 0H 0M 0S, …"},{"path":"/reference/normalise_proportion.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate a normalised risk ration from proportions — normalise_proportion","title":"Calculate a normalised risk ration from proportions — normalise_proportion","text":"assumes case distribution proportions stratified population grouping, e.g. geography age, estimates size population time period. Normalising population proportion allows us compare groups.","code":""},{"path":"/reference/normalise_proportion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate a normalised risk ration from proportions — normalise_proportion","text":"","code":"normalise_proportion(   modelled = i_proportion_model,   base = i_baseline_proportion_data,   ... )"},{"path":"/reference/normalise_proportion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate a normalised risk ration from proportions — normalise_proportion","text":"modelled Model output processing raw dataframe something like proportion_locfit_model dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` proportion.fit (double) - estimate proportion logit scale proportion.se.fit (double) - standard error proportion estimate logit scale proportion.0.025 (proportion) - lower confidence limit proportion (true scale) proportion.0.5 (proportion) - median estimate proportion (true scale) proportion.0.975 (proportion) - upper confidence limit proportion (true scale) mandatory groupings. default value. base baseline data must grouped way modelled. dataframe containing following columns: baseline_proportion (proportion) - Size population mandatory groupings. default value. ... used","code":""},{"path":"/reference/normalise_proportion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate a normalised risk ration from proportions — normalise_proportion","text":"dataframe incidence rates per unit capita. dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period proportion.fit (double) - estimate proportion logit scale proportion.se.fit (double) - standard error proportion estimate logit scale proportion.0.025 (proportion) - lower confidence limit proportion (true scale) proportion.0.5 (proportion) - median estimate proportion (true scale) proportion.0.975 (proportion) - upper confidence limit proportion (true scale) risk_ratio.0.025 (positive_double) - lower confidence limit excess risk ratio population group risk_ratio.0.5 (positive_double) - median estimate excess risk ratio population group risk_ratio.0.975 (positive_double) - upper confidence limit excess risk ratio population group baseline_proportion (proportion) - population baseline risk excess risk ratio based mandatory groupings. default value.","code":""},{"path":"/reference/normalise_proportion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate a normalised risk ration from proportions — normalise_proportion","text":"","code":"tmp = ggoutbreak::england_covid %>%   ggoutbreak::proportion_locfit_model(window=21) %>%   ggoutbreak::normalise_proportion(ggoutbreak::england_demographics) %>%   dplyr::glimpse() #> Rows: 26,790 #> Columns: 17 #> Groups: class [19] #> $ class                  <fct> 00_04, 00_04, 00_04, 00_04, 00_04, 00_04, 00_04… #> $ time                   <time_prd> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, … #> $ proportion.fit         <dbl> -13.433629, -13.178345, -12.898497, -12.600007,… #> $ proportion.se.fit      <dbl> 51.598289, 49.954079, 48.024633, 45.878749, 43.… #> $ proportion.0.025       <dbl> 1.759164e-50, 5.698079e-49, 3.308357e-47, 2.991… #> $ proportion.0.5         <dbl> 1.465037e-06, 1.891110e-06, 2.501801e-06, 3.371… #> $ proportion.0.975       <dbl> 1.0000000, 1.0000000, 1.0000000, 1.0000000, 1.0… #> $ relative.growth.fit    <dbl> 0.24102860, 0.24048966, 0.23901181, 0.23680352,… #> $ relative.growth.se.fit <dbl> 1.2309119, 1.2257057, 1.2114298, 1.1900979, 1.1… #> $ relative.growth.0.025  <dbl> -2.1715143, -2.1618494, -2.1353470, -2.0957455,… #> $ relative.growth.0.5    <dbl> 0.24102860, 0.24048966, 0.23901181, 0.23680352,… #> $ relative.growth.0.975  <dbl> 2.6535715, 2.6428288, 2.6133706, 2.5693525, 2.5… #> $ population             <dbl> 3077000, 3077000, 3077000, 3077000, 3077000, 30… #> $ baseline_proportion    <dbl> 0.05447011, 0.05447011, 0.05447011, 0.05447011,… #> $ risk_ratio.0.025       <dbl> 3.229595e-49, 1.046093e-47, 6.073711e-46, 5.491… #> $ risk_ratio.0.5         <dbl> 2.689616e-05, 3.471831e-05, 4.592981e-05, 6.190… #> $ risk_ratio.0.975       <dbl> 18.35869, 18.35869, 18.35869, 18.35869, 18.3586…  plot_growth_phase(tmp) #> Coordinate system already present. Adding new coordinate system, which will #> replace the existing one."},{"path":"/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"/reference/plot_growth_phase.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot an incidence or proportion vs. growth phase diagram — plot_growth_phase","title":"Plot an incidence or proportion vs. growth phase diagram — plot_growth_phase","text":"Plot incidence proportion vs. growth phase diagram","code":""},{"path":"/reference/plot_growth_phase.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot an incidence or proportion vs. growth phase diagram — plot_growth_phase","text":"","code":"plot_growth_phase(   modelled = i_timestamped,   timepoints = NULL,   duration = max(dplyr::count(modelled)$n),   interval = 7,   mapping = if (interfacer::is_col_present(modelled, class)) ggplot2::aes(colour = class)     else ggplot2::aes(),   cis = TRUE,   ... )"},{"path":"/reference/plot_growth_phase.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot an incidence or proportion vs. growth phase diagram — plot_growth_phase","text":"modelled Either: dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period incidence.fit (double) - estimate incidence rate log scale incidence.se.fit (double) - standard error incidence rate estimate log scale incidence.0.025 (positive_double) - lower confidence limit incidence rate (true scale) incidence.0.5 (positive_double) - median estimate incidence rate (true scale) incidence.0.975 (positive_double) - upper confidence limit incidence rate (true scale) growth.fit (double) - estimate growth rate growth.se.fit (double) - standard error growth rate growth.0.025 (double) - lower confidence limit growth rate growth.0.5 (double) - median estimate growth rate growth.0.975 (double) - upper confidence limit growth rate mandatory groupings. default value. : dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period proportion.fit (double) - estimate proportion logit scale proportion.se.fit (double) - standard error proportion estimate logit scale proportion.0.025 (proportion) - lower confidence limit proportion (true scale) proportion.0.5 (proportion) - median estimate proportion (true scale) proportion.0.975 (proportion) - upper confidence limit proportion (true scale) relative.growth.fit (double) - estimate relative growth rate relative.growth.se.fit (double) - standard error relative growth rate relative.growth.0.025 (double) - lower confidence limit relative growth rate relative.growth.0.5 (double) - median estimate relative growth rate relative.growth.0.975 (double) - upper confidence limit relative growth rate mandatory groupings. default value. timepoints timepoints (Date time_period vector) dates plot phase diagrams. multiple result sequence plots facets. NULL (default) last time point series duration length growth rate phase trail interval length time markers phase plot mapping ggplot2::aes() mapping cis phases marked confidence intervals? ... Arguments passed geom_events events Significant events time spans dataframe containing following columns: label (character) - event label start (date) - start date, date event end (date) - end date NA single event mandatory groupings. default value defined.","code":""},{"path":"/reference/plot_growth_phase.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot an incidence or proportion vs. growth phase diagram — plot_growth_phase","text":"ggplot timeseries","code":""},{"path":"/reference/plot_growth_phase.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot an incidence or proportion vs. growth phase diagram — plot_growth_phase","text":"","code":"# example code  tmp = ggoutbreak::england_covid %>%   time_aggregate(count=sum(count))  tmp_pop = ggoutbreak::england_demographics %>%   dplyr::ungroup() %>%   dplyr::summarise(population = sum(population))  # If the incidence is normalised by population tmp2 = tmp %>%   poisson_locfit_model() %>%   normalise_incidence(tmp_pop)  timepoints = as.Date(c(\"Lockdown 1\" = \"2020-03-30\", \"Lockdown 2\" = \"2020-12-31\"))  plot_growth_phase(tmp2, timepoints, duration=108)"},{"path":"/reference/plot_growth_rate.html","id":null,"dir":"Reference","previous_headings":"","what":"Growth rate timeseries diagram — plot_growth_rate","title":"Growth rate timeseries diagram — plot_growth_rate","text":"Growth rate timeseries diagram","code":""},{"path":"/reference/plot_growth_rate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Growth rate timeseries diagram — plot_growth_rate","text":"","code":"plot_growth_rate(   modelled = i_timeseries,   ...,   mapping = if (interfacer::is_col_present(modelled, class)) ggplot2::aes(colour = class)     else ggplot2::aes(),   events = i_events )"},{"path":"/reference/plot_growth_rate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Growth rate timeseries diagram — plot_growth_rate","text":"modelled Either: dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period incidence.fit (double) - estimate incidence rate log scale incidence.se.fit (double) - standard error incidence rate estimate log scale incidence.0.025 (positive_double) - lower confidence limit incidence rate (true scale) incidence.0.5 (positive_double) - median estimate incidence rate (true scale) incidence.0.975 (positive_double) - upper confidence limit incidence rate (true scale) growth.fit (double) - estimate growth rate growth.se.fit (double) - standard error growth rate growth.0.025 (double) - lower confidence limit growth rate growth.0.5 (double) - median estimate growth rate growth.0.975 (double) - upper confidence limit growth rate mandatory groupings. default value. : dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period proportion.fit (double) - estimate proportion logit scale proportion.se.fit (double) - standard error proportion estimate logit scale proportion.0.025 (proportion) - lower confidence limit proportion (true scale) proportion.0.5 (proportion) - median estimate proportion (true scale) proportion.0.975 (proportion) - upper confidence limit proportion (true scale) relative.growth.fit (double) - estimate relative growth rate relative.growth.se.fit (double) - standard error relative growth rate relative.growth.0.025 (double) - lower confidence limit relative growth rate relative.growth.0.5 (double) - median estimate relative growth rate relative.growth.0.975 (double) - upper confidence limit relative growth rate mandatory groupings. default value. ... Arguments passed geom_events   mapping ggplot2::aes mapping. importantly setting colour something multiple incidence time series plot events Significant events time spans dataframe containing following columns: label (character) - event label start (date) - start date, date event end (date) - end date NA single event mandatory groupings. default value defined.","code":""},{"path":"/reference/plot_growth_rate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Growth rate timeseries diagram — plot_growth_rate","text":"ggplot timeseries","code":""},{"path":"/reference/plot_growth_rate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Growth rate timeseries diagram — plot_growth_rate","text":"","code":"# example code tmp = ggoutbreak::england_covid %>%   time_aggregate(count=sum(count))  tmp_pop = ggoutbreak::england_demographics %>%   dplyr::ungroup() %>%   dplyr::summarise(population = sum(population))    # If the incidence is normalised by population tmp2 = tmp %>%   poisson_locfit_model() %>%   normalise_incidence(tmp_pop)  # Default pdf device doesn't support unicode plot_growth_rate(tmp2,colour=\"blue\")   tmp3 = ggoutbreak::england_covid %>%   proportion_locfit_model()  # Default pdf device doesn't support unicode plot_growth_rate(tmp3)"},{"path":"/reference/plot_incidence.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot an incidence timeseries — plot_incidence","title":"Plot an incidence timeseries — plot_incidence","text":"Plot incidence timeseries","code":""},{"path":"/reference/plot_incidence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot an incidence timeseries — plot_incidence","text":"","code":"plot_incidence(   modelled = i_incidence_model,   raw = i_incidence_data,   ...,   mapping = if (interfacer::is_col_present(modelled, class)) ggplot2::aes(colour = class)     else ggplot2::aes(),   events = i_events )"},{"path":"/reference/plot_incidence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot an incidence timeseries — plot_incidence","text":"modelled optional estimate incidence time series. modelled missing estimated raw using poisson_locfit_model. case parameters window deg may supplied control fit. dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period incidence.fit (double) - estimate incidence rate log scale incidence.se.fit (double) - standard error incidence rate estimate log scale incidence.0.025 (positive_double) - lower confidence limit incidence rate (true scale) incidence.0.5 (positive_double) - median estimate incidence rate (true scale) incidence.0.975 (positive_double) - upper confidence limit incidence rate (true scale) mandatory groupings. default value. modelled can also output normalise_incidence case plot uses per capita rates calculated function raw raw count data dataframe containing following columns: count (positive_integer) - Positive case counts associated specified timeframe time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` mandatory groupings. default value. ... Arguments passed geom_events, poisson_locfit_model window number data points defining bandwidth estimate, smaller values result less smoothing, large value . default value 14 calibrated data provided daily frequency, weekly data lower value may preferred. - (defaults 14) deg polynomial degree (min 1) - higher degree results less smoothing, lower values result smoothing. degree 1 fitting linear model piece wise. - (defaults 1) frequency density output estimates time period 7 days 2 weeks. - (defaults \"1 day\") mapping ggplot2::aes mapping. importantly setting colour something multiple incidence timeseries plot events Significant events time spans dataframe containing following columns: label (character) - event label start (date) - start date, date event end (date) - end date NA single event mandatory groupings. default value defined.","code":""},{"path":"/reference/plot_incidence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot an incidence timeseries — plot_incidence","text":"ggplot object","code":""},{"path":"/reference/plot_incidence.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot an incidence timeseries — plot_incidence","text":"","code":"# example code  tmp = ggoutbreak::england_covid %>%   time_aggregate(count=sum(count))  tmp_pop = ggoutbreak::england_demographics %>%   dplyr::ungroup() %>%   dplyr::summarise(population = sum(population))  # If the incidence is normalised by population tmp2 = tmp %>%   poisson_locfit_model() %>%   normalise_incidence(tmp_pop)  plot_incidence(tmp2,tmp %>% dplyr::cross_join(tmp_pop),colour=\"blue\",size=0.25)"},{"path":"/reference/plot_multinomial.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a multinomial proportions mode — plot_multinomial","title":"Plot a multinomial proportions mode — plot_multinomial","text":"Plot multinomial proportions mode","code":""},{"path":"/reference/plot_multinomial.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a multinomial proportions mode — plot_multinomial","text":"","code":"plot_multinomial(   modelled = i_multinomial_proportion_model,   ...,   mapping = ggplot2::aes(fill = class),   events = i_events,   normalise = FALSE )"},{"path":"/reference/plot_multinomial.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a multinomial proportions mode — plot_multinomial","text":"modelled multinomial count data dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` class (factor) - factor specifying type observation. things like variant, serotype, multinomial model. missing data points ignored. proportion.0.5 (proportion) - median estimate proportion (true scale) Must grouped : class (exactly). default value. ... Arguments passed geom_events   mapping ggplot2::aes mapping. importantly setting colour something multiple incidence timeseries plot events Significant events time spans dataframe containing following columns: label (character) - event label start (date) - start date, date event end (date) - end date NA single event mandatory groupings. default value defined. normalise make sure probabilities add one - can bad idea know may missing values.","code":""},{"path":"/reference/plot_multinomial.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a multinomial proportions mode — plot_multinomial","text":"ggplot","code":""},{"path":"/reference/plot_multinomial.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot a multinomial proportions mode — plot_multinomial","text":"","code":"tmp = ggoutbreak::england_covid %>%   ggoutbreak::proportion_locfit_model(window=21) %>%   dplyr::glimpse() #> Rows: 26,790 #> Columns: 12 #> Groups: class [19] #> $ class                  <fct> 00_04, 00_04, 00_04, 00_04, 00_04, 00_04, 00_04… #> $ time                   <time_prd> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, … #> $ proportion.fit         <dbl> -13.433629, -13.178345, -12.898497, -12.600007,… #> $ proportion.se.fit      <dbl> 51.598289, 49.954079, 48.024633, 45.878749, 43.… #> $ proportion.0.025       <dbl> 1.759164e-50, 5.698079e-49, 3.308357e-47, 2.991… #> $ proportion.0.5         <dbl> 1.465037e-06, 1.891110e-06, 2.501801e-06, 3.371… #> $ proportion.0.975       <dbl> 1.0000000, 1.0000000, 1.0000000, 1.0000000, 1.0… #> $ relative.growth.fit    <dbl> 0.24102860, 0.24048966, 0.23901181, 0.23680352,… #> $ relative.growth.se.fit <dbl> 1.2309119, 1.2257057, 1.2114298, 1.1900979, 1.1… #> $ relative.growth.0.025  <dbl> -2.1715143, -2.1618494, -2.1353470, -2.0957455,… #> $ relative.growth.0.5    <dbl> 0.24102860, 0.24048966, 0.23901181, 0.23680352,… #> $ relative.growth.0.975  <dbl> 2.6535715, 2.6428288, 2.6133706, 2.5693525, 2.5…  plot_multinomial(tmp, normalise=TRUE)+   ggplot2::scale_fill_viridis_d()"},{"path":"/reference/plot_proportion.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a proportions timeseries — plot_proportion","title":"Plot a proportions timeseries — plot_proportion","text":"Plot proportions timeseries","code":""},{"path":"/reference/plot_proportion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a proportions timeseries — plot_proportion","text":"","code":"plot_proportion(   modelled = i_proportion_model,   raw = i_proportion_data,   ...,   mapping = if (interfacer::is_col_present(modelled, class)) ggplot2::aes(colour = class)     else ggplot2::aes(),   events = i_events )"},{"path":"/reference/plot_proportion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a proportions timeseries — plot_proportion","text":"modelled Proportion model estimates dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` proportion.fit (double) - estimate proportion logit scale proportion.se.fit (double) - standard error proportion estimate logit scale proportion.0.025 (proportion) - lower confidence limit proportion (true scale) proportion.0.5 (proportion) - median estimate proportion (true scale) proportion.0.975 (proportion) - upper confidence limit proportion (true scale) mandatory groupings. default value. raw Raw count data dataframe containing following columns: denom (positive_integer) - Total test counts associated specified timeframe count (positive_integer) - Positive case counts associated specified timeframe time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` mandatory groupings. default value. ... Arguments passed geom_events, proportion_locfit_model window number data points defining bandwidth estimate, smaller values result less smoothing, large value . default value 14 calibrated data provided daily frequency, weekly data lower value may preferred. - (defaults 14) deg polynomial degree (min 1) - higher degree results less smoothing, lower values result smoothing. degree 1 fitting linear model piece wise. - (defaults 1) frequency density output estimates time period 7 days 2 weeks. - (defaults \"1 day\") mapping ggplot2::aes mapping. importantly setting colour something multiple incidence timeseries plot events Significant events time spans dataframe containing following columns: label (character) - event label start (date) - start date, date event end (date) - end date NA single event mandatory groupings. default value defined.","code":""},{"path":"/reference/plot_proportion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a proportions timeseries — plot_proportion","text":"ggplot object","code":""},{"path":"/reference/plot_proportion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot a proportions timeseries — plot_proportion","text":"","code":"tmp = ggoutbreak::england_covid %>%   ggoutbreak::proportion_locfit_model(window=21) %>%   dplyr::glimpse() #> Rows: 26,790 #> Columns: 12 #> Groups: class [19] #> $ class                  <fct> 00_04, 00_04, 00_04, 00_04, 00_04, 00_04, 00_04… #> $ time                   <time_prd> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, … #> $ proportion.fit         <dbl> -13.433629, -13.178345, -12.898497, -12.600007,… #> $ proportion.se.fit      <dbl> 51.598289, 49.954079, 48.024633, 45.878749, 43.… #> $ proportion.0.025       <dbl> 1.759164e-50, 5.698079e-49, 3.308357e-47, 2.991… #> $ proportion.0.5         <dbl> 1.465037e-06, 1.891110e-06, 2.501801e-06, 3.371… #> $ proportion.0.975       <dbl> 1.0000000, 1.0000000, 1.0000000, 1.0000000, 1.0… #> $ relative.growth.fit    <dbl> 0.24102860, 0.24048966, 0.23901181, 0.23680352,… #> $ relative.growth.se.fit <dbl> 1.2309119, 1.2257057, 1.2114298, 1.1900979, 1.1… #> $ relative.growth.0.025  <dbl> -2.1715143, -2.1618494, -2.1353470, -2.0957455,… #> $ relative.growth.0.5    <dbl> 0.24102860, 0.24048966, 0.23901181, 0.23680352,… #> $ relative.growth.0.975  <dbl> 2.6535715, 2.6428288, 2.6133706, 2.5693525, 2.5…  plot_proportion(tmp)+   ggplot2::scale_fill_viridis_d(aesthetics = c(\"fill\",\"colour\"))"},{"path":"/reference/plot_rt.html","id":null,"dir":"Reference","previous_headings":"","what":"Reproduction number timeseries diagram — plot_rt","title":"Reproduction number timeseries diagram — plot_rt","text":"Reproduction number timeseries diagram","code":""},{"path":"/reference/plot_rt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reproduction number timeseries diagram — plot_rt","text":"","code":"plot_rt(   modelled = i_reproduction_number,   ...,   mapping = if (interfacer::is_col_present(modelled, class)) ggplot2::aes(colour = class)     else ggplot2::aes(),   events = i_events )"},{"path":"/reference/plot_rt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reproduction number timeseries diagram — plot_rt","text":"modelled modelled Rt estimate dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` rt.fit (double) - estimate reproduction number rt.se.fit (double) - standard error reproduction number rt.0.025 (double) - lower confidence limit reproduction number rt.0.5 (double) - median estimate reproduction number rt.0.975 (double) - upper confidence limit reproduction number mandatory groupings. default value. ... Arguments passed geom_events   mapping ggplot2::aes mapping. importantly setting colour something multiple incidence time series plot events Significant events time spans dataframe containing following columns: label (character) - event label start (date) - start date, date event end (date) - end date NA single event mandatory groupings. default value defined.","code":""},{"path":"/reference/plot_rt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reproduction number timeseries diagram — plot_rt","text":"ggplot timeseries","code":""},{"path":"/reference/plot_rt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reproduction number timeseries diagram — plot_rt","text":"","code":"# example code tmp = ggoutbreak::england_covid %>%   time_aggregate(count=sum(count)) if (FALSE) {    tmp2 = tmp %>%     poisson_locfit_model() %>%     rt_from_growth_rate()    # comparing RT from growth rates with England consensus Rt:   plot_rt(tmp2,colour=\"blue\")+     geom_errorbar(data=england_consensus_rt, mapping=aes(x=date-21,ymin=low,ymax=high),colour=\"red\")  }"},{"path":"/reference/poisson_glm_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Poisson time-series model. — poisson_glm_model","title":"Poisson time-series model. — poisson_glm_model","text":"uses generalised linear model fit quasi-poisson model time varying rate natural cubic spline approx one degree freedom per window units time series.","code":""},{"path":"/reference/poisson_glm_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Poisson time-series model. — poisson_glm_model","text":"","code":"poisson_glm_model(d = i_incidence_input, ..., window = 14, frequency = \"1 day\")"},{"path":"/reference/poisson_glm_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Poisson time-series model. — poisson_glm_model","text":"d Count model input dataframe containing following columns: count (positive_integer) - Positive case counts associated specified timeframe time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` Ungrouped. default value. ... used present allow proportion model used group_modify window number data points defining bandwidth estimate, smaller values result less smoothing, large value . default value 14 calibrated data provided daily frequency, weekly data lower value may preferred. - (defaults 14) frequency density output estimates time period 7 days 2 weeks. - (defaults \"1 day\")","code":""},{"path":"/reference/poisson_glm_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Poisson time-series model. — poisson_glm_model","text":"dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period incidence.fit (double) - estimate incidence rate log scale incidence.se.fit (double) - standard error incidence rate estimate log scale incidence.0.025 (positive_double) - lower confidence limit incidence rate (true scale) incidence.0.5 (positive_double) - median estimate incidence rate (true scale) incidence.0.975 (positive_double) - upper confidence limit incidence rate (true scale) mandatory groupings. default value.","code":""},{"path":"/reference/poisson_glm_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Poisson time-series model. — poisson_glm_model","text":"","code":"tmp = ggoutbreak::england_covid %>%  ggoutbreak::poisson_glm_model(window=21) %>%  dplyr::glimpse() #> Rows: 26,790 #> Columns: 7 #> Groups: class [19] #> $ class            <fct> 00_04, 00_04, 00_04, 00_04, 00_04, 00_04, 00_04, 00_0… #> $ time             <time_prd> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14… #> $ incidence.fit    <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N… #> $ incidence.se.fit <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N… #> $ incidence.0.025  <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N… #> $ incidence.0.5    <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N… #> $ incidence.0.975  <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…"},{"path":"/reference/poisson_locfit_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Poisson time-series model. — poisson_locfit_model","title":"Poisson time-series model. — poisson_locfit_model","text":"Takes list times counts fits quasi-poisson model fitted log link function count data using local regression using package locfit.","code":""},{"path":"/reference/poisson_locfit_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Poisson time-series model. — poisson_locfit_model","text":"","code":"poisson_locfit_model(   d = i_incidence_input,   ...,   window = 14,   deg = 1,   frequency = \"1 day\",   predict = TRUE )"},{"path":"/reference/poisson_locfit_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Poisson time-series model. — poisson_locfit_model","text":"d input data dataframe containing following columns: count (positive_integer) - Positive case counts associated specified timeframe time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` Ungrouped. default value. ... used present allow proportion model used group_modify window number data points defining bandwidth estimate, smaller values result less smoothing, large value . default value 14 calibrated data provided daily frequency, weekly data lower value may preferred. - (defaults 14) deg polynomial degree (min 1) - higher degree results less smoothing, lower values result smoothing. degree 1 fitting linear model piece wise. - (defaults 1) frequency density output estimates time period 7 days 2 weeks. - (defaults \"1 day\") predict result prediction dataframe. false return locfit models (advanced). - (defaults TRUE)","code":""},{"path":"/reference/poisson_locfit_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Poisson time-series model. — poisson_locfit_model","text":"dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period incidence.fit (double) - estimate incidence rate log scale incidence.se.fit (double) - standard error incidence rate estimate log scale incidence.0.025 (positive_double) - lower confidence limit incidence rate (true scale) incidence.0.5 (positive_double) - median estimate incidence rate (true scale) incidence.0.975 (positive_double) - upper confidence limit incidence rate (true scale) growth.fit (double) - estimate growth rate growth.se.fit (double) - standard error growth rate growth.0.025 (double) - lower confidence limit growth rate growth.0.5 (double) - median estimate growth rate growth.0.975 (double) - upper confidence limit growth rate mandatory groupings. default value.","code":""},{"path":"/reference/poisson_locfit_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Poisson time-series model. — poisson_locfit_model","text":"results incidence rate estimate plus absolute exponential growth rate estimate based time unit input data (e.g. daily data rate cases per day growth rate daily).","code":""},{"path":"/reference/poisson_locfit_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Poisson time-series model. — poisson_locfit_model","text":"","code":"ggoutbreak::england_covid %>%   ggoutbreak::poisson_locfit_model(window=21) %>%   dplyr::glimpse() #> Rows: 26,790 #> Columns: 12 #> Groups: class [19] #> $ class            <fct> 00_04, 00_04, 00_04, 00_04, 00_04, 00_04, 00_04, 00_0… #> $ time             <time_prd> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14… #> $ incidence.fit    <dbl> -17.891227, -17.395804, -16.873590, -16.331042, -15.7… #> $ incidence.se.fit <dbl> 1.9111699, 1.9238465, 1.9194060, 1.9000358, 1.8681012… #> $ incidence.0.025  <dbl> 4.010032e-10, 6.419738e-10, 1.091671e-09, 1.950766e-0… #> $ incidence.0.5    <dbl> 1.698004e-08, 2.786752e-08, 4.697785e-08, 8.081996e-0… #> $ incidence.0.975  <dbl> 7.190010e-07, 1.209705e-06, 2.021596e-06, 3.348359e-0… #> $ growth.fit       <dbl> 0.4798757, 0.4792888, 0.4776793, 0.4752744, 0.4723010… #> $ growth.se.fit    <dbl> 0.05395200, 0.05584978, 0.05729669, 0.05835042, 0.059… #> $ growth.0.025     <dbl> 0.3741317, 0.3698252, 0.3653799, 0.3609097, 0.3565117… #> $ growth.0.5       <dbl> 0.4798757, 0.4792888, 0.4776793, 0.4752744, 0.4723010… #> $ growth.0.975     <dbl> 0.5856197, 0.5887523, 0.5899788, 0.5896391, 0.5880903…"},{"path":"/reference/proportion_glm_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Binomial time-series model. — proportion_glm_model","title":"Binomial time-series model. — proportion_glm_model","text":"uses generalised linear model fit quasi-binomial model time varying rate natural cubic spline approx one degree freedom per window units time series.","code":""},{"path":"/reference/proportion_glm_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Binomial time-series model. — proportion_glm_model","text":"","code":"proportion_glm_model(   d = i_proportion_input,   ...,   window = 14,   frequency = \"1 day\" )"},{"path":"/reference/proportion_glm_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Binomial time-series model. — proportion_glm_model","text":"d Proportion model input dataframe containing following columns: denom (positive_integer) - Total test counts associated specified timeframe count (positive_integer) - Positive case counts associated specified timeframe time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` Ungrouped. default value. ... used present allow proportion model used group_modify window number data points defining bandwidth estimate, smaller values result less smoothing, large value . default value 14 calibrated data provided daily frequency, weekly data lower value may preferred. - (defaults 14) frequency density output estimates time period 7 days 2 weeks. - (defaults \"1 day\")","code":""},{"path":"/reference/proportion_glm_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Binomial time-series model. — proportion_glm_model","text":"dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period proportion.fit (double) - estimate proportion logit scale proportion.se.fit (double) - standard error proportion estimate logit scale proportion.0.025 (proportion) - lower confidence limit proportion (true scale) proportion.0.5 (proportion) - median estimate proportion (true scale) proportion.0.975 (proportion) - upper confidence limit proportion (true scale) mandatory groupings. default value.","code":""},{"path":"/reference/proportion_glm_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Binomial time-series model. — proportion_glm_model","text":"","code":"# TODO: find out cause of the warnings # \"observations with zero weight not used for calculating dispersion\" suppressWarnings(   ggoutbreak::england_covid %>%    ggoutbreak::proportion_glm_model(window=21) %>%    dplyr::glimpse() ) #> Rows: 26,790 #> Columns: 7 #> Groups: class [19] #> $ class             <fct> 00_04, 00_04, 00_04, 00_04, 00_04, 00_04, 00_04, 00_… #> $ time              <time_prd> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 1… #> $ proportion.fit    <dbl> -8.889667, -8.842042, -8.794113, -8.745576, -8.69612… #> $ proportion.se.fit <dbl> 51.296631, 48.776606, 46.264194, 43.765615, 41.28710… #> $ proportion.0.025  <dbl> 2.220446e-16, 2.220446e-16, 2.220446e-16, 2.220446e-… #> $ proportion.0.5    <dbl> 0.0001377866, 0.0001445064, 0.0001516000, 0.00015913… #> $ proportion.0.975  <dbl> 1.0000000, 1.0000000, 1.0000000, 1.0000000, 1.000000…"},{"path":"/reference/proportion_locfit_model.html","id":null,"dir":"Reference","previous_headings":"","what":"A binomial proportion estimate and associated exponential growth rate — proportion_locfit_model","title":"A binomial proportion estimate and associated exponential growth rate — proportion_locfit_model","text":"takes list times, counts denominator fits quasi-binomial model using logit link function proportion data using local regression using package locfit.","code":""},{"path":"/reference/proportion_locfit_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A binomial proportion estimate and associated exponential growth rate — proportion_locfit_model","text":"","code":"proportion_locfit_model(   d = i_proportion_input,   ...,   window = 14,   deg = 1,   frequency = \"1 day\",   predict = TRUE )"},{"path":"/reference/proportion_locfit_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A binomial proportion estimate and associated exponential growth rate — proportion_locfit_model","text":"d input dataframe containing following columns: denom (positive_integer) - Total test counts associated specified timeframe count (positive_integer) - Positive case counts associated specified timeframe time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` Ungrouped. default value. ... used present allow proportion model used group_modify window number data points defining bandwidth estimate, smaller values result less smoothing, large value . default value 14 calibrated data provided daily frequency, weekly data lower value may preferred. - (defaults 14) deg polynomial degree (min 1) - higher degree results less smoothing, lower values result smoothing. degree 1 fitting linear model piece wise. - (defaults 1) frequency density output estimates time period 7 days 2 weeks. - (defaults \"1 day\") predict result prediction dataframe. false return locfit models (advanced). - (defaults TRUE)","code":""},{"path":"/reference/proportion_locfit_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A binomial proportion estimate and associated exponential growth rate — proportion_locfit_model","text":"dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period proportion.fit (double) - estimate proportion logit scale proportion.se.fit (double) - standard error proportion estimate logit scale proportion.0.025 (proportion) - lower confidence limit proportion (true scale) proportion.0.5 (proportion) - median estimate proportion (true scale) proportion.0.975 (proportion) - upper confidence limit proportion (true scale) relative.growth.fit (double) - estimate relative growth rate relative.growth.se.fit (double) - standard error relative growth rate relative.growth.0.025 (double) - lower confidence limit relative growth rate relative.growth.0.5 (double) - median estimate relative growth rate relative.growth.0.975 (double) - upper confidence limit relative growth rate mandatory groupings. default value.","code":""},{"path":"/reference/proportion_locfit_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"A binomial proportion estimate and associated exponential growth rate — proportion_locfit_model","text":"expects d contain one combination : time count denom columns - e.g. tests conducted. results one versus others comparison binomial proportion estimate plus relative growth rate estimate specifying much quicker growing compared growth denominator. denominator maybe sum subgroups denom = sum(count), e.g. situation multiple variants disease circulating. case relative growth subgroup compared overall. can make one-versus-others comparison making denominator exclude current item (e.g. denom = sum(count)-count). denominator can also used express size population tested. gives us relative growth rate different essence previous may better estimate true growth rate situation testing effort variable, capacity saturated.","code":""},{"path":"/reference/proportion_locfit_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A binomial proportion estimate and associated exponential growth rate — proportion_locfit_model","text":"","code":"ggoutbreak::england_covid %>%  ggoutbreak::proportion_locfit_model(window=21) %>%  dplyr::glimpse() #> Rows: 26,790 #> Columns: 12 #> Groups: class [19] #> $ class                  <fct> 00_04, 00_04, 00_04, 00_04, 00_04, 00_04, 00_04… #> $ time                   <time_prd> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, … #> $ proportion.fit         <dbl> -13.433629, -13.178345, -12.898497, -12.600007,… #> $ proportion.se.fit      <dbl> 51.598289, 49.954079, 48.024633, 45.878749, 43.… #> $ proportion.0.025       <dbl> 1.759164e-50, 5.698079e-49, 3.308357e-47, 2.991… #> $ proportion.0.5         <dbl> 1.465037e-06, 1.891110e-06, 2.501801e-06, 3.371… #> $ proportion.0.975       <dbl> 1.0000000, 1.0000000, 1.0000000, 1.0000000, 1.0… #> $ relative.growth.fit    <dbl> 0.24102860, 0.24048966, 0.23901181, 0.23680352,… #> $ relative.growth.se.fit <dbl> 1.2309119, 1.2257057, 1.2114298, 1.1900979, 1.1… #> $ relative.growth.0.025  <dbl> -2.1715143, -2.1618494, -2.1353470, -2.0957455,… #> $ relative.growth.0.5    <dbl> 0.24102860, 0.24048966, 0.23901181, 0.23680352,… #> $ relative.growth.0.975  <dbl> 2.6535715, 2.6428288, 2.6133706, 2.5693525, 2.5…"},{"path":"/reference/reband_discrete.html","id":null,"dir":"Reference","previous_headings":"","what":"Reband any discrete distribution — reband_discrete","title":"Reband any discrete distribution — reband_discrete","text":"e.g. age banded population, discrete probability distribution e.g. serial interval distribution. method fits monotonically increasing spline cumulative distribution (including upper lower limits) interpolating using spline new cut points.","code":""},{"path":"/reference/reband_discrete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reband any discrete distribution — reband_discrete","text":"","code":"reband_discrete(   x,   y,   xout,   xlim = c(0, NA),   ytotal = c(0, sum(y)),   digits = 0,   labelling = c(\"positive_integer\", \"inclusive\", \"exclusive\"),   sep = \"-\" )"},{"path":"/reference/reband_discrete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reband any discrete distribution — reband_discrete","text":"x set upper limits bands, e.g. age: 0-14;15-64;65-79;80+ 15,65,80,NA y set quantities band e.g. population figures xout set new upper limits xlim Upper lower limits x. last band e.g 80+ input want know 85+ band output kind maximum upper limit needed interpolate . ytotal upper lower limits y. interpolation values fall outside x min max limits y given . c(0,1) probability distribution, example. digits xout value continuous many significant figures put labels labelling xout values interpretable inclusive upper limit, exclusive upper limit, upper limit `positive_integer`` quantity sep seperator names e.g. 18-24 18 24","code":""},{"path":"/reference/reband_discrete.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reband any discrete distribution — reband_discrete","text":"rebanded set discrete values, guaranteed sum y","code":""},{"path":"/reference/reband_discrete.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reband any discrete distribution — reband_discrete","text":"","code":"ul = stringr::str_extract(england_demographics$class, \"_([0-9]+)\",group = 1) %>%   as.numeric()  tmp = reband_discrete(   ul, england_demographics$population,   c(5,10,15,40,80), xlim=c(0,120))  tmp #>      0-4      5-9    10-14    15-39    40-79      80+  #>  3745688  3361511  3384582 18173104 25360084  2464731   sum(tmp) #> [1] 56489700 sum(england_demographics$population) #> [1] 56489700"},{"path":"/reference/rt_epiestim.html","id":null,"dir":"Reference","previous_headings":"","what":"EpiEstim reproduction number — rt_epiestim","title":"EpiEstim reproduction number — rt_epiestim","text":"Calculate reproduction number estimate incidence data using EpiEstim library empirical generation time distribution. uses resampling transmit uncertainty generation time estimates. quite slow time series depending number bootstraps samples infectivity profile.","code":""},{"path":"/reference/rt_epiestim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"EpiEstim reproduction number — rt_epiestim","text":"","code":"rt_epiestim(   df = i_incidence_input,   ip = i_infectivity_profile,   bootstraps = 2000,   window = 14,   mean_prior = 1,   std_prior = 2,   ... )"},{"path":"/reference/rt_epiestim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"EpiEstim reproduction number — rt_epiestim","text":"df Count data. Extra groups allowed. dataframe containing following columns: count (positive_integer) - Positive case counts associated specified timeframe time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` Ungrouped. default value. ip infectivity profile dataframe containing following columns: boot (anything + default(1)) - bootstrap identifier time (positive_double) - end time period (days) probability (proportion) - probability infection previous time period `time` Must grouped : boot (exactly). default value defined. bootstraps number bootstraps take calculate point. window width epiestim window mean_prior prior $R_t$ estimate. sample size low $R_t$ estimate revert prior. EpiEstim default high number allow detection insufficient data tends create anomalies early part infection timeseries. possible value $R_0$ fact also poor choice value $R_t$ case numbers drop low value. std_prior prior $R_t$ SD. ... used","code":""},{"path":"/reference/rt_epiestim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"EpiEstim reproduction number — rt_epiestim","text":"dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period rt.fit (double) - estimate reproduction number rt.se.fit (double) - standard error reproduction number rt.0.025 (double) - lower confidence limit reproduction number rt.0.5 (double) - median estimate reproduction number rt.0.975 (double) - upper confidence limit reproduction number mandatory groupings. default value.","code":""},{"path":"/reference/rt_epiestim.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"EpiEstim reproduction number — rt_epiestim","text":"calculate reproduction number group input dataframe.","code":""},{"path":"/reference/rt_epiestim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"EpiEstim reproduction number — rt_epiestim","text":"","code":"tmp = ggoutbreak::england_covid %>%   time_aggregate(count=sum(count))  if (FALSE) {   # not run due to long running   tmp2 = tmp %>% rt_epiestim() }"},{"path":"/reference/rt_from_growth_rate.html","id":null,"dir":"Reference","previous_headings":"","what":"Wallinga-Lipsitch reproduction number — rt_from_growth_rate","title":"Wallinga-Lipsitch reproduction number — rt_from_growth_rate","text":"Calculate reproduction number estimate growth rate using Wallinga 2007 estimation using empirical generation time distribution. uses resampling transmit uncertainty growth rate estimates","code":""},{"path":"/reference/rt_from_growth_rate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wallinga-Lipsitch reproduction number — rt_from_growth_rate","text":"","code":"rt_from_growth_rate(   df = i_growth_rate,   ip = i_infectivity_profile,   bootstraps = 1000,   seed = Sys.time() )"},{"path":"/reference/rt_from_growth_rate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wallinga-Lipsitch reproduction number — rt_from_growth_rate","text":"df Growth rate estimates dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` growth.fit (double) - estimate growth rate growth.se.fit (double) - standard error growth rate growth.0.025 (double) - lower confidence limit growth rate growth.0.5 (double) - median estimate growth rate growth.0.975 (double) - upper confidence limit growth rate mandatory groupings. default value. ip Infectivity profile dataframe containing following columns: boot (anything + default(1)) - bootstrap identifier time (positive_double) - end time period (days) probability (proportion) - probability infection previous time period `time` Must grouped : boot (exactly). default value defined. bootstraps number bootstraps take calculate point. seed random number generator seed","code":""},{"path":"/reference/rt_from_growth_rate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Wallinga-Lipsitch reproduction number — rt_from_growth_rate","text":"dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period rt.fit (double) - estimate reproduction number rt.se.fit (double) - standard error reproduction number rt.0.025 (double) - lower confidence limit reproduction number rt.0.5 (double) - median estimate reproduction number rt.0.975 (double) - upper confidence limit reproduction number mandatory groupings. default value.","code":""},{"path":"/reference/rt_from_growth_rate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Wallinga-Lipsitch reproduction number — rt_from_growth_rate","text":"","code":"tmp = ggoutbreak::england_covid %>%   time_aggregate(count=sum(count))   if (FALSE) {   # not run   tmp2 = tmp %>%     poisson_locfit_model() %>%     rt_from_growth_rate() }"},{"path":"/reference/rt_from_incidence.html","id":null,"dir":"Reference","previous_headings":"","what":"Reproduction number from modelled incidence — rt_from_incidence","title":"Reproduction number from modelled incidence — rt_from_incidence","text":"Calculate reproduction number estimate modelled incidence using methods described vignette \"Estimating reproduction number modelled incidence\" using set empirical generation time distributions.","code":""},{"path":"/reference/rt_from_incidence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reproduction number from modelled incidence — rt_from_incidence","text":"","code":"rt_from_incidence(df = i_incidence_model, ip = i_infectivity_profile)"},{"path":"/reference/rt_from_incidence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reproduction number from modelled incidence — rt_from_incidence","text":"df modelled incidence estimate dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` incidence.fit (double) - estimate incidence rate log scale incidence.se.fit (double) - standard error incidence rate estimate log scale incidence.0.025 (positive_double) - lower confidence limit incidence rate (true scale) incidence.0.5 (positive_double) - median estimate incidence rate (true scale) incidence.0.975 (positive_double) - upper confidence limit incidence rate (true scale) mandatory groupings. default value. ip infectivity profile dataframe containing following columns: boot (anything + default(1)) - bootstrap identifier time (positive_double) - end time period (days) probability (proportion) - probability infection previous time period `time` Must grouped : boot (exactly). default value defined.","code":""},{"path":"/reference/rt_from_incidence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reproduction number from modelled incidence — rt_from_incidence","text":"dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period rt.fit (double) - estimate reproduction number rt.se.fit (double) - standard error reproduction number rt.0.025 (double) - lower confidence limit reproduction number rt.0.5 (double) - median estimate reproduction number rt.0.975 (double) - upper confidence limit reproduction number mandatory groupings. default value.","code":""},{"path":"/reference/rt_from_incidence.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reproduction number from modelled incidence — rt_from_incidence","text":"","code":"df = ggoutbreak::england_covid %>%   time_aggregate(count=sum(count)) %>%     poisson_locfit_model()   if (FALSE) {   # not run   tmp3 = df %>% rt_from_incidence() }"},{"path":"/reference/rt_from_renewal.html","id":null,"dir":"Reference","previous_headings":"","what":"Reproduction number from renewal equation applied to modelled incidence using statistical re-sampling — rt_from_renewal","title":"Reproduction number from renewal equation applied to modelled incidence using statistical re-sampling — rt_from_renewal","text":"Calculate reproduction number estimate modelled incidence estimates, statistical sampling log-normally distributed incidence estimate, combined uncertain infectivity profile specified multiple discrete empirical distributions.","code":""},{"path":"/reference/rt_from_renewal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reproduction number from renewal equation applied to modelled incidence using statistical re-sampling — rt_from_renewal","text":"","code":"rt_from_renewal(   df = i_incidence_model,   ip = i_infectivity_profile,   bootstraps = 1000,   seed = Sys.time() )"},{"path":"/reference/rt_from_renewal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reproduction number from renewal equation applied to modelled incidence using statistical re-sampling — rt_from_renewal","text":"df modelled incidence estimate dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` incidence.fit (double) - estimate incidence rate log scale incidence.se.fit (double) - standard error incidence rate estimate log scale incidence.0.025 (positive_double) - lower confidence limit incidence rate (true scale) incidence.0.5 (positive_double) - median estimate incidence rate (true scale) incidence.0.975 (positive_double) - upper confidence limit incidence rate (true scale) mandatory groupings. default value. ip infectivity profile dataframe containing following columns: boot (anything + default(1)) - bootstrap identifier time (positive_double) - end time period (days) probability (proportion) - probability infection previous time period `time` Must grouped : boot (exactly). default value defined. bootstraps number samples take time point. rounded whole multiple infectivity profile distribution length. seed random number seed reproducibility","code":""},{"path":"/reference/rt_from_renewal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reproduction number from renewal equation applied to modelled incidence using statistical re-sampling — rt_from_renewal","text":"dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period rt.fit (double) - estimate reproduction number rt.se.fit (double) - standard error reproduction number rt.0.025 (double) - lower confidence limit reproduction number rt.0.5 (double) - median estimate reproduction number rt.0.975 (double) - upper confidence limit reproduction number mandatory groupings. default value.","code":""},{"path":"/reference/rt_from_renewal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reproduction number from renewal equation applied to modelled incidence using statistical re-sampling — rt_from_renewal","text":"","code":"df = ggoutbreak::england_covid %>%   time_aggregate(count=sum(count)) %>%     poisson_locfit_model()  if (FALSE) {   # not run   tmp2 = df %>% rt_from_renewal()  }"},{"path":"/reference/scale_y_log1p.html","id":null,"dir":"Reference","previous_headings":"","what":"A log1p y scale — scale_y_log1p","title":"A log1p y scale — scale_y_log1p","text":"log1p y scale","code":""},{"path":"/reference/scale_y_log1p.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A log1p y scale — scale_y_log1p","text":"","code":"scale_y_log1p(..., n = 5, base = 10, dp = 0)"},{"path":"/reference/scale_y_log1p.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A log1p y scale — scale_y_log1p","text":"... arguments passed scale_(x|y)_continuous() n number major breaks base base logarithm dp decimal points","code":""},{"path":"/reference/scale_y_log1p.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A log1p y scale — scale_y_log1p","text":"ggplot scale","code":""},{"path":"/reference/scale_y_logit.html","id":null,"dir":"Reference","previous_headings":"","what":"A logit y scale — scale_y_logit","title":"A logit y scale — scale_y_logit","text":"logit y scale","code":""},{"path":"/reference/scale_y_logit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A logit y scale — scale_y_logit","text":"","code":"scale_y_logit(...)"},{"path":"/reference/scale_y_logit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A logit y scale — scale_y_logit","text":"... arguments passed scale_(x|y)_continuous()","code":""},{"path":"/reference/scale_y_logit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A logit y scale — scale_y_logit","text":"ggplot scale","code":""},{"path":"/reference/time_aggregate.html","id":null,"dir":"Reference","previous_headings":"","what":"Aggregate time series data preserving the time series — time_aggregate","title":"Aggregate time series data preserving the time series — time_aggregate","text":"Aggregate time series data preserving time series","code":""},{"path":"/reference/time_aggregate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Aggregate time series data preserving the time series — time_aggregate","text":"","code":"time_aggregate(   df = i_timestamped,   ...,   .groups = NULL,   .cols = NULL,   .fns = NULL )"},{"path":"/reference/time_aggregate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Aggregate time series data preserving the time series — time_aggregate","text":"df optionally grouped time series. Grouping include time column. grouping works differently dplyr::summarise last level non-time groups lost operation, subgroup wish aggregate included grouping. ... set dplyr::summarise statements, additional parameters .fns .groups per dplyr::summarise .cols Optional tidyselect column specification dplyr::across. .fns given .cols parameter specified columns summarise automatically identified. Date columns dropped. want .cols ... must given .fns Optional set function specifications per dplyr::across","code":""},{"path":"/reference/time_aggregate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Aggregate time series data preserving the time series — time_aggregate","text":"summarised time series preserving time column, grouping structure involving one fewer levels input","code":""},{"path":"/reference/time_aggregate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Aggregate time series data preserving the time series — time_aggregate","text":"","code":"ggoutbreak::england_covid %>%   time_aggregate(count = sum(count), denom = sum(denom)) %>%   dplyr::glimpse() #> Rows: 1,410 #> Columns: 3 #> $ time  <time_prd> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1… #> $ count <dbl> 1, 0, 0, 1, 18, 0, 1, 0, 0, 3, 1, 1, 3, 1, 1, 0, 0, 0, 1, 0, 0, … #> $ denom <dbl> 19, 0, 0, 19, 342, 0, 19, 0, 0, 57, 19, 19, 57, 19, 19, 0, 0, 0,…  ggoutbreak::england_covid %>%   time_aggregate(.fns=mean) %>%   dplyr::glimpse() #> Rows: 1,410 #> Columns: 3 #> $ time  <time_prd> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1… #> $ count <dbl> 0.05263158, 0.00000000, 0.00000000, 0.05263158, 0.94736842, 0.00… #> $ denom <dbl> 1, 0, 0, 1, 18, 0, 1, 0, 0, 3, 1, 1, 3, 1, 1, 0, 0, 0, 1, 0, 0, …"},{"path":"/reference/time_summarise.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarise data from a line list to a time-series of counts. — time_summarise","title":"Summarise data from a line list to a time-series of counts. — time_summarise","text":"principally designed take record single events produce summary time-series count events group, class date. default behaviour guess cadence input data summarise event line list (set ) regular time-series counts use incidence growth rate estimates.","code":""},{"path":"/reference/time_summarise.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarise data from a line list to a time-series of counts. — time_summarise","text":"","code":"time_summarise(   df = i_dated,   unit,   anchor = \"start\",   rectangular = FALSE,   ...,   .fill = list(count = 0) )"},{"path":"/reference/time_summarise.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarise data from a line list to a time-series of counts. — time_summarise","text":"df line list data want summarise, optionally grouped. grouped group treated independently. remaining columns must contain date column may contain class column. count column present counts summed, otherwise individual row counted single event (linelist) unit period e.g. \"1 week\" anchor one date, \"start\" \"end\" weekday name e.g. \"mon\" always one start time periods cutting rectangular resulting time series length groups. case can sure data complete subgroups, otherwise missing data treated zero counts. important leading trailing missing data one subgroup can due reporting delay subgroup, case rectangular time series erroneously fill zero counts missing data. ... spec dplyr::summary(...) - optional, provided count = dplyr::n() count = sum(count) performed. .fill list similar tidyr::complete values fill variables ","code":""},{"path":"/reference/time_summarise.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarise data from a line list to a time-series of counts. — time_summarise","text":"output depends whether input grouped class column. detailed output : dataframe containing following columns: denom (positive_integer) - Total test counts associated specified timeframe count (positive_integer) - Positive case counts associated specified timeframe time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period mandatory groupings. default value. minimal output input plain list dated events: dataframe containing following columns: count (positive_integer) - Positive case counts associated specified timeframe time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period mandatory groupings. default value.","code":""},{"path":"/reference/time_summarise.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summarise data from a line list to a time-series of counts. — time_summarise","text":"data given class column time series interpreted denominator, consisting different classes within time period. may subtypes (e.g. variants, serotypes) markers test positivity. either case resulting time series counts classes denominators combination. flexibility kinds summarisation raw data count based (e.g. means continuous variables) case slider package usually going better, time summarise look non overlapping time periods fixed lengths. another use case existing  timeseries particular frequency aggregated another less frequent basis (e.g. moving daily timeseries weekly one). case input contain count column. mode checks made frequent events present summarisation result may include different numbers input periods (e.g. going weeks months may 4 5 weeks month)","code":""},{"path":"/reference/time_to_date.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a set of timepoints to dates — time_to_date","title":"Convert a set of timepoints to dates — time_to_date","text":"Convert set timepoints dates","code":""},{"path":"/reference/time_to_date.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a set of timepoints to dates — time_to_date","text":"","code":"time_to_date(   timepoints,   unit = attr(timepoints, \"unit\"),   start_date = attr(timepoints, \"start_date\") )"},{"path":"/reference/time_to_date.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert a set of timepoints to dates — time_to_date","text":"timepoints set numeric time points unit period / unit time points, extracted timepoints possible start_date zero day time series, extracted timepoints possible","code":""},{"path":"/reference/time_to_date.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert a set of timepoints to dates — time_to_date","text":"vector dates","code":""},{"path":"/reference/time_to_date.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert a set of timepoints to dates — time_to_date","text":"","code":"times = date_to_time(as.Date(\"2019-12-29\")+0:100, \"1 week\") dates = time_to_date(times)"},{"path":"/reference/type.time_period.html","id":null,"dir":"Reference","previous_headings":"","what":"Type coercion to a time_period class — type.time_period","title":"Type coercion to a time_period class — type.time_period","text":"Type coercion time_period class","code":""},{"path":"/reference/type.time_period.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Type coercion to a time_period class — type.time_period","text":"","code":"type.time_period(x)"},{"path":"/reference/type.time_period.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Type coercion to a time_period class — type.time_period","text":"x vector coerced time period","code":""},{"path":"/reference/type.time_period.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Type coercion to a time_period class — type.time_period","text":"time_period error","code":""},{"path":"/reference/type.time_period.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Type coercion to a time_period class — type.time_period","text":"","code":"type.time_period(1:100) #> time unit: day, origin: 2019-12-29 (a Sunday) #>   [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18 #>  [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36 #>  [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54 #>  [55]  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72 #>  [73]  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90 #>  [91]  91  92  93  94  95  96  97  98  99 100"},{"path":"/reference/wallinga_lipsitch.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the reproduction number from a growth rate estimate and an infectivity profile — wallinga_lipsitch","title":"Calculate the reproduction number from a growth rate estimate and an infectivity profile — wallinga_lipsitch","text":"Calculate reproduction number growth rate estimate infectivity profile","code":""},{"path":"/reference/wallinga_lipsitch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the reproduction number from a growth rate estimate and an infectivity profile — wallinga_lipsitch","text":"","code":"wallinga_lipsitch(r, y, a = 1:length(y))"},{"path":"/reference/wallinga_lipsitch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the reproduction number from a growth rate estimate and an infectivity profile — wallinga_lipsitch","text":"r growth rate (may vector) y empirical infectivity profile probability vector, starting P(0<t,[1]) end time estimate (defaults single days).","code":""},{"path":"/reference/wallinga_lipsitch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the reproduction number from a growth rate estimate and an infectivity profile — wallinga_lipsitch","text":"reproduction number estimate based r","code":""},{"path":"/reference/wallinga_lipsitch.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the reproduction number from a growth rate estimate and an infectivity profile — wallinga_lipsitch","text":"","code":"wallinga_lipsitch(r=seq(-0.1,0.1,length.out=9), y=dgamma(1:50, 5,2)) #> [1] 0.8140287 0.8581458 0.9038343 0.9511131 1.0000000 1.0505120 1.1026647 #> [8] 1.1564727 1.2119494"}]
