[{"path":"https://ai4ci.github.io/ggoutbreak/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2022 ggoutbreak authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (â€œSoftwareâ€), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED â€œâ€, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/articles/covid-timeseries.html","id":"incidence-and-growth-rate-from-case-positive-counts","dir":"Articles","previous_headings":"","what":"Incidence and growth rate from case positive counts","title":"England COVID-19 cases","text":"method uses case positive count dataset bundled growth rates age stratified (age grouping class column). look age stratification different vignettes instance want aggregate England wide rate. purpose time_aggregate() performs simple summarisation. raw COVID-19 case count log1p scale total detected cases per day.  Major events timeseries can plotted axes. â€™ve focussed first 2 years pandemic:  incidence model assumes case rates result Poisson process rate estimated time varying locally fitted polynomial degree defined deg parameter, using log link function, according methods Loader et al.Â (see utils::citation(\"locfit\")). fitting process local maximum likelihood estimation uses bandwidth defined account data points within window time point estimated. gradient fitted polynomial log scale, exponential growth rate. scale independent view rate growth epidemic. estimation methodology compared consensus estimates SPI-M-O UK government advisory group red, shifted forward time 14 days. SPI-M-O estimates made pandemic retrospective whereas ones can use information time point now may better represent timing changes.  state epidemic described incidence growth, phase plots allow us see different time points. case epidemic state 10 weeks leading Christmas 2021, 2022 2023:","code":"example_england_covid_by_age() %>% dplyr::glimpse() #> Rows: 26,790 #> Columns: 9 #> Groups: class [19] #> $ class      <fct> 00_04, 05_09, 10_14, 15_19, 20_24, 25_29, 30_34, 35_39, 40_â€¦ #> $ time       <t[day]> 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, â€¦ #> $ code       <chr> \"E92000001\", \"E92000001\", \"E92000001\", \"E92000001\", \"E92000â€¦ #> $ date       <date> 2020-01-30, 2020-01-30, 2020-01-30, 2020-01-30, 2020-01-30â€¦ #> $ name       <chr> \"England\", \"England\", \"England\", \"England\", \"England\", \"Engâ€¦ #> $ codeType   <chr> \"CTRY20\", \"CTRY20\", \"CTRY20\", \"CTRY20\", \"CTRY20\", \"CTRY20\",â€¦ #> $ count      <dbl> 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,â€¦ #> $ denom      <dbl> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,â€¦ #> $ population <dbl> 3299637, 3538206, 3354246, 3090232, 3487863, 3801409, 38079â€¦  data = example_england_covid_by_age() %>%   time_aggregate(count=sum(count)) fit = data %>%    poisson_locfit_model()   plot_incidence(fit,raw = data, colour=\"blue\",size=0.025)+   scale_y_log1p(n=7) plot_incidence(fit, raw = data, events = ukc19::timeline, colour=\"blue\",size=0.025)+   scale_y_log1p(n=7) + ggplot2::coord_cartesian(xlim=as.Date(c(\"2020-01-01\",\"2022-01-01\"))) plot_growth_rate(fit,events = ukc19::timeline, colour=\"blue\")+   ggplot2::coord_cartesian(xlim=as.Date(c(\"2020-01-01\",\"2022-01-01\")), ylim=c(-0.15,0.15))+   ggplot2::geom_errorbar(data=ukc19::spim_consensus, ggplot2::aes(x=date-14,ymin=growth.low,ymax=growth.high),colour=\"red\") plot_growth_phase(fit,     timepoints = as.Date(c(\"Xmas 2020\"=\"2020-12-25\",\"Xmas 2021\"=\"2021-12-25\",\"Xmas 2022\"=\"2022-12-25\")),     duration = 70,      interval = 7,     colour=\"blue\",     strip.position = \"top\" )"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/covid-timeseries.html","id":"reproduction-number-estimation","dir":"Articles","previous_headings":"","what":"Reproduction number estimation","title":"England COVID-19 cases","text":"growth rate unit â€œper dayâ€ example. can derive reproduction number, using methods Wallinga Lipsitch estimate infectivity profile COVID-19. describes probability infectee infected x days infector, includes temporal dimension rendering reproduction number dimensionless quantity reflecting average number infectees resulting infector. also methods infer reproduction number modelled incidence estimates logarithmic link functions used. described vignette: vignette(\"rt--incidence\", package=\"ggoutbreak\") ggoutbreak estimate infectivity profile based meta-analysis serial interval estimates COVID-19. infectivity profile bootstrapped set discrete probability distributions. truncated 14 days.  effective RtR_t estimates compared consensus values SPI-M-O group (red):  EpiEstim RtR_t fits comparison data, infectivity profile much certain exhibit oscillation due weekly periodicity underlying time series.","code":"covid_ip = example_ganyani_ip() ggoutbreak::plot_ip(ip=covid_ip, alpha=0.1) rt_fit = fit %>% ggoutbreak::rt_from_incidence(ip = covid_ip)  plot_rt(rt_fit, events = ukc19::timeline, colour=\"blue\")+   ggplot2::coord_cartesian(xlim=as.Date(c(\"2020-01-01\",\"2022-01-01\")), ylim=c(0.6,1.6))+   ggplot2::geom_errorbar(data=ukc19::spim_consensus, ggplot2::aes(x=date-14,ymin=rt.low,ymax=rt.high),colour=\"red\") rt_epi_fit = data %>% ggoutbreak::rt_epiestim(ip = covid_ip,window = 14)  plot_rt(rt_epi_fit, events = ukc19::timeline, colour=\"blue\")+   ggplot2::coord_cartesian(xlim=as.Date(c(\"2020-01-01\",\"2022-01-01\")), ylim=c(0.6,1.6))+   ggplot2::geom_errorbar(data=ukc19::spim_consensus,ggplot2::aes(x=date-14,ymin=rt.low,ymax=rt.high),colour=\"red\")"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/covid-timeseries.html","id":"prevalence-and-growth-rate-from-test-positivity-rates","dir":"Articles","previous_headings":"","what":"Prevalence and growth rate from test positivity rates","title":"England COVID-19 cases","text":"Test availability consistent pandemic. early stages PCR tests difficult obtain case positive incidence estimates thought vast underestimate. certain parts pandemic targeted testing high risk groups occurred. Test positivity different view pandemic accounts biases introduces others . data must contain denom column case represents number tests conducted:  case gradient proportion logistic scale estimate growth rate. senses relative growth testing effort case produces answer similar incidence model.  similar growth rate estimates method can also theoretically used calculate estimates RtR_t. Growth-proportion phase diagrams can also compare different points times see elsewhere, different populations.","code":"england_covid_pcr_positivity = ukc19::england_covid_positivity %>%    dplyr::mutate(time = as.time_period(date)) %>%   dplyr::group_by(code,name) %>%   dplyr::glimpse() #> Rows: 1,413 #> Columns: 7 #> Groups: code, name [1] #> $ date     <date> 2020-01-30, 2020-01-31, 2020-02-01, 2020-02-02, 2020-02-03, â€¦ #> $ code     <chr> \"E92000001\", \"E92000001\", \"E92000001\", \"E92000001\", \"E9200000â€¦ #> $ name     <chr> \"England\", \"England\", \"England\", \"England\", \"England\", \"Englaâ€¦ #> $ count    <dbl> 1, 0, 0, 1, 18, 0, 1, 0, 0, 3, 1, 1, 4, 1, 1, 0, 0, 0, 1, 0, â€¦ #> $ denom    <dbl> 53, 75, 165, 172, 297, 147, 155, 103, 186, 568, 583, 599, 887â€¦ #> $ codeType <chr> \"CTRY20\", \"CTRY20\", \"CTRY20\", \"CTRY20\", \"CTRY20\", \"CTRY20\", \"â€¦ #> $ time     <t[day]> -330, -329, -328, -327, -326, -325, -324, -323, -322, -321â€¦ fit2 = england_covid_pcr_positivity %>%   dplyr::filter(denom !=0) %>%   ggoutbreak::proportion_locfit_model()  plot_proportion(fit2, england_covid_pcr_positivity, events = ukc19::timeline, size=0.25, colour=\"blue\")+   ggplot2::coord_cartesian(xlim=as.Date(c(\"2020-01-01\",\"2022-01-01\"))) plot_growth_rate(fit2, events = ukc19::timeline, colour=\"blue\")+   ggplot2::coord_cartesian(xlim=as.Date(c(\"2020-01-01\",\"2022-01-01\")), ylim=c(-0.15,0.15))+   ggplot2::geom_errorbar(data=ukc19::spim_consensus, ggplot2::aes(x=date-14,ymin=growth.low,ymax=growth.high),colour=\"red\") plot_growth_phase(fit2,     timepoints = as.Date(c(\"Xmas 2020\"=\"2020-12-25\",\"Xmas 2021\"=\"2021-12-25\",\"Xmas 2022\"=\"2022-12-25\")),     duration = 70,      interval = 7,     colour=\"blue\" )"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/covid-timeseries.html","id":"nhs-covid-app","dir":"Articles","previous_headings":"","what":"NHS COVID app","title":"England COVID-19 cases","text":"NHS COVID-19 app performed digital contact tracing. rate venue check-ins demonstrates levels high risk social contacts however became optional Aug 2021. Self isolation alerts peaked Aug / Sept 2021 Delta wave Dec 2021 / Jan 2022 Omicron wave. Periods rapid growth precede increases NHS app notifications. (N.B. data https://www.gov.uk/government/publications/nhs-covid-19-app-statistics)  weekly alerts data can also modelled poisson process can converted daily timeseries aligned incidence growth rate data. fully aligned modelled data set can test granger causality: conclusion test growth predictive alerts rather vice versa, much depends precise timing recorded data may subject reporting delays, well time delays result modelling.","code":"p1 = plot_incidence(fit,events = ukc19::timeline, colour=\"blue\", date_breaks=\"3 months\")+   ggplot2::coord_cartesian(xlim=as.Date(c(\"2020-01-01\",\"2023-07-01\")))+   ggplot2::facet_wrap(~\"Cases\")+   ggplot2::theme(axis.text.x.bottom = ggplot2::element_blank())+   scale_y_log1p()  p2 = plot_growth_rate(fit,events = ukc19::timeline, colour=\"blue\", date_breaks=\"3 months\")+   ggplot2::coord_cartesian(xlim=as.Date(c(\"2020-01-01\",\"2023-07-01\")), ylim=c(-0.15,0.15))+   ggplot2::geom_errorbar(data=ukc19::spim_consensus,ggplot2::aes(x=date-21,ymin=growth.low,ymax=growth.high),colour=\"red\")+   ggplot2::facet_wrap(~\"Growth rate\")+   ggplot2::theme(axis.text.x.bottom = ggplot2::element_blank(),axis.text.x.top = ggplot2::element_blank())  p3 = ggplot2::ggplot(ukc19::nhs_app)+   geom_events(events=ukc19::timeline,hide_labels = TRUE)+   ggplot2::geom_step(ggplot2::aes(x=date, y=alerts/mean(alerts, na.rm=TRUE),colour=\"alerts\"))+   ggplot2::geom_step(ggplot2::aes(x=date, y=visits/mean(visits, na.rm=TRUE),colour=\"venue visits\"))+   ggplot2::geom_rect(ggplot2::aes(xmin=date,xmax=dplyr::lead(date), ymin=0, ymax=alerts/mean(alerts, na.rm=TRUE),fill=\"alerts\"), linewidth=0, alpha=0.2)+   ggplot2::geom_rect(ggplot2::aes(xmin=date,xmax=dplyr::lead(date), ymin=0, ymax=visits/mean(visits, na.rm=TRUE),fill=\"venue visits\"), linewidth=0, alpha=0.2)+   ggplot2::coord_cartesian(xlim=as.Date(c(\"2020-01-01\",\"2023-07-01\")))+   ggplot2::ylab(\"relative frequency\")+   ggplot2::xlab(NULL)+   ggplot2::facet_wrap(~\"NHS app\")+   ggplot2::scale_color_brewer(palette=\"Dark2\", name=NULL, aesthetics = c(\"fill\",\"colour\"))+   ggplot2::scale_x_date(date_breaks=\"3 months\",date_labels = \"%b %y\")+   ggplot2::theme(legend.position = \"bottom\")  p1+p2+p3+patchwork::plot_layout(ncol=1) alerts = ukc19::nhs_app %>%    dplyr::mutate(time = as.time_period(date)) %>%   dplyr::rename(count = alerts) %>%    poisson_locfit_model() %>%    rescale_model(\"1 day\") %>%   dplyr::mutate(time = as.time_period(time, fit$time)) %>%   dplyr::select(-dplyr::starts_with(\"growth\")) %>%   dplyr::rename_with(.cols = dplyr::starts_with(\"incidence\"), .fn = ~ stringr::str_replace(.x,\"incidence\",\"alert\")) %>%   dplyr::inner_join(fit, by=\"time\")  lmtest::grangertest(alert.0.5 ~ growth.0.5, order = 1, data=alerts) #> Granger causality test #>  #> Model 1: alert.0.5 ~ Lags(alert.0.5, 1:1) + Lags(growth.0.5, 1:1) #> Model 2: alert.0.5 ~ Lags(alert.0.5, 1:1) #>   Res.Df Df      F    Pr(>F)     #> 1    133                         #> 2    134 -1 38.071 7.671e-09 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 lmtest::grangertest(growth.0.5 ~ alert.0.5, order = 1, data=alerts) #> Granger causality test #>  #> Model 1: growth.0.5 ~ Lags(growth.0.5, 1:1) + Lags(alert.0.5, 1:1) #> Model 2: growth.0.5 ~ Lags(growth.0.5, 1:1) #>   Res.Df Df      F Pr(>F) #> 1    133                  #> 2    134 -1 0.2767 0.5998  lmtest::grangertest(incidence.0.5 ~ alert.0.5, order = 1, data=alerts) #> Granger causality test #>  #> Model 1: incidence.0.5 ~ Lags(incidence.0.5, 1:1) + Lags(alert.0.5, 1:1) #> Model 2: incidence.0.5 ~ Lags(incidence.0.5, 1:1) #>   Res.Df Df      F  Pr(>F)   #> 1    133                     #> 2    134 -1 4.9361 0.02799 * #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 lmtest::grangertest(alert.0.5 ~ incidence.0.5, order = 1, data=alerts) #> Granger causality test #>  #> Model 1: alert.0.5 ~ Lags(alert.0.5, 1:1) + Lags(incidence.0.5, 1:1) #> Model 2: alert.0.5 ~ Lags(alert.0.5, 1:1) #>   Res.Df Df      F Pr(>F) #> 1    133                  #> 2    134 -1 0.0658 0.7979"},{"path":[]},{"path":"https://ai4ci.github.io/ggoutbreak/articles/estimators-example.html","id":"simple-incidence-test-with-a-poisson-model","dir":"Articles","previous_headings":"Locfit models","what":"Simple incidence test with a poisson model","title":"Simulation tests for growth rate estimators","text":"incidence mode based absolute counts:  Estimated absolute growth rate versus simulation (red)","code":"data = sim_poisson_model() data %>% dplyr::glimpse() #> Rows: 105 #> Columns: 6 #> Groups: statistic [1] #> $ time      <t[day]> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,â€¦ #> $ growth    <dbl> 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, â€¦ #> $ imports   <dbl> 100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0â€¦ #> $ rate      <dbl> 100.0000, 110.5171, 122.1403, 134.9859, 149.1825, 164.8721, â€¦ #> $ count     <int> 89, 99, 130, 132, 139, 154, 180, 232, 227, 252, 275, 309, 36â€¦ #> $ statistic <chr> \"infections\", \"infections\", \"infections\", \"infections\", \"infâ€¦ tmp = data %>% poisson_locfit_model(window=7, deg = 2)  plot_incidence(tmp, data)+ggplot2::geom_line(   mapping=ggplot2::aes(x=as.Date(time),y=rate), data=data, colour=\"red\",inherit.aes = FALSE) plot_growth_rate(tmp)+   ggplot2::geom_line(mapping=ggplot2::aes(x=as.Date(time),y=growth), data=data, colour=\"red\",inherit.aes = FALSE) plot_growth_phase(tmp)"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/estimators-example.html","id":"multinomial-data","dir":"Articles","previous_headings":"Locfit models","what":"Multinomial data","title":"Simulation tests for growth rate estimators","text":"Multiple classes simulated 3 independent epidemics (â€˜variant1â€™, â€˜variant2â€™ â€˜variant3â€™) known growth rates initial sample size resulting 3 parallel time series. combined give overall epidemic proportional distribution â€˜variantâ€™ fraction whole. relative growth rate calculated based set parameters.","code":"data2 = sim_multinomial() %>% dplyr::group_by(class) %>% dplyr::glimpse() #> Rows: 315 #> Columns: 10 #> Groups: class [3] #> $ time            <t[day]> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1â€¦ #> $ growth          <dbl> 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,â€¦ #> $ imports         <dbl> 100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0â€¦ #> $ rate            <dbl> 100.0000, 110.5171, 122.1403, 134.9859, 149.1825, 164.â€¦ #> $ count           <int> 110, 105, 132, 144, 151, 174, 198, 207, 245, 260, 268,â€¦ #> $ statistic       <chr> \"infections\", \"infections\", \"infections\", \"infections\"â€¦ #> $ class           <chr> \"variant1\", \"variant1\", \"variant1\", \"variant1\", \"variaâ€¦ #> $ proportion      <dbl> 0.3333333, 0.3382826, 0.3420088, 0.3445125, 0.3458146,â€¦ #> $ proportion.obs  <dbl> 0.3503185, 0.3230769, 0.3646409, 0.3711340, 0.3842239,â€¦ #> $ relative.growth <dbl> 0.025000000, 0.019385523, 0.013833622, 0.008404115, 0.â€¦"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/estimators-example.html","id":"poisson-model","dir":"Articles","previous_headings":"Locfit models > Multinomial data","what":"Poisson model","title":"Simulation tests for growth rate estimators","text":"Firstly fitting incidence model groupwise fashion:  absolute growth rates:","code":"tmp2 = data2 %>% poisson_locfit_model(window=7, deg = 1)  plot_incidence(tmp2, data2)+scale_y_log1p() plot_growth_rate(modelled = tmp2)+    ggplot2::geom_line(mapping=ggplot2::aes(x=as.Date(time),y=growth, colour=class), data=data2, inherit.aes = FALSE)+    ggplot2::facet_wrap(dplyr::vars(class), ncol=1)"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/estimators-example.html","id":"one-versus-others-binomial-model","dir":"Articles","previous_headings":"Locfit models > Multinomial data","what":"One versus others Binomial model","title":"Simulation tests for growth rate estimators","text":"looks proportions three variants growth rate relative : Firstly proportions:  secondly relative growth rate:","code":"# This will reinterpret total to be the total of positives across all variants data3 = data2 %>%    dplyr::group_by(time) %>%    dplyr::mutate(denom = sum(count)) %>%   dplyr::group_by(class) %>%   dplyr::glimpse() #> Rows: 315 #> Columns: 11 #> Groups: class [3] #> $ time            <t[day]> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1â€¦ #> $ growth          <dbl> 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,â€¦ #> $ imports         <dbl> 100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0â€¦ #> $ rate            <dbl> 100.0000, 110.5171, 122.1403, 134.9859, 149.1825, 164.â€¦ #> $ count           <int> 110, 105, 132, 144, 151, 174, 198, 207, 245, 260, 268,â€¦ #> $ statistic       <chr> \"infections\", \"infections\", \"infections\", \"infections\"â€¦ #> $ class           <chr> \"variant1\", \"variant1\", \"variant1\", \"variant1\", \"variaâ€¦ #> $ proportion      <dbl> 0.3333333, 0.3382826, 0.3420088, 0.3445125, 0.3458146,â€¦ #> $ proportion.obs  <dbl> 0.3503185, 0.3230769, 0.3646409, 0.3711340, 0.3842239,â€¦ #> $ relative.growth <dbl> 0.025000000, 0.019385523, 0.013833622, 0.008404115, 0.â€¦ #> $ denom           <int> 314, 325, 362, 388, 393, 490, 565, 637, 658, 762, 828,â€¦ tmp3 = data3 %>% proportion_locfit_model(window=14, deg = 2)  plot_proportion(modelled = tmp3,raw = data3)+   ggplot2::facet_wrap(dplyr::vars(class), ncol=1) plot_growth_rate(modelled = tmp3)+    ggplot2::geom_line(mapping=ggplot2::aes(x=as.Date(time),y=relative.growth, colour=class), data=data2, inherit.aes = FALSE)+    ggplot2::facet_wrap(dplyr::vars(class), ncol=1) plot_growth_phase(tmp3)"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/estimators-example.html","id":"multinomial-model","dir":"Articles","previous_headings":"Locfit models > Multinomial data","what":"Multinomial model","title":"Simulation tests for growth rate estimators","text":"multinomial model gives us absolute proportions (growth rates)","code":"# we don't need to calculate the denominator as it is done automatically by the  # multinomial model  tmp4 = data2 %>% multinomial_nnet_model() #> # weights:  30 (18 variable) #> initial  value 355466.992121  #> iter  10 value 179300.960957 #> iter  20 value 176149.623005 #> final  value 174429.728510  #> converged plot_multinomial(tmp4) # plot_multinomial(tmp3, events = event_test,normalise = TRUE)"},{"path":[]},{"path":"https://ai4ci.github.io/ggoutbreak/articles/estimators-example.html","id":"poisson-model-1","dir":"Articles","previous_headings":"GLM models","what":"Poisson model","title":"Simulation tests for growth rate estimators","text":"Run poisson model input data using glm returns incidence . Derived growth rates can estimated using savitsky-golay filter based approach.","code":"tmp5 = data %>% poisson_glm_model(window=7) %>% growth_rate_from_incidence() plot_incidence(tmp5,data) plot_growth_rate(tmp5)+   ggplot2::geom_line(mapping=ggplot2::aes(x=as.Date(time),y=growth), data=data, colour=\"red\",inherit.aes = FALSE) plot_growth_phase(tmp5)"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/estimators-example.html","id":"binomial-model","dir":"Articles","previous_headings":"GLM models","what":"Binomial model","title":"Simulation tests for growth rate estimators","text":"Run binomial model input data using glm returns absolute proportions derived growth rates point supported.","code":"tmp6 = data3 %>% proportion_glm_model(window=14, deg = 2) plot_proportion(tmp6,data3)"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/ggoutbreak.html","id":"background","dir":"Articles","previous_headings":"","what":"Background","title":"Getting started with `ggoutbreak`","text":"collection tools COVID-19 focus simplicity goal provide simple pipeline data visualisation. main features listed . documentation development. time best resources vignettes including: vignette(\"covid-timeseries\",package=\"ggoutbreak\") vignette(\"incidence-trends\",package=\"ggoutbreak\") vignette(\"variant-proportions\",package=\"ggoutbreak\") vignette(\"weekly-incidence\",package=\"ggoutbreak\") vignette(\"rt--incidence\",package=\"ggoutbreak\") vignette(\"simulation-test-models\",package=\"ggoutbreak\")","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/articles/ggoutbreak.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"Getting started with `ggoutbreak`","text":"ggoutbreak hosted AI4CI r-universe. Installation follows: can install development version ggoutbreak GitHub :","code":"options(repos = c(   \"ai4ci\" = 'https://ai4ci.r-universe.dev/',   CRAN = 'https://cloud.r-project.org'))  # Download and install ggoutbreak in R install.packages(\"ggoutbreak\") # install.packages(\"devtools\") devtools::install_github(\"ai4ci/ggoutbreak\")"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/ggoutbreak.html","id":"features","dir":"Articles","previous_headings":"","what":"Features","title":"Getting started with `ggoutbreak`","text":"Simulation Poisson (aggregate count) & branching process (line list) Time varying parametrisations Test harness estimators, including scoring metrics. Estimation Collection methods incidence, growth rate, reproduction number (wrappers existing tools) Poisson count binomial/multinomial proportion models Visualization Default ggplot2 visualisations epidemic time series, including adjustment population variable time steps.","code":""},{"path":[]},{"path":"https://ai4ci.github.io/ggoutbreak/articles/ggoutbreak.html","id":"models","dir":"Articles","previous_headings":"Simulation","what":"Models:","title":"Getting started with `ggoutbreak`","text":"Poisson growth rate (count model) Poisson reproduction number (count model) Branching process model (individual model) SEIR ODE (compartment model)","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/articles/ggoutbreak.html","id":"time-varying-parameters","dir":"Articles","previous_headings":"Simulation","what":"Time varying parameters:","title":"Getting started with `ggoutbreak`","text":"Rt / growth rate / transmission Importation Generation time Ascertainment Delay observation, e.g.Â symptoms, admissions, death Contact matrices Dispersion","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/articles/ggoutbreak.html","id":"scoring","dir":"Articles","previous_headings":"Simulation","what":"Scoring","title":"Getting started with `ggoutbreak`","text":"mean_quantile_bias - average universal residuals. Lower values better. mean_bias - bias natural scale (may interpreted additive multiplicative depending link) pit_was - unadjusted probability integral transform histogram Wasserstein distance uniform (lower values better). unbiased_pit_was - PIT Wasserstein distance uniform, adjusted estimator bias (lower values better). measure calibration. directed_pit_was - PIT Wasserstein distance uniform, directed away centre, adjusted estimator bias (values closer zero better, positive values indicate overconfidence, negative values excessively conservative estimates). percent_iqr_coverage - percentage estimators include true value IQR. perfectly calibrated estimate 0.5. Lower values reflect overconfidence, higher values reflect excessively conservative estimates. measure calibration influenced bias. unbiased_percent_iqr_coverage - percentage estimators include true value IQR adjusted bias. 0.5. measure calibration, tells direction (smaller numbers -confident, larger values excessively conservative). mean_prediction_interval_width_50 - prediction interval width measure sharpness (smaller values sharper). Sharper estimators superior unbiased well calibrated. mean_crps - mean value continuous rank probability score point estimate (lower values better) threshold_misclassification_probability - metric natural threshold like 1 RtR_t measures probable estimate propose epidemic shrinking growing vice versa. Lower better.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/articles/ggoutbreak.html","id":"estimation-methods","dir":"Articles","previous_headings":"","what":"Estimation methods","title":"Getting started with `ggoutbreak`","text":"Rapid simple estimates. methods can operate multiple sub-group time series. Supports daily / weekly / monthly / yearly time series* Testing estimators simulations.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/articles/ggoutbreak.html","id":"infectivity-profile-estimation","dir":"Articles","previous_headings":"Estimation methods","what":"Infectivity profile estimation","title":"Getting started with `ggoutbreak`","text":"Estimation generation time serial interval published estimates (including uncertainty) Resampled raw interval data (bootstrapping uncertainty) posterior estimates fitted gamma distribution","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/articles/ggoutbreak.html","id":"poisson-rate-models","dir":"Articles","previous_headings":"Estimation methods","what":"Poisson rate models","title":"Getting started with `ggoutbreak`","text":"Locfit GLM fitted time varying quasipoisson model. GAM models including adjustment right censoring. Estimates incidence growth rate Normalisation per capita population population baseline rate","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/articles/ggoutbreak.html","id":"binomial-proportion-models","dir":"Articles","previous_headings":"Estimation methods","what":"Binomial proportion models","title":"Getting started with `ggoutbreak`","text":"Locfit GLM fitted time varying quasibinomial model. Estimates proportion relative growth rate Normalisation population baseline risk","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/articles/ggoutbreak.html","id":"multinomial-proportion-models","dir":"Articles","previous_headings":"Estimation methods","what":"Multinomial proportion models","title":"Getting started with `ggoutbreak`","text":"nnet based multinomial proportion models.","code":""},{"path":[]},{"path":"https://ai4ci.github.io/ggoutbreak/articles/ggoutbreak.html","id":"epiestim-wrapper","dir":"Articles","previous_headings":"Estimation methods > RtR_t estimation methods:","what":"EpiEstim wrapper","title":"Getting started with `ggoutbreak`","text":"Simple adaptor EpiEstim reference method","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/articles/ggoutbreak.html","id":"reimplementation-of-cori-method","dir":"Articles","previous_headings":"Estimation methods > RtR_t estimation methods:","what":"Reimplementation of Cori method","title":"Getting started with `ggoutbreak`","text":"Inputs raw incidence time series Reimplementation integrates estimates range time windows Handles missing data. Less lag uncertainty.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/articles/ggoutbreak.html","id":"wallinga-and-lipsitch-growth-rates-method","dir":"Articles","previous_headings":"Estimation methods > RtR_t estimation methods:","what":"Wallinga and Lipsitch growth rates method","title":"Getting started with `ggoutbreak`","text":"Inputs exponential growth rate time series estimate (assumed normally distributed) Uses MGF discrete SI distribution Monte-Carlo resampling propagation uncertainty Moderately slow","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/articles/ggoutbreak.html","id":"r_t-from-modelled-incidence","dir":"Articles","previous_headings":"Estimation methods > RtR_t estimation methods:","what":"RtR_t from modelled incidence","title":"Getting started with `ggoutbreak`","text":"Inputs log-normally distributed incidence estimate. Propagates uncertainty infectivity profile incidence data Deterministic & tolerant missing values. Can use incidence model derived weekly count time series. Can deal negative values serial interval","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/articles/ggoutbreak.html","id":"bootstrapped-renewal-eqaution","dir":"Articles","previous_headings":"Estimation methods > RtR_t estimation methods:","what":"Bootstrapped renewal eqaution","title":"Getting started with `ggoutbreak`","text":"Inputs distributional incidence estimate. Uses resampling propagate uncertainty incidence infectivity profile Non deterministic, can use weekly time-series","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/articles/incidence-trends.html","id":"incidence-poisson-rate-model","dir":"Articles","previous_headings":"","what":"Incidence Poisson rate model","title":"Population comparisons and incidence","text":"plot normalised incidence rates COVID-19 population size, shows initially rate COVID cases highest elderly. late 2020 pattern changed rates uniform across age groups. early 2021 vaccination took hold school testing rolled , younger age groups higher rates COVID positive tests, curious spike young age groups around November 2021. early 2022 pattern reversed elderly became age group highest rates, pattern persisted present. Transiently instantaneous rates per 1000 person years exceeded 1000 age groups, possible limited time periods, multiple episodes per year can observed.  use test positives proxy COVID incidence clearly potentially biased testing (particularly first wave testing limited hospital). reliable comparison situation test positive proportion, unfortunately testing rates published broken age. exponential growth rate already normalised population size. Comparisons growth rate populations gives idea tightly coupled . age groups epidemic growing shrinking sync apart possibly young. COVID detections age group particularly reliable though easy -interpret.  combination growth normalised incidence allows us compare epidemic state different time points, case Christmas day 2020, 2021 2022. shows data previous graphs.","code":"poisson_model = example_england_covid_by_age() %>%    ggoutbreak::poisson_locfit_model(window=21) %>%    ggoutbreak::normalise_incidence(england_demographics, population_unit=1000, normalise_time=\"1 year\")  raw_pop = example_england_covid_by_age() %>%    ggoutbreak::normalise_count(england_demographics, population_unit=1000, normalise_time=\"1 year\")  plot_incidence(poisson_model, raw = raw_pop, size=0.25)+scale_y_log1p(n=7)+   ggplot2::scale_colour_viridis_d(aesthetics = c(\"fill\",\"colour\")) plot_growth_rate(poisson_model)+   ggplot2::scale_fill_viridis_d(aesthetics = c(\"fill\",\"colour\"))+   ggplot2::coord_cartesian(ylim=c(-0.15,0.15)) plot_growth_phase(poisson_model,     timepoints = as.Date(c(\"Xmas 2020\"=\"2020-12-25\",\"Xmas 2021\"=\"2021-12-25\",\"Xmas 2022\"=\"2022-12-25\")),     duration = 70,      interval = 7 )+   ggplot2::scale_colour_viridis_d()"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/incidence-trends.html","id":"proportion-model","dir":"Articles","previous_headings":"","what":"Proportion model","title":"Population comparisons and incidence","text":"two possible proportions models interest . mentioned proportion positive tests age group give us clearer picture whether differences age groups differential testing, unfortunately testing denominator available data set. second potential use distribution ages test positive age group. age distribution gives us information burden disease population also biased test prioritisation. case denominator number cases age groups, proportions model tells us relative frequency cases age group. multinomial proportion shows similar patterns normalised incidence plot :  age distribution test positives can normalised age distribution population. give us relative proportion age groups people testing positive versus expected population. conceptually relative risk age group given COVID status .e.Â P(age=80+|COVID+)P(age=80+)\\frac{P(age = 80+|COVID+)}{P(age = 80+)} point time given population quantity centred around 1 comparing growth rate gives us possibly clearer picture trajectory relative distribution COVID population. Xmas 2021 although majority cases young, relatively high growth elderly population meant catching , can see early 2022 elderly highest COVID positive rates. 2022 however, separation age groups established trajectories acting preserve separation.","code":"binomial_model = example_england_covid_by_age() %>%     ggoutbreak::proportion_locfit_model(window=21) %>%     dplyr::group_by(class)  p1 = plot_multinomial(binomial_model, normalise = TRUE)+   ggplot2::scale_fill_viridis_d()  p2 = ggplot2::ggplot(england_demographics)+   ggplot2::geom_bar(ggplot2::aes(x=\"baseline\",y=population/sum(population)*100,fill=class), stat=\"identity\", position=\"stack\", colour=\"black\", linewidth=0.1)+   ggplot2::scale_fill_viridis_d(guide=\"none\")+   ggplot2::xlab(NULL)+   ggplot2::ylab(NULL)+   ggplot2::theme(axis.text.y = ggplot2::element_blank())+   ggplot2::coord_cartesian(expand=FALSE)  p1+p2+patchwork::plot_layout(nrow=1,widths = c(20,1),guides = \"collect\") risk_ratio_model = binomial_model %>% infer_risk_ratio(england_demographics %>% dplyr::group_by(class))  plot_growth_phase(risk_ratio_model,     timepoints = as.Date(c(\"Xmas 2020\"=\"2020-12-25\",\"Xmas 2021\"=\"2021-12-25\",\"Xmas 2022\"=\"2022-12-25\")),     duration = 70,      interval = 7 )+   ggplot2::scale_colour_viridis_d()"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/incidence-trends.html","id":"pre-test-probability","dir":"Articles","previous_headings":"Proportion model","what":"Pre test probability","title":"Population comparisons and incidence","text":"Using ONS COVID-19 infection survey can look population prevalence based random sampling (panel ). proportion people positive random sample population can compared proportion people testing positive people tested. ratio indication pre-test probability disease non-random sample group gives us idea selectively testing applied. testing done people symptoms example pre-test probability disease higher general population. shown panel B, also can interpreted biased sample tested symptoms . Likewise incidence cases per capita can compared prevalence. prevalence-like estimate can made incidence convolving incidence estimate delay distribution represents duration infection. Duration infection represented either sensitivity test detect infection function time infection, probability successful viral culture function time symptom onset. case ratio prevalence derived positive case counts, resulting symptomatic testing, prevalence measured directly random sample ONS survey connection ascertainment rate. actual value ascertainment rate calculated method depends heavily assumptions duration infection, hence prevalence derived case rates, absolute value derived ascertainment reliable, however relative change number still informative demonstrates case ascertainment fell abruptly omicron wave (panel C).","code":"england_ons_infection_survey = ukc19::ons_infection_survey %>%    dplyr::filter(name == \"England\") %>%   dplyr::mutate(time = as.time_period(date))  p1 = ggoutbreak::plot_prevalence(     england_ons_infection_survey,     events = ukc19::timeline   )+   ggplot2::theme(     axis.title.x = ggplot2::element_blank(),      axis.text.x = ggplot2::element_blank(),      axis.text.x.bottom = ggplot2::element_blank()   )+   ggplot2::ylab(\"ONS prevalence (%)\")   p2 = ukc19::england_covid_positivity %>%    dplyr::filter(name == \"England\") %>%   dplyr::mutate(time = as.time_period(date, england_ons_infection_survey$time)) %>%   proportion_locfit_model() %>%   dplyr::inner_join(england_ons_infection_survey %>%                        dplyr::rename_with(.cols = dplyr::starts_with(\"prevalence\"), .fn = ~stringr::str_replace(.x,\"prevalence\",\"ons\")), by=c(\"time\")   ) %>%   dplyr::transmute(date=date, pre_test_odds = proportion.0.5 / ons.0.5) %>%   ggplot2::ggplot(ggplot2::aes(x=date,y=pre_test_odds)) + ggplot2::geom_line() +   ggplot2::geom_hline(yintercept=1, colour=\"grey40\",linetype=\"dashed\") +   ggplot2::ylab(\"Pre-test odds ratio\") +   ggoutbreak::geom_events(events = ukc19::timeline,hide_labels = TRUE)+   ggplot2::theme(     axis.title.x = ggplot2::element_blank(),      axis.text.x = ggplot2::element_blank(),      axis.text.x.bottom = ggplot2::element_blank(),      axis.text.x.top = ggplot2::element_blank()   ) england_pop = england_demographics %>%    dplyr::ungroup() %>%    dplyr::summarise(population = sum(population))  p3 = ukc19::england_covid_positivity %>%    dplyr::mutate(time = as.time_period(date)) %>%   dplyr::filter(name == \"England\") %>%   ggoutbreak::poisson_locfit_model() %>%   # N.B. `covid_viral_shedding` is technically from symptom onset not infection.   # We could argue that this is a good thing as case positivity is closer in time   # to symptom onset however this is forgetting about all the cases that would   # test positive if they had been tested. An alternative to this would have been    # to use `covid_test_sensitivity` which looks at probability of detection from    # time of infection but it is only in cases with proven infection so a biased    # prior.   ggoutbreak::infer_prevalence(pop = england_pop, ip = ukc19::viral_shedding$resampled ) %>%   dplyr::inner_join(     england_ons_infection_survey %>%        dplyr::filter(name==\"England\") %>%        dplyr::rename_with(.cols = dplyr::starts_with(\"prevalence\"), .fn = ~stringr::str_replace(.x,\"prevalence\",\"ons\")), by=c(\"time\")   ) %>%   dplyr::transmute(date=date, ascertainment = prevalence.0.5 / ons.0.5 * 100) %>%   ggplot2::ggplot(ggplot2::aes(x=date,y=ascertainment)) +    ggplot2::geom_line() +    ggplot2::ylab(\"Ascertainment rate (%)\") +   ggoutbreak::geom_events(events = ukc19::timeline, hide_labels = TRUE)   p1+p2+p3+patchwork::plot_layout(ncol=1)+patchwork::plot_annotation(tag_levels=\"A\")"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/infectivity-profile-discretisation.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Infectivity profile discretisation","text":"methods involved EpiEstim require infectivity profile discrete probability distribution probability transmission time zero zero. diseases shorter serial interval, constraints difficult resolve, discretisation infectivity profile distribution using offset 1 gamma distribution results unusual shape discrete distribution. Wallinga-Lipsitch framework estimating reproduction number growth rate constraints apply can compare EpiEstims discretisation approach one closer originally estimated continuous distribution, requires framework can handle non zero probability transmission day zero. comparison suggests discretisation may bias EpiEstims estimates reproduction number 20% growth rates high, even higher compared equilibrium point Rt=1R_t=1. Alternative strategies discretisation frameworks relax requirement probability infection zero time zero benefit investigation particularly diseases shorter serial interval.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/articles/right-censoring.html","id":"background","dir":"Articles","previous_headings":"","what":"Background","title":"Estimating the reproduction number from right censored data","text":"Right censoring typically seen epidemiological data result delays observing proportion patients.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/articles/right-censoring.html","id":"simulation","dir":"Articles","previous_headings":"","what":"Simulation","title":"Estimating the reproduction number from right censored data","text":"TODO: setup simulation.  Fit GAM delay term : Plot fitted incidence accounting non observed cases:  Plot associated RtR_t estimate:","code":"# changes = dplyr::tribble( #   ~t,    ~r, #   0,      0, #   5,     0.2, #   10,     0.1, #   20,     0, #   25,     -0.1, #   35,     -0.05, #   45,     0.1 # )   #  # bpm = sim_branching_process(seed = 100) %>% #   ggoutbreak::sim_apply_delay() %>% #   glimpse() #  #  # # timeseries counts by observation day: # # All of this is observation delay (not physiological delay) # # sample results available when with result (sample date) # # admissions and deaths delayed reporting. # # test results available immediately (reporting date) # # symptoms available immediately #  # delayed_counts = bpm %>% #   ggoutbreak::sim_summarise_linelist( #     censoring = list( #       admitted = function(t) rgamma2(t, mean = 5), #       death = function(t) rgamma2(t, mean = 10), #       sample = function(t, result_delay) result_delay #     ), #     max_time = 0:80 #   ) #  # plot_counts( #   delayed_counts %>% filter(obs_time %% 10 == 0), #   mapping = aes(colour = labels(obs_time)) # ) + #   geom_line() + #   facet_wrap(~statistic, scales = \"free_y\") #  # test_delayed_observation = delayed_counts %>% #   filter(statistic == \"admitted\") %>% #   select(statistic, obs_time, time, count) %>% #   glimpse()   sim = example_delayed_observation() plot_counts(sim %>% dplyr::filter(floor(obs_time) %% 5==0), mapping = ggplot2::aes(colour=factor(obs_time)))+   ggplot2::geom_line() model = gam_delayed_reporting(knots_fn = ~ c(15,30,40,45,50,60,70,75)) poisson_gam = sim %>% poisson_gam_model(   model_fn = model$model_fn,   predict = model$predict,   ip=example_ip()) plot_incidence(poisson_gam)+     ggplot2::geom_line(        data=sim,        mapping = ggplot2::aes(x=as.Date(time),y=count,colour=as.factor(obs_time))        )+     ggplot2::guides(colour=ggplot2::guide_none()) plot_rt(poisson_gam, events = sim_events(sim),         ip = example_ip())"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/rt-from-incidence.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Estimating the reproduction number from modelled incidence","text":"estimated incidence disease ItI_t using poisson rate using maximum likelihood estimators, rate typically log-normally distributed parameters Î¼\\mu Ïƒ\\sigma. fitted model shown log1p scale, COVID-19 epidemic England:  appealing use modelled incidence estimate calculate estimate reproduction number, RtR_t. Incidence models can derived number ways, easily inspected error can made tolerant missing values outliers.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/articles/rt-from-incidence.html","id":"methods","dir":"Articles","previous_headings":"","what":"Methods","title":"Estimating the reproduction number from modelled incidence","text":"use modelled estimate incidence predict RtR_t need propagate uncertainty incidence RtR_t estimates. calculate RtR_t can use backwards-looking renewal equations incorporate infectivity profile disease (Ï‰\\omega) number days infection (Ï„\\tau): âˆ¼Poisson(Î»t)Î»tâˆ¼Lognormal(Î¼t,Ïƒt)Rt=âˆ‘Ï„Ï‰Ï„Itâˆ’Ï„ \\begin{eqnarray} \\begin{aligned} I_t &\\sim Poisson(\\lambda_t) \\\\ \\lambda_t &\\sim Lognormal(\\mu_t,\\sigma_t) \\\\ R_t &= \\frac{I_t}{\\sum_{\\tau}{\\omega_{\\tau}I_{t-\\tau}}} \\end{aligned} \\end{eqnarray} expectation, gives: Rtâ‰ˆÎ»tâˆ‘Ï„=1kÏ‰Ï„Î»tâˆ’Ï„âˆ¼Lognormal(Î¼t,Ïƒt)âˆ‘Ï„=1kLognormal(Î¼tâˆ’Ï„+logÏ‰Ï„,Ïƒtâˆ’Ï„) \\begin{eqnarray} \\begin{aligned} R_t &\\approx \\frac{\\lambda_t}{\\sum_{\\tau=1}^{k} \\omega_\\tau \\lambda_{t-\\tau}} \\\\ &\\sim \\frac{\\text{Lognormal}(\\mu_t, \\sigma_t)}{\\sum_{\\tau=1}^{k} \\text{Lognormal}\\left( \\mu_{t-\\tau} + \\log \\omega_\\tau, \\sigma_{t-\\tau} \\right)} \\end{aligned} \\tag{1} \\end{eqnarray} shown sum correlated log-normal distributed random variables can approximated another log-normal parameters Î¼Z\\mu_Z ÏƒZ\\sigma_Z, correlation Ïij=Corr(logXi,logXj)\\rho_{ij} = \\text{Corr}(\\log X_i, \\log X_j). S+=ğ”¼[âˆ‘iXi]=âˆ‘iğ”¼[Xi]=âˆ‘ieÎ¼i+12Ïƒi2ÏƒZ2=1S+2âˆ‘,jÏijÏƒiÏƒjğ”¼[Xi]ğ”¼[Xj]=1S+2âˆ‘,jÏijÏƒiÏƒjeÎ¼i+12Ïƒi2eÎ¼j+12Ïƒj2Î¼Z=logS+âˆ’12ÏƒZ2 \\begin{eqnarray} \\begin{aligned}     S_+ &= \\mathbb{E}\\left[\\sum_i X_i \\right] = \\sum_i     \\mathbb{E}[X_i] \\\\     &= \\sum_i e^{\\mu_i + \\frac{1}{2}\\sigma_i^2}     \\\\     \\sigma^2_{Z} &= \\frac{1}{S_+^2} \\, \\sum_{,j}       \\rho_{ij} \\sigma_i \\sigma_j \\mathbb{E}[X_i] \\mathbb{E}[X_j] \\\\       &= \\frac{1}{S_+^2} \\, \\sum_{,j}       \\rho_{ij} \\sigma_i \\sigma_j e^{\\mu_i+\\frac{1}{2}\\sigma_i^2}       e^{\\mu_j+\\frac{1}{2}\\sigma_j^2}     \\\\     \\mu_Z &= \\log S_+ - \\frac{1}{2}\\sigma_{Z}^2 \\end{aligned} \\tag{2} \\end{eqnarray} sum term denominator renewal equation (1) consists set correlated scaled log normal distributions scale defined infectivity profile (Ï‰\\omega). case given time point tt equate Xi=Ï‰Ï„Î»tâˆ’Ï„X_i = \\omega_{\\tau} \\lambda_{t-\\tau}, substitute Î¼i\\mu_i = Î¼tâˆ’Ï„+log(Ï‰Ï„)\\mu_{t-\\tau} + log(\\omega_{\\tau}) Ïƒi=Ïƒtâˆ’Ï„\\sigma_i = \\sigma_{t-\\tau} (2) account infectivity profile. define kk support infectivity profile (k=|Ï‰|k = |\\omega|). msm_{s} weighted contribution incidence estimates day tâˆ’Ï„t-\\tau, Î£ij\\Sigma_{ij} covariance log-incidence estimates days tâˆ’-tâˆ’jt-j. mÏ„=eÎ¼tâˆ’Ï„+logÏ‰Ï„+12Ïƒtâˆ’Ï„2Î£ij=Cov(logÎ»tâˆ’,logÎ»tâˆ’j)=Ï(tâˆ’)(tâˆ’j)Ïƒtâˆ’iÏƒtâˆ’jS+=âˆ‘Ï„=1kmÏ„ÏƒZ2=âˆ‘,j=1k(mimjÎ£ij)S+2Î¼Z=logS+âˆ’12ÏƒZ2 \\begin{eqnarray} \\begin{aligned}     m_{\\tau} &= e^{\\mu_{t-\\tau} + \\log \\omega_{\\tau} + \\frac{1}{2}\\sigma_{t-\\tau}^2 } \\\\     \\Sigma_{ij} &= \\text{Cov}(\\log \\lambda_{t-}, \\log \\lambda_{t-j}) = \\rho_{(t-)(t-j)} \\sigma_{t-} \\sigma_{t-j} \\\\     S_{+} &= \\sum_{\\tau=1}^k { m_{\\tau} } \\\\     \\sigma_{Z}^2 &=       \\frac{         \\sum_{,j=1}^k {           (m_{} m_{j} \\Sigma_{ij})         }       }{S_{+}^2}    \\\\     \\mu_{Z} &= \\log S_+ - \\frac{1}{2}\\sigma_{Z}^2 \\end{aligned} \\end{eqnarray} Î¼Z\\mu_{Z} ÏƒZ\\sigma_{Z} defined, RtR_t approximated ratio two log-normals Î£0Z=Cov(logÎ»t,logS)\\Sigma_{0Z} = \\text{Cov}(\\log \\lambda_t, \\log S) covariance numerator log-denominator. Since S=âˆ‘Ï„XÏ„S = \\sum_\\tau X_\\tau, using first-order approximation, covariance weighted average covariances logÎ»t\\log \\lambda_t logÎ»tâˆ’Ï„\\log \\lambda_{t-\\tau}, weighted relative expected contributions mÏ„m_\\tau.: Rtâˆ¼Lognormal(Î¼t,Ïƒt)Lognormal(Î¼Z,ÏƒZ)Î¼Rt=Î¼tâˆ’Î¼Z=Î¼tâˆ’logS++12ÏƒZ2ÏƒRt=Ïƒt2+ÏƒZ2âˆ’2Î£0ZÎ£0Z=âˆ‘Ï„=1kmÏ„Î£0Ï„âˆ‘Ï„=1kmÏ„=1S+âˆ‘Ï„=1kmÏ„Î£0Ï„Rtâˆ¼Lognormal(Î¼Rt,ÏƒRt) \\begin{eqnarray} \\tag{3} \\begin{aligned} R_t &\\sim \\frac{Lognormal(\\mu_t,\\sigma_t)} {Lognormal( \\mu_{Z}, \\sigma_{Z})} \\\\ \\mu_{R_t} &= \\mu_t - \\mu_{Z} = \\mu_t - \\log S_+ + \\frac{1}{2}\\sigma_{Z}^2\\\\ \\sigma_{R_t} &= \\sqrt{\\sigma_t^2+\\sigma_{Z}^2 - 2 \\Sigma_{0Z}} \\\\ \\Sigma_{0Z} &= \\frac{\\sum_{\\tau=1}^k m_\\tau \\Sigma_{0\\tau}}{\\sum_{\\tau=1}^k m_\\tau} = \\frac{1}{S_+}\\sum_{\\tau=1}^k m_\\tau \\Sigma_{0\\tau}\\\\ R_t &\\sim Lognormal(\\mu_{R_t}, \\sigma_{R_t}) \\end{aligned} \\end{eqnarray} formulation RtR_t (3) assumes knowledge posterior prediction covariance incidence estimates (Î£ij\\Sigma_ij). typical modern frameworks , situations may available. case assume individual estimates incidence independent, however increases uncertainty RtR_t estimate certain circumstances introduces potential underestimation bias, influenced true -diagonal correlation mass certainty incidence estimates. alternative approach assume weak stationarity estimate parametric correlation model data used build incidence model, using Pearson residuals parameterise exponential decay function based time difference (see supporting software package implementation). degree bias investigated supplementary materials, heuristics assessing significance bias proposed. method estimating RtR_t modelled incidence described assuming non-negative component infectivity profile, implicit infector infectee necessarily sequential time. situation symptomatic case counts used proxy incidence serial interval proxy infectivity profile, negative times serial cases may observed due variation delay observation transmission chain. nothing framework stop use negative time infectivity profile, can directly support RtR_t estimates cases.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/articles/rt-from-incidence.html","id":"numerical-stability","dir":"Articles","previous_headings":"Methods","what":"Numerical stability","title":"Estimating the reproduction number from modelled incidence","text":"(3) Î¼t\\mu_t log-scale mean incidence estimate time tt, Ïƒt\\sigma_t standard deviation. can large, leading numerical instability terms involving exp(Î¼+Ïƒ2)\\exp(\\mu + \\sigma^2). However, assuming non-negative correlations using log-space computation optimized log-sum-exp functions , expressions remain computationally tractable: logmÏ„=Î¼tâˆ’Ï„+logÏ‰Ï„+12Ïƒtâˆ’Ï„2logS+=logsumexpÏ„(logmÏ„)logÏƒZ2=logsumexpi,j(logmi+logmj+logÎ£ij)âˆ’2logS+logÎ£0Z=logsumexpÏ„(logmÏ„+logÎ£0Ï„)âˆ’logS+ \\begin{eqnarray} \\begin{aligned} \\log m_\\tau &= \\mu_{t-\\tau} + \\log \\omega_\\tau + \\frac{1}{2} \\sigma_{t-\\tau}^2 \\\\ \\log S_+ &= \\text{logsumexp}_\\tau(\\log m_\\tau) \\\\ \\log \\sigma_Z^2 &= \\text{logsumexp}_{,j} \\left( \\log m_i + \\log m_j + \\log \\Sigma_{ij} \\right) - 2 \\log S_+ \\\\ \\log \\Sigma_{0Z} &= \\text{logsumexp}_\\tau \\left( \\log m_\\tau + \\log \\Sigma_{0\\tau} \\right) - \\log S_+ \\end{aligned} \\tag{4} \\end{eqnarray} relations may implemented directly (3).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/articles/rt-from-incidence.html","id":"infectivity-profile-uncertainty","dir":"Articles","previous_headings":"Methods","what":"Infectivity profile uncertainty","title":"Estimating the reproduction number from modelled incidence","text":"estimate RtR_t conditioned single known infectivity profile. reality also uncertainty infectivity profile (Ï‰\\omega) plays role definition Î¼Z,t\\mu_{Z,t} ÏƒZ,t\\sigma_{Z,t}. assume particular distributional form infectivity profile, can use range empirical estimates infectivity profile calculate multiple distributional estimates RtR_t combine mixture distribution. nature mixture distribution depend various empirical infectivity profile distributions. However, can use general properties mixture distributions create estimates mean variance reproduction number estimate (Rt*R_t^*) combining uncertainty arising multiple infection profile estimates (Î©\\Omega) incidence estimate model : E[Rt|Ï‰]=e(Î¼Rt,Ï‰âˆ’12ÏƒRt,Ï‰2)V[Rt|Ï‰]=[e(ÏƒRt,Ï‰2)âˆ’1][e2Î¼Rt,Ï‰+ÏƒRt,Ï‰2]E[Rt*]=1|Î©|âˆ‘Ï‰âˆˆÎ©E[Rt|Ï‰]V[Rt*]=1|Î©|[âˆ‘Ï‰âˆˆÎ©V[Rt|Ï‰]+E[Rt|Ï‰]2]âˆ’E[Rt*]2 \\begin{eqnarray} \\begin{aligned} E[R_t|\\omega] &= e^{(\\mu_{R_t,\\omega} - \\frac{1}{2}\\sigma_{R_t,\\omega}^2)} \\\\ V[R_t|\\omega] &= \\big[e^{(\\sigma_{R_t,\\omega}^2)} - 1\\big] \\big[e^{2 \\mu_{R_t,\\omega} + \\sigma_{R_t,\\omega}^2}\\big] \\\\ E[R_t^*] &= \\frac{1}{|\\Omega|}\\sum_{\\omega \\\\Omega} E[{R_t|\\omega}] \\\\ V[R_t^*] &= \\frac{1}{|\\Omega|} \\bigg[\\sum_{\\omega \\\\Omega}{V[R_t|\\omega]+E[R_t|\\omega]^2}\\bigg] - E[R_t^*]^2 \\\\ \\end{aligned} \\end{eqnarray} cumulative distribution function mixture simply arithmetic mean component cumulative distribution functions (conditioned infectivity profile). Î¦\\Phi cumulative distribution function standard normal distribution: FRt*(x)=1|Î©|âˆ‘Ï‰âˆˆÎ©FRt(x|Ï‰)P(Rt*â‰¤x)=1|Î©|âˆ‘Ï‰âˆˆÎ©P(Rt,Ï‰â‰¤x)P(Rt*â‰¤x)=1|Î©|âˆ‘Ï‰âˆˆÎ©Î¦(ln(x)âˆ’Î¼Rt,Ï‰ÏƒRt,Ï‰) \\begin{eqnarray} \\begin{aligned} F_{R_t^*}(x) &= \\frac{1}{|\\Omega|}\\sum_{\\omega \\\\Omega}F_{R_t}(x|\\omega) \\\\ P(R_t^* \\le x) &= \\frac{1}{|\\Omega|}\\sum_{\\omega \\\\Omega} P(R_{t,\\omega} \\le x) \\\\ P(R_t^* \\le x) &= \\frac{1}{|\\Omega|}\\sum_{\\omega \\\\Omega} \\Phi\\bigg(\\frac{ln(x) - \\mu_{R_t,\\omega}}{\\sigma_{R_t,\\omega}}\\bigg) \\end{aligned} \\end{eqnarray} cumulative density function mixture distribution strictly increasing function, specific solutions median (q0.5q_{0.5}) 95% confidence intervals (q0.025q_{0.025} q0.975q_{0.975}) can calculated numerically solving following equations: 1|Î©|âˆ‘Ï‰âˆˆÎ©Î¦(ln(q0.025)âˆ’Î¼Rt,Ï‰ÏƒRt,Ï‰)âˆ’0.025=01|Î©|âˆ‘Ï‰âˆˆÎ©Î¦(ln(q0.5)âˆ’Î¼Rt,Ï‰ÏƒRt,Ï‰)âˆ’0.5=01|Î©|âˆ‘Ï‰âˆˆÎ©Î¦(ln(q0.975)âˆ’Î¼Rt,Ï‰ÏƒRt,Ï‰)âˆ’0.975=0 \\begin{eqnarray} \\begin{aligned} \\frac{1}{|\\Omega|}\\sum_{\\omega \\\\Omega} \\Phi\\bigg(\\frac{ln(q_{0.025}) - \\mu_{R_t,\\omega}}{\\sigma_{R_t,\\omega}}\\bigg) - 0.025 &= 0 \\\\ \\frac{1}{|\\Omega|}\\sum_{\\omega \\\\Omega} \\Phi\\bigg(\\frac{ln(q_{0.5}) - \\mu_{R_t,\\omega}}{\\sigma_{R_t,\\omega}}\\bigg) - 0.5 &= 0 \\\\ \\frac{1}{|\\Omega|}\\sum_{\\omega \\\\Omega} \\Phi\\bigg(\\frac{ln(q_{0.975}) - \\mu_{R_t,\\omega}}{\\sigma_{R_t,\\omega}}\\bigg) - 0.975 &= 0 \\end{aligned} \\end{eqnarray} Numerical solutions moderately expensive perform. reasonable approximation can expected matching moments log normal distribution mean E[Rt*]E[R_t^*] variance V[Rt*]V[R_t^*] mixture. gives us final closed form estimator reproduction number given set infectivity profiles, Rt,Î©Â¯\\overline{R_{t,\\Omega}}, : Î¼t|Î©=log(E[Rt*]2E[Rt*]2+V[Rt*])Ïƒt|Î©=log(1+V[Rt*]E[Rt*]2)Rt|Î©Â¯âˆ¼Lognormal(Î¼t|Î©,Ïƒt|Î©) \\begin{eqnarray} \\begin{aligned} \\mu_{t|\\Omega} &= log\\bigg(\\frac{E[R_t^*]^2}{\\sqrt{E[R_t^*]^2 + V[R_t^*]}}\\bigg) \\\\ \\sigma_{t|\\Omega} &= \\sqrt{log\\bigg(1 + \\frac{V[R_t^*]}{E[R_t^*]^2}\\bigg)}\\\\ \\overline{R_{t|\\Omega}} &\\sim Lognormal(\\mu_{t|\\Omega},\\sigma_{t|\\Omega}) \\end{aligned} \\end{eqnarray} summary present method retrieving distributional form reproduction number log normally distributed probabilistic estimates incidence arising simple statistical count models. includes uncertainty arising count models infectivity profile distributions. fully deterministic computationally inexpensive. place particular constraints nature infectivity profile distribution can handle distributions negative component, sometimes seen serial interval estimates.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/articles/rt-from-incidence.html","id":"implementation","dir":"Articles","previous_headings":"","what":"Implementation","title":"Estimating the reproduction number from modelled incidence","text":"method implemented using following R function, designed numerical stability speed. Generating RtR_t estimates given modelled incidence typically occurring matter seconds:","code":"#> function (mu_t, vcov_ij = diag(sigma_t^2), omega, sigma_t = NULL,  #>     tau_offset = 0)  #> { #>     omega_m = as.matrix(omega) #>     k = nrow(omega_m) #>     if (k != length(mu_t)) { #>         stop(\"omega must have the same number of rows as length of mu_t.\") #>     } #>     if (!all(dim(vcov_ij) == k)) { #>         stop(\"vcov_ij must be a square matrix with the same dimensions as mu_t, and nrow(omega)\") #>     } #>     omega_m = apply(omega_m, MARGIN = 2, rev) #>     sigma_t = sqrt(diag(vcov_ij)) #>     time_Rt = length(mu_t) - tau_offset #>     mu = mu_t[time_Rt] #>     sigma = sigma_t[time_Rt] #>     tmp = apply(omega_m, MARGIN = 2, function(omega) { #>         log_m_tau = mu_t + sigma_t^2/2 + log(omega) #>         log_S_plus = .logsumexp(log_m_tau) #>         log_Sigma_ij = log(pmax(vcov_ij, 0)) #>         log_Sigma_0tau = log_Sigma_ij[time_Rt, ] #>         log_sigma_Z2 = .logsumexp(outer(log_m_tau, log_m_tau,  #>             \"+\") + log_Sigma_ij) - 2 * log_S_plus #>         mu_Z = log_S_plus - 1/2 * exp(log_sigma_Z2) #>         log_Sigma_0Z = .logsumexp(log_m_tau + log_Sigma_0tau) -  #>             log_S_plus #>         mu_Rt = mu - mu_Z #>         sigma_Rt2 = sigma^2 + exp(log_sigma_Z2) - 2 * exp(log_Sigma_0Z) #>         return(c(mu_Rt, sigma_Rt2)) #>     }) #>     mu_Rt = tmp[1, ] #>     sigma_Rt2 = tmp[2, ] #>     means = exp(mu_Rt + sigma_Rt2/2) #>     vars = (exp(sigma_Rt2) - 1) * exp(2 * mu_Rt + sigma_Rt2) #>     mean_star = mean(means) #>     var_star = mean(vars + means^2) - mean_star^2 #>     mu_star = log(mean_star) - log(var_star/mean_star^2 + 1)/2 #>     sigma_star = sqrt(log(1 + var_star/mean_star^2)) #>     return(list(time_Rt = time_Rt, mean_Rt_star = mean_star,  #>         var_Rt_star = var_star, meanlog_Rt_star = mu_star, sdlog_Rt_star = sigma_star,  #>         mu_Rt_mix = mu_Rt, sigma_Rt_mix = sqrt(sigma_Rt2), quantile_Rt_fn = function(p) { #>             .qmixlnorm(p, mu_Rt, sqrt(sigma_Rt2)) #>         })) #> } #> <bytecode: 0x5eef167003a8> #> <environment: namespace:ggoutbreak>"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/rt-from-incidence.html","id":"results","dir":"Articles","previous_headings":"","what":"Results","title":"Estimating the reproduction number from modelled incidence","text":"Testing incidence model shown , comparing results SPI-M-O consensus RtR_t estimates gives us following time-series England. formally evaluated elsewhere qualitatively good fit. took seconds calculate reproduction number single time series 1410 time points , opens possibility performing RtR_t estimates fine grained geographical demographic subgroups.","code":"#>    user  system elapsed  #>   6.793   0.297   7.091"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/rt-from-incidence.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Estimating the reproduction number from modelled incidence","text":"present methodology deriving RtR_t modelled estimates incidence propagating uncertainty. demonstrate produces satisfactory qualitative results COVID-19 data. method relatively quick, fully deterministic, can used top statistical models estimating incidence use logarithmic link functions.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/articles/sampling-serial-interval.html","id":"alternative-resampling","dir":"Articles","previous_headings":"","what":"Alternative resampling","title":"Sampling the infectivity profile from published serial interval estimates","text":"mean SD gamma distribution modelled EpiEstim independent truncated normally distributed quantities, assumed know mean, sd, lower upper bounds distribution. assumption breaks SD gamma distributions close mean, correlation SD mean. alternative assumption mean SD infectivity profile gamma distributions correlated log-normal distributed quantities. case see results MCMC fitting seem correlated log scale feasible normally distributed.  Let us also assume rather knowledge mean, sd, etc, know median 95% credible intervals distribution mean SD, commonly reported literature. time also assume know degree correlation. re-sampling process produces closer set distributions EpiEstim approach, assume can estimate correlation mean SD.  distributions better fit derived original data sampling strategy EpiEstim produce resampled distributions incompatible discretisation strategy EpiEstim mean < 1. samples excluded allow used Cori method. make difference?  EpiEstimâ€™s default resampling strategy example results slightly less skewed discretised infectivity profile distribution either original data derived (raw mcmc) log-normally resampled correlation (corr log normal). result can examined looking EpiEstim estimates reproduction number using different infectivity profiles. simulate artificial incidence time series set growth rates use EpiEstim produce reproduction number estimates synthetic timeseries using either data-derived infectivity profiles (raw mcmc), EpiEstim resampled infectivity profiles (epiestim), correlated log-normal resampled infectivity profiles (corr log normal):  Compared reproduction number estimates mcmc originals, epiestim re-sampling using correlated log-normals similar. produce correlated log-normals assuming knowledge correlation mean SD, usually specified published data.","code":"# They are a correlated approximately lognormal distributed quantity ggplot2::ggplot(gammas,ggplot2::aes(x=lmean,y=lsd))+ggplot2::geom_point(alpha=0.1)+ggplot2::geom_rug(alpha=0.02) correlation = stats::cor(gammas$mean, gammas$sd) correlation ## [1] 0.7331017 # However typically we will be provided with quantiles of mean and SD # We can log transform quantiles and estimate a normal distribution # on the log scale. quantiles = gammas %>%    dplyr::select(mean, sd) %>%    dplyr::reframe(dplyr::across(dplyr::everything(), ~ stats::quantile(p=c(0.025,0.5,0.975),.x))) %>% dplyr::mutate(p=c(0.025,0.5,0.975)) quantiles %>% dplyr::glimpse() ## Rows: 3 ## Columns: 3 ## $ mean <dbl> 0.9639519, 1.5100723, 2.3842426 ## $ sd   <dbl> 0.8333187, 1.3802986, 2.7504063 ## $ p    <dbl> 0.025, 0.500, 0.975 # We can log transform quantiles and estimate a normal distribution # on the log scale. quantiles = quantiles %>% dplyr::mutate(lmean = log(mean), lsd = log(sd), z = stats::qnorm(p))  # this linear model fits a (log)normal distribution to provided quantiles. # lm coefficients - intercept is mean and z gradient is sd. lmMean = stats::lm(formula = lmean~z, quantiles)$coeff lmSd = stats::lm(formula = lsd~z, quantiles)$coeff  # means here is mean of mu=log(mean) and mean of sigma=log(sd) means2 = c(lmMean[1],lmSd[1]) names(means2) = c(\"lmean\",\"lsd\")  # sds here is sd of mu=log(mean) and sd of sigma=log(sd) sds2 = c(lmMean[2],lmSd[2]) names(sds2) = c(\"lmean\",\"lsd\")  .cor2cov = function(correlation, sds) {   corMatrix = matrix(c(1,correlation,correlation,1),nrow = 2)   covMatrix2 = diag(sds) %*% corMatrix %*% diag(sds)   colnames(covMatrix2) = names(sds)   rownames(covMatrix2) = names(sds)   return(covMatrix2) }  covMatrix2 = .cor2cov(correlation, sds2)  simulated2 = MASS::mvrnorm(n=5000, mu=means2, Sigma = covMatrix2) %>% as.data.frame() simulated2 = simulated2 %>% dplyr::mutate(mean = exp(lmean), sd = exp(lsd), shape = (mean^2)/(sd^2), rate = mean/(sd^2)) comparison2 = dplyr::bind_rows(     simulated2 %>% dplyr::mutate(source=\"corr log normal\"),     gammas %>% dplyr::mutate(source = \"raw mcmc\")   ) %>% dplyr::mutate(source = factor(source,labels = c(\"raw mcmc\",\"corr log normal\")))  p1 = ggplot2::ggplot(comparison2)+   ggplot2::geom_point(mapping=ggplot2::aes(x=mean,y=sd,colour=source), alpha = 0.1)+   ggplot2::geom_abline()  p2 = ggplot2::ggplot(comparison2)+   ggplot2::geom_point(mapping=ggplot2::aes(x=shape,y=rate,colour=source),alpha=0.1)  p1+p2+patchwork::plot_annotation(tag_levels = \"A\") comparison = dplyr::bind_rows(     epiestim_si_samples %>% dplyr::mutate(source=\"epiestim\"),     simulated2 %>% dplyr::mutate(source=\"corr log normal\"),     gammas %>% dplyr::mutate(source = \"raw mcmc\")   )  original_disc = comparison %>%   dplyr::filter(mean > 1) %>%   dplyr::group_by(source) %>%   dplyr::transmute(     coll = dplyr::row_number(),     disc = purrr::map2(mean,sd, ~ dplyr::tibble(                          x=0:50,                          p = EpiEstim::discr_si(0:50, .x, .y))),     disc_type = \"discr_si\" ) %>% tidyr::unnest(disc)   tmp = original_disc %>% dplyr::mutate(source=factor(source, levels = c(\"raw mcmc\",\"epiestim\",\"corr log normal\")))  sources = length(levels(tmp$source))  tmp_summ = tmp %>% dplyr::group_by(source,x) %>% dplyr::summarise(p = mean(p)) ## `summarise()` has grouped output by 'source'. You can override using the ## `.groups` argument. tmp_mean = tmp %>% dplyr::group_by(source,coll) %>%    dplyr::summarise(mean = sum(x*p)) %>%    dplyr::summarise(sd = stats::sd(mean),mean = mean(mean), parameter=\"mean\", disc_type=\"epiestim\") %>%   dplyr::bind_rows(     gammas %>% dplyr::summarise(sd = stats::sd(mean),mean=mean(mean), parameter=\"mean\",source=\"raw\",disc_type=\"none\" )   ) ## `summarise()` has grouped output by 'source'. You can override using the ## `.groups` argument. ggplot2::ggplot(tmp)+   ggplot2::geom_segment(mapping=ggplot2::aes(x=x+as.numeric(source)/sources-1/sources,xend=x+as.numeric(source)/sources,y=p, colour=source), alpha=0.01)+   ggplot2::geom_segment(data = tmp_summ, mapping=ggplot2::aes(x=x+as.numeric(source)/sources-1/sources,xend=x+as.numeric(source)/sources,y=p), colour=\"black\")+   ggplot2::xlab(\"time\")+   ggplot2::coord_cartesian(xlim=c(0,max_x+1))+   ggplot2::guides(colour = ggplot2::guide_legend(override.aes = list(alpha = 1))) tmp_mean ## # A tibble: 4 Ã— 5 ##   source             sd  mean parameter disc_type ##   <chr>           <dbl> <dbl> <chr>     <chr>     ## 1 raw mcmc        0.360  1.57 mean      epiestim  ## 2 epiestim        0.330  1.60 mean      epiestim  ## 3 corr log normal 0.349  1.57 mean      epiestim  ## 4 raw             0.375  1.54 mean      none r = c(0.4,0.2,0.1,0.05,0,-0.05,-0.1)  # select a shorter list of samples tmp2 = tmp %>% dplyr::group_by(source) %>% dplyr::reframe(   si_matrix = list(matrix(as.vector(p),nrow=51)[,1:250]),   r = list(r) ) %>% tidyr::unnest(r)  # tmp2$si_matrix[[1]][1:10,1:10]  compare_R = tmp2 %>% dplyr::mutate(R = purrr::map2(si_matrix, r, ~ {   ts = dplyr::tibble(         t = 0:50       ) %>% dplyr::mutate(         I = 100*exp(.y*t)       )   return(EpiEstim::estimate_R(ts,        method=\"si_from_sample\", si_sample = .x,       config = EpiEstim::make_config(t_start=2, t_end = 50))$R)   }) ) ## Warning: There were 21 warnings in `dplyr::mutate()`. ## The first warning was: ## â„¹ In argument: `R = purrr::map2(...)`. ## Caused by warning: ## ! Unknown or uninitialised column: `dates`. ## â„¹ Run `dplyr::last_dplyr_warnings()` to see the 20 remaining warnings. ggplot2::ggplot(compare_R %>% tidyr::unnest(R))+   ggplot2::geom_point(ggplot2::aes(x=as.factor(r), colour=source, y=`Median(R)`), position=ggplot2::position_dodge(width=0.8))+   ggplot2::geom_errorbar(ggplot2::aes(x=as.factor(r), colour=source, ymin=`Quantile.0.025(R)`, ymax=`Quantile.0.975(R)`), position=ggplot2::position_dodge(width=0.8), width=0.2)+   ggplot2::xlab(\"Growth rate (dayâ»Â¹)\")+   ggplot2::ylab(\"Reproduction number\")+   ggplot2::geom_hline(yintercept=1)"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/sampling-serial-interval.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Sampling the infectivity profile from published serial interval estimates","text":"assumption made EpiEstim uncertainty infectivity profile distributions, can specified mean, SD, upper lower limit truncated normal distributions turn define mean SD gamma distribution. gamma distribution discretised using PDF gamma distribution offset 1 day. requires lower bound mean 1 day. Changing assumptions instead specifying parameters gamma distribution pair correlated log normally distributed quantities gives qualitatively better fit original distribution. , however, affect reproduction number estimation, assumes knowledge correlation mean SD gamma distribution. find evidence benefit changing resampling procedure used EpiEstim, care must taken ensure resampling algorithm given correct parameters. Published serial interval estimates often given median 95% credible intervals distribution mean SD parameters EpiEstim expects. reproduction number estimation using EpiEstim subject constraint infectivity time zero zero. Coupled discretisation another potential source bias can investigated using different reproduction number framework.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/articles/sampling-serial-interval.html","id":"addendum","dir":"Articles","previous_headings":"","what":"Addendum","title":"Sampling the infectivity profile from published serial interval estimates","text":"possible left truncation inherent EpiEstim discretisation RtR_t estimation hiding effect repeated analysis. time make infectivity profiles posterior samples resampled summarised parameters EpiEstim using correlated log-normal method described using different discretisation framework, estimate RtR_t using method require probability infection time 0 zero. result less - although possibly argue case EpiEstim re-sampling procedure resulted uncertainty higher growth rates, analysis using correlated log-normal resampling make huge improvement.","code":"comparison2 = dplyr::bind_rows(   do.call(make_posterior_ip, gammas %>% dplyr::select(shape,rate)) %>% dplyr::mutate(source=\"raw mcmc\"),   do.call(make_posterior_ip, simulated2 %>% dplyr::select(shape,rate)) %>% dplyr::mutate(source=\"corr log normal\"),   do.call(make_posterior_ip, epiestim_si_samples %>% dplyr::select(shape,rate)) %>% dplyr::mutate(source=\"epiestim\") ) %>% tidyr::nest(ip = -source)  tmp3 = dplyr::tibble(r = r) %>%   dplyr::mutate(     data = purrr::map(r, ~ {       dplyr::tibble(         time = 0:30,         count = stats::rpois(0:30, 100*exp(.x*0:30))       )}     )) %>%   dplyr::cross_join(comparison2) %>%   dplyr::mutate(fit = purrr::map2(data,ip, ~       .x %>%          poisson_locfit_model() %>%         rt_from_incidence(ip = .y)     )   ) ## Rt from incidence: assuming independence and approximating quantiles.  ## (N.B. this message will only be displayed once.) tmp4 = tmp3 %>% dplyr::select(-ip) %>% tidyr::unnest(fit) %>% dplyr::filter(time>10) %>%    dplyr::group_by(source,r) %>%   dplyr::summarise(     rt.0.025 = mean(rt.0.025),     rt.0.5 = mean(rt.0.5),     rt.0.975 = mean(rt.0.975)   ) ## `summarise()` has grouped output by 'source'. You can override using the ## `.groups` argument. ggplot2::ggplot(tmp4)+   ggplot2::geom_point(ggplot2::aes(x=as.factor(r), colour=source, y=rt.0.5), position=ggplot2::position_dodge(width=0.8))+   ggplot2::geom_errorbar(ggplot2::aes(x=as.factor(r), colour=source, ymin=rt.0.025, ymax=rt.0.975), position=ggplot2::position_dodge(width=0.8), width=0.2)+   ggplot2::xlab(\"Growth rate (dayâ»Â¹)\")+   ggplot2::ylab(\"Reproduction number\")+   ggplot2::geom_hline(yintercept=1)"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/simulation-test-models.html","id":"background","dir":"Articles","previous_headings":"","what":"Background","title":"Simulations and test harnesses","text":"Testing inference RtR_t growth rate estimates needs ground truth, missing real outbreaks infection events truly observed. Testing accuracy estimates RtR_t example needs one simulations outbreaks known parametrisation. ggoutbreak contains functions generate synthetic datasets exhibit complexities observed COVID-19 pandemic. two levels simulations work, aggregate counts case line list simulations. ggoutbreak includes set simulations can used generate test data known parameters. can used validate output model parameter estimates, calculated simulated data gold standard values parameters. Simulations aggregate level generating count data, individual level generating line lists. parameters implemented far follows: Importation rate Reproduction number Growth rate Infectivity profile (generation time time delay infectee infection time infector infection) Case ascertainment rate Probability symptoms given infection Time delay symptom onset time infection Probability hospital admission given infection Time delay hospital admission time infection Probability death given infection Time delay death time infection Probability testing given infection (given symptoms) Time delay test sampling time infection (symptoms) Time delay test result time test sampling Depending model may specified different ways. Different delays rates observation can added ad-hoc simulations can stratified different classes. simulations can propagated using equivalent contact matrix.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/articles/simulation-test-models.html","id":"specifying-time-varying-parameters","dir":"Articles","previous_headings":"","what":"Specifying time varying parameters","title":"Simulations and test harnesses","text":"simulation framework highly configurable, key part specifying parameters vary time, random non random day day variation. simulation parameters must given time varying function, parameters often available. ggoutbreak includes various ways generating functions, simulation configuration options expect function identified fn_... prefix, example fn_p_symptomatic. Functions evaluated context simulation data frame, built. always time count column, may columns . evaluation happens internally use .ts_evaluate function demonstrate results. static value can supplied purrr style lambda. time varying function can supplied purrr style lambda first parameter time column demo dataframe alternative syntax uses anonymous function named parameters. time column always shortened t. format can used key variables allow time varying, class specific parameter returned donâ€™t know columns available providing empty otherwise incorrect function results valid parameter names displayed error message:","code":"demo = dplyr::tibble(   time = 0:9,   class = rep(c(\"one\",\"two\"),5),   flag = c(rep(TRUE,5),rep(FALSE,5)) ) .ts_evaluate( ~ 0.5, demo ) #> [1] 0.5 .ts_evaluate( ~ ifelse(.x < 5, 2, 0.5), demo ) #>  [1] 2.0 2.0 2.0 2.0 2.0 0.5 0.5 0.5 0.5 0.5 .ts_evaluate( function(t, class) dplyr::case_when(   class == \"one\" ~ \"variant 1 R_t value\",   class == \"two\" ~ \"variant 2 R_t value\" ), demo ) #>  [1] \"variant 1 R_t value\" \"variant 2 R_t value\" \"variant 1 R_t value\" #>  [4] \"variant 2 R_t value\" \"variant 1 R_t value\" \"variant 2 R_t value\" #>  [7] \"variant 1 R_t value\" \"variant 2 R_t value\" \"variant 1 R_t value\" #> [10] \"variant 2 R_t value\" try(.ts_evaluate( function() {} , demo )) #> Error : Function must define at least one parameter, available values are: t, class, flag"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/simulation-test-models.html","id":"step-and-linear-functions","dir":"Articles","previous_headings":"Specifying time varying parameters","what":"Step and linear functions","title":"Simulations and test harnesses","text":"common need set number fixed levels, fixed knots function interpolate . step function might used parametrise RtR_t event lock-example. make simple simulation functions take changes dataframe defines time point new value , either reproduction number growth rate time point. can used parametrisation reproduction number.  cfg_linear_fn produces similar effect less abrupt changes RtR_t changes occurring value knot correct.","code":"changes = dplyr::tibble(   t = c(0,20,40,60,80),    growth = c(0.1,0,-0.1,0,0.1) )  fn = cfg_step_fn(changes) ggplot2::ggplot()+ggplot2::geom_function(fun = fn, xlim = c(0,100))+ggplot2::ylab(\"growth rate\") changes = dplyr::tibble(   t = c(0,10,20,30,40,50,60,70,80),    R = c(1,1.5,1.75,1.25,0.9,0.7,0.8,0.95,1) )  fn = cfg_linear_fn(changes) ggplot2::ggplot()+   ggplot2::geom_function(fun = fn, xlim = c(0,100))+ggplot2::ylab(\"reproduction number\")+   ggplot2::geom_hline(yintercept=1,linetype=\"dashed\")"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/simulation-test-models.html","id":"random-functions","dir":"Articles","previous_headings":"Specifying time varying parameters","what":"Random functions","title":"Simulations and test harnesses","text":"applications (e.g.Â ascertainment, importation) might useful value includes random noise, expected value average. easiest purrr style lambda. convenience ggoutbreak includes RNGs parametrised mean dispersion parameter. functions can combined logic make time dependent random number, case first 5 random gammas drawn distribution mean 1 SD 1 last 5 mean 6 SD 1: Although time dependence likely scenario, simulation component can used control gamma beta distributed quantities. allows configuring variant specific hospitalisation rates, delays example.","code":"# A random normally distributed value with mean 5 and SD 1 # `.x` here will be interpreted as time as the first parameter, and in this # case is only used to size the returned random gaussian. .ts_evaluate(~ stats::rnorm(.x,5,1), demo) #>  [1] 3.599956 5.255317 2.562736 4.994429 5.621553 6.148412 3.178182 4.752675 #>  [9] 4.755800 4.717295 # A random Bernoulli parametrised by probability. .ts_evaluate(~ rbern(.x, p = 0.5), demo) #>  [1]  TRUE FALSE FALSE  TRUE FALSE FALSE  TRUE FALSE FALSE FALSE  # A beta distributed quantity parametrised by probability and dispersion (1-high to 0-none) .ts_evaluate(~ rbeta2(.x, prob = 0.7, kappa = 0.1), demo) #>  [1] 0.7506903 0.7129819 0.7013073 0.6861331 0.7230630 0.6881060 0.6908378 #>  [8] 0.7337567 0.7024199 0.7236393  # A log normal parametrised by mean and SD on the true scale .ts_evaluate(~ rlnorm2(.x, mean = 5, sd =1), demo) #>  [1] 4.887440 4.162386 3.633908 5.900688 5.077301 5.145320 6.762271 5.012906 #>  [9] 4.774506 3.358685  # A gamma parametrised by mean and SD on the true scale .ts_evaluate(~ rgamma2(.x, mean = 5, sd =1), demo) #>  [1] 4.627468 5.050369 4.614360 4.287724 6.389703 4.144172 8.007341 4.946172 #>  [9] 5.488590 5.017705 # A random number from a gamma distribution parametrised by mean and SD on the true scale # where the mean is a time varying value. Again here `.x` is the time and it is # being used to define the number of returned value sand the mean of these values .ts_evaluate(~ rgamma2(.x, mean = ifelse(.x < 5,1,6), sd =1), demo) #>  [1] 0.9002344 0.1013501 0.5136526 0.5211211 0.9643644 3.8738828 5.9171433 #>  [8] 6.6902884 6.2615691 6.0851481 hospitalisation_prob_fn = cfg_beta_prob_rng(   probability_fn = function(variant) ifelse(variant==\"alpha\", 0.2, 0.02),   kappa_fn = ~ 0.1 )   demo = dplyr::tibble(   t = 1:200,   variant = c(rep(\"wildtype\",100),rep(\"alpha\", 100)) ) %>% dplyr::mutate(   value = .ts_evaluate(hospitalisation_prob_fn, .) )  ggplot2::ggplot(demo, ggplot2::aes(x=variant,y=value))+ggplot2::geom_point(position = \"jitter\")+   ggplot2::ylab(\"probability hospitalisation\")"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/simulation-test-models.html","id":"delay-distributions-and-delay-rngs","dir":"Articles","previous_headings":"Specifying time varying parameters","what":"Delay distributions and delay RNGs","title":"Simulations and test harnesses","text":"key parameter generation interval infectivity profile defines delay infection infector infectee transmission chain. delays infection symptoms, infection admission also need parametrised. done using empirical probability distribution described vignette (referred â€˜IP distributionsâ€™). general IP distributions either used convolution summary count data, simulate effect delay aggregate measure, random sampling generate delay individual line list. couple ways constructing simulation:  IP distributions used directly convolution aggregate simulations. line list simulations want random sample apply individuals. gamma based IP distributions rgamma rgamma2 functions used directly. empirical distributions can generate random numbers  IP delay distributions may change time, change result characteristics simulation. difficult demo outside simulation, give examples later. principle though time varying function selecting one 2 IP delays might look like :  time varying delays individual based models things little simpler. create RNG mean every individual simulation.  approaches can applied delay distribution, time infection time hospitalisation, can made vary variables simulation variant class potentially patient age.","code":"gamma_ip = make_fixed_ip(mean = 5, sd = 1) emp_ip = make_empirical_ip(omega = c(0,0,0,1,1,2,3,3,2,1,0,0))  p1=gamma_ip %>% plot_ip() + ggplot2::facet_wrap(~\"gamma\") p2=emp_ip %>% plot_ip() + ggplot2::facet_wrap(~\"empirical\") p1+p2+patchwork::plot_layout(nrow=1)#,axes = \"collect\") emp_sample_fn = cfg_ip_sampler_rng(emp_ip)  tmp = dplyr::tibble(   serial_interval = emp_sample_fn(2000) )  p3 = p2 + ggplot2::geom_histogram(data=tmp,mapping=ggplot2::aes(x=serial_interval, y=ggplot2::after_stat(density)),       breaks = c(0,seq(0.5,12)),fill=\"grey80\",colour=\"grey40\", alpha=0.5) p3 # We start by defining a time varying function for the mean of a gamma delay_mean_fn = cfg_linear_fn(dplyr::tribble(   ~t , ~delay,   0, 3, # 3 day delays initially,   4, 3, # Until day 4. Between day 4 and 10 delays improving   10, 1 # by day 10 delays steady at 1 day ))  # We wrap this in a a function to calculate a IP for each time point delay_fn = function(t) purrr::map( delay_mean_fn(t), function(mean) {   make_fixed_ip(mean = mean, sd = sqrt(mean)) })  # Within the simulation this delay function will be evaluated for each day # here we do it manually  times = 0:14 delay_t = delay_fn(t=times)  # this is a list of IP distributions. dplyr::tibble(ip = delay_t, t=times) %>% tidyr::unnest(ip) %>% dplyr::glimpse() %>%   ggplot2::ggplot()+   ggplot2::geom_rect(ggplot2::aes(xmin=t,xmax=t+1,ymin=a0,ymax=a1,fill = probability))+   ggplot2::xlab(\"time\")+ggplot2::ylab(\"delay\") #> Rows: 158 #> Columns: 6 #> $ tau         <int> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 1, 2, 3, 4, 5â€¦ #> $ a0          <dbl> 0.0, 0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5, 10.â€¦ #> $ a1          <dbl> 0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5, 10.5, 11â€¦ #> $ probability <dbl> 0.0143876780, 0.1767654915, 0.2650337147, 0.2229659170, 0.â€¦ #> $ boot        <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1â€¦ #> $ t           <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1â€¦ delay_mean_fn = cfg_linear_fn(dplyr::tribble(   ~t , ~delay,   0, 3, # 3 day delays initially,   4, 3, # Until day 4. Between day 4 and 10 delays improving   10, 1 # by day 10 delays steady at 1 day ))  delay_rng = function(t) { rgamma2(t, delay_mean_fn(t)) }  times = rep(0:14,1000) delay = delay_rng(t=times)  dplyr::tibble(delay = delay, t=times) %>%   ggplot2::ggplot()+ggplot2::geom_boxplot(ggplot2::aes(x=as.factor(t),y=delay),outliers = FALSE)+   ggplot2::xlab(\"time\")+ggplot2::ylab(\"delay\")"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/simulation-test-models.html","id":"periodic-functions","dir":"Articles","previous_headings":"Specifying time varying parameters","what":"Periodic functions","title":"Simulations and test harnesses","text":"periodic function obviously useful generate seasonal forcing:  important uses periodic functions simulate patterns within week variation. often seen testing data result delays tested, test processing weekend. model two variants weekly periodicity use gamma distribution delay. One can used represent delay distribution convolution count based simulations another random sampling individual based simulations. demonstrate simulation later.","code":"# A simple to interpret and easy to make integrate to 0, so that growth remains # bounded.  growth_rate_fn = function(t) dplyr::case_when(   t %% 365 < 40 ~ 0.1,   t %% 365 < 80 ~ -0.1,   TRUE ~ 0) ggplot2::ggplot()+ggplot2::geom_function(fun = growth_rate_fn, xlim = c(0,365*2))+ggplot2::ylab(\"growth rate\") gamma_means = c(1,1,1,1,4,3,2) delay_fn = cfg_weekly_ip_fn(mean=gamma_means)  # delay_fn can be used as the parameter for a delay distribution convolution  # format_ip takes a probability based delay distribution and gives us a summary # the mean, sd, etc. .ts_evaluate(delay_fn, dplyr::tibble(t=1:7)) %>%    purrr::map_chr(format_ip) #> [1] \"mean: 1.06; sd: 1.01\" \"mean: 4; sd: 2.04\"    \"mean: 3; sd: 1.77\"    #> [4] \"mean: 2.02; sd: 1.44\" \"mean: 1.06; sd: 1.01\" \"mean: 1.06; sd: 1.01\" #> [7] \"mean: 1.06; sd: 1.01\" # for line list functions a RNG with weekly periodicity generates samples  # of the interval that is consistent with the parameters passed to  # `cfg_weekly_gamma_rng` delay_rng = cfg_weekly_gamma_rng(mean=gamma_means)  dplyr::tibble(t=rep(1:7,100)) %>%   dplyr::mutate(sample = .ts_evaluate(delay_rng, .)) %>%   dplyr::group_by(t) %>%   dplyr::summarise(     mean = mean(sample),     sd = stats::sd(sample)   ) %>%   dplyr::mutate(     expected_mean = gamma_means,     expected_sd = sqrt(gamma_means)   ) #> # A tibble: 7 Ã— 5 #>       t  mean    sd expected_mean expected_sd #>   <int> <dbl> <dbl>         <dbl>       <dbl> #> 1     1 0.838 0.839             1        1    #> 2     2 4.23  1.85              1        1    #> 3     3 3.10  1.94              1        1    #> 4     4 2.15  1.48              1        1    #> 5     5 1.03  0.992             4        2    #> 6     6 0.983 0.919             3        1.73 #> 7     7 0.842 0.735             2        1.41"},{"path":[]},{"path":"https://ai4ci.github.io/ggoutbreak/articles/simulation-test-models.html","id":"count-based-simulations","dir":"Articles","previous_headings":"Simulation cookbook","what":"Count based simulations","title":"Simulations and test harnesses","text":"Count based models typically based around poisson process expected number cases per day expressed function imports growth, either terms exponential growth rate, combination reproduction number infectivity profile (generation time).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/articles/simulation-test-models.html","id":"basic-growth-rate-possion-model-with-ascertainment-noise-","dir":"Articles","previous_headings":"Simulation cookbook > Count based simulations","what":"Basic growth rate possion model with ascertainment noise.","title":"Simulations and test harnesses","text":"Daily count simulations based around defined incidence rates, can expressed terms time dependent growth rate time dependent importation rate. incidence time series can generated using poisson negative binomial distribution. can also define simulation terms time dependent reproduction number, time dependent infectivity profile, time dependent importation rate.  produces summary statistics . growth rate infectivity profile, can use methods Wallinga Lipsitch infer theoretical value RtR_t, giving us ground truth validate RtR_t estimates.  Simulated noise can introduced scaling incidence rate random ascertainment rate, can vary time. randomness factor (kappa - measure dispersion) calibrated range 0 (none) 1 (maximum).  example select time varying delay distribution, reflecting test processing delays, due setting testing public holiday. can applied time-varying convolution filter summary case count simulations simulate effect changing delay distributions aggregate case counts. example dynamic delays test processing can result slow catch anomalies.","code":"withr::with_options(list('day_zero'=Sys.Date()),{    # define a growth rate time series   changes = dplyr::tibble(     t = c(0,15,40,60,80),      growth = c(0.1,0.01,-0.075,0,0.05)   )      sim = sim_poisson_model(     changes = changes,     max_time = 120,     time_unit = \"1 day\"   )      p1 = plot_changes(sim, \"parametrised growth rate\", date_breaks = \"2 weeks\")    p2 = ggoutbreak::plot_counts(sim, events = attr(sim,\"events\"), date_breaks = \"2 weeks\")   p1+p2+patchwork::plot_annotation(tag_levels = \"A\")+plot_layout(ncol=1,axes = \"collect\")  }) # COVID-19 generation time estimates from Ganyani et al 2020. ip = make_gamma_ip(5.2, 3.78, 6.78, 1.72, 0.91, 3.93, epiestim_sampler=FALSE, epiestim_compat=FALSE)  fn_Rt = changes %>%    dplyr::transmute(     t,     R_t = wallinga_lipsitch(growth, y = ip$probability, a0 = ip$a0, a1 = ip$a1)) %>%   cfg_step_fn()  plot_changes(sim, \"parametrised reproduction number\", fn=fn_Rt, date_breaks = \"2 weeks\") sim2 = dplyr::bind_rows(lapply(c(0,0.25,0.5,1), function(k)      sim %>%      sim_apply_ascertainment(       fn_asc = ~ rbeta2(.x, prob = 0.7, kappa = k)     ) %>%     dplyr::mutate(ascertainment_noise = k)    )) %>%   dplyr::group_by(ascertainment_noise)  ggoutbreak::plot_counts(sim2, events = attr(sim,\"events\"), date_breaks = \"2 weeks\")+   ggplot2::facet_wrap(~sprintf(\"randomness: %1.2f\",ascertainment_noise),ncol=2) # Noise introduced by random day to day ascertainment variation: ip_mean_fn = cfg_linear_fn(dplyr::tribble(   ~t , ~delay,   0, 3, # 3 day avg delays initially   10, 1, # by day 10 delays decreased to 1   25, 1, # remain steady until day 25   26, 3, # public holiday on day 26    27, 3, # and day 27   28, 1 # returning to normal on day 28 ))  p_detection_fn = cfg_linear_fn(dplyr::tribble(   ~t , ~p,   0, 0.1, # initial low probability of detection   10, 0.7,   90, 0.7,   120,0.3 ))  delay_detection_fn = ~ make_fixed_ip(mean = ip_mean_fn(.x))  sim3 = sim %>% sim_convolution(   p_fn = p_detection_fn,   delay_fn = delay_detection_fn,   output = \"detected\" ) %>% sim_delayed_observation(   input = \"detected\",   delay_fn = ~ make_fixed_ip(mean = 7,sd = 10) )  p1=plot_changes(sim3,name = \"delays (days)\", fn = ip_mean_fn)+ggplot2::ylim(0,NA) p2=plot_changes(sim3,name = \"detection\", fn = p_detection_fn)+ggplot2::ylim(0,1) p3=plot_counts(sim3,events = attr(sim3,\"events\"),mapping=ggplot2::aes(colour=statistic))+ggplot2::geom_line()  p1+p2+p3+patchwork::plot_layout(ncol=1,heights=c(1,1,2),axes = \"collect\")"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/simulation-test-models.html","id":"seasonal-outbreak-using-a-reproduction-number","dir":"Articles","previous_headings":"Simulation cookbook > Count based simulations","what":"Seasonal outbreak using a reproduction number","title":"Simulations and test harnesses","text":"can simulate seasonal outbreak providing periodic growth rate RtR_t parameter simple poisson model. example also simulated default set delays keying infection event, generate delayed set symptom observations, test samples, results, hospitalisations death time series.","code":"seasonal_rt_fn = function(t) dplyr::case_when(   t %% 365 < 20 ~ 2.5,   t %% 365 < 60 ~ 0.6,   TRUE ~ 1 )  seasonal_imports = function(t) ifelse(   t %% 365 < 5, 5, 0  )   seasonal_sim = sim_poisson_Rt_model(     max_time = 365*3,     fn_Rt = seasonal_rt_fn,     fn_imports = seasonal_imports,     fn_ip = ~ make_fixed_ip(6)   )  # profvis::profvis( system.time({   seasonal_sim = seasonal_sim %>% sim_apply_delay() }) #>    user  system elapsed  #>  17.461   0.003  17.472 # )  p1=plot_changes(         seasonal_sim,          name = \"Rt\",          fn = seasonal_rt_fn,          max_y = 3)  p2=plot_counts(         seasonal_sim,          events = sim_events(seasonal_sim) %>% dplyr::ungroup() %>% dplyr::select(-statistic),         mapping=ggplot2::aes(colour=statistic),size=0.25)+       ggplot2::geom_line()+       ggplot2::facet_wrap(~ statistic,ncol=1,scales = \"free_y\")  p1+p2+patchwork::plot_layout(ncol=1,axes = \"collect\",heights=c(1,10))"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/simulation-test-models.html","id":"line-list-simulations","dir":"Articles","previous_headings":"","what":"Line list simulations","title":"Simulations and test harnesses","text":"want investigate estimates delays serial interval, rates case fatality rate, necessary simulate individuals interaction. use branching process model parametrised directly RtR_t. time varying RtR_t defines expected number onward infections individual sampled using poisson negative binomial distribution. infectee given time infection depending specified infectivity profile, times events symptom onset, hospitalisation, death, test sampling, test results can assigned, following known event probabilities delay distributions. Summary counts events indexed time event, demonstrate well known biases, right truncation. simulation directly parametrised theoretical RtR_t value; summary network edges gives us realised case reproduction number specific individual simulation, force infection gives us instantaneous reproduction number estimate individual simulation. parametrised infectivity profile can use methods Wallinga Lipsitch solve theoretical growth rate.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/articles/simulation-test-models.html","id":"basic-outbreak-with-delays-and-censoring","dir":"Articles","previous_headings":"Line list simulations","what":"Basic outbreak with delays and censoring","title":"Simulations and test harnesses","text":"minimal outbreak simulation using branching process model takes time varying function reproduction number time varying function number imported cases. generates set infection events specified time period (staring day 0).  set infections can add observations, based probability observation delay observation. time varying functions, can example vary result day week. example add â€œsequencingâ€ column set describes sample taken genomic sequencing. sampling delayed slightly infections arising weekend. additional date can summarise time points daily counts infections, case â€œsequencingâ€ samples, shows periodicity result extended delay weekend. However common also sort delay reporting results test. case added longish delay getting results back. aggregating sample date therefore right censoring effect positive sample counts.","code":"# A simple outbreak linelist = sim_branching_process(    fn_Rt = ~ ifelse(.x < 40, 1.5, 0.95),    max_time = 120,    seed = 100,    fn_imports = ~ ifelse(.x<10,8,0) )  plot_cases(linelist, events = sim_events(linelist))+ggplot2::coord_cartesian() linelist2 = linelist %>% sim_delay(   p_fn = ~ 0.6,    delay_fn = cfg_weekly_gamma_rng(c(3,3,3,3,3,3.5,3.5), sd=1),   output = \"sequencing\" )  # The delay function results in additional columns prefixed by \"sequencing\" # of reach individual. linelist2 %>% dplyr::glimpse() #> Rows: 14,826 #> Columns: 8 #> $ time                <t[day]> 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,â€¦ #> $ id                  <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,â€¦ #> $ generation_interval <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NAâ€¦ #> $ infector            <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NAâ€¦ #> $ generation          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,â€¦ #> $ sequencing          <lgl> TRUE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE, FALSEâ€¦ #> $ sequencing_delay    <dbl> 2.181526, NA, NA, NA, 3.985014, 3.530621, 2.217753â€¦ #> $ sequencing_time     <t[day]> 2.18, NA, NA, NA, 3.99, 3.53, 2.22, NA, NA, NA,â€¦ summary = linelist2 %>% sim_summarise_linelist(     censoring = list(       \"sequencing\" = ~ rgamma2(.x, mean = 14)     )   )  # plot the counts for comparison. p1=plot_changes(summary,\"Rt\",max_y = 2.0, case = TRUE) p2=plot_counts(summary,events = sim_events(summary), mapping=ggplot2::aes(colour=statistic),size=0.5)+ggplot2::geom_line() patchwork::wrap_plots(p1,p2,ncol=1,axes=\"collect\")"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/simulation-test-models.html","id":"variant-introduction-alpha-example","dir":"Articles","previous_headings":"Line list simulations","what":"Variant introduction: Alpha example","title":"Simulations and test harnesses","text":"infectivity profile changing dynamically simulation alters relationship reproduction number growth rate. line list models infectivity profile potentially vary individual individual depending variant infected , can cause rapid growth variant. hard differentiate higher reproduction number shorter generation time, especially short term. However decreased generation time lead steeper flatter curve compared increased RtR_t, tend take gradually, trajectory original variant, curve away quickly higher exponential rate kicks .","code":"variant_imports_df = dplyr::tribble(   ~time, ~variant, ~count,   0:4, \"wild-type\", 5,   20:24, \"alpha\", 5 )  # The fist scenario is a two variant outbreak with one variant with a shorter # generation time.  variant_ip_fn = cfg_gamma_ip_fn(     mean_fn = function(variant) dplyr::case_when(       # Two infectivity profiles one for each variant.       variant==\"wild-type\" ~ 8,       variant==\"alpha\" ~ 5) # variant 2 has a shorter generation time )   scenario1 = sim_branching_process(   max_time = 120,   fn_Rt = ~ 1.15, # Both variants have the same fixed R_t   fn_ip = variant_ip_fn,   imports_df = variant_imports_df,   seed=101 )   # The second scenario involves two variants one with a slight reproduction  # number advantage. Both have the same (longer) generation time  variant_Rt_fn = function(t,variant) dplyr::case_when(   variant==\"wild-type\" ~ 1.15,   variant==\"alpha\" ~ 1.3 )  scenario2 = sim_branching_process(   max_time = 120,   fn_Rt = variant_Rt_fn,    fn_ip = ~ make_fixed_ip(8), # Both variants have the same fixed ip with mean 8   imports_df = variant_imports_df,   seed=100 )  comparison = dplyr::bind_rows(   scenario1 %>% sim_summarise_linelist(variant) %>% dplyr::mutate(scenario = \"1 - Shorter GT\"),   scenario2 %>% sim_summarise_linelist(variant) %>% dplyr::mutate(scenario = \"2 - Rt advantage\") )  p1=plot_changes(comparison,\"Rt\", max_y = 2.5,mapping = ggplot2::aes(colour=variant))+ggplot2::facet_wrap(~scenario) p2=plot_counts(comparison %>% dplyr::group_by(scenario,variant), mapping = ggplot2::aes(colour=variant))+ggplot2::facet_wrap(~scenario)  patchwork::wrap_plots(p1,p2,ncol=1,axes=\"collect\")"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/simulation-test-models.html","id":"two-variants-delta-outbreak","dir":"Articles","previous_headings":"Line list simulations","what":"Two variants: Delta outbreak","title":"Simulations and test harnesses","text":"pandemic Delta started spreading whilst Alpha declining. due generation time, change overall direction epidemic . must associated transmissible nature.","code":"variant_imports_df = dplyr::tribble(   ~time, ~variant, ~count,   -20:-1, \"alpha\", 300,   15:19, \"delta\", 5 )  variant_Rt_fn = function(t,variant) dplyr::case_when(   t < 0 ~ 0,   variant==\"alpha\" ~ 0.8,   variant==\"delta\" ~ 1.3 )  scenario = sim_branching_process(   max_time = 120,   fn_Rt = variant_Rt_fn,    fn_ip = ~ make_fixed_ip(8), # Both variants have the same fixed ip with mean 8   imports_df = variant_imports_df,   seed=100 )  summary1 =  scenario %>% sim_summarise_linelist(variant) %>% dplyr::filter(time >= 0)  summary2 =  scenario %>% sim_summarise_linelist() %>% dplyr::filter(time >= 0)  p1=plot_counts(summary1, mapping=ggplot2::aes(colour=variant)) p2=plot_counts(summary2)  p3=ggplot2::ggplot(summary1, ggplot2::aes(x=as.Date(time), colour=variant))+     ggplot2::geom_point(ggplot2::aes(y=rt.inst))+     ggplot2::geom_line(ggplot2::aes(y=rt.weighted))+     ggplot2::coord_cartesian(ylim=c(0,3.5))+     ggplot2::xlab(NULL)  p4=ggplot2::ggplot(summary2, ggplot2::aes(x=as.Date(time)))+     ggplot2::geom_point(ggplot2::aes(y=rt.inst))+     ggplot2::geom_line(ggplot2::aes(y=rt.weighted))+     ggplot2::coord_cartesian(ylim=c(0,3.5))+     ggplot2::xlab(NULL)  patchwork::wrap_plots(p1,p2,p3,p4,ncol=2,axes=\"collect\")"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/simulation-test-models.html","id":"over-dispersion","dir":"Articles","previous_headings":"Line list simulations","what":"Over-dispersion","title":"Simulations and test harnesses","text":"branching process model, infected individual daily probability infecting someone based current reproduction number infectivity profile. sampled using either poisson negative binomial distribution depending dispersion parameter (kappa==1 poisson distributed, anything larger negative binomial). can made time dependent, can simulate changes response , example, shutting social venues. -dispersed outbreaks higher chance becoming extinct early stage reproduction number, realistic. likely scenario subset population high super-spreading potential.","code":"kappa = c(1,1.5,2,3,4) ip = make_fixed_ip(8)  comparison = dplyr::bind_rows(lapply(kappa, function(k) {      sim_branching_process(     max_time = 80,     fn_Rt = ~ 2, # Both variants have the same fixed R_t     fn_ip = ~ ip,     fn_import = ~ ifelse(.x<10,4,0),     fn_kappa = ~ k,     seed=101   ) %>%      sim_summarise_linelist() %>%     dplyr::mutate(scenario = sprintf(\"Dispersion: %1.2f\",k))    }))  plot_counts(comparison %>% dplyr::group_by(class=scenario))+scale_y_log1p()"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/simulation-test-models.html","id":"age-stratification-contact-matrices","dir":"Articles","previous_headings":"Line list simulations","what":"Age stratification & contact matrices","title":"Simulations and test harnesses","text":"can specify metadata branching process model. example variant, transmitted infectee. can define probabilistic mapping metadata classes can simulate stratified populations age. define function reacts metadata assigns infectee class. also need define initial metadata imported cases.","code":"# This simulation is seeded in the younger age groups: strat_imports_df = dplyr::tribble(   ~time, ~age_cat, ~count,   0:4, \"child\", 5,   0:4, \"adolescent\", 5 ) %>% dplyr::mutate(age_cat = factor(age_cat,levels = c(\"child\",\"adolescent\",\"adult\",\"elderly\")))  # The next generation function in this form is similar to a  # next generation matrix however it does not include R_t components:  strat_fn_list_next_gen = list(   \"age_cat\" = ~ dplyr::case_when(     .x == \"child\" ~ rcategorical(.x, prob = c(\"child\"=0.4,\"adolescent\"=0.2,\"adult\"=0.4,\"elderly\"=0)),     .x == \"adolescent\" ~ rcategorical(.x, prob = c(\"child\"=0.2,\"adolescent\"=0.4,\"adult\"=0.3,\"elderly\"=0.1)),     .x == \"adult\" ~ rcategorical(.x, prob = c(\"child\"=0.1,\"adolescent\"=0.1,\"adult\"=0.4,\"elderly\"=0.4)),     .x == \"elderly\" ~ rcategorical(.x, prob = c(\"child\"=0,\"adolescent\"=0.2,\"adult\"=0.3,\"elderly\"=0.5)),   ) )  strat_fn_Rt = function(age_cat) dplyr::case_when(   age_cat == \"child\" ~ 1.2,   age_cat == \"adolescent\" ~ 1.2,   age_cat == \"adult\" ~ 1.2,   age_cat == \"elderly\" ~ 2, )  strat_bpm = sim_branching_process(     max_time = 80,     fn_Rt = strat_fn_Rt,     fn_ip = ~ make_fixed_ip(8),     imports_df = strat_imports_df,     fn_list_next_gen = strat_fn_list_next_gen,     seed=101   ) %>% dplyr::mutate(age_cat = factor(age_cat,levels = c(\"child\",\"adolescent\",\"adult\",\"elderly\")))  plot_cases(strat_bpm,mapping = ggplot2::aes(fill=age_cat),individual=TRUE)+ggplot2::coord_cartesian()"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/simulation-test-models.html","id":"future-steps","dir":"Articles","previous_headings":"","what":"Future steps","title":"Simulations and test harnesses","text":"","code":"#TODO: defaults in function that line up with sim_apply_delay_convolution #' # move this to vignette examples #' tmp2 = tmp %>% sim_apply_delay( #'   fn_p_symptomatic = ~ 0.8, #'   fn_symptom_delay = ~ stats::rgamma(.x, shape = 3), #'   fn_p_tested = function(symptomatic,...) ifelse(symptomatic, 0.8, 0.1), #'   fn_sample_delay = ~ stats::rgamma(.x, shape = 2), #'   fn_result_delay = function(sample_time,...) dplyr::case_when( #'       floor(sample_time) %% 7 %in% c(0,1,2,3,4) ~ stats::rgamma(sample_time, shape=2), # Sun, Mon to Thurs #'       floor(sample_time) %% 7 == 5 ~ stats::rgamma(sample_time, shape=4), # Fri #'       floor(sample_time) %% 7 == 6 ~ stats::rgamma(sample_time, shape=3), # Sat #'   ) #' ) #'  #'  #'  #' # Delay distribution example: #' tmp3 = sim_branching_process( #'   changes = dplyr::tibble(t = c(0,20,40,60,80,110), R_t = c(1.8,1.5,0.9,1.5,0.8,1.2)), #'   kappa = 1, #'   max_time = 120, #'   seed = 100, #'   summarise = FALSE #'  ) %>% sim_apply_delay( #'   fn_p_symptomatic = ~ 0.8, #'   fn_symptom_delay = ~ stats::rgamma(.x, shape = 3), #'   fn_p_symptomatic = ~ 0.8, #'   fn_symptom_delay = ~ stats::rgamma(.x, shape = 3), #'   fn_p_tested = function(symptomatic,...) ifelse(symptomatic, 0.8, 0.1), #'   fn_sample_delay = function(symptomatic, symptom_time, ...) dplyr::case_when( #'       !symptomatic ~ stats::runif(symptomatic, max = 14), #'       TRUE ~ cfg_weekly_gamma_rng(c(1,1,1,1,3,2,2))(symptom_time) #'   ), #'   fn_result_delay = function(sample_time,...) cfg_weekly_gamma_rng(c(1,1,1,1,3,2,2))(sample_time) #'  ) #' #' tmp4 = tmp3 %>% sim_summarise_linelist() #' #' ggplot2::ggplot(tmp4 %>% dplyr::filter(!is.na(count)), ggplot2::aes(x=time, colour=statistic))+ #'   ggplot2::geom_line(ggplot2::aes(y=count))+ #'   ggplot2::facet_wrap(~statistic,ncol=1) #' } #' #' #' tmp2 = sim_branching_process( #'   changes = dplyr::tibble(t = c(0,20,40,60,80,110), R = c(1.8,1.5,0.9,1.5,0.8,1.2)), #'   kappa = 1, #'   max_time = 120, #'   seed = 100 #' ) %>% sim_summarise_linelist() #' #' ggplot2::ggplot(tmp2, ggplot2::aes(x=time))+ #'   ggplot2::geom_point(ggplot2::aes(y=count))+ #'   ggplot2::geom_line(ggplot2::aes(y=original)) #' # ggplot2::ggplot(tmp2, ggplot2::aes(x=time))+ #    ggplot2::geom_step(ggplot2::aes(y=rt.weighted), colour=\"black\")+ #    ggplot2::geom_point(ggplot2::aes(y=rt.inst, colour=\"Instantaneous\"))+ #    ggplot2::geom_point(ggplot2::aes(y=rt.case, colour=\"Case\"))+ #    ggplot2::coord_cartesian(ylim=c(0,3))"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/time-periods.html","id":"line-lists-vs--time-series","dir":"Articles","previous_headings":"","what":"Line lists vs.Â time series","title":"Data wrangling and working with `ggoutbreak`","text":"Infectious disease data usually either comes set observations individual infection time stamp (.e.Â line list) count events (e.g.Â positive tests, hospitalisations, deaths) happening within specific period (day, week, month etc.) time series. count data may also denominator known. testing number tests performed, number patients risk hospitalisation. data types may also class associated observation, defining subgroup infections interest. variant virus, age group, example. may make sense compare different subgroups . case denominator may total counts among groups per unit time. Additionally may information size population subgroup. ggoutbreak assumes part input data form set time series counts, unique set times, usually complete. create datasets like line lists ggoutbreak provides infrastructure dealing time series","code":""},{"path":[]},{"path":"https://ai4ci.github.io/ggoutbreak/articles/time-periods.html","id":"a-simple-linelist","dir":"Articles","previous_headings":"Coercing data into ggoutbreak format","what":"A simple linelist","title":"Data wrangling and working with `ggoutbreak`","text":"lowest level linelist might list timestamps observation. easiest input process imported single column data frame. linelist timestamped using S3 time_period class simply numeric defined length time units (case days) origin (case 2019-12-29). can plot individual cases.  Supposing slightly complex input data. Maybe also gender age well onset_dates column dataframe. can let ggoutbreak guess structure linelist, time stamp . multiple date columns also specified date:   Plotting also easy, case organised week:","code":"# Set the default start date and unit for `ggoutbreak`: # This is not absolutely required as will set itself but helps in the long run set_defaults(\"2019-12-29\",\"1 day\")  # Timestamps of 100 cases in first 40 days with a exponential growth rate of 0.1. lldates = as.Date(\"2019-12-29\")+rexpgrowth(100,0.1,40) ll = lldates %>% linelist()  ll %>% dplyr::glimpse() #> Rows: 100 #> Columns: 1 #> $ time <t[day]> 39.17, 22.9, 31.09, 38.32, 39.93, 33.88, 33.29, 36.65, 27.29, â€¦ ll %>% plot_cases(individual=TRUE) lldf = dplyr::tibble(   onset_dates = lldates,   gender = rcategorical(100, c(male = 0.54, women = 0.46), factor = TRUE),   age = rcategorical(100, c(`0-17` = 0.2, `18-64` = 0.6, `65+`=0.2), factor = TRUE) )  # in this case we can let `ggoutbreak` guess the structure of this linelist:  ll2 = lldf %>% linelist()  ll2 %>% dplyr::glimpse() #> Rows: 100 #> Columns: 4 #> $ onset_dates <date> 2020-02-06, 2020-01-20, 2020-01-29, 2020-02-05, 2020-02-0â€¦ #> $ gender      <fct> women, women, male, male, male, women, male, women, male, â€¦ #> $ age         <fct> 18-64, 65+, 18-64, 0-17, 0-17, 65+, 18-64, 18-64, 0-17, 65â€¦ #> $ time        <t[day]> 39.17, 22.9, 31.09, 38.32, 39.93, 33.88, 33.29, 36.65, â€¦  # And we can plot it with the data ordered how we like: ll2 %>%    dplyr::arrange(dplyr::desc(age)) %>%   plot_cases(mapping = ggplot2::aes(fill=age), individual=TRUE) ll2 %>%    dplyr::arrange(gender) %>%   plot_cases(mapping = ggplot2::aes(fill=gender), individual=TRUE) # In this case as it is a different time we can if we like anchor the time # series to the `start` so the time column runs from zero. In this case we are # also going to make the time stamp count in weeks:  sl2014 = outbreaks::ebola_sierraleone_2014 %>%    linelist(date = date_of_onset, anchor=\"start\", unit=\"weeks\") %>%   dplyr::mutate(     age_cat = cut(age, c(0,18,65,Inf)),     dplyr::across(dplyr::where(is.character),forcats::as_factor)   ) %>%   dplyr::glimpse() #> Rows: 11,903 #> Columns: 10 #> $ id             <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, â€¦ #> $ age            <dbl> 20, 42, 45, 15, 19, 55, 50, 8, 54, 57, 50, 27, 38, 29, â€¦ #> $ sex            <fct> F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, Fâ€¦ #> $ status         <fct> confirmed, confirmed, confirmed, confirmed, confirmed, â€¦ #> $ date_of_onset  <date> 2014-05-18, 2014-05-20, 2014-05-20, 2014-05-21, 2014-0â€¦ #> $ date_of_sample <date> 2014-05-23, 2014-05-25, 2014-05-25, 2014-05-26, 2014-0â€¦ #> $ district       <fct> Kailahun, Kailahun, Kailahun, Kailahun, Kailahun, Kailaâ€¦ #> $ chiefdom       <fct> Kissi Teng, Kissi Teng, Kissi Tonge, Kissi Teng, Kissi â€¦ #> $ time           <t[week]> 0, 0.29, 0.29, 0.43, 0.43, 0.43, 0.43, 0.57, 0.57, â€¦ #> $ age_cat        <fct> \"(18,65]\", \"(18,65]\", \"(18,65]\", \"(0,18]\", \"(18,65]\", \"â€¦ sl2014 %>%   dplyr::arrange(status) %>%   plot_cases(mapping = ggplot2::aes(fill=status))"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/time-periods.html","id":"count-data","dir":"Articles","previous_headings":"Coercing data into ggoutbreak format","what":"Count data","title":"Data wrangling and working with `ggoutbreak`","text":"Count data describes number cases time period, e.g.Â day, week etc. may also associated one major grouping, age category, gender, geographical region, ethnicity, viral subtype. groups potentially population denominator, often major grouping may define different denominator (e.g.Â total tested individuals). categories can arbitrarily bought ggoutbreak managed groups exactly normal dplyr pipeline. count data needs unique group time point extra checks carried make sure count grouping correct: case level detail may want deal aggregating groups maybe useful (mre details later):","code":"nhs111 = outbreaks::covid19_england_nhscalls_2020 %>%   dplyr::group_by(sex,ccg_code,ccg_name,nhs_region) %>%   timeseries(     class = age   ) %>%   dplyr::glimpse() #> Rows: 253,670 #> Columns: 13 #> Groups: sex, ccg_code, ccg_name, nhs_region, class, site_type [3,706] #> $ sex        <chr> \"female\", \"female\", \"female\", \"female\", \"female\", \"female\",â€¦ #> $ ccg_code   <chr> \"e38000062\", \"e38000163\", \"e38000001\", \"e38000002\", \"e38000â€¦ #> $ ccg_name   <chr> \"nhs_gloucestershire_ccg\", \"nhs_south_tyneside_ccg\", \"nhs_aâ€¦ #> $ nhs_region <chr> \"South West\", \"North East and Yorkshire\", \"North East and Yâ€¦ #> $ class      <fct> missing, missing, 0-18, 0-18, 0-18, 0-18, 0-18, 0-18, 0-18,â€¦ #> $ time       <t[day]> 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, â€¦ #> $ site_type  <chr> \"111\", \"111\", \"111\", \"111\", \"111\", \"111\", \"111\", \"111\", \"11â€¦ #> $ date       <date> 2020-03-18, 2020-03-18, 2020-03-18, 2020-03-18, 2020-03-18â€¦ #> $ age        <chr> \"missing\", \"missing\", \"0-18\", \"0-18\", \"0-18\", \"0-18\", \"0-18â€¦ #> $ postcode   <chr> \"gl34fe\", \"ne325nn\", \"bd57jr\", \"tn254ab\", \"rm13ae\", \"n111npâ€¦ #> $ day        <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,â€¦ #> $ weekday    <fct> rest_of_week, rest_of_week, rest_of_week, rest_of_week, resâ€¦ #> $ count      <int> 1, 1, 8, 7, 35, 9, 11, 19, 6, 9, 27, 13, 9, 13, 20, 6, 21, â€¦ nhs111combined = nhs111 %>%    dplyr::group_by(sex,class,age) %>%   time_aggregate() %>%    dplyr::glimpse() #> Rows: 1,713 #> Columns: 4 #> Groups: sex, class [12] #> $ sex   <chr> \"female\", \"female\", \"female\", \"female\", \"female\", \"female\", \"femâ€¦ #> $ class <fct> 0-18, 0-18, 0-18, 0-18, 0-18, 0-18, 0-18, 0-18, 0-18, 0-18, 0-18â€¦ #> $ time  <t[day]> 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 9â€¦ #> $ count <int> 10283, 10400, 9029, 8849, 9185, 9326, 7617, 6890, 5768, 5709, 58â€¦  nhs111combined %>% plot_counts(mapping=ggplot2::aes(colour=class))+   ggplot2::facet_wrap(~sex)+   scale_y_log1p()"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/time-periods.html","id":"more-detail-on-time-periods","dir":"Articles","previous_headings":"","what":"More detail on time periods","title":"Data wrangling and working with `ggoutbreak`","text":"weekly case rate represents time slice seven days start finish date. Dates continuous quantity, cut_dates() can used classify continuous dates periods equal duration, start date: Performing calculations using interval censored dates awkward. numeric version dates useful can keep track start date time series intrinsic duration, numeric. purpose time_period class: time_period defaults using start first defined time_period session origin calculating duration unit based data (case weekly). behaviour can controlled explicitly set_default_start() set_default_unit(), ad-hoc basis providing start_date anchor unit variables calls .time_period() usual set S3 methods available formatting, printing, labelling, casting time_periods dates POSIXct classes: weekly time series can recast different frequency, start date: original dates recoverable: date_seq() can used make sure set periodic times complete: time_periods can also used monthly yearly data data regular. approximately handled irregular date periods generally OK use ggoutbreak. functions like date_seq may work anticipated irregular dates, conversions weeks months, example, potentially lossy. Two time series can aligned make comparable, although default creation time series means already comparable:","code":"random_dates = Sys.Date()+sample.int(21,50,replace = TRUE) cut_date( random_dates, unit = \"1 week\", anchor = \"start\", dfmt = \"%d %b\") #> 12 Dec â€” 18 Dec 26 Dec â€” 01 Jan 26 Dec â€” 01 Jan 19 Dec â€” 25 Dec 19 Dec â€” 25 Dec  #>    \"2025-12-12\"    \"2025-12-26\"    \"2025-12-26\"    \"2025-12-19\"    \"2025-12-19\"  #> 19 Dec â€” 25 Dec 12 Dec â€” 18 Dec 26 Dec â€” 01 Jan 26 Dec â€” 01 Jan 26 Dec â€” 01 Jan  #>    \"2025-12-19\"    \"2025-12-12\"    \"2025-12-26\"    \"2025-12-26\"    \"2025-12-26\"  #> 19 Dec â€” 25 Dec 12 Dec â€” 18 Dec 26 Dec â€” 01 Jan 19 Dec â€” 25 Dec 26 Dec â€” 01 Jan  #>    \"2025-12-19\"    \"2025-12-12\"    \"2025-12-26\"    \"2025-12-19\"    \"2025-12-26\"  #> 12 Dec â€” 18 Dec 26 Dec â€” 01 Jan 26 Dec â€” 01 Jan 12 Dec â€” 18 Dec 12 Dec â€” 18 Dec  #>    \"2025-12-12\"    \"2025-12-26\"    \"2025-12-26\"    \"2025-12-12\"    \"2025-12-12\"  #> 19 Dec â€” 25 Dec 12 Dec â€” 18 Dec 19 Dec â€” 25 Dec 26 Dec â€” 01 Jan 12 Dec â€” 18 Dec  #>    \"2025-12-19\"    \"2025-12-12\"    \"2025-12-19\"    \"2025-12-26\"    \"2025-12-12\"  #> 26 Dec â€” 01 Jan 12 Dec â€” 18 Dec 19 Dec â€” 25 Dec 26 Dec â€” 01 Jan 19 Dec â€” 25 Dec  #>    \"2025-12-26\"    \"2025-12-12\"    \"2025-12-19\"    \"2025-12-26\"    \"2025-12-19\"  #> 19 Dec â€” 25 Dec 19 Dec â€” 25 Dec 26 Dec â€” 01 Jan 26 Dec â€” 01 Jan 19 Dec â€” 25 Dec  #>    \"2025-12-19\"    \"2025-12-19\"    \"2025-12-26\"    \"2025-12-26\"    \"2025-12-19\"  #> 12 Dec â€” 18 Dec 26 Dec â€” 01 Jan 12 Dec â€” 18 Dec 19 Dec â€” 25 Dec 19 Dec â€” 25 Dec  #>    \"2025-12-12\"    \"2025-12-26\"    \"2025-12-12\"    \"2025-12-19\"    \"2025-12-19\"  #> 19 Dec â€” 25 Dec 26 Dec â€” 01 Jan 26 Dec â€” 01 Jan 12 Dec â€” 18 Dec 26 Dec â€” 01 Jan  #>    \"2025-12-19\"    \"2025-12-26\"    \"2025-12-26\"    \"2025-12-12\"    \"2025-12-26\"  #> 26 Dec â€” 01 Jan 26 Dec â€” 01 Jan 26 Dec â€” 01 Jan 26 Dec â€” 01 Jan 19 Dec â€” 25 Dec  #>    \"2025-12-26\"    \"2025-12-26\"    \"2025-12-26\"    \"2025-12-26\"    \"2025-12-19\" dates = seq(as.Date(\"2020-01-01\"),by=7,length.out = 5) tmp = as.time_period(dates) tmp #> time unit: day, origin: 2019-12-29 (a Sunday) #> 3 10 17 24 31 suppressWarnings(labels(tmp)) #> [1] \"01/Jan\" \"08/Jan\" \"15/Jan\" \"22/Jan\" \"29/Jan\" tmp2 = as.time_period(tmp, unit = \"2 days\", start_date = \"2020-01-01\") tmp2 #> time unit: 2 days, origin: 2020-01-01 (a Wednesday) #> 0 3.5 7 10.5 14 as.Date(tmp2) #> [1] \"2020-01-01\" \"2020-01-08\" \"2020-01-15\" \"2020-01-22\" \"2020-01-29\" tmp3 = as.time_period(Sys.Date()+c(0:2,4:5)*7,anchor = \"start\") as.Date(date_seq(tmp3)) #> [1] \"2025-12-11\" \"2025-12-18\" \"2025-12-25\" \"2026-01-01\" \"2026-01-08\" #> [6] \"2026-01-15\" orig_dates = Sys.Date()+1:10*7  # a 2 daily time series based on weekly dates t1 = as.time_period(orig_dates, unit = \"2 days\", anchor = \"2021-01-01\") t1 #> time unit: 2 days, origin: 2021-01-01 (a Friday) #> 906 909.5 913 916.5 920 923.5 927 930.5 934 937.5  # a weekly with different start date t2 = as.time_period(orig_dates, unit = \"1 week\", anchor = \"2022-01-01\") t2 #> time unit: week, origin: 2022-01-01 (a Saturday) #> 206.7 207.7 208.7 209.7 210.7 211.7 212.7 213.7 214.7 215.7  # rebase t1 into the same format as t2 # as t1 and t2 based on the same original dates converting t2 onto the same # peridicty as t1 results in an identical set of times t3 = as.time_period(t1,t2) t3 #> time unit: week, origin: 2022-01-01 (a Saturday) #> 206.7 207.7 208.7 209.7 210.7 211.7 212.7 213.7 214.7 215.7  # This happens automatically when the vectors are concatented c(t1,t2) #> time unit: 2 days, origin: 2021-01-01 (a Friday) #> 906 909.5 913 916.5 920 923.5 927 930.5 934 937.5 906 909.5 913 916.5 920 923.5 927 930.5 934 937.5"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/time-periods.html","id":"times-in-ggoutbreak-and-conversion-of-line-lists","dir":"Articles","previous_headings":"","what":"Times in ggoutbreak and conversion of line-lists","title":"Data wrangling and working with `ggoutbreak`","text":"ggoutbreak uses time_period class internally extensively. Casting dates time_periods generally needs done using ggoutbreak done automatically linelist() timeseries() functions. functions ggoutbreak operate time series data expect unique (usually complete) set data periodic time. help prepare line-list data time series time_summarise() function. minimal line-list date column nothing else. can generate count cases specific time unit: line-list contains class column interpreted complete record possible options can calculate denominator. case positive negative results test: specific example subsequent analysis ggoutbreak may focus positive subgroup , comparison positive negative test results trivial. another example class may test results, major subdivision e.g.Â variant disease. case comparison different groups may much relevant. use class major sub-group convenience. Additional grouping class columns also possible multi-faceted comparisons, grouping preserved included automatically denominator, may need manually calculated:","code":"random_dates = Sys.Date()+sample.int(21,50,replace = TRUE) linelist = dplyr::tibble(date = random_dates) linelist %>% time_summarise(unit=\"1 week\") %>% dplyr::glimpse() #> Rows: 3 #> Columns: 2 #> $ time  <t[week]> 0, 1, 2 #> $ count <int> 16, 20, 14 random_dates = Sys.Date()+sample.int(21,200,replace = TRUE) linelist2 = dplyr::tibble(   date = random_dates,   class = stats::rbinom(200, 1, 0.04) %>% ifelse(\"positive\",\"negative\") ) linelist2 %>% time_summarise(unit=\"1 week\") %>% dplyr::glimpse() #> Rows: 6 #> Columns: 4 #> Groups: class [2] #> $ class <chr> \"negative\", \"negative\", \"negative\", \"positive\", \"positive\", \"posâ€¦ #> $ time  <t[week]> 0, 1, 2, 0, 1, 2 #> $ count <int> 66, 76, 53, 2, 2, 1 #> $ denom <int> 68, 78, 54, 68, 78, 54 random_dates = Sys.Date()+sample.int(21,200,replace = TRUE) variant = apply(stats::rmultinom(200, 1, c(0.1,0.3,0.6)), MARGIN = 2, function(x) which(x==1))  linelist3 = dplyr::tibble(   date = random_dates,   class = c(\"variant1\",\"variant2\",\"variant3\")[variant],   gender = ifelse(stats::rbinom(200,1,0.5),\"male\",\"female\") )    count_by_gender = linelist3 %>%    dplyr::group_by(gender) %>%    time_summarise(unit=\"1 week\") %>%    dplyr::arrange(time, gender, class) %>%   dplyr::glimpse() #> Rows: 18 #> Columns: 5 #> Groups: gender, class [6] #> $ gender <chr> \"female\", \"female\", \"female\", \"male\", \"male\", \"male\", \"female\",â€¦ #> $ class  <chr> \"variant1\", \"variant2\", \"variant3\", \"variant1\", \"variant2\", \"vaâ€¦ #> $ time   <t[week]> 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2 #> $ count  <int> 2, 9, 28, 6, 10, 16, 2, 13, 22, 3, 6, 22, 2, 10, 22, 2, 10, 15 #> $ denom  <int> 39, 39, 39, 32, 32, 32, 37, 37, 37, 31, 31, 31, 34, 34, 34,â€¦"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/time-periods.html","id":"aggregating-time-series-datasets-","dir":"Articles","previous_headings":"","what":"Aggregating time series datasets.","title":"Data wrangling and working with `ggoutbreak`","text":"case time series additional grouping present, removing level grouping whilst retaining time made easier time_aggregate(). case wish sum count denom gender, retaining class grouping. default time_aggregate sum count, denom population columns behaviour can specified passing dplyr::summarise style directives function.","code":"count_by_gender %>%    dplyr::group_by(class,gender) %>%    time_aggregate() %>%   dplyr::glimpse() #> Rows: 9 #> Columns: 4 #> Groups: class [3] #> $ class <chr> \"variant1\", \"variant1\", \"variant1\", \"variant2\", \"variant2\", \"varâ€¦ #> $ time  <t[week]> 0, 1, 2, 0, 1, 2, 0, 1, 2 #> $ count <int> 8, 5, 4, 19, 19, 20, 44, 44, 37 #> $ denom <int> 71, 68, 61, 71, 68, 61, 71, 68, 61"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/time-units.html","id":"background","dir":"Articles","previous_headings":"","what":"Background","title":"Estimating the reproduction number from weekly data","text":"common epidemic data aggregated weekly, monthly even yearly case counts, example result batching reporting processes. ggoutbreak set infrastructure allow case counts used estimate reproduction number, regardless periodicity.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/articles/time-units.html","id":"simulation-with-weekly-data","dir":"Articles","previous_headings":"","what":"Simulation with weekly data","title":"Estimating the reproduction number from weekly data","text":"construct simple count model based time-varying growth rate specified exponential growth case counts per week. time_unit defined 1 week, typically determined data. ggoutbreak generally make informed guess periodicity data construct time_period column dates, stated. case simulation generates outbreak course one year maximum number weekly cases around 250, resulting initial import 30 infectious cases week 0.  can go ahead model case rate exponential growth rate using poisson model plot , parametrised growth rate red. case time unit rates per week. Although time unit per week, model output creating estimate per day (controlled frequency parameter ), allow smooth plot.  want estimate reproduction number, methods need estimates daily incidence cases, input renewal equation. rescale temporal dimension model (using rescale_model()) replot . plot daily case rate estimated peak just 30 (= 250/7 approx). growth rate also rescaled account fact exponential growth rate per day compounded per week figures .  can easily use incidence estimates generation time distribution estimate reproduction number time-series. compare use different method (Wallinga-Lipsitch 2007) convert growth rate parametrisation direct equivalent reproduction number. see good agreement, uncertainty associated RtR_t estimates derived weekly count data appropriately large, include uncertainty generation time.","code":"changes = tibble::tribble(   ~t,    ~r,   0,      0,   5,     0.2,   10,     0.1,   20,     0,   25,     -0.1,   35,     -0.05,   45,     0.1 )    sim = sim_poisson_model(   changes = changes,   max_time = 52,   time_unit = \"1 week\",   fn_imports = ~ ifelse(.x == 0, 30, 0),   seed=100 )  events = attr(sim,\"events\")  plot_cases(sim, events = events, colour=\"grey60\") # Estimate weekly incidence and weekly exponential growth rate incidence = sim %>% ggoutbreak::poisson_locfit_model(frequency = \"1 day\",deg = 2, window=5)  p1 = plot_incidence(incidence, events=events, raw = sim) p2 = plot_growth_rate(incidence,events = events)+ggplot2::coord_cartesian(ylim=c(-0.05*7,+0.05*7))+   # The simulation data includes the parametrised growth rate:   ggplot2::geom_line(data = sim, mapping = ggplot2::aes(x=as.Date(time), y=growth), colour=\"red\") p1+p2+patchwork::plot_layout(ncol=1,axes=\"collect\")+patchwork::plot_annotation(tag_levels = \"A\") # Rescale weekly to daily incidence estimates incidence2 = incidence %>% rescale_model(time_unit = \"1 day\")  p1 = plot_incidence(incidence2, events=events, raw = sim) p2 = plot_growth_rate(incidence2,events = events)+ggplot2::coord_cartesian(ylim=c(-0.05,+0.05))  p1+p2+patchwork::plot_layout(ncol=1,axes = \"collect\")+patchwork::plot_annotation(tag_level=\"A\") # Convert weekly growth rate input to simulation to a reproduction number # and ensure time scales align. changes2 = changes %>% dplyr::transmute(   t = t*7,   R = wallinga_lipsitch(r/7, ganyani_ip_2) ) rt_for_date = \\(t) cfg_step_fn(changes2)(as.time_period(t, unit=\"1 day\"))  # Calculate the reproduction number from daily incidence estimates rt_estim = incidence2 %>% rt_from_incidence(ip = ganyani_ip_2,approx = TRUE)  plot_rt(rt_estim,events = events)+   ggplot2::geom_function(fun=rt_for_date,colour=\"red\",n=nrow(rt_estim))"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/variant-proportions.html","id":"covid-19-proportions-in-england","dir":"Articles","previous_headings":"","what":"COVID-19 proportions in England","title":"Multinomial proportions models for genomic variants","text":"Sanger Centre & COGUK performed large amount sequencing COVID-19 pandemic, identify emerging genomic variants. scaled second half 2021 continued beginning 2023. Lineages assigned using Pango lineage system important ones given nicknames . Sanger variants data discontinued, still available download. code download, process data sets determine full lineage data-raw/variants.R file, output bundled data set . many caveats data terms bias regarded definitive: data must class column defining main categorisation data (case main Pango variant). time column time_period derived date (weekly). necessary column count column integer counts class. data must grouped class. Multiple models can fitted simultaneously data grouped columns.","code":"# tidy copy of the sanger weekly variants count data aggregated to England level england_variants = ukc19::covid_variants %>%    dplyr::mutate(time = as.time_period(date, \"1 day\")) %>%   dplyr::glimpse() #> Rows: 479 #> Columns: 6 #> Groups: class [10] #> $ date      <date> 2020-09-05, 2020-09-05, 2020-09-12, 2020-09-12, 2020-09-19,â€¦ #> $ class     <fct> Other, Alpha (B.1.1.7), Other, Alpha (B.1.1.7), Other, Alphaâ€¦ #> $ who_class <fct> Other, Alpha, Other, Alpha, Other, Alpha, Other, Alpha, Otheâ€¦ #> $ count     <dbl> 1182, 371, 1439, 588, 837, 429, 1685, 1157, 1208, 823, 1501,â€¦ #> $ denom     <dbl> 1553, 1553, 2027, 2027, 1266, 1266, 2842, 2842, 2031, 2031, â€¦ #> $ time      <t[day]> 0, 0, 7, 7, 14, 14, 21, 21, 28, 28, 35, 35, 42, 42, 49, 4â€¦"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/variant-proportions.html","id":"multinomial-proportions-model-","dir":"Articles","previous_headings":"","what":"Multinomial proportions model.","title":"Multinomial proportions models for genomic variants","text":"Genomic testing happened subset cases. testing effort varied significantly time. proportion variant time can estimated multinomial model.","code":"probs = england_variants %>%    multinomial_nnet_model(window = 28) #> # weights:  40 (27 variable) #> initial  value 3583520.087982  #> iter  10 value 1562162.620103 #> iter  20 value 1380207.974678 #> iter  30 value 959088.555894 #> iter  40 value 742507.401941 #> iter  50 value 731767.878774 #> iter  60 value 729647.595794 #> iter  70 value 726795.599521 #> iter  80 value 716309.104988 #> iter  90 value 709310.965531 #> iter 100 value 707285.575109 #> final  value 707285.575109  #> stopped after 100 iterations  plot_multinomial(probs)+   ggplot2::scale_fill_viridis_d(option=\"cividis\")"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/variant-proportions.html","id":"binomial-proportions-model","dir":"Articles","previous_headings":"","what":"Binomial proportions model","title":"Multinomial proportions models for genomic variants","text":"binomial (one versus others) proportions different multinomial probabilities calculated , come confidence intervals, however median values necessarily sum 1.  rate change proportion individual variant versus others logistic scale can used work exponential growth rate one variant relative others. relative growth rate taken together estimates variants given time centred around zero. one variant growth advantage, definition others growth disadvantage despite potentially causing larger disease burden potentially increasing numbers growing epidemic.  binomial relative growth rate per day growth advantage existing variants. dependency unit time controlled time_period configuration. data provided time_period defined daily basis despite data provided weekly. Doubling time make strict sense describing relative growth rates shown . variant advantage terms reproduction number needs additional information infectivity profile (aka generation time distribution) result much complex.","code":"probs2 = england_variants %>% proportion_locfit_model(window = 14, deg=1)  plot_proportion(probs2)+   ggplot2::scale_colour_viridis_d(option=\"cividis\",aesthetics = c(\"colour\",\"fill\")) plot_growth_rate(probs2) +   ggplot2::scale_fill_viridis_d(option=\"cividis\",aesthetics = c(\"colour\",\"fill\"))"},{"path":"https://ai4ci.github.io/ggoutbreak/articles/weekly-incidence.html","id":"background","dir":"Articles","previous_headings":"","what":"Background","title":"Estimating the reproduction number from weekly data","text":"common epidemic data aggregated weekly, monthly even yearly case counts, example result batching reporting processes. ggoutbreak set infrastructure allow case counts used estimate reproduction number, regardless periodicity.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/articles/weekly-incidence.html","id":"simulation-with-weekly-data","dir":"Articles","previous_headings":"","what":"Simulation with weekly data","title":"Estimating the reproduction number from weekly data","text":"construct simple count model based time-varying growth rate specified exponential growth case counts per week. time_unit defined 1 week, typically determined data. ggoutbreak generally make informed guess periodicity data construct time_period column dates, stated. case simulation generates outbreak course one year maximum number weekly cases around 250, resulting initial import 30 infectious cases week 0.  can go ahead model case rate exponential growth rate using poisson model plot , parametrised growth rate red. case time unit rates per week. Although time unit per week, model output creating estimate per day (controlled frequency parameter ), allow smooth plot.  want estimate reproduction number, methods need estimates daily incidence cases, input renewal equation. rescale temporal dimension model (using rescale_model()) replot . plot daily case rate estimated peak just 30 (= 250/7 approx). growth rate also rescaled account fact exponential growth rate per day compounded per week figures .  can easily use incidence estimates generation time distribution estimate reproduction number time-series. compare use different method (Wallinga-Lipsitch 2007) convert growth rate parametrisation direct equivalent reproduction number. see good agreement, uncertainty associated RtR_t estimates derived weekly count data appropriately large, include uncertainty generation time.","code":"changes = dplyr::tribble(   ~t,    ~r,   0,      0,   5,     0.2,   10,     0.1,   20,     0,   25,     -0.1,   35,     -0.05,   45,     0.1 )  set_default_start(\"2025-01-01\") #> NULL    sim = sim_poisson_model(   changes = changes,   max_time = 52,   time_unit = \"1 week\",   fn_imports = ~ ifelse(.x == 0, 30, 0),   seed=100 )  # extract the changes as an events data frame events = sim_events(sim)  plot_cases(sim, events = events, colour=\"grey60\") # Estimate weekly incidence and weekly exponential growth rate incidence = sim %>% ggoutbreak::poisson_locfit_model(frequency = \"1 day\",deg = 2, window=5)  p1 = plot_incidence(incidence, events=events, raw = sim) p2 = plot_growth_rate(incidence,events = events)+ggplot2::coord_cartesian(ylim=c(-0.05*7,+0.05*7))+   # The simulation data includes the parametrised growth rate:   ggplot2::geom_line(data = sim, mapping = ggplot2::aes(x=as.Date(time), y=growth), colour=\"red\") p1+p2+patchwork::plot_layout(ncol=1,axes=\"collect\")+patchwork::plot_annotation(tag_levels = \"A\") # Rescale weekly to daily incidence estimates incidence2 = incidence %>% rescale_model(time_unit = \"1 day\")  p1 = plot_incidence(incidence2, events=events, raw = sim) p2 = plot_growth_rate(incidence2,events = events)+ggplot2::coord_cartesian(ylim=c(-0.05,+0.05))  p1+p2+patchwork::plot_layout(ncol=1,axes = \"collect\")+patchwork::plot_annotation(tag_level=\"A\") # Convert weekly growth rate input to simulation to a reproduction number # and ensure time scales align. changes2 = changes %>% dplyr::transmute(   t = t*7,   R = wallinga_lipsitch(r/7, example_ganyani_ip()) ) rt_for_date = function(t) cfg_step_fn(changes2)(as.time_period(t, unit=\"1 day\"))  # Calculate the reproduction number from daily incidence estimates rt_estim = incidence2 %>% rt_from_incidence(ip =  example_ganyani_ip(),approx = TRUE)  plot_rt(rt_estim,events = events)+   ggplot2::geom_function(fun=rt_for_date,colour=\"red\",n=nrow(rt_estim))"},{"path":"https://ai4ci.github.io/ggoutbreak/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Robert Challen. Author, maintainer, copyright holder.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Challen R (2025). ggoutbreak: Estimate Incidence, Proportions Exponential Growth Rates. R package version 0.6.1, https://ai4ci.github.io/ggoutbreak/.","code":"@Manual{,   title = {ggoutbreak: Estimate Incidence, Proportions and Exponential Growth Rates},   author = {Robert Challen},   year = {2025},   note = {R package version 0.6.1},   url = {https://ai4ci.github.io/ggoutbreak/}, }"},{"path":"https://ai4ci.github.io/ggoutbreak/index.html","id":"ggoutbreak-","dir":"","previous_headings":"","what":"Estimate Incidence, Proportions and Exponential Growth Rates","title":"Estimate Incidence, Proportions and Exponential Growth Rates","text":"Simple statistical models visualisations calculating incidence, proportion, exponential growth rate, reproduction number infectious disease case time series. tool kit largely developed COVID-19 pandemic.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Estimate Incidence, Proportions and Exponential Growth Rates","text":"ggoutbreak hosted AI4CI r-universe. Installation follows: can install development version ggoutbreak GitHub :","code":"options(repos = c(   \"ai4ci\" = 'https://ai4ci.r-universe.dev/',   CRAN = 'https://cloud.r-project.org'))  # Download and install ggoutbreak in R install.packages(\"ggoutbreak\") # install.packages(\"devtools\") devtools::install_github(\"ai4ci/ggoutbreak\")"},{"path":"https://ai4ci.github.io/ggoutbreak/index.html","id":"funding","dir":"","previous_headings":"","what":"Funding","title":"Estimate Incidence, Proportions and Exponential Growth Rates","text":"authors gratefully acknowledge support UK Research Innovation AI programme Engineering Physical Sciences Research Council EPSRC grant EP/Y028392/1.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/S3_time_period.html","id":null,"dir":"Reference","previous_headings":"","what":"S3 time period class â€” S3_time_period","title":"S3 time period class â€” S3_time_period","text":"Time periods just zero based numeric representation dates time unit baked . allows variable length periods (e.g. days weeks), fractional days represented consistent(ish) way","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/S3_time_period.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"S3 time period class â€” S3_time_period","text":"","code":"new_time_period(   x = double(),   start_date = as.Date(0),   unit = lubridate::days(1) )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/S3_time_period.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"S3 time period class â€” S3_time_period","text":"x description start_date zero time date something can coerced date. x input already time_period different start_date x recalibrated use new start date. unit length one unit time. either integer number days, specification \"1 week\", another time_period. x time_period, unit different x return rescaled time_period using new units.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/S3_time_period.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"S3 time period class â€” S3_time_period","text":"time_period class, consisting vector numbers, attributes time period start_date","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/S3_time_period.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"S3 time period class â€” S3_time_period","text":"new_time_period(): Construct new time period","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/S3_time_period.html","id":"unit-tests","dir":"Reference","previous_headings":"","what":"Unit tests","title":"S3 time period class â€” S3_time_period","text":"","code":"default = new_time_period(as.numeric(1:10)) shifted = new_time_period(as.numeric(1:10), start_date = as.Date(\"1970-01-10\")) stretched = new_time_period(as.numeric(1:10), unit = lubridate::weeks(1))  testthat::expect_equal(   format(default),   c(\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\") )  testthat::expect_equal(   vec_ptype_full(default),   \"time unit: day, origin: 1970-01-01 (a Thursday)\" )  testthat::expect_equal(   vec_ptype_full(shifted),   \"time unit: day, origin: 1970-01-10 (a Saturday)\" )  testthat::expect_equal(   vec_ptype_full(stretched),   \"time unit: week, origin: 1970-01-01 (a Thursday)\" )  testthat::expect_equal(vec_ptype_abbr(default), \"t[day]\")  dshifted = vec_cast(default, shifted) testthat::expect_equal(   as.Date(dshifted) == as.Date(default),   c(TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE) )  dsquashed = vec_cast(default, stretched) testthat::expect_equal(vec_cast(dsquashed, double()), c(   0.142857142857143,   0.285714285714286,   0.428571428571429,   0.571428571428571,   0.714285714285714,   0.857142857142857,   1,   1.14285714285714,   1.28571428571429,   1.42857142857143 ))  testthat::expect_equal(   diff(vec_cast(stretched, Sys.Date())),   structure(     c(7, 7, 7, 7, 7, 7, 7, 7, 7),     class = \"difftime\",     units = \"days\"   ) )  # Cast numeric to time period check equality testthat::expect_equal(all(c(shifted, vec_cast(11:20, shifted)) == 1:20), TRUE)  # Different cadence can be matched: testthat::expect_equal(   vec_match(default, stretched),   c(NA, NA, NA, NA, NA, NA, 1L, NA, NA, NA) )  # Matching is within tolerance testthat::expect_equal(all(default == default + 0.0000001), TRUE)  # comparison testthat::expect_equal(   shifted > rev(shifted),   c(FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE, TRUE, TRUE) )  # sorting testthat::expect_equal(   as.numeric(sort(sample(shifted, 10))),   c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10) )  # Arithmetic: tmp = withr::with_seed(100, default + runif(10)) testthat::expect_equal(any(tmp == default), FALSE) testthat::expect_equal(all(floor(tmp) == default), TRUE)  # Basic operation returns the time_period testthat::expect_equal(is.time_period(default - 1), TRUE)  # modulo works: testthat::expect_equal(default  # Other operations will work but the result has to be interpreted relative to origin testthat::expect_equal(sin(default * pi / 2), c(   1, 0, -1, 0, 1, 0, -1, 0, 1, 0 ))"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/as.Date.time_period.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert time period to dates â€” as.Date.time_period","title":"Convert time period to dates â€” as.Date.time_period","text":"Convert time period dates","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/as.Date.time_period.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert time period to dates â€” as.Date.time_period","text":"","code":"# S3 method for class 'time_period' as.Date(x, ...)  # S3 method for class 'time_period' as.POSIXct(x, ...)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/as.Date.time_period.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert time period to dates â€” as.Date.time_period","text":"x time_period ... used","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/as.Date.time_period.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert time period to dates â€” as.Date.time_period","text":"vector dates representing start input time_period entries","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/as.Date.time_period.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Convert time period to dates â€” as.Date.time_period","text":".POSIXct(time_period): Convert vector POSIXct","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/as.time_period.html","id":null,"dir":"Reference","previous_headings":"","what":"Time period S3 class methods â€” as.time_period","title":"Time period S3 class methods â€” as.time_period","text":"Time periods just zero based numeric representation dates time unit baked . allows variable length periods (e.g. days weeks), fractional days represented consistent(ish) way things want deal dates (like ggplot) things want deal numbers (like model fitting)","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/as.time_period.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Time period S3 class methods â€” as.time_period","text":"","code":"as.time_period(x, ...)  # S3 method for class 'time_period' as.time_period(x, unit = NULL, start_date = NULL, ...)  # S3 method for class 'Date' as.time_period(x, unit = NULL, anchor = NULL, ...)  # S3 method for class 'numeric' as.time_period(x, unit = NULL, start_date = NULL, ...)  # S3 method for class 'grates_epiweek' as.time_period(x, ...)  # S3 method for class 'grates_isoweek' as.time_period(x, ...)  # S3 method for class 'grates_period' as.time_period(x, ...)  # S3 method for class 'time_period' seq(from, to = from, ...)  is.time_period(x)  date_to_time(dates, unit = NULL, start_date = NULL)  time_to_date(   timepoints,   unit = attr(timepoints, \"unit\"),   start_date = attr(timepoints, \"start_date\") )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/as.time_period.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Time period S3 class methods â€” as.time_period","text":"x vector dates, numbers (may integer real) time_period convert time_period ... arguments passed methods. unit length one unit time. either integer number days, specification \"1 week\", another time_period. x time_period, unit different x return rescaled time_period using new units. start_date zero time date something can coerced date. x input already time_period different start_date x recalibrated use new start date. anchor relevant x vector dates, date, \"start\" \"end\" weekday name e.g. \"mon\". vector dates x use anchor find reference date time-series. provided current defaults used. (see set_defaults()) , starting (maximal) end values     sequence.  length 1 unless just supplied     unnamed argument. dates vector dates convert time_period timepoints time_period vector convert set dates.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/as.time_period.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Time period S3 class methods â€” as.time_period","text":"vector class time_period","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/as.time_period.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Time period S3 class methods â€” as.time_period","text":"seq(time_period): Create sequence using time_periods .time_period(): Check time_period date_to_time(): Convert set dates numeric timepoints time_to_date(): Convert set time points dates","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/as.time_period.html","id":"unit-tests","dir":"Reference","previous_headings":"","what":"Unit tests","title":"Time period S3 class methods â€” as.time_period","text":"","code":"tmp = as.time_period(grates::as_epiweek(\"2019-W12\", format = \"yearweek\")+0:2) testthat::expect_equal(   lubridate::epiweek(as.Date(tmp)),   c(12, 13, 14) )  tmp = as.time_period(grates::as_isoweek(\"2019-W12\", format = \"yearweek\")+0:2) testthat::expect_equal(   lubridate::isoweek(as.Date(tmp)),   c(12, 13, 14) )  x = as.time_period(as.Date(\"2025-01-01\")+0:2, anchor=\"start\", unit=\"1 day\") y = as.time_period(as.Date(\"2025-01-07\")+0:2, anchor=\"start\", unit=\"1 day\") testthat::expect_equal(as.numeric(c(x, y)), c(0, 1, 2, 6, 7, 8)) testthat::expect_equal(as.numeric(c(y, x)), c(0, 1, 2, -6, -5, -4))  z = as.time_period(as.Date(\"2025-01-01\")+0:2*7, anchor=\"start\", unit=\"1 week\") testthat::expect_equal(as.numeric(c(x, z)), c(0, 1, 2, 0, 7, 14)) testthat::expect_equal(   as.numeric(c(z, x)),   c(0, 1, 2, 0, 0.142857142857143, 0.285714285714286) )  testthat::expect_equal(   as.Date(c(y, z)),   structure(c(20095, 20096, 20097, 20089, 20096, 20103), class = \"Date\") )  seq(x[[1]], y[[1]])"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/as.time_period.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Time period S3 class methods â€” as.time_period","text":"","code":"#' # 100 weeks from 2020-01-01  tmp = as.time_period(0:100, 7, \"2020-01-01\") as.Date(tmp) #>   [1] \"2020-01-01\" \"2020-01-08\" \"2020-01-15\" \"2020-01-22\" \"2020-01-29\" #>   [6] \"2020-02-05\" \"2020-02-12\" \"2020-02-19\" \"2020-02-26\" \"2020-03-04\" #>  [11] \"2020-03-11\" \"2020-03-18\" \"2020-03-25\" \"2020-04-01\" \"2020-04-08\" #>  [16] \"2020-04-15\" \"2020-04-22\" \"2020-04-29\" \"2020-05-06\" \"2020-05-13\" #>  [21] \"2020-05-20\" \"2020-05-27\" \"2020-06-03\" \"2020-06-10\" \"2020-06-17\" #>  [26] \"2020-06-24\" \"2020-07-01\" \"2020-07-08\" \"2020-07-15\" \"2020-07-22\" #>  [31] \"2020-07-29\" \"2020-08-05\" \"2020-08-12\" \"2020-08-19\" \"2020-08-26\" #>  [36] \"2020-09-02\" \"2020-09-09\" \"2020-09-16\" \"2020-09-23\" \"2020-09-30\" #>  [41] \"2020-10-07\" \"2020-10-14\" \"2020-10-21\" \"2020-10-28\" \"2020-11-04\" #>  [46] \"2020-11-11\" \"2020-11-18\" \"2020-11-25\" \"2020-12-02\" \"2020-12-09\" #>  [51] \"2020-12-16\" \"2020-12-23\" \"2020-12-30\" \"2021-01-06\" \"2021-01-13\" #>  [56] \"2021-01-20\" \"2021-01-27\" \"2021-02-03\" \"2021-02-10\" \"2021-02-17\" #>  [61] \"2021-02-24\" \"2021-03-03\" \"2021-03-10\" \"2021-03-17\" \"2021-03-24\" #>  [66] \"2021-03-31\" \"2021-04-07\" \"2021-04-14\" \"2021-04-21\" \"2021-04-28\" #>  [71] \"2021-05-05\" \"2021-05-12\" \"2021-05-19\" \"2021-05-26\" \"2021-06-02\" #>  [76] \"2021-06-09\" \"2021-06-16\" \"2021-06-23\" \"2021-06-30\" \"2021-07-07\" #>  [81] \"2021-07-14\" \"2021-07-21\" \"2021-07-28\" \"2021-08-04\" \"2021-08-11\" #>  [86] \"2021-08-18\" \"2021-08-25\" \"2021-09-01\" \"2021-09-08\" \"2021-09-15\" #>  [91] \"2021-09-22\" \"2021-09-29\" \"2021-10-06\" \"2021-10-13\" \"2021-10-20\" #>  [96] \"2021-10-27\" \"2021-11-03\" \"2021-11-10\" \"2021-11-17\" \"2021-11-24\" #> [101] \"2021-12-01\"  range(tmp) #> time unit: week, origin: 2020-01-01 (a Wednesday) #> 0 100 min(tmp) #> time unit: week, origin: 2020-01-01 (a Wednesday) #> 0 tmp2 = as.integer(as.Date(tmp)) # testthat::expect_true(all(na.omit(tmp2-lag(tmp2)) == 7))  tmp2 = as.time_period(0:23, 1/24, \"2020-01-01\") as.POSIXct(tmp2) #>  [1] \"2020-01-01 00:00:00 GMT\" \"2020-01-01 01:00:00 GMT\" #>  [3] \"2020-01-01 02:00:00 GMT\" \"2020-01-01 03:00:00 GMT\" #>  [5] \"2020-01-01 04:00:00 GMT\" \"2020-01-01 05:00:00 GMT\" #>  [7] \"2020-01-01 06:00:00 GMT\" \"2020-01-01 07:00:00 GMT\" #>  [9] \"2020-01-01 08:00:00 GMT\" \"2020-01-01 09:00:00 GMT\" #> [11] \"2020-01-01 10:00:00 GMT\" \"2020-01-01 11:00:00 GMT\" #> [13] \"2020-01-01 12:00:00 GMT\" \"2020-01-01 13:00:00 GMT\" #> [15] \"2020-01-01 14:00:00 GMT\" \"2020-01-01 15:00:00 GMT\" #> [17] \"2020-01-01 16:00:00 GMT\" \"2020-01-01 17:00:00 GMT\" #> [19] \"2020-01-01 18:00:00 GMT\" \"2020-01-01 19:00:00 GMT\" #> [21] \"2020-01-01 20:00:00 GMT\" \"2020-01-01 21:00:00 GMT\" #> [23] \"2020-01-01 22:00:00 GMT\" \"2020-01-01 23:00:00 GMT\"  # convert timeseries to new \"unit\" tmp = as.time_period(0:100, 7, \"2020-01-01\") tmp2 = as.time_period(tmp,1) testthat::expect_equal(as.numeric(tmp2), 0:100*7)  # 100 weeks from 2020-01-01  tmp = as.time_period(0:100, 7, \"2020-01-01\") as.Date(tmp) #>   [1] \"2020-01-01\" \"2020-01-08\" \"2020-01-15\" \"2020-01-22\" \"2020-01-29\" #>   [6] \"2020-02-05\" \"2020-02-12\" \"2020-02-19\" \"2020-02-26\" \"2020-03-04\" #>  [11] \"2020-03-11\" \"2020-03-18\" \"2020-03-25\" \"2020-04-01\" \"2020-04-08\" #>  [16] \"2020-04-15\" \"2020-04-22\" \"2020-04-29\" \"2020-05-06\" \"2020-05-13\" #>  [21] \"2020-05-20\" \"2020-05-27\" \"2020-06-03\" \"2020-06-10\" \"2020-06-17\" #>  [26] \"2020-06-24\" \"2020-07-01\" \"2020-07-08\" \"2020-07-15\" \"2020-07-22\" #>  [31] \"2020-07-29\" \"2020-08-05\" \"2020-08-12\" \"2020-08-19\" \"2020-08-26\" #>  [36] \"2020-09-02\" \"2020-09-09\" \"2020-09-16\" \"2020-09-23\" \"2020-09-30\" #>  [41] \"2020-10-07\" \"2020-10-14\" \"2020-10-21\" \"2020-10-28\" \"2020-11-04\" #>  [46] \"2020-11-11\" \"2020-11-18\" \"2020-11-25\" \"2020-12-02\" \"2020-12-09\" #>  [51] \"2020-12-16\" \"2020-12-23\" \"2020-12-30\" \"2021-01-06\" \"2021-01-13\" #>  [56] \"2021-01-20\" \"2021-01-27\" \"2021-02-03\" \"2021-02-10\" \"2021-02-17\" #>  [61] \"2021-02-24\" \"2021-03-03\" \"2021-03-10\" \"2021-03-17\" \"2021-03-24\" #>  [66] \"2021-03-31\" \"2021-04-07\" \"2021-04-14\" \"2021-04-21\" \"2021-04-28\" #>  [71] \"2021-05-05\" \"2021-05-12\" \"2021-05-19\" \"2021-05-26\" \"2021-06-02\" #>  [76] \"2021-06-09\" \"2021-06-16\" \"2021-06-23\" \"2021-06-30\" \"2021-07-07\" #>  [81] \"2021-07-14\" \"2021-07-21\" \"2021-07-28\" \"2021-08-04\" \"2021-08-11\" #>  [86] \"2021-08-18\" \"2021-08-25\" \"2021-09-01\" \"2021-09-08\" \"2021-09-15\" #>  [91] \"2021-09-22\" \"2021-09-29\" \"2021-10-06\" \"2021-10-13\" \"2021-10-20\" #>  [96] \"2021-10-27\" \"2021-11-03\" \"2021-11-10\" \"2021-11-17\" \"2021-11-24\" #> [101] \"2021-12-01\"  range(tmp) #> time unit: week, origin: 2020-01-01 (a Wednesday) #> 0 100 min(tmp) #> time unit: week, origin: 2020-01-01 (a Wednesday) #> 0 tmp2 = as.integer(as.Date(tmp)) # testthat::expect_true(all(na.omit(tmp2-lag(tmp2)) == 7))  tmp2 = as.time_period(0:23, 1/24, \"2020-01-01\") as.POSIXct(tmp2) #>  [1] \"2020-01-01 00:00:00 GMT\" \"2020-01-01 01:00:00 GMT\" #>  [3] \"2020-01-01 02:00:00 GMT\" \"2020-01-01 03:00:00 GMT\" #>  [5] \"2020-01-01 04:00:00 GMT\" \"2020-01-01 05:00:00 GMT\" #>  [7] \"2020-01-01 06:00:00 GMT\" \"2020-01-01 07:00:00 GMT\" #>  [9] \"2020-01-01 08:00:00 GMT\" \"2020-01-01 09:00:00 GMT\" #> [11] \"2020-01-01 10:00:00 GMT\" \"2020-01-01 11:00:00 GMT\" #> [13] \"2020-01-01 12:00:00 GMT\" \"2020-01-01 13:00:00 GMT\" #> [15] \"2020-01-01 14:00:00 GMT\" \"2020-01-01 15:00:00 GMT\" #> [17] \"2020-01-01 16:00:00 GMT\" \"2020-01-01 17:00:00 GMT\" #> [19] \"2020-01-01 18:00:00 GMT\" \"2020-01-01 19:00:00 GMT\" #> [21] \"2020-01-01 20:00:00 GMT\" \"2020-01-01 21:00:00 GMT\" #> [23] \"2020-01-01 22:00:00 GMT\" \"2020-01-01 23:00:00 GMT\"  # convert timeseries to new \"unit\" tmp = as.time_period(0:100, 7, \"2020-01-01\") tmp2 = as.time_period(tmp,1) testthat::expect_equal(as.numeric(tmp2), 0:100*7)  # Time to date times = date_to_time(as.Date(\"2019-12-29\")+0:100, \"1 week\") dates = time_to_date(times)  # Date to time times = date_to_time(as.Date(\"2019-12-29\")+0:100, \"1 week\") dates = time_to_date(times)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/breaks_log1p.html","id":null,"dir":"Reference","previous_headings":"","what":"A scales breaks generator for log1p scales â€” breaks_log1p","title":"A scales breaks generator for log1p scales â€” breaks_log1p","text":"scales breaks generator log1p scales","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/breaks_log1p.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A scales breaks generator for log1p scales â€” breaks_log1p","text":"","code":"breaks_log1p(n = 5, base = 10)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/breaks_log1p.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A scales breaks generator for log1p scales â€” breaks_log1p","text":"n number breaks base base breaks","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/breaks_log1p.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A scales breaks generator for log1p scales â€” breaks_log1p","text":"function ggplot scale breaks","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/breaks_log1p.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A scales breaks generator for log1p scales â€” breaks_log1p","text":"","code":"ggplot2::ggplot(ggplot2::diamonds, ggplot2::aes(x=price))+   ggplot2::geom_density()+   ggplot2::scale_x_continuous(trans=\"log1p\", breaks=breaks_log1p())"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_beta_prob_rng.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a random probability based on features of the simulation â€” cfg_beta_prob_rng","title":"Generate a random probability based on features of the simulation â€” cfg_beta_prob_rng","text":"Generate random probability based features simulation","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_beta_prob_rng.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a random probability based on features of the simulation â€” cfg_beta_prob_rng","text":"","code":"cfg_beta_prob_rng(probability_fn = ~0.8, kappa_fn = ~0.1)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_beta_prob_rng.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a random probability based on features of the simulation â€” cfg_beta_prob_rng","text":"probability_fn function gives time-varying mean beta distribution, function called minimally .x `tâ€œ time time period. variables may present. kappa_fn function gives time-varying dispersion beta distribution. function called minimally .x t time period .y mean mean. variables may present.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_beta_prob_rng.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a random probability based on features of the simulation â€” cfg_beta_prob_rng","text":"time dependent function inputs time (time_period) returns probability day defined probability_fn kappa_fn","code":""},{"path":[]},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_beta_prob_rng.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a random probability based on features of the simulation â€” cfg_beta_prob_rng","text":"","code":"fn = cfg_beta_prob_rng(~ ifelse(.x<=5,0.1,0.9)) fn(1:10) #>  [1] 0.09994303 0.10665743 0.11315549 0.08053910 0.09749180 0.90247668 #>  [7] 0.90286478 0.90559741 0.89325780 0.91719053"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_gamma_ip_fn.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a IP generating function from time varying mean and SD of a gamma function â€” cfg_gamma_ip_fn","title":"Get a IP generating function from time varying mean and SD of a gamma function â€” cfg_gamma_ip_fn","text":"Get IP generating function time varying mean SD gamma function","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_gamma_ip_fn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a IP generating function from time varying mean and SD of a gamma function â€” cfg_gamma_ip_fn","text":"","code":"cfg_gamma_ip_fn(mean_fn = ~2, sd_fn = function(mean) sqrt(mean))"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_gamma_ip_fn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a IP generating function from time varying mean and SD of a gamma function â€” cfg_gamma_ip_fn","text":"mean_fn function gives time-varying mean gamma distribution, function called minimally .x t time time period. variables may present. sd_fn function gives time-varying mean gamma distribution. function called minimally .x t time period .y mean mean. variables may present.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_gamma_ip_fn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get a IP generating function from time varying mean and SD of a gamma function â€” cfg_gamma_ip_fn","text":"time dependent function inputs time (time_period) returns ip delay distribution day defined mean_fn sd_fn","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_gamma_ip_fn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get a IP generating function from time varying mean and SD of a gamma function â€” cfg_gamma_ip_fn","text":"","code":"fn = cfg_gamma_ip_fn(mean_fn = function(t) ifelse(t < 5, 4, 2)) # a gamma function that changes mean at time 5 fn(4) #> [[1]] #> # A tibble: 15 Ã— 5 #> # Groups:   boot [1] #>      tau    a0    a1 probability  boot #>    <int> <dbl> <dbl>       <dbl> <int> #>  1     0   0     0.5    0.00175      1 #>  2     1   0.5   1.5    0.0639       1 #>  3     2   1.5   2.5    0.177        1 #>  4     3   2.5   3.5    0.221        1 #>  5     4   3.5   4.5    0.194        1 #>  6     5   4.5   5.5    0.141        1 #>  7     6   5.5   6.5    0.0898       1 #>  8     7   6.5   7.5    0.0527       1 #>  9     8   7.5   8.5    0.0290       1 #> 10     9   8.5   9.5    0.0152       1 #> 11    10   9.5  10.5    0.00771      1 #> 12    11  10.5  11.5    0.00378      1 #> 13    12  11.5  12.5    0.00181      1 #> 14    13  12.5  13.5    0.000848     1 #> 15    14  13.5  14.5    0.000707     1 #>  fn(7) #> [[1]] #> # A tibble: 11 Ã— 5 #> # Groups:   boot [1] #>      tau    a0    a1 probability  boot #>    <int> <dbl> <dbl>       <dbl> <int> #>  1     0   0     0.5    0.0902       1 #>  2     1   0.5   1.5    0.352        1 #>  3     2   1.5   2.5    0.271        1 #>  4     3   2.5   3.5    0.151        1 #>  5     4   3.5   4.5    0.0748       1 #>  6     5   4.5   5.5    0.0345       1 #>  7     6   5.5   6.5    0.0153       1 #>  8     7   6.5   7.5    0.00657      1 #>  9     8   7.5   8.5    0.00277      1 #> 10     9   8.5   9.5    0.00115      1 #> 11    10   9.5  10.5    0.000786     1 #>"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_ip_sampler_rng.html","id":null,"dir":"Reference","previous_headings":"","what":"Randomly sample from an empirical distribution â€” cfg_ip_sampler_rng","title":"Randomly sample from an empirical distribution â€” cfg_ip_sampler_rng","text":"used random sampling infectivity profile times infection, example. nothing stop putting delay distribution negative times strange things may happen simulation.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_ip_sampler_rng.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Randomly sample from an empirical distribution â€” cfg_ip_sampler_rng","text":"","code":"cfg_ip_sampler_rng(ip = i_empirical_ip)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_ip_sampler_rng.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Randomly sample from an empirical distribution â€” cfg_ip_sampler_rng","text":"ip long format empirical distribution - dataframe columns: boot (anything + default(1)) - bootstrap identifier probability (proportion) - probability new event period. a0 (double) - beginning time period (days) a1 (double) - end time period (days) Minimally grouped : boot (groupings allowed).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_ip_sampler_rng.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Randomly sample from an empirical distribution â€” cfg_ip_sampler_rng","text":"function accepts n parameter produces random samples ip distribution","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_ip_sampler_rng.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Randomly sample from an empirical distribution â€” cfg_ip_sampler_rng","text":"","code":"tmp = cfg_ip_sampler_rng(example_ganyani_ip())(10000)  # This discretised ganyani distribution is based on these figures: # mean: 5.2 (3.78-6.78) and sd: 1.72 (0.91-3.93) format_ip(example_ganyani_ip()) #> [1] \"PDF: mean: 5.2 [3.98 â€” 6.82]; sd: 2.06 [0.644 â€” 3.19]; 100 bootstraps\"  mean(tmp) # Should be about 5.2 #> [1] 5.265945 stats::sd(tmp) # Should be about 1.72 #> [1] 2.248792"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_linear_fn.html","id":null,"dir":"Reference","previous_headings":"","what":"Linear function from dataframe â€” cfg_linear_fn","title":"Linear function from dataframe â€” cfg_linear_fn","text":"Linear function dataframe","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_linear_fn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Linear function from dataframe â€” cfg_linear_fn","text":"","code":"cfg_linear_fn(changes, ..., col_name = setdiff(colnames(changes), \"t\"))"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_linear_fn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Linear function from dataframe â€” cfg_linear_fn","text":"changes dataframe t <col_name> columns define change points piecewise linear function. ... used col_name value column (optional 2 columns)","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_linear_fn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Linear function from dataframe â€” cfg_linear_fn","text":"function inputs vector t returns linearly interpolated value <col_name>","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_step_fn.html","id":null,"dir":"Reference","previous_headings":"","what":"Step function from dataframe â€” cfg_step_fn","title":"Step function from dataframe â€” cfg_step_fn","text":"Step function dataframe","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_step_fn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Step function from dataframe â€” cfg_step_fn","text":"","code":"cfg_step_fn(changes, ..., col_name = setdiff(colnames(changes), \"t\"))"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_step_fn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Step function from dataframe â€” cfg_step_fn","text":"changes dataframe t <col_name> columns define cut points step function. ... used col_name value column (optional 2 columns)","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_step_fn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Step function from dataframe â€” cfg_step_fn","text":"function inputs vector t returns next smallest corresponding value <col_name> (first one)","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_transition_fn.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample from a multinomial transition matrix â€” cfg_transition_fn","title":"Sample from a multinomial transition matrix â€” cfg_transition_fn","text":"particularly designed use within fn_list_next_gen parameter sim_branching_process() allow age group contract matrices applied example (assuming categorical age).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_transition_fn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample from a multinomial transition matrix â€” cfg_transition_fn","text":"","code":"cfg_transition_fn(transition)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_transition_fn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample from a multinomial transition matrix â€” cfg_transition_fn","text":"transition transition matrix long format dataframe. matrix columns add 1, column names input class. row names output class. data frame format must input, output, probability columns.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_transition_fn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample from a multinomial transition matrix â€” cfg_transition_fn","text":"function given input return samples output class according probability distributions.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_transition_fn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample from a multinomial transition matrix â€” cfg_transition_fn","text":"","code":"age = rep(c(\"child\",\"adult\",\"elderly\"),100)  fn = cfg_transition_fn(dplyr::tribble(   ~input, ~output, ~probability,   \"child\", \"child\", 0.5,   \"child\", \"adult\", 0.5,   \"adult\", \"child\", 0.5,   \"adult\", \"adult\", 0.3,   \"adult\", \"elderly\", 0.2,   \"elderly\",\"elderly\", 0.5,   \"elderly\",\"adult\", 0.5, ))  table(fn(age),age) #>          age #>           adult child elderly #>   adult      33    37      63 #>   child      48    63       0 #>   elderly    19     0      37"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_weekly_gamma_rng.html","id":null,"dir":"Reference","previous_headings":"","what":"Weekly delay function with day of week effect â€” cfg_weekly_gamma_rng","title":"Weekly delay function with day of week effect â€” cfg_weekly_gamma_rng","text":"function returns random number generator gamma distribution weekly period configurable degree additional variability around weekly pattern. suited delays things like testing may depend day week.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_weekly_gamma_rng.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Weekly delay function with day of week effect â€” cfg_weekly_gamma_rng","text":"","code":"cfg_weekly_gamma_rng(   mean = c(1, 1, 1, 1, 4, 3, 2),   sd = sqrt(mean),   week_starts = weekdays(as.Date(\"2024-10-14\")) )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_weekly_gamma_rng.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Weekly delay function with day of week effect â€” cfg_weekly_gamma_rng","text":"mean mean amount delay day week sd SD delay week_starts locale description first day week (default \"Monday\").","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_weekly_gamma_rng.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Weekly delay function with day of week effect â€” cfg_weekly_gamma_rng","text":"random number generator taking t time parameter returning duration time t depending day week.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_weekly_gamma_rng.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Weekly delay function with day of week effect â€” cfg_weekly_gamma_rng","text":"","code":"fn = cfg_weekly_gamma_rng(c(1,1,1,1,4,3,2)) matrix(fn(1:42),ncol=7,byrow=TRUE) #>            [,1]      [,2]      [,3]      [,4]      [,5]      [,6]       [,7] #> [1,] 1.08641963 6.8155467 1.9760900 8.0821977 0.7375058 1.3381693 0.08969051 #> [2,] 0.17190983 0.9741694 1.3303021 0.7651640 4.1862424 0.4389224 0.43008356 #> [3,] 0.06361773 6.3169688 0.7769338 0.4975902 1.3216847 0.8802695 0.18040673 #> [4,] 0.53048240 3.6359255 2.9786923 1.9336943 1.1536887 0.3358088 0.53352742 #> [5,] 0.78839729 0.5108545 4.0479716 0.1951924 0.3334846 0.7118283 1.83446885 #> [6,] 0.68615325 3.2840124 2.1744995 1.9013039 1.1313860 1.4806989 0.24784653"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_weekly_ip_fn.html","id":null,"dir":"Reference","previous_headings":"","what":"Weekly convolution distribution function â€” cfg_weekly_ip_fn","title":"Weekly convolution distribution function â€” cfg_weekly_ip_fn","text":"Weekly convolution distribution function","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_weekly_ip_fn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Weekly convolution distribution function â€” cfg_weekly_ip_fn","text":"","code":"cfg_weekly_ip_fn(   mean = c(1, 1, 1, 1, 4, 3, 2),   sd = sqrt(mean),   week_starts = weekdays(as.Date(\"2024-10-14\")) )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_weekly_ip_fn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Weekly convolution distribution function â€” cfg_weekly_ip_fn","text":"mean means gamma distributed delay function weekday sd sds gamma distributed delay function weekday week_starts locale description first day week (default \"Monday\").","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_weekly_ip_fn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Weekly convolution distribution function â€” cfg_weekly_ip_fn","text":"time dependent function inputs time (time_period) generates IP delay distribution day varying day week","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_weekly_ip_fn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Weekly convolution distribution function â€” cfg_weekly_ip_fn","text":"","code":"cat(sapply(cfg_weekly_ip_fn()(1:7),format_ip),sep = \"\\n\") #> mean: 1.06; sd: 1.01 #> mean: 4; sd: 2.04 #> mean: 3; sd: 1.77 #> mean: 2.02; sd: 1.44 #> mean: 1.06; sd: 1.01 #> mean: 1.06; sd: 1.01 #> mean: 1.06; sd: 1.01"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_weekly_proportion_rng.html","id":null,"dir":"Reference","previous_headings":"","what":"Random probability function with day of week effect â€” cfg_weekly_proportion_rng","title":"Random probability function with day of week effect â€” cfg_weekly_proportion_rng","text":"function returns random probability generator weekly period configurable degree additional variability around weekly pattern. suited probabilities things like testing may depend day week.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_weekly_proportion_rng.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random probability function with day of week effect â€” cfg_weekly_proportion_rng","text":"","code":"cfg_weekly_proportion_rng(   prob = c(0.8, 0.8, 0.8, 0.8, 0.8, 0.5, 0.5),   kappa = 0.1,   week_starts = weekdays(as.Date(\"2024-10-14\")) )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_weekly_proportion_rng.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random probability function with day of week effect â€” cfg_weekly_proportion_rng","text":"prob rates e.g. ascertainment day week. kappa dispersion parameter 0 1. O dispersion. 1 maximum week_starts locale description first day week (default \"Monday\").","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_weekly_proportion_rng.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Random probability function with day of week effect â€” cfg_weekly_proportion_rng","text":"random number generator function taking t time parameter returning probability ascertainment time, depending day week etc.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cfg_weekly_proportion_rng.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Random probability function with day of week effect â€” cfg_weekly_proportion_rng","text":"","code":"fn = cfg_weekly_proportion_rng(c(0.9,0.9,0.9,0.9,0.9,0.1,0.1)) matrix(fn(1:42),ncol=7,byrow=TRUE) #>           [,1]      [,2]       [,3]       [,4]      [,5]      [,6]      [,7] #> [1,] 0.9174375 0.9022554 0.09517817 0.09628920 0.8979259 0.8899529 0.8954396 #> [2,] 0.8828648 0.8942341 0.10573120 0.09786131 0.9071478 0.9139198 0.9071535 #> [3,] 0.8930483 0.8982471 0.09208758 0.09737471 0.9094128 0.8943528 0.8894383 #> [4,] 0.9101896 0.8971038 0.08945290 0.09997201 0.8997584 0.8991862 0.9045917 #> [5,] 0.9069867 0.8974974 0.09865388 0.09596240 0.9041086 0.8914366 0.9073698 #> [6,] 0.8907440 0.8831391 0.09738555 0.09781887 0.8899456 0.8962666 0.9039236"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/covid_ip.html","id":null,"dir":"Reference","previous_headings":"","what":"A COVID-19 infectivity profile based on an empirical resampling approach â€” covid_ip","title":"A COVID-19 infectivity profile based on an empirical resampling approach â€” covid_ip","text":"infectivity profile derived meta-analysis serial intervals.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/covid_ip.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A COVID-19 infectivity profile based on an empirical resampling approach â€” covid_ip","text":"","code":"data(covid_ip)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/covid_ip.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"A COVID-19 infectivity profile based on an empirical resampling approach â€” covid_ip","text":"dataframe containing following columns: boot (anything + default(1)) - bootstrap identifier probability (proportion) - probability infection previous time period time time (double) - end time period (days) Must grouped : boot (exactly). dataframe containing following columns: boot (anything + default(1)) - bootstrap identifier probability (proportion) - probability infection previous time period time tau (numeric) - time index probability relates (days) a0 (numeric) - beginning time period a1 (numeric) - end time period Grouped : boot. 1400 rows 5 columns","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/covid_test_sensitivity.html","id":null,"dir":"Reference","previous_headings":"","what":"Test sensitivity of PCR tests â€” covid_test_sensitivity","title":"Test sensitivity of PCR tests â€” covid_test_sensitivity","text":"probability detecting COVID using PCR given time since infection, based Binny et al 2023.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/covid_test_sensitivity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test sensitivity of PCR tests â€” covid_test_sensitivity","text":"","code":"data(covid_test_sensitivity)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/covid_test_sensitivity.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Test sensitivity of PCR tests â€” covid_test_sensitivity","text":"dataframe containing following columns: tau (numeric) - time column probability (numeric) - probability column boot (integer) - boot column Must grouped : boot (groupings allowed). 5100 rows 3 columns","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/covid_test_sensitivity.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Test sensitivity of PCR tests â€” covid_test_sensitivity","text":"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9384503/","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/covid_viral_shedding.html","id":null,"dir":"Reference","previous_headings":"","what":"The COVID-19 viral shedding duration â€” covid_viral_shedding","title":"The COVID-19 viral shedding duration â€” covid_viral_shedding","text":"COVID-19 viral shedding duration","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/covid_viral_shedding.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The COVID-19 viral shedding duration â€” covid_viral_shedding","text":"","code":"data(covid_viral_shedding)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/covid_viral_shedding.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"The COVID-19 viral shedding duration â€” covid_viral_shedding","text":"dataframe containing following columns: boot (anything + default(1)) - bootstrap identifier probability (proportion) - probability infection previous time period time tau (numeric) - time index probability relates (days) a0 (numeric) - beginning time period a1 (numeric) - end time period Grouped : boot. 2600 rows 3 columns","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/covid_viral_shedding.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"The COVID-19 viral shedding duration â€” covid_viral_shedding","text":"https://www.nature.com/articles/s41467-020-20568-4 Von Kampen et al.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cut_date.html","id":null,"dir":"Reference","previous_headings":"","what":"Places a set of dates within a regular time series â€” cut_date","title":"Places a set of dates within a regular time series â€” cut_date","text":"counterpart date_seq_dates(). Take original set data place within regular time series periodicity time series may expressed numbers days, weeks, months quarters, years, periods defined anchoring date, day week reference start end input dates. can either return periods dates factors (e.g. plotting) time_period analysis relies numeric representation date duration anchor.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cut_date.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Places a set of dates within a regular time series â€” cut_date","text":"","code":"cut_date(   dates,   unit,   anchor = \"start\",   output = c(\"date\", \"factor\", \"time_period\"),   dfmt = \"%d/%b/%y\",   ifmt = \"{start} â€” {end}\",   ... )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cut_date.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Places a set of dates within a regular time series â€” cut_date","text":"dates set dates unit period e.g. \"1 week\" anchor one date, \"start\" \"end\" weekday name e.g. \"mon\" always one start time periods cutting output return result either \"date\" (default), ordered \"factor\" date ranges label, \"time_period\". result named labels referring dfmt strptime format dates labels ifmt sprintf format period label containing %s exactly twice. ... ignored","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cut_date.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Places a set of dates within a regular time series â€” cut_date","text":"set dates, times factor level, representing start period date falls , period defined duration anchor","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/cut_date.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Places a set of dates within a regular time series â€” cut_date","text":"","code":"dates = as.Date(c(\"2020-01-01\",\"2020-02-01\",\"2020-01-15\",\"2020-02-03\",NA)) fs = date_seq(dates, \"2 days\") dates - cut_date(dates, \"2 days\") #> Time differences in days #> 01/Jan/20 â€” 02/Jan/20 31/Jan/20 â€” 01/Feb/20 15/Jan/20 â€” 16/Jan/20  #>                     0                     1                     0  #> 02/Feb/20 â€” 03/Feb/20               Unknown  #>                     1                    NA  cut_date(dates,unit=\"2 days\", output=\"time_period\") #> time unit: 2 days, origin: 2020-01-01 (a Wednesday) #> 0 15 7 16 NA  # A weekly set of dates: dates2 = Sys.Date() + floor(stats::runif(50,max=10))*7  # in this specific situation the final date is not truncated because the # input data is seen as an exact match for the whole output period. cut_date(dates2, \"1 week\", \"sun\", output=\"factor\") #>  [1] 08/Feb/26 â€” 14/Feb/26 28/Dec/25 â€” 03/Jan/26 01/Feb/26 â€” 07/Feb/26 #>  [4] 04/Jan/26 â€” 10/Jan/26 28/Dec/25 â€” 03/Jan/26 11/Jan/26 â€” 17/Jan/26 #>  [7] 25/Jan/26 â€” 31/Jan/26 07/Dec/25 â€” 13/Dec/25 08/Feb/26 â€” 14/Feb/26 #> [10] 04/Jan/26 â€” 10/Jan/26 01/Feb/26 â€” 07/Feb/26 04/Jan/26 â€” 10/Jan/26 #> [13] 28/Dec/25 â€” 03/Jan/26 01/Feb/26 â€” 07/Feb/26 28/Dec/25 â€” 03/Jan/26 #> [16] 01/Feb/26 â€” 07/Feb/26 25/Jan/26 â€” 31/Jan/26 25/Jan/26 â€” 31/Jan/26 #> [19] 18/Jan/26 â€” 24/Jan/26 21/Dec/25 â€” 27/Dec/25 08/Feb/26 â€” 14/Feb/26 #> [22] 25/Jan/26 â€” 31/Jan/26 21/Dec/25 â€” 27/Dec/25 07/Dec/25 â€” 13/Dec/25 #> [25] 11/Jan/26 â€” 17/Jan/26 04/Jan/26 â€” 10/Jan/26 11/Jan/26 â€” 17/Jan/26 #> [28] 28/Dec/25 â€” 03/Jan/26 21/Dec/25 â€” 27/Dec/25 25/Jan/26 â€” 31/Jan/26 #> [31] 21/Dec/25 â€” 27/Dec/25 08/Feb/26 â€” 14/Feb/26 04/Jan/26 â€” 10/Jan/26 #> [34] 08/Feb/26 â€” 14/Feb/26 18/Jan/26 â€” 24/Jan/26 28/Dec/25 â€” 03/Jan/26 #> [37] 18/Jan/26 â€” 24/Jan/26 08/Feb/26 â€” 14/Feb/26 11/Jan/26 â€” 17/Jan/26 #> [40] 14/Dec/25 â€” 20/Dec/25 08/Feb/26 â€” 14/Feb/26 28/Dec/25 â€” 03/Jan/26 #> [43] 07/Dec/25 â€” 13/Dec/25 08/Feb/26 â€” 14/Feb/26 25/Jan/26 â€” 31/Jan/26 #> [46] 14/Dec/25 â€” 20/Dec/25 21/Dec/25 â€” 27/Dec/25 04/Jan/26 â€” 10/Jan/26 #> [49] 08/Feb/26 â€” 14/Feb/26 28/Dec/25 â€” 03/Jan/26 #> 11 Levels: 07/Dec/25 â€” 13/Dec/25 < ... < 15/Feb/26 â€” 21/Feb/26 cut_date(dates2, dfmt = \"%d/%b\", output=\"factor\", unit = \"2 weeks\", anchor=\"sun\") #>  [1] 01/Feb â€” 14/Feb 21/Dec â€” 03/Jan 01/Feb â€” 14/Feb 04/Jan â€” 17/Jan #>  [5] 21/Dec â€” 03/Jan 04/Jan â€” 17/Jan 18/Jan â€” 31/Jan 07/Dec â€” 20/Dec #>  [9] 01/Feb â€” 14/Feb 04/Jan â€” 17/Jan 01/Feb â€” 14/Feb 04/Jan â€” 17/Jan #> [13] 21/Dec â€” 03/Jan 01/Feb â€” 14/Feb 21/Dec â€” 03/Jan 01/Feb â€” 14/Feb #> [17] 18/Jan â€” 31/Jan 18/Jan â€” 31/Jan 18/Jan â€” 31/Jan 21/Dec â€” 03/Jan #> [21] 01/Feb â€” 14/Feb 18/Jan â€” 31/Jan 21/Dec â€” 03/Jan 07/Dec â€” 20/Dec #> [25] 04/Jan â€” 17/Jan 04/Jan â€” 17/Jan 04/Jan â€” 17/Jan 21/Dec â€” 03/Jan #> [29] 21/Dec â€” 03/Jan 18/Jan â€” 31/Jan 21/Dec â€” 03/Jan 01/Feb â€” 14/Feb #> [33] 04/Jan â€” 17/Jan 01/Feb â€” 14/Feb 18/Jan â€” 31/Jan 21/Dec â€” 03/Jan #> [37] 18/Jan â€” 31/Jan 01/Feb â€” 14/Feb 04/Jan â€” 17/Jan 07/Dec â€” 20/Dec #> [41] 01/Feb â€” 14/Feb 21/Dec â€” 03/Jan 07/Dec â€” 20/Dec 01/Feb â€” 14/Feb #> [45] 18/Jan â€” 31/Jan 07/Dec â€” 20/Dec 21/Dec â€” 03/Jan 04/Jan â€” 17/Jan #> [49] 01/Feb â€” 14/Feb 21/Dec â€” 03/Jan #> 6 Levels: 07/Dec â€” 20/Dec < 21/Dec â€” 03/Jan < ... < 15/Feb â€” 28/Feb"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/date_seq.Date.html","id":null,"dir":"Reference","previous_headings":"","what":"Expand a date vector to the full range of possible dates â€” date_seq.Date","title":"Expand a date vector to the full range of possible dates â€” date_seq.Date","text":"Derive vector observation dates, complete ordered sequence periods regular time series, length periods specified, number days, weeks, years etcetera. E.g. can convert random set dates ordered complete list 1 week intervals (2 month intervals) spanning range dates. interesting problems regarding put breaks within month week. Often either based specific date (e.g. yearly periods starting 2020-01-01) day week (e.g. 2 weekly periods staring Sunday) maybe relative input time series (weekly ending last date data). also problem consider data may incomplete starting end periods, may comparable periods, may need exclude result.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/date_seq.Date.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expand a date vector to the full range of possible dates â€” date_seq.Date","text":"","code":"# S3 method for class 'Date' date_seq(x, period = .day_interval(x), anchor = \"start\", complete = FALSE, ...)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/date_seq.Date.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expand a date vector to the full range of possible dates â€” date_seq.Date","text":"x vector dates, possibly including NA values period gap observations number days natural language definition period \"1 week\", '2 weeks', '1 month', etcetera. given derived dates. anchor defines day appears sequence (extend far). Given either date, \"start\", \"end\" day week, e.g. \"mon\". complete truncate incomplete start end periods ... ignored","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/date_seq.Date.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expand a date vector to the full range of possible dates â€” date_seq.Date","text":"vector dates regular periods minimum maximum dates, boundaries defined anchor.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/date_seq.Date.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expand a date vector to the full range of possible dates â€” date_seq.Date","text":"","code":"date_seq(as.Date(c(\"2020-01-01\",\"2020-02-01\",\"2020-01-15\",\"2020-02-01\",NA)), \"2 days\") #>  [1] \"2020-01-01\" \"2020-01-03\" \"2020-01-05\" \"2020-01-07\" \"2020-01-09\" #>  [6] \"2020-01-11\" \"2020-01-13\" \"2020-01-15\" \"2020-01-17\" \"2020-01-19\" #> [11] \"2020-01-21\" \"2020-01-23\" \"2020-01-25\" \"2020-01-27\" \"2020-01-29\" #> [16] \"2020-01-31\""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/date_seq.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the full sequence of values in a vector â€” date_seq","title":"Create the full sequence of values in a vector â€” date_seq","text":"useful want fill missing values observed . example, date_seq(c(1, 2, 4, 6), 1) return 1:6.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/date_seq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the full sequence of values in a vector â€” date_seq","text":"","code":"date_seq(x, period, ...)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/date_seq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the full sequence of values in a vector â€” date_seq","text":"x numeric date vector period Gap observation. existing data checked ensure actually periodicity. ... subtype methods","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/date_seq.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create the full sequence of values in a vector â€” date_seq","text":"vector type input","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/date_seq.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create the full sequence of values in a vector â€” date_seq","text":"","code":"date_seq(c(1, 2, 4, 5, 10), 1) #>  [1]  1  2  3  4  5  6  7  8  9 10"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/date_seq.numeric.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the full sequence of values in a vector â€” date_seq.numeric","title":"Create the full sequence of values in a vector â€” date_seq.numeric","text":"useful want fill missing values observed . example, date_seq(c(1, 2, 4, 6), 1) return 1:6.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/date_seq.numeric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the full sequence of values in a vector â€” date_seq.numeric","text":"","code":"# S3 method for class 'numeric' date_seq(x, period = 1, tol = 1e-06, ...)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/date_seq.numeric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the full sequence of values in a vector â€” date_seq.numeric","text":"x numeric date vector period Gap observation. existing data checked ensure actually periodicity. tol Numerical tolerance checking periodicity. ... subtype methods","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/date_seq.numeric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create the full sequence of values in a vector â€” date_seq.numeric","text":"vector type input","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/date_seq.numeric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create the full sequence of values in a vector â€” date_seq.numeric","text":"","code":"date_seq(c(1, 2, 4, 5, 10), 1) #>  [1]  1  2  3  4  5  6  7  8  9 10"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/date_seq.time_period.html","id":null,"dir":"Reference","previous_headings":"","what":"Expand a time_period vector to the full range of possible times â€” date_seq.time_period","title":"Expand a time_period vector to the full range of possible times â€” date_seq.time_period","text":"Derive vector observation time_periods, complete ordered sequence periods regular time series, length periods specified, number days, weeks, years etc. E.g. can convert random set times ordered complete list 1 week intervals (2 month intervals) spanning range dates. interesting problems regarding put breaks within month week. Often either based specific date (e.g. yearly periods starting 2020-01-01) day week (e.g. 2 weekly periods staring sunday) maybe relative input time series (weekly ending last date data). also problem consider data may incomplete starting end periods, may comparable periods, may need exclude result.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/date_seq.time_period.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expand a time_period vector to the full range of possible times â€” date_seq.time_period","text":"","code":"# S3 method for class 'time_period' date_seq(x, period = attributes(x)$unit, complete = FALSE, ...)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/date_seq.time_period.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expand a time_period vector to the full range of possible times â€” date_seq.time_period","text":"x time period vector period gap observations number days natural language definition period \"1 week\", '2 weeks', '1 month', etc. given derived dates. complete truncate incomplete start end periods ... ignored","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/date_seq.time_period.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expand a time_period vector to the full range of possible times â€” date_seq.time_period","text":"vector time_periods regular periods minimum maximum dates, boundaries defined anchor.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/date_seq.time_period.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expand a time_period vector to the full range of possible times â€” date_seq.time_period","text":"","code":"tmp = as.time_period(c(0,10,100), 7, \"2020-01-01\") date_seq(tmp, \"7 days\") #> time unit: week, origin: 2020-01-01 (a Wednesday) #> 0 10 20 30 40 50 60 70 80 90 100 date_seq(tmp, \"1 day\") #> time unit: week, origin: 2020-01-01 (a Wednesday) #> 0.14 0.29 0.43 0.57 0.71 0.86 1 1.14 1.29 1.43 1.57 1.71 1.86 2 2.14 2.29 2.43 2.57 2.71 2.86 3 3.14 3.29 3.43 3.57 3.71 3.86 4 4.14 4.29 4.43 4.57 4.71 4.86 5 5.14 5.29 5.43 5.57 5.71 5.86 6 6.14 6.29 6.43 6.57 6.71 6.86 7 7.14 7.29 7.43 7.57 7.71 7.86 8 8.14 8.29 8.43 8.57 8.71 8.86 9 9.14 9.29 9.43 9.57 9.71 9.86 10 10.14 10.29 10.43 10.57 10.71 10.86 11 11.14 11.29 11.43 11.57 11.71 11.86 12 12.14 12.29 12.43 12.57 12.71 12.86 13 13.14 13.29 13.43 13.57 13.71 13.86 14 14.14 14.29 14.43 14.57 14.71 14.86 15 15.14 15.29 15.43 15.57 15.71 15.86 16 16.14 16.29 16.43 16.57 16.71 16.86 17 17.14 17.29 17.43 17.57 17.71 17.86 18 18.14 18.29 18.43 18.57 18.71 18.86 19 19.14 19.29 19.43 19.57 19.71 19.86 20 20.14 20.29 20.43 20.57 20.71 20.86 21 21.14 21.29 21.43 21.57 21.71 21.86 22 22.14 22.29 22.43 22.57 22.71 22.86 23 23.14 23.29 23.43 23.57 23.71 23.86 24 24.14 24.29 24.43 24.57 24.71 24.86 25 25.14 25.29 25.43 25.57 25.71 25.86 26 26.14 26.29 26.43 26.57 26.71 26.86 27 27.14 27.29 27.43 27.57 27.71 27.86 28 28.14 28.29 28.43 28.57 28.71 28.86 29 29.14 29.29 29.43 29.57 29.71 29.86 30 30.14 30.29 30.43 30.57 30.71 30.86 31 31.14 31.29 31.43 31.57 31.71 31.86 32 32.14 32.29 32.43 32.57 32.71 32.86 33 33.14 33.29 33.43 33.57 33.71 33.86 34 34.14 34.29 34.43 34.57 34.71 34.86 35 35.14 35.29 35.43 35.57 35.71 35.86 36 36.14 36.29 36.43 36.57 36.71 36.86 37 37.14 37.29 37.43 37.57 37.71 37.86 38 38.14 38.29 38.43 38.57 38.71 38.86 39 39.14 39.29 39.43 39.57 39.71 39.86 40 40.14 40.29 40.43 40.57 40.71 40.86 41 41.14 41.29 41.43 41.57 41.71 41.86 42 42.14 42.29 42.43 42.57 42.71 42.86 43 43.14 43.29 43.43 43.57 43.71 43.86 44 44.14 44.29 44.43 44.57 44.71 44.86 45 45.14 45.29 45.43 45.57 45.71 45.86 46 46.14 46.29 46.43 46.57 46.71 46.86 47 47.14 47.29 47.43 47.57 47.71 47.86 48 48.14 48.29 48.43 48.57 48.71 48.86 49 49.14 49.29 49.43 49.57 49.71 49.86 50 50.14 50.29 50.43 50.57 50.71 50.86 51 51.14 51.29 51.43 51.57 51.71 51.86 52 52.14 52.29 52.43 52.57 52.71 52.86 53 53.14 53.29 53.43 53.57 53.71 53.86 54 54.14 54.29 54.43 54.57 54.71 54.86 55 55.14 55.29 55.43 55.57 55.71 55.86 56 56.14 56.29 56.43 56.57 56.71 56.86 57 57.14 57.29 57.43 57.57 57.71 57.86 58 58.14 58.29 58.43 58.57 58.71 58.86 59 59.14 59.29 59.43 59.57 59.71 59.86 60 60.14 60.29 60.43 60.57 60.71 60.86 61 61.14 61.29 61.43 61.57 61.71 61.86 62 62.14 62.29 62.43 62.57 62.71 62.86 63 63.14 63.29 63.43 63.57 63.71 63.86 64 64.14 64.29 64.43 64.57 64.71 64.86 65 65.14 65.29 65.43 65.57 65.71 65.86 66 66.14 66.29 66.43 66.57 66.71 66.86 67 67.14 67.29 67.43 67.57 67.71 67.86 68 68.14 68.29 68.43 68.57 68.71 68.86 69 69.14 69.29 69.43 69.57 69.71 69.86 70 70.14 70.29 70.43 70.57 70.71 70.86 71 71.14 71.29 71.43 71.57 71.71 71.86 72 72.14 72.29 72.43 72.57 72.71 72.86 73 73.14 73.29 73.43 73.57 73.71 73.86 74 74.14 74.29 74.43 74.57 74.71 74.86 75 75.14 75.29 75.43 75.57 75.71 75.86 76 76.14 76.29 76.43 76.57 76.71 76.86 77 77.14 77.29 77.43 77.57 77.71 77.86 78 78.14 78.29 78.43 78.57 78.71 78.86 79 79.14 79.29 79.43 79.57 79.71 79.86 80 80.14 80.29 80.43 80.57 80.71 80.86 81 81.14 81.29 81.43 81.57 81.71 81.86 82 82.14 82.29 82.43 82.57 82.71 82.86 83 83.14 83.29 83.43 83.57 83.71 83.86 84 84.14 84.29 84.43 84.57 84.71 84.86 85 85.14 85.29 85.43 85.57 85.71 85.86 86 86.14 86.29 86.43 86.57 86.71 86.86 87 87.14 87.29 87.43 87.57 87.71 87.86 88 88.14 88.29 88.43 88.57 88.71 88.86 89 89.14 89.29 89.43 89.57 89.71 89.86 90 90.14 90.29 90.43 90.57 90.71 90.86 91 91.14 91.29 91.43 91.57 91.71 91.86 92 92.14 92.29 92.43 92.57 92.71 92.86 93 93.14 93.29 93.43 93.57 93.71 93.86 94 94.14 94.29 94.43 94.57 94.71 94.86 95 95.14 95.29 95.43 95.57 95.71 95.86 96 96.14 96.29 96.43 96.57 96.71 96.86 97 97.14 97.29 97.43 97.57 97.71 97.86 98 98.14 98.29 98.43 98.57 98.71 98.86 99 99.14 99.29 99.43 99.57 99.71 99.86"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dbeta2.html","id":null,"dir":"Reference","previous_headings":"","what":"The Beta Distribution â€” dbeta2","title":"The Beta Distribution â€” dbeta2","text":"Density, distribution function, quantile function random   generation Beta distribution parameters shape1   shape2 (optional non-centrality parameter ncp).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dbeta2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The Beta Distribution â€” dbeta2","text":"","code":"dbeta2(x, prob, kappa, log = FALSE)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dbeta2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The Beta Distribution â€” dbeta2","text":"x vector quantiles prob mean probability (vectorised) kappa coefficient variation. 0 variability 1 maximally variability (vectorised) log logical; TRUE, probabilities p given log(p).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dbeta2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The Beta Distribution â€” dbeta2","text":"dbeta gives density, pbeta distribution   function, qbeta quantile function, rbeta   generates random deviates. Invalid arguments result return value NaN, warning. length result determined n   rbeta, maximum lengths   numerical arguments functions. numerical arguments n recycled   length result.  first elements logical   arguments used.","code":""},{"path":[]},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dbeta2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The Beta Distribution â€” dbeta2","text":"","code":"dbeta2(c(0.25,0.5,0.75), 0.5, 0.25) #> [1] 0.008405383 5.441004532 0.008405383"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dcgamma.html","id":null,"dir":"Reference","previous_headings":"","what":"Density: gamma distribution constrained to have mean > sd â€” dcgamma","title":"Density: gamma distribution constrained to have mean > sd â€” dcgamma","text":"following conversion describes parameters mean kappa","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dcgamma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Density: gamma distribution constrained to have mean > sd â€” dcgamma","text":"","code":"dcgamma(x, mean, kappa = 1/mean, log = FALSE)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dcgamma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Density: gamma distribution constrained to have mean > sd â€” dcgamma","text":"x vector quantiles mean mean value true scale (vectorised) kappa coefficient variation. 0 variability 1 maximally variability (vectorised) log logical; TRUE, probabilities p given log(p).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dcgamma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Density: gamma distribution constrained to have mean > sd â€” dcgamma","text":"dgamma gives density,   pgamma gives distribution function,   qgamma gives quantile function,   rgamma generates random deviates. Invalid arguments result return value NaN, warning. length result determined n   rgamma, maximum lengths   numerical arguments functions. numerical arguments n recycled   length result.  first elements logical   arguments used.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dcgamma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Density: gamma distribution constrained to have mean > sd â€” dcgamma","text":"$$ \\text{shape: } \\alpha = \\frac{1}{\\kappa} \\\\ \\text{rate: } \\beta = \\frac{1}{\\mu \\times \\kappa} \\\\ \\text{scale: } \\sigma = \\mu \\times \\kappa \\\\ $$","code":""},{"path":[]},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dcgamma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Density: gamma distribution constrained to have mean > sd â€” dcgamma","text":"","code":"dcgamma(seq(0,4,0.25), 2, 0.5) #>  [1] 0.00000000 0.19470020 0.30326533 0.35427491 0.36787944 0.35813100 #>  [7] 0.33469524 0.30410440 0.27067057 0.23714826 0.20521250 0.17580162 #> [13] 0.14936121 0.12601618 0.10569084 0.08819155 0.07326256"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dgamma2.html","id":null,"dir":"Reference","previous_headings":"","what":"The Gamma Distribution â€” dgamma2","title":"The Gamma Distribution â€” dgamma2","text":"Density, distribution function, quantile function random   generation Gamma distribution parameters shape   scale.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dgamma2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The Gamma Distribution â€” dgamma2","text":"","code":"dgamma2(x, mean, sd = sqrt(mean), log = FALSE)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dgamma2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The Gamma Distribution â€” dgamma2","text":"x vector quantiles mean mean value true scale (vectorised) sd standard deviation true scale (vectorised) log logical; TRUE, probabilities p given log(p).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dgamma2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The Gamma Distribution â€” dgamma2","text":"dgamma gives density,   pgamma gives distribution function,   qgamma gives quantile function,   rgamma generates random deviates. Invalid arguments result return value NaN, warning. length result determined n   rgamma, maximum lengths   numerical arguments functions. numerical arguments n recycled   length result.  first elements logical   arguments used.","code":""},{"path":[]},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dgamma2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The Gamma Distribution â€” dgamma2","text":"","code":"dgamma2(seq(0,4,0.25), 2, 1) #>  [1] 0.00000000 0.02527211 0.12262648 0.25102143 0.36089409 0.42752603 #>  [7] 0.44808362 0.43157094 0.39073363 0.33743577 0.28074779 0.22664553 #> [13] 0.17847016 0.13762733 0.10425850 0.07777749 0.05725229"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dlnorm2.html","id":null,"dir":"Reference","previous_headings":"","what":"The Log Normal Distribution â€” dlnorm2","title":"The Log Normal Distribution â€” dlnorm2","text":"Density, distribution function, quantile function random   generation log normal distribution whose logarithm mean   equal meanlog standard deviation equal sdlog.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dlnorm2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The Log Normal Distribution â€” dlnorm2","text":"","code":"dlnorm2(x, mean = 1, sd = sqrt(exp(1) - 1), log = FALSE)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dlnorm2.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"The Log Normal Distribution â€” dlnorm2","text":"dlnorm calculated definition (â€˜Detailsâ€™).   [pqr]lnorm based relationship normal. Consequently, model single point mass exp(meanlog)   boundary case sdlog = 0.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dlnorm2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The Log Normal Distribution â€” dlnorm2","text":"x vector quantiles mean mean value true scale (vectorised) sd standard deviation true scale (vectorised) log logical; TRUE, probabilities p given log(p).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dlnorm2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The Log Normal Distribution â€” dlnorm2","text":"dlnorm gives density,   plnorm gives distribution function,   qlnorm gives quantile function,   rlnorm generates random deviates. length result determined n   rlnorm, maximum lengths   numerical arguments functions. numerical arguments n recycled   length result.  first elements logical   arguments used.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dlnorm2.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The Log Normal Distribution â€” dlnorm2","text":"log normal distribution density   $$     f(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma x} e^{-(\\log(x) - \\mu)^2/2 \\sigma^2}%   $$   \\(\\mu\\) \\(\\sigma\\) mean standard   deviation logarithm.   mean \\(E(X) = exp(\\mu + 1/2 \\sigma^2)\\),   median \\(med(X) = exp(\\mu)\\), variance   \\(Var(X) = exp(2\\mu + \\sigma^2)(exp(\\sigma^2) - 1)\\)   hence coefficient variation   \\(\\sqrt{exp(\\sigma^2) - 1}\\)   approximately \\(\\sigma\\) small (e.g., \\(\\sigma < 1/2\\)).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dlnorm2.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"The Log Normal Distribution â€” dlnorm2","text":"cumulative hazard \\(H(t) = - \\log(1 - F(t))\\)   -plnorm(t, r, lower = FALSE, log = TRUE).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dlnorm2.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"The Log Normal Distribution â€” dlnorm2","text":"Becker, R. ., Chambers, J. M. Wilks, . R. (1988)   New S Language.   Wadsworth & Brooks/Cole. Johnson, N. L., Kotz, S. Balakrishnan, N. (1995)   Continuous Univariate Distributions, volume 1, chapter 14.   Wiley, New York.","code":""},{"path":[]},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dlnorm2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The Log Normal Distribution â€” dlnorm2","text":"","code":"dlnorm2(seq(0,4,0.25), 2, 1) #>  [1] 0.0000000000 0.0005757428 0.0442991085 0.2071346586 0.3958009702 #>  [6] 0.5066252419 0.5252248069 0.4820705272 0.4106521947 0.3336148024 #> [11] 0.2628174046 0.2029235657 0.1546511354 0.1168989116 0.0879351969 #> [16] 0.0659844844 0.0494751213"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dlogitnorm.html","id":null,"dir":"Reference","previous_headings":"","what":"Logit-normal distribution â€” dlogitnorm","title":"Logit-normal distribution â€” dlogitnorm","text":"logit-normal distribution support 0 1.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dlogitnorm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logit-normal distribution â€” dlogitnorm","text":"","code":"dlogitnorm(x, meanlogit = 0, sdlogit = 1, log = FALSE)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dlogitnorm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logit-normal distribution â€” dlogitnorm","text":"x vector quantiles (0<x<1) meanlogit mean logit scale sdlogit sd logit scale log logical; TRUE, probabilities p given log(p).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dlogitnorm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Logit-normal distribution â€” dlogitnorm","text":"vector probabilities, quantiles, densities samples.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dlogitnorm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Logit-normal distribution â€” dlogitnorm","text":"","code":"dlogitnorm(seq(0.1,0.9,0.1), 0, 1) #> [1] 0.3965747 0.9538364 1.3267766 1.5310853 1.5957691 1.5310853 1.3267766 #> [8] 0.9538364 0.3965747"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dlogitnorm2.html","id":null,"dir":"Reference","previous_headings":"","what":"Logit-normal distribution â€” dlogitnorm2","title":"Logit-normal distribution â€” dlogitnorm2","text":"logit-normal distribution support 0 1.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dlogitnorm2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logit-normal distribution â€” dlogitnorm2","text":"","code":"dlogitnorm2(x, prob.0.5 = 0.5, kappa = 1 - exp(-1), log = FALSE)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dlogitnorm2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logit-normal distribution â€” dlogitnorm2","text":"x vector quantiles (0<x<1) prob.0.5 median true scale kappa dispersion parameter 0 (none) 1 maximum dispersion log logical; TRUE, probabilities p given log(p).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dlogitnorm2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Logit-normal distribution â€” dlogitnorm2","text":"vector probabilities, quantiles, densities samples.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dlogitnorm2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Logit-normal distribution â€” dlogitnorm2","text":"","code":"q = seq(0.1,0.9,0.1) eps = sqrt(.Machine$double.eps) dlogitnorm2(q, 0.75, 0.2) #> [1] 8.444866e-47 1.318563e-26 2.611608e-16 1.014980e-09 3.898403e-05 #> [6] 5.982202e-02 4.515133e+00 4.867271e+00 1.082890e-04  (plogitnorm2(q+eps, 0.75, 0.2) -   plogitnorm2(q-eps, 0.75, 0.2)) / (2*eps) #> [1] 8.444866e-47 1.318563e-26 2.611608e-16 1.014980e-09 3.898403e-05 #> [6] 5.982202e-02 4.515133e+00 4.867271e+00 1.082905e-04"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dnbinom2.html","id":null,"dir":"Reference","previous_headings":"","what":"The Negative Binomial Distribution â€” dnbinom2","title":"The Negative Binomial Distribution â€” dnbinom2","text":"Density, distribution function, quantile function random   generation negative binomial distribution parameters   size prob.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dnbinom2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The Negative Binomial Distribution â€” dnbinom2","text":"","code":"dnbinom2(x, mean, sd = sqrt(mean), log = FALSE)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dnbinom2.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"The Negative Binomial Distribution â€” dnbinom2","text":"dnbinom computes via binomial probabilities, using code   contributed Catherine Loader (see dbinom). pnbinom uses pbeta. qnbinom uses Cornishâ€“Fisher Expansion include skewness   correction normal approximation, followed search. rnbinom uses derivation gamma mixture Poisson   distributions, see Devroye, L. (1986) Non-Uniform Random Variate Generation.   Springer-Verlag, New York. Page 480.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dnbinom2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The Negative Binomial Distribution â€” dnbinom2","text":"x vector (non-negative integer) quantiles. mean mean value true scale (vectorised) sd standard deviation true scale (vectorised) log logical; TRUE, probabilities p given log(p).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dnbinom2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The Negative Binomial Distribution â€” dnbinom2","text":"dnbinom gives density,   pnbinom gives distribution function,   qnbinom gives quantile function,   rnbinom generates random deviates. Invalid size prob result return value   NaN, warning. length result determined n   rnbinom, maximum lengths   numerical arguments functions. numerical arguments n recycled   length result.  first elements logical   arguments used. rnbinom returns vector type integer unless generated   values exceed maximum representable integer double   values returned.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dnbinom2.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The Negative Binomial Distribution â€” dnbinom2","text":"negative binomial distribution size \\(= n\\)   prob \\(= p\\) density   $$     p(x) = \\frac{\\Gamma(x+n)}{\\Gamma(n) x!} p^n (1-p)^x$$   \\(x = 0, 1, 2, \\ldots\\), \\(n > 0\\) \\(0 < p \\le 1\\). represents number failures occur sequence   Bernoulli trials target number successes reached.   mean \\(\\mu = n(1-p)/p\\) variance \\(n(1-p)/p^2\\). negative binomial distribution can also arise mixture   Poisson distributions mean distributed gamma distribution   (see pgamma) scale parameter (1 - prob)/prob   shape parameter size.  (definition allows non-integer   values size.) alternative parametrization (often used ecology)   mean mu (see ), size, dispersion   parameter, prob = size/(size+mu).  variance   mu + mu^2/size parametrization. element x integer, result dnbinom   zero, warning. case size == 0 distribution concentrated zero.   limiting distribution size approaching zero,   even mu rather prob held constant.  Notice   though, mean limit distribution 0, whatever   value mu. quantile defined smallest value \\(x\\)   \\(F(x) \\ge p\\), \\(F\\) distribution function.","code":""},{"path":[]},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dnbinom2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The Negative Binomial Distribution â€” dnbinom2","text":"","code":"dnbinom2(0:5, 2, sqrt(2)) #> [1] 0.13533528 0.27067057 0.27067057 0.18044704 0.09022352 0.03608941"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dnull.html","id":null,"dir":"Reference","previous_headings":"","what":"Null distributions always returns NA â€” dnull","title":"Null distributions always returns NA â€” dnull","text":"Null distributions always returns NA","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dnull.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Null distributions always returns NA â€” dnull","text":"","code":"dnull(x, ...)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dnull.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Null distributions always returns NA â€” dnull","text":"x vector quantiles ... used","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dnull.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Null distributions always returns NA â€” dnull","text":"","code":"dnull(c(0.25,0.5,0.75), 0.5, 0.25) #> [1] NA NA NA"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-day_interval.html","id":null,"dir":"Reference","previous_headings":"","what":"Guess the intervals between a sequence of dates: â€” .day_interval","title":"Guess the intervals between a sequence of dates: â€” .day_interval","text":"Guess intervals sequence dates:","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-day_interval.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Guess the intervals between a sequence of dates: â€” .day_interval","text":"","code":".day_interval(dates)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-day_interval.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Guess the intervals between a sequence of dates: â€” .day_interval","text":"dates set dates","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-day_interval.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Guess the intervals between a sequence of dates: â€” .day_interval","text":"natural number days ordering","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-day_interval.html","id":"unit-tests","dir":"Reference","previous_headings":"","what":"Unit tests","title":"Guess the intervals between a sequence of dates: â€” .day_interval","text":"","code":"r = c(1,rpois(10, 3)+1) interval = 2 dates = as.Date(\"2025-01-01\")+r*interval testthat::expect_equal(.day_interval(dates) == interval, TRUE)  interval = 0.5 dates = as.Date(\"2025-01-01\")+r*interval testthat::expect_equal(.day_interval(dates) == interval, TRUE)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-fit_lm_1d.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit a weighted 1D linear model and predict output â€” .fit_lm_1d","title":"Fit a weighted 1D linear model and predict output â€” .fit_lm_1d","text":"weights NA ignored.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-fit_lm_1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit a weighted 1D linear model and predict output â€” .fit_lm_1d","text":"","code":".fit_lm_1d(y, x)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-fit_lm_1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit a weighted 1D linear model and predict output â€” .fit_lm_1d","text":"y y values. least 2. x x values. least 2.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-fit_lm_1d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit a weighted 1D linear model and predict output â€” .fit_lm_1d","text":"vector intercept (c) gradient (m)","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-fit_lm_1d.html","id":"unit-tests","dir":"Reference","previous_headings":"","what":"Unit tests","title":"Fit a weighted 1D linear model and predict output â€” .fit_lm_1d","text":"","code":"testthat::expect_equal(.fit_lm_1d(y = 1:10 * 2 + 5, x = 1:10), c(c = 5, m = 2))"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-infer_grouping.html","id":null,"dir":"Reference","previous_headings":"","what":"Add grouping to ensure a column is groupwise unique â€” .infer_grouping","title":"Add grouping to ensure a column is groupwise unique â€” .infer_grouping","text":"Add grouping ensure column groupwise unique","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-infer_grouping.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add grouping to ensure a column is groupwise unique â€” .infer_grouping","text":"","code":".infer_grouping(df, unique_col)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-infer_grouping.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add grouping to ensure a column is groupwise unique â€” .infer_grouping","text":"df dataframe, maybe grouped unique_col column reference groupwise unique","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-infer_grouping.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add grouping to ensure a column is groupwise unique â€” .infer_grouping","text":"regrouped dataframe unique_col indeed unique","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-infer_grouping.html","id":"unit-tests","dir":"Reference","previous_headings":"","what":"Unit tests","title":"Add grouping to ensure a column is groupwise unique â€” .infer_grouping","text":"","code":"df = dplyr::tibble(   original_grp = as.vector(sapply(LETTERS[1:4],rep,20)),   to_find = as.vector(sapply(letters[1:10],rep,8)),   to_make_unique = rep(1:10,8),   distractor = runif(80) )  unique_col = as.symbol(\"to_make_unique\") tmp = .infer_grouping(df, to_make_unique) testthat::expect_equal(   format(groups(tmp)),   c(\"original_grp\", \"to_find\") )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-pmixbeta.html","id":null,"dir":"Reference","previous_headings":"","what":"The cumulative density function of a mixture of beta distributions â€” .pmixbeta","title":"The cumulative density function of a mixture of beta distributions â€” .pmixbeta","text":"cumulative density function mixture beta distributions","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-pmixbeta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The cumulative density function of a mixture of beta distributions â€” .pmixbeta","text":"","code":".pmixbeta(q, alphas, betas, weights = 1, na.rm = FALSE)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-pmixbeta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The cumulative density function of a mixture of beta distributions â€” .pmixbeta","text":"q vector quantiles. alphas vector beta distribution alphas betas vector gamma distribution betas weights vector weights na.rm remove distributions NA shape rate","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-pmixbeta.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The cumulative density function of a mixture of beta distributions â€” .pmixbeta","text":"pdf mixture distribution.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-pmixbeta.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The cumulative density function of a mixture of beta distributions â€” .pmixbeta","text":"","code":"try({   .pmixbeta(q=c(2,20), alphas=c(10,13,14), betas=c(1,1,1), weights=c(2,2,3)) }) #> Error in .pmixbeta(q = c(2, 20), alphas = c(10, 13, 14), betas = c(1,  :  #>   could not find function \".pmixbeta\""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-pmixgamma.html","id":null,"dir":"Reference","previous_headings":"","what":"The cumulative density function of a mixture of gamma distributions â€” .pmixgamma","title":"The cumulative density function of a mixture of gamma distributions â€” .pmixgamma","text":"cumulative density function mixture gamma distributions","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-pmixgamma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The cumulative density function of a mixture of gamma distributions â€” .pmixgamma","text":"","code":".pmixgamma(q, shapes, rates, weights = 1, na.rm = FALSE)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-pmixgamma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The cumulative density function of a mixture of gamma distributions â€” .pmixgamma","text":"q vector quantiles. shapes vector gamma distribution shapes rates vector gamma distribution rates weights vector weights na.rm remove distributions NA shape rate","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-pmixgamma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The cumulative density function of a mixture of gamma distributions â€” .pmixgamma","text":"pdf mixture distribution.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-pmixgamma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The cumulative density function of a mixture of gamma distributions â€” .pmixgamma","text":"","code":"try({   .pmixgamma(q=c(2,20), shapes=c(10,13,14), rates=c(1,1,1), weights=c(2,2,3))   }) #> Error in .pmixgamma(q = c(2, 20), shapes = c(10, 13, 14), rates = c(1,  :  #>   could not find function \".pmixgamma\""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-pmixlnorm.html","id":null,"dir":"Reference","previous_headings":"","what":"The cumulative density function of a mixture of log normal distributions â€” .pmixlnorm","title":"The cumulative density function of a mixture of log normal distributions â€” .pmixlnorm","text":"cumulative density function mixture log normal distributions","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-pmixlnorm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The cumulative density function of a mixture of log normal distributions â€” .pmixlnorm","text":"","code":".pmixlnorm(q, meanlogs, sdlogs, weights = 1, na.rm = FALSE)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-pmixlnorm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The cumulative density function of a mixture of log normal distributions â€” .pmixlnorm","text":"q vector quantiles. meanlogs vector normal distribution means sdlogs vector normal distribution sds weights vector weights na.rm remove distributions NA mean sd","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-pmixlnorm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The cumulative density function of a mixture of log normal distributions â€” .pmixlnorm","text":"pdf mixture distribution.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-pmixlnorm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The cumulative density function of a mixture of log normal distributions â€” .pmixlnorm","text":"","code":"try({ .pmixlnorm(q=c(2,20), meanlogs=c(1.0,1.3,1.4), sdlogs=c(1,1,2), weights=c(2,2,3)) }) #> Error in .pmixlnorm(q = c(2, 20), meanlogs = c(1, 1.3, 1.4), sdlogs = c(1,  :  #>   could not find function \".pmixlnorm\""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-pmixnorm.html","id":null,"dir":"Reference","previous_headings":"","what":"The cumulative density function of a mixture of normal distributions â€” .pmixnorm","title":"The cumulative density function of a mixture of normal distributions â€” .pmixnorm","text":"cumulative density function mixture normal distributions","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-pmixnorm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The cumulative density function of a mixture of normal distributions â€” .pmixnorm","text":"","code":".pmixnorm(q, means, sds, weights = 1, na.rm = FALSE)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-pmixnorm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The cumulative density function of a mixture of normal distributions â€” .pmixnorm","text":"q vector quantiles. means vector normal distribution means sds vector normal distribution sds weights vector weights na.rm remove distributions NA mean sd","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-pmixnorm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The cumulative density function of a mixture of normal distributions â€” .pmixnorm","text":"pdf mixture distribution.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-pmixnorm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The cumulative density function of a mixture of normal distributions â€” .pmixnorm","text":"","code":"try({ .pmixnorm(q=c(2,20), means=c(10,13,14), sds=c(1,1,2), weights=c(2,2,3)) }) #> Error in .pmixnorm(q = c(2, 20), means = c(10, 13, 14), sds = c(1, 1,  :  #>   could not find function \".pmixnorm\""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-qmixbeta.html","id":null,"dir":"Reference","previous_headings":"","what":"A quantile function for a mixture of gamma distributions â€” .qmixbeta","title":"A quantile function for a mixture of gamma distributions â€” .qmixbeta","text":"quantile function mixture gamma distributions","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-qmixbeta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A quantile function for a mixture of gamma distributions â€” .qmixbeta","text":"","code":".qmixbeta(   p,   alphas,   betas,   weights = 1,   na.rm = FALSE,   method = c(\"exact\", \"samples\", \"moments\"),   ... )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-qmixbeta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A quantile function for a mixture of gamma distributions â€” .qmixbeta","text":"p vector probabilities. alphas vector gamma distribution shapes betas vector gamma distribution rates weights vector weights na.rm remove distributions NA values mean sd method one exact (solve uniroot), samples (random resampling), moments (Cornish Fisher approximation) ... passed internal function, seed=XXX fix random seed","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-qmixbeta.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A quantile function for a mixture of gamma distributions â€” .qmixbeta","text":"value pth quantile","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-qmixbeta.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A quantile function for a mixture of gamma distributions â€” .qmixbeta","text":"","code":"try({   .qmixbeta(p=c(0.025,0.5,0.975), alphas=c(10,13,14), betas=c(1,1,2))   .qmixbeta(p=c(0.025,0.5,0.975), alphas=c(10,13,14), betas=c(1,1,2), method=\"moments\") }) #> Error in .qmixbeta(p = c(0.025, 0.5, 0.975), alphas = c(10, 13, 14), betas = c(1,  :  #>   could not find function \".qmixbeta\""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-qmixgamma.html","id":null,"dir":"Reference","previous_headings":"","what":"A quantile function for a mixture of gamma distributions â€” .qmixgamma","title":"A quantile function for a mixture of gamma distributions â€” .qmixgamma","text":"quantile function mixture gamma distributions","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-qmixgamma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A quantile function for a mixture of gamma distributions â€” .qmixgamma","text":"","code":".qmixgamma(   p,   shapes,   rates,   weights = 1,   na.rm = FALSE,   method = c(\"exact\", \"samples\", \"moments\"),   ... )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-qmixgamma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A quantile function for a mixture of gamma distributions â€” .qmixgamma","text":"p vector probabilities. shapes vector gamma distribution shapes rates vector gamma distribution rates weights vector weights na.rm remove distributions NA values mean sd method one exact (solve uniroot), samples (random resampling), moments (Cornish Fisher approximation) ... passed internal function, seed=XXX fix random seed","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-qmixgamma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A quantile function for a mixture of gamma distributions â€” .qmixgamma","text":"value pth quantile","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-qmixgamma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A quantile function for a mixture of gamma distributions â€” .qmixgamma","text":"","code":"try({   .qmixgamma(p=c(0.025,0.5,0.975), shapes=c(10,13,14), rates=c(1,1,2), method=\"moments\")   .qmixgamma(p=c(0.025,0.5,0.975), shapes=c(10,13,14), rates=c(1,1,2), method=\"exact\")    means = runif(100,5,6)   sds = runif(100,2,3)   shapes = means^2/sds^2   rates = means/sds^2    if (sd(means) < mean(sds)) message(\"mixture moments should be close\")    qgamma(c(0.025,0.5,0.975), shape =mean(means^2)/mean(sds^2), rate = mean(means)/mean(sds^2))   system.time(   .qmixgamma(p=c(0.025,0.5,0.975), shapes=shapes, rates=rates, method=\"moments\")   )   system.time(   .qmixgamma(p=c(0.025,0.5,0.975), shapes=shapes, rates=rates, method=\"exact\")   )    means = runif(100,2,12)   sds = runif(100,0.5,1)   shapes = means^2/sds^2   rates = means/sds^2    if (sd(means) < mean(sds)) message(\"mixture moments should be close\")    qgamma(c(0.025,0.5,0.975), shape =mean(means^2)/mean(sds^2), rate = mean(means)/mean(sds^2))   system.time(   .qmixgamma(p=c(0.025,0.5,0.975), shapes=shapes, rates=rates, method=\"moments\")   )   system.time(   .qmixgamma(p=c(0.025,0.5,0.975), shapes=shapes, rates=rates, method=\"exact\")   )   quantile(means, prob=c(0.025,0.5,0.975))  }) #> Error in .qmixgamma(p = c(0.025, 0.5, 0.975), shapes = c(10, 13, 14),  :  #>   could not find function \".qmixgamma\""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-qmixlnorm.html","id":null,"dir":"Reference","previous_headings":"","what":"A quantile function for a mixture of log normal distributions â€” .qmixlnorm","title":"A quantile function for a mixture of log normal distributions â€” .qmixlnorm","text":"quantile function mixture log normal distributions","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-qmixlnorm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A quantile function for a mixture of log normal distributions â€” .qmixlnorm","text":"","code":".qmixlnorm(   p,   meanlogs,   sdlogs,   weights = rep(1, length(meanlogs)),   na.rm = FALSE,   method = c(\"exact\", \"samples\", \"moments\"),   ... )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-qmixlnorm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A quantile function for a mixture of log normal distributions â€” .qmixlnorm","text":"p vector probabilities. meanlogs vector log normal distribution means sdlogs vector log normal distribution sds weights vector weights na.rm remove distributions NA values mean sd method one exact (solve uniroot), samples (random resampling), moments (Cornish Fisher approximation) ... passed internal function, seed=XXX fix random seed","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-qmixlnorm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A quantile function for a mixture of log normal distributions â€” .qmixlnorm","text":"value pth quantile","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-qmixlnorm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A quantile function for a mixture of log normal distributions â€” .qmixlnorm","text":"","code":"try({   .qmixlnorm(p=c(0.025,0.5,0.975), meanlogs=c(1,1.3,1.4), sdlogs=c(0.1,0.1,0.2))   .qmixlnorm(p=c(0.025,0.5,0.975), meanlogs=c(1,1.3,1.4), sdlogs=c(0.1,0.1,0.2), method=\"samples\")   .qmixlnorm(p=c(0.025,0.5,0.975), meanlogs=c(1,1.3,1.4), sdlogs=c(0.1,0.1,0.2), method=\"moments\") }) #> Error in .qmixlnorm(p = c(0.025, 0.5, 0.975), meanlogs = c(1, 1.3, 1.4),  :  #>   could not find function \".qmixlnorm\""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-qmixnorm.html","id":null,"dir":"Reference","previous_headings":"","what":"A quantile function for a mixture of normal distributions â€” .qmixnorm","title":"A quantile function for a mixture of normal distributions â€” .qmixnorm","text":"quantile function mixture normal distributions","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-qmixnorm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A quantile function for a mixture of normal distributions â€” .qmixnorm","text":"","code":".qmixnorm(   p,   means,   sds,   weights = 1,   na.rm = FALSE,   method = c(\"exact\", \"samples\", \"moments\"),   ... )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-qmixnorm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A quantile function for a mixture of normal distributions â€” .qmixnorm","text":"p vector probabilities. means vector normal distribution means sds vector normal distribution sds weights vector weights na.rm remove distributions NA values mean sd method one exact (solve uniroot), samples (random resampling), moments (Cornish Fisher approximation) ... passed internal function, samples=TRUE force random sampling","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-qmixnorm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A quantile function for a mixture of normal distributions â€” .qmixnorm","text":"value pth quantile","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-qmixnorm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A quantile function for a mixture of normal distributions â€” .qmixnorm","text":"","code":"try({ .qmixnorm(p=c(0.025,0.5,0.975), means=c(10,13,14), sds=c(1,1,2), method=\"exact\") .qmixnorm(p=c(0.025,0.5,0.975), means=c(10,13,14), sds=c(1,1,2), method=\"moments\") }) #> Error in .qmixnorm(p = c(0.025, 0.5, 0.975), means = c(10, 13, 14), sds = c(1,  :  #>   could not find function \".qmixnorm\""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-singleton.html","id":null,"dir":"Reference","previous_headings":"","what":"A once only evaluation function generator â€” .singleton","title":"A once only evaluation function generator â€” .singleton","text":"function can used package create package local variable calculated first use stored rest session. expression throws uncaught error value stored. expression evaluated environment first called .","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-singleton.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A once only evaluation function generator â€” .singleton","text":"","code":".singleton(   expr,   on_error = function(e) {      stop(\"Initialising value failed:\", e, call. = FALSE)  } )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-singleton.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A once only evaluation function generator â€” .singleton","text":"expr expression value cached. on_error function takes single value (error) handles rethrows .","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-singleton.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A once only evaluation function generator â€” .singleton","text":"result expr.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-singleton.html","id":"unit-tests","dir":"Reference","previous_headings":"","what":"Unit tests","title":"A once only evaluation function generator â€” .singleton","text":"","code":"fixed_rnorm = .singleton(rnorm(10)) a = fixed_rnorm() b = fixed_rnorm() testthat::expect_equal(a,b)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-ts_evaluate.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate a function in a timeseries dataframe â€” .ts_evaluate","title":"Evaluate a function in a timeseries dataframe â€” .ts_evaluate","text":"N.B. exported used one vignette demo purposes","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-ts_evaluate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate a function in a timeseries dataframe â€” .ts_evaluate","text":"","code":".ts_evaluate(fn, df)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-ts_evaluate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate a function in a timeseries dataframe â€” .ts_evaluate","text":"fn function. df dataframe numeric time column, plus columns","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-ts_evaluate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate a function in a timeseries dataframe â€” .ts_evaluate","text":"vector, result applying function df.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dot-ts_evaluate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluate a function in a timeseries dataframe â€” .ts_evaluate","text":"","code":"test = dplyr::tibble(   time = 1:10,   class = rep(c(\"one\",\"two\"),5) ) .ts_evaluate(function(t,class) {print(t); print(class); 1}, test ) #>  [1]  1  2  3  4  5  6  7  8  9 10 #>  [1] \"one\" \"two\" \"one\" \"two\" \"one\" \"two\" \"one\" \"two\" \"one\" \"two\" #>  [1] 1 1 1 1 1 1 1 1 1 1"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/doubling_time.html","id":null,"dir":"Reference","previous_headings":"","what":"Doubling time from growth rate â€” doubling_time","title":"Doubling time from growth rate â€” doubling_time","text":"unit doubling times always days.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/doubling_time.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Doubling time from growth rate â€” doubling_time","text":"","code":"doubling_time(x, ...)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/doubling_time.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Doubling time from growth rate â€” doubling_time","text":"x proportion incidence growth rates - EITHER: dataframe columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` incidence.fit (double) - estimate incidence rate log scale incidence.se.fit (positive_double) - standard error incidence rate estimate log scale incidence.0.025 (positive_double) - lower confidence limit incidence rate (true scale) incidence.0.5 (positive_double) - median estimate incidence rate (true scale) incidence.0.975 (positive_double) - upper confidence limit incidence rate (true scale) growth.fit (double) - estimate growth rate growth.se.fit (positive_double) - standard error growth rate growth.0.025 (double) - lower confidence limit growth rate growth.0.5 (double) - median estimate growth rate growth.0.975 (double) - upper confidence limit growth rate grouping allowed. columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` proportion.fit (double) - estimate proportion logit scale proportion.se.fit (positive_double) - standard error proportion estimate logit scale proportion.0.025 (proportion) - lower confidence limit proportion (true scale) proportion.0.5 (proportion) - median estimate proportion (true scale) proportion.0.975 (proportion) - upper confidence limit proportion (true scale) relative.growth.fit (double) - estimate relative growth rate relative.growth.se.fit (positive_double) - standard error relative growth rate relative.growth.0.025 (double) - lower confidence limit relative growth rate relative.growth.0.5 (double) - median estimate relative growth rate relative.growth.0.975 (double) - upper confidence limit relative growth rate grouping allowed. ... used","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/doubling_time.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Doubling time from growth rate â€” doubling_time","text":"dataframe additional columns doubling time relative doubling time plus confidence intervals.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/doubling_time.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Doubling time from growth rate â€” doubling_time","text":"","code":"example_poisson_rt_smooth() %>%   poisson_locfit_model(window=21) %>%   doubling_time() %>%   dplyr::glimpse() #> Rows: 161 #> Columns: 23 #> Groups: statistic [1] #> $ statistic           <chr> \"infections\", \"infections\", \"infections\", \"infectiâ€¦ #> $ time                <t[day]> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 1â€¦ #> $ incidence.fit       <dbl> 2.5234144, 2.3339883, 2.1567327, 1.9915858, 1.8384â€¦ #> $ incidence.se.fit    <dbl> 0.3218402, 0.2840632, 0.2540868, 0.2311115, 0.2143â€¦ #> $ incidence.0.025     <dbl> 6.636728, 5.913481, 5.252644, 4.658137, 4.130242, â€¦ #> $ incidence.0.05      <dbl> 7.345106, 6.467218, 5.690494, 5.010026, 4.418875, â€¦ #> $ incidence.0.25      <dbl> 10.037584, 8.519781, 7.281623, 6.269543, 5.440648,â€¦ #> $ incidence.0.5       <dbl> 12.471105, 10.319015, 8.642853, 7.327144, 6.287011â€¦ #> $ incidence.0.75      <dbl> 15.494611, 12.498217, 10.258552, 8.563150, 7.26503â€¦ #> $ incidence.0.95      <dbl> 21.174432, 16.464896, 13.126963, 10.715919, 8.9449â€¦ #> $ incidence.0.975     <dbl> 23.434507, 18.006663, 14.221199, 11.525431, 9.5700â€¦ #> $ growth.fit          <dbl> -0.195531855, -0.183763734, -0.171804108, -0.15971â€¦ #> $ growth.se.fit       <dbl> 0.051884572, 0.048622636, 0.045353832, 0.042104737â€¦ #> $ growth.0.025        <dbl> -0.297223748, -0.279062350, -0.260695985, -0.24223â€¦ #> $ growth.0.05         <dbl> -0.280874382, -0.263740853, -0.246404523, -0.22896â€¦ #> $ growth.0.25         <dbl> -0.230527467, -0.216559203, -0.202394803, -0.18811â€¦ #> $ growth.0.5          <dbl> -0.195531855, -0.183763734, -0.171804108, -0.15971â€¦ #> $ growth.0.75         <dbl> -0.1605362428, -0.1509682637, -0.1412134134, -0.13â€¦ #> $ growth.0.95         <dbl> -0.110189328, -0.103786614, -0.097203693, -0.09045â€¦ #> $ growth.0.975        <dbl> -0.093839962, -0.088465117, -0.082912231, -0.07718â€¦ #> $ doubling_time.0.5   <dbl> -3.544932, -3.771948, -4.034520, -4.339986, -4.697â€¦ #> $ doubling_time.0.025 <dbl> -7.386482, -7.835260, -8.360011, -8.979977, -9.721â€¦ #> $ doubling_time.0.975 <dbl> -2.332072, -2.483843, -2.658833, -2.861459, -3.097â€¦"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/du_serial_interval_ip.html","id":null,"dir":"Reference","previous_headings":"","what":"The Du empirical serial interval dataset â€” du_serial_interval_ip","title":"The Du empirical serial interval dataset â€” du_serial_interval_ip","text":"Z. Du, X. Xu, Y. Wu, L. Wang, B. J. Cowling, L. . Meyers, â€˜Serial Interval COVID-19 among Publicly Reported Confirmed Casesâ€™, Emerg Infect Dis, vol. 26, . 6, pp. 1341â€“1343, Jun. 2020, doi: 10.3201/eid2606.200357.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/du_serial_interval_ip.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The Du empirical serial interval dataset â€” du_serial_interval_ip","text":"","code":"data(du_serial_interval_ip)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/du_serial_interval_ip.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"The Du empirical serial interval dataset â€” du_serial_interval_ip","text":"dataframe containing following columns: boot (anything + default(1)) - bootstrap identifier probability (proportion) - probability infection previous time period time tau (numeric) - time index probability relates (days) a0 (numeric) - beginning time period a1 (numeric) - end time period Grouped : boot. 2603 rows 5 columns","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dwedge.html","id":null,"dir":"Reference","previous_headings":"","what":"Wedge distribution â€” dwedge","title":"Wedge distribution â€” dwedge","text":"wedge distribution support 0 1 linear probability density function support.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dwedge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wedge distribution â€” dwedge","text":"","code":"dwedge(x, a, lower.tail = TRUE, log = FALSE)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dwedge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wedge distribution â€” dwedge","text":"x vector quantiles gradient -2 (left skewed) 2 (right skewed) lower.tail logical; TRUE (default), probabilities P[X<=x] otherwise P[X>x]. log logical; TRUE, probabilities p given log(p).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dwedge.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Wedge distribution â€” dwedge","text":"vector probabilities, quantiles, densities samples.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dwedge.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Wedge distribution â€” dwedge","text":"rwedge can combined quantile functions skew standard distributions, introduce correlation weight certain parts distribution.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/dwedge.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Wedge distribution â€” dwedge","text":"","code":"pwedge(seq(0,1,0.1), a=1) #>  [1] 0.5 0.6 0.7 0.8 0.9 1.0 1.1 1.2 1.3 1.4 1.5 dwedge(seq(0,1,0.1), a=1) #>  [1] 0.000 0.055 0.120 0.195 0.280 0.375 0.480 0.595 0.720 0.855 1.000 qwedge(c(0.25,0.5,0.75), a=-1) #> [1] 0.1771243 0.3819660 0.6339746  stats::cor(   stats::qnorm(rwedge(1000, a=2)),   stats::qnorm(rwedge(1000, a=-2)) ) #> [1] -0.007274514"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_consensus_growth_rate.html","id":null,"dir":"Reference","previous_headings":"","what":"The SPI-M-O England consensus growth rate â€” england_consensus_growth_rate","title":"The SPI-M-O England consensus growth rate â€” england_consensus_growth_rate","text":"SPI-M-O used range different statistical mechanistic models produce estimates growth rate epidemic various data sources (including early version ggoutbreak).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_consensus_growth_rate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The SPI-M-O England consensus growth rate â€” england_consensus_growth_rate","text":"","code":"data(england_consensus_growth_rate)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_consensus_growth_rate.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"The SPI-M-O England consensus growth rate â€” england_consensus_growth_rate","text":"dataframe containing following columns: date (date) - date estimate low (numeric) - lower published estimate growth rate high (numeric) - higher published estimate growth rate mandatory groupings. default value. 111 rows 3 columns","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_consensus_rt.html","id":null,"dir":"Reference","previous_headings":"","what":"The SPI-M-O England consensus reproduction number â€” england_consensus_rt","title":"The SPI-M-O England consensus reproduction number â€” england_consensus_rt","text":"SPI-M-O used range different statistical mechanistic models produce estimates  reproduction number epidemic various data sources.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_consensus_rt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The SPI-M-O England consensus reproduction number â€” england_consensus_rt","text":"","code":"data(england_consensus_rt)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_consensus_rt.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"The SPI-M-O England consensus reproduction number â€” england_consensus_rt","text":"dataframe containing following columns: date (date) - date estimate low (numeric) - lower published estimate reproduction number high (numeric) - higher published estimate reproduction number mandatory groupings. default value. 113 rows 3 columns","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_covid.html","id":null,"dir":"Reference","previous_headings":"","what":"Daily COVID-19 case counts by age group in England â€” england_covid","title":"Daily COVID-19 case counts by age group in England â€” england_covid","text":"dataset daily count COVID-19 cases age group England downloaded UKHSA coronavirus API, formatted use ggoutbreak. denominator calculated overall positive count age groups. data set can used calculate group-wise incidence absolute growth rates group wise proportions relative growth rates age group.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_covid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Daily COVID-19 case counts by age group in England â€” england_covid","text":"","code":"data(england_covid)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_covid.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Daily COVID-19 case counts by age group in England â€” england_covid","text":"dataframe containing following columns: date (.Date) - date column class (enum(00_04,05_09,10_14,15_19,20_24,25_29,30_34,35_39,40_44,45_49,50_54,55_59,60_64,65_69,70_74,75_79,80_84,85_89,90+)) - class column count (numeric) - test positives age group denom (numeric) - test positives across age groups time (time_period) - time column Must grouped : class (groupings allowed). default value. 26790 rows 5 columns","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_covid.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Daily COVID-19 case counts by age group in England â€” england_covid","text":"may want england_covid_test_positives instead includes population denominator. denominator total number positive tests across age groups number tests taken population size.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_covid_pcr_positivity.html","id":null,"dir":"Reference","previous_headings":"","what":"England COVID-19 PCR test positivity â€” england_covid_pcr_positivity","title":"England COVID-19 PCR test positivity â€” england_covid_pcr_positivity","text":"coronavirus.gov.uk dashboard published tests conducted positive results separate data sets range geographies. case data combined testing rate denominator, test positives count whole England.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_covid_pcr_positivity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"England COVID-19 PCR test positivity â€” england_covid_pcr_positivity","text":"","code":"data(england_covid_pcr_positivity)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_covid_pcr_positivity.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"England COVID-19 PCR test positivity â€” england_covid_pcr_positivity","text":"dataframe containing following columns: date (date) - daily time series time (time_period) - time column count (numeric) - test positives England day denom (numeric) - total tests conducted day mandatory groupings. default value. 1413 rows 4 columns","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_covid_poisson.html","id":null,"dir":"Reference","previous_headings":"","what":"The England COVID-19 poisson model dataset â€” england_covid_poisson","title":"The England COVID-19 poisson model dataset â€” england_covid_poisson","text":"output following estimator, speed examples:","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_covid_poisson.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The England COVID-19 poisson model dataset â€” england_covid_poisson","text":"","code":"england_covid_proportion_age_stratified()"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_covid_poisson.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The England COVID-19 poisson model dataset â€” england_covid_poisson","text":"dataframe containing following columns: time (.time_period) - time column incidence.fit (numeric) - incidence.fit column incidence.se.fit (numeric) - incidence.se.fit column incidence.0.025 (numeric) - incidence.0.025 column incidence.0.05 (numeric) - incidence.0.05 column incidence.0.25 (numeric) - incidence.0.25 column incidence.0.5 (numeric) - incidence.0.5 column incidence.0.75 (numeric) - incidence.0.75 column incidence.0.95 (numeric) - incidence.0.95 column incidence.0.975 (numeric) - incidence.0.975 column growth.fit (numeric) - growth.fit column growth.se.fit (numeric) - growth.se.fit column growth.0.025 (numeric) - growth.0.025 column growth.0.05 (numeric) - growth.0.05 column growth.0.25 (numeric) - growth.0.25 column growth.0.5 (numeric) - growth.0.5 column growth.0.75 (numeric) - growth.0.75 column growth.0.95 (numeric) - growth.0.95 column growth.0.975 (numeric) - growth.0.975 column grouping allowed. 1410 rows 19 columns","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_covid_poisson.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The England COVID-19 poisson model dataset â€” england_covid_poisson","text":"","code":"england_covid %>% time_aggregate() %>% ggoutbreak::poisson_locfit_model(window=14)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_covid_poisson_age_stratified.html","id":null,"dir":"Reference","previous_headings":"","what":"The England COVID-19 age stratified poisson model dataset â€” england_covid_poisson_age_stratified","title":"The England COVID-19 age stratified poisson model dataset â€” england_covid_poisson_age_stratified","text":"output following estimator, speed examples:","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_covid_poisson_age_stratified.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The England COVID-19 age stratified poisson model dataset â€” england_covid_poisson_age_stratified","text":"","code":"england_covid_poisson_age_stratified()"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_covid_poisson_age_stratified.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The England COVID-19 age stratified poisson model dataset â€” england_covid_poisson_age_stratified","text":"dataframe containing following columns: class (enum(00_04,05_09,10_14,15_19,20_24,25_29,30_34,35_39,40_44,45_49,50_54,55_59,60_64,65_69,70_74,75_79,80_84,85_89,90+)) - class column time (.time_period) - time column incidence.fit (numeric) - incidence.fit column incidence.se.fit (numeric) - incidence.se.fit column incidence.0.025 (numeric) - incidence.0.025 column incidence.0.05 (numeric) - incidence.0.05 column incidence.0.25 (numeric) - incidence.0.25 column incidence.0.5 (numeric) - incidence.0.5 column incidence.0.75 (numeric) - incidence.0.75 column incidence.0.95 (numeric) - incidence.0.95 column incidence.0.975 (numeric) - incidence.0.975 column growth.fit (numeric) - growth.fit column growth.se.fit (numeric) - growth.se.fit column growth.0.025 (numeric) - growth.0.025 column growth.0.05 (numeric) - growth.0.05 column growth.0.25 (numeric) - growth.0.25 column growth.0.5 (numeric) - growth.0.5 column growth.0.75 (numeric) - growth.0.75 column growth.0.95 (numeric) - growth.0.95 column growth.0.975 (numeric) - growth.0.975 column Minimally grouped : class (groupings allowed). 26790 rows 20 columns","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_covid_poisson_age_stratified.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The England COVID-19 age stratified poisson model dataset â€” england_covid_poisson_age_stratified","text":"","code":"england_covid %>% ggoutbreak::poisson_locfit_model(window=14)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_covid_proportion.html","id":null,"dir":"Reference","previous_headings":"","what":"England COVID by age group for ascertainment â€” england_covid_proportion","title":"England COVID by age group for ascertainment â€” england_covid_proportion","text":"age group stratified dataset ","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_covid_proportion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"England COVID by age group for ascertainment â€” england_covid_proportion","text":"","code":"data(england_covid_proportion)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_covid_proportion.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"England COVID by age group for ascertainment â€” england_covid_proportion","text":"dataframe containing following columns: class (character) - age group date (date) - start date week count (numeric) - count COVID positives denom (numeric) - number COVID tests performed population (numeric) - size population age group time (time_period) - time column (weekly) Must grouped : class (groupings allowed). default value. 1050 rows 6 columns","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_covid_proportion.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"England COVID by age group for ascertainment â€” england_covid_proportion","text":"coronavirus.gov.uk site positive cases aggregated 10 year age groups weekly time. NHS test trace date reported regional age group testing effort aggregated country level. ONS 2021 census population aggregated 10 year age groups.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_covid_proportion_age_stratified.html","id":null,"dir":"Reference","previous_headings":"","what":"The England COVID-19 age stratified proportion model dataset â€” england_covid_proportion_age_stratified","title":"The England COVID-19 age stratified proportion model dataset â€” england_covid_proportion_age_stratified","text":"output following estimator, speed examples. proportion represented positive tests age group, versus positive tests age groups. considered respect overall population.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_covid_proportion_age_stratified.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The England COVID-19 age stratified proportion model dataset â€” england_covid_proportion_age_stratified","text":"","code":"data(england_covid_proportion_age_stratified)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_covid_proportion_age_stratified.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"The England COVID-19 age stratified proportion model dataset â€” england_covid_proportion_age_stratified","text":"dataframe containing following columns: class (enum(00_04,05_09,10_14,15_19,20_24,25_29,30_34,35_39,40_44,45_49,50_54,55_59,60_64,65_69,70_74,75_79,80_84,85_89,90+)) - class column time (.time_period) - time column proportion.fit (numeric) - proportion.fit column proportion.se.fit (numeric) - proportion.se.fit column proportion.0.025 (numeric) - proportion.0.025 column proportion.0.05 (numeric) - proportion.0.05 column proportion.0.25 (numeric) - proportion.0.25 column proportion.0.5 (numeric) - proportion.0.5 column proportion.0.75 (numeric) - proportion.0.75 column proportion.0.95 (numeric) - proportion.0.95 column proportion.0.975 (numeric) - proportion.0.975 column relative.growth.fit (numeric) - relative.growth.fit column relative.growth.se.fit (numeric) - relative.growth.se.fit column relative.growth.0.025 (numeric) - relative.growth.0.025 column relative.growth.0.05 (numeric) - relative.growth.0.05 column relative.growth.0.25 (numeric) - relative.growth.0.25 column relative.growth.0.5 (numeric) - relative.growth.0.5 column relative.growth.0.75 (numeric) - relative.growth.0.75 column relative.growth.0.95 (numeric) - relative.growth.0.95 column relative.growth.0.975 (numeric) - relative.growth.0.975 column Minimally grouped : class (groupings allowed). 26790 rows 20 columns","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_covid_proportion_age_stratified.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The England COVID-19 age stratified proportion model dataset â€” england_covid_proportion_age_stratified","text":"","code":"england_covid %>% ggoutbreak::proportion_locfit_model(window=14)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_covid_test_positives.html","id":null,"dir":"Reference","previous_headings":"","what":"Weekly England COVID test positives by age group including testing effort â€” england_covid_test_positives","title":"Weekly England COVID test positives by age group including testing effort â€” england_covid_test_positives","text":"age group stratified dataset ","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_covid_test_positives.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Weekly England COVID test positives by age group including testing effort â€” england_covid_test_positives","text":"","code":"data(england_covid_test_positives)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_covid_test_positives.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Weekly England COVID test positives by age group including testing effort â€” england_covid_test_positives","text":"dataframe containing following columns: class (character) - age group date (date) - start date week count (numeric) - count COVID positives denom (numeric) - number COVID tests performed age group week population (numeric) - size population age group time (time_period) - time column (weekly) Must grouped : class (groupings allowed). default value. 1050 rows 6 columns","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_covid_test_positives.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Weekly England COVID test positives by age group including testing effort â€” england_covid_test_positives","text":"coronavirus.gov.uk site positive cases aggregated 10 year age groups weekly time. NHS test trace date reported regional age group testing effort aggregated country level. ONS 2021 census population aggregated 10 year age groups.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_demographics.html","id":null,"dir":"Reference","previous_headings":"","what":"England demographics â€” england_demographics","title":"England demographics â€” england_demographics","text":"Population counts 5 year age group England 2021 census.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_demographics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"England demographics â€” england_demographics","text":"","code":"data(england_demographics)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_demographics.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"England demographics â€” england_demographics","text":"dataframe containing following columns: class (enum(00_04,05_09,10_14,15_19,20_24,25_29,30_34,35_39,40_44,45_49,50_54,55_59,60_64,65_69,70_74,75_79,80_84,85_89,90+)) - class column population (numeric) - population count column baseline_proportion (numeric) - baseline proportion proportion age group makes total. Must grouped : class (groupings allowed). default value. 19 rows 3 columns","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_demographics.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"England demographics â€” england_demographics","text":"https://www.ons.gov.uk/file?uri=/peoplepopulationandcommunity/populationandmigration/populationestimates/datasets/populationandhouseholdestimatesenglandandwalescensus2021/census2021/census2021firstresultsenglandwales1.xlsx","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_events.html","id":null,"dir":"Reference","previous_headings":"","what":"Key dated in the COVID-19 response in England â€” ukc19::timeline","title":"Key dated in the COVID-19 response in England â€” ukc19::timeline","text":"includes mainly dates lockdowns, releases social distancing measures dates new variants first detected.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_events.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Key dated in the COVID-19 response in England â€” ukc19::timeline","text":"","code":"data(ukc19::timeline)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_events.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Key dated in the COVID-19 response in England â€” ukc19::timeline","text":"dataframe containing following columns: label (character) - event label start (date) - event start date end (date) - (optional) event end date mandatory groupings. default value. 13 rows 3 columns","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_nhs_app.html","id":null,"dir":"Reference","previous_headings":"","what":"NHS COVID-19 app data â€” england_nhs_app","title":"NHS COVID-19 app data â€” england_nhs_app","text":"check-(social activity) alerts (self isolation instruction) data NHS COVID-19 app, aggregated country level week week basis.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_nhs_app.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"NHS COVID-19 app data â€” england_nhs_app","text":"","code":"data(england_nhs_app)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_nhs_app.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"NHS COVID-19 app data â€” england_nhs_app","text":"dataframe containing following columns: date (date) - start date week alerts (integer) - count self-isolation alerts visits (integer) - number venue check-ins representing visits social venues. time (time_period) - time column mandatory groupings. default value. 137 rows 4 columns","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_ons_infection_survey.html","id":null,"dir":"Reference","previous_headings":"","what":"The england_ons_infection_survey dataset â€” england_ons_infection_survey","title":"The england_ons_infection_survey dataset â€” england_ons_infection_survey","text":"COVID-19 ONS infection survey took random sample population provides estimate prevalence COVID-19 supposedly free ascertainment bias.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_ons_infection_survey.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The england_ons_infection_survey dataset â€” england_ons_infection_survey","text":"","code":"data(england_ons_infection_survey)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_ons_infection_survey.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"The england_ons_infection_survey dataset â€” england_ons_infection_survey","text":"dataframe containing following columns: date (date) - date column geography (character) - geography column prevalence.0.5 (numeric) - median proportion people region testing positive COVID-19 prevalence.0.025 (numeric) - lower CI proportion people region testing positive COVID-19 prevalence.0.975 (numeric) - upper CI proportion people region testing positive COVID-19 denom (integer) - sample size estimate made (daily rate inferred weekly sample sizes.) time (time_period) - time column mandatory groupings. default value. 9820 rows 7 columns","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_ons_infection_survey.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The england_ons_infection_survey dataset â€” england_ons_infection_survey","text":"data available : https://www.ons.gov.uk/file?uri=/peoplepopulationandcommunity/healthandsocialcare/conditionsanddiseases/datasets/coronaviruscovid19infectionsurveydata/2023/20230310covid19infectionsurveydatasetsengland.xlsx","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_variants.html","id":null,"dir":"Reference","previous_headings":"","what":"Counts of COVID-19 variants â€” england_variants","title":"Counts of COVID-19 variants â€” england_variants","text":"Data COG-UK Sanger centre sequencing programme. data made available Welcome foundation Lower tier local authority level, weekly time series counts per variant. Variants assigned using tree structure Pango lineage. Different sub-lineages aggregated major variants concern.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_variants.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Counts of COVID-19 variants â€” england_variants","text":"","code":"data(england_variants)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/england_variants.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Counts of COVID-19 variants â€” england_variants","text":"dataframe containing following columns: date (date) - end date week time (time_period) - time column class (enum(,Alpha (B.1.1.7),Delta (B.1.617.2),Delta (AY.4),Omicron (),Omicron (BA.2),Omicron (BA.4),Omicron (BA.5),XBB (),Kraken (XBB.1.5),Arcturus (XBB.1.16),Eris (EG.5.1))) - class column who_class (enum(,Alpha,Delta,Omicron,Kraken,Arcturus,Eris)) - who_class column count (numeric) - weekly count column denom (numeric) - number sequences performed week Must grouped : class (groupings allowed). default value. 479 rows 6 columns","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/example_fns.html","id":null,"dir":"Reference","previous_headings":"","what":"Example generators â€” example_fns","title":"Example generators â€” example_fns","text":"set internally cached functions support examples. exported internal functions examples can run correctly cache output prevent excessive repetition code examples.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/example_fns.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example generators â€” example_fns","text":"","code":"example_england_covid_by_age()  example_poisson_age_stratified()  example_poisson_locfit()  example_proportion_age_stratified()  example_ganyani_ip()  example_du_serial()  example_ip()  example_bpm()  example_serial()  example_poisson_rt()  example_poisson_growth_rate()  example_poisson_rt_smooth()  example_poisson_rt_2class()  example_delayed_observation()"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/example_fns.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Example generators â€” example_fns","text":"example output stated functions, usually dataframe.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/example_fns.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Example generators â€” example_fns","text":"example_england_covid_by_age(): Example input format including age stratified COVID-19 data. example_poisson_age_stratified(): Example output poisson_locfit_model() run age stratified COVID-19 data. example_poisson_locfit(): Example output poisson_locfit_model() run un-stratified COVID-19 data. example_proportion_age_stratified(): Example output proportion_locfit_model() England COVID-19 age stratified proportion model dataset. proportion represented positive tests age group, versus positive tests age groups, represents relative growth ne age group versus others. example_ganyani_ip(): Generation time estimate make_gamma_ip(). estimate truncated make compatible EpiEstim. Take Ganyani T, Kremer C, Chen D, Torneri , Faes C, Wallinga J, Hens N. Estimating generation interval coronavirus disease (COVID-19) based symptom onset data, March 2020. Euro Surveill. 2020 Apr;25(17):2000257. doi: 10.2807/1560-7917.ES.2020.25.17.2000257. PMID: 32372755; PMCID: PMC7201952. example_du_serial(): undjusted serial interval symptoms make_resampled_ip() Z. Du, X. Xu, Y. Wu, L. Wang, B. J. Cowling, L. . Meyers, â€˜Serial Interval COVID-19 among Publicly Reported Confirmed Casesâ€™, Emerg Infect Dis, vol. 26, . 6, pp. 1341â€“1343, Jun. 2020, doi: 10.3201/eid2606.200357. example_ip(): Example output make_gamma_ip() test infectivity profile generated set discretised gamma distributions parameters mean 5 (95% CI 4-6) sd 2 (95% CI 1.5-2.5). example_bpm(): Example output sim_branching_process() example linelist output branching process model simulation. generated using example_ip() infectivity profile also includes delay symptom onset random gamma distributed quantity mean 6 standard deviation 2 example_serial(): Example output make_resampled_ip() serial interval estimated symptom onset simulated data including negative intervals. serial interval resampled first 1000 patients example_bpm() dataset infector infectee symptoms. patients generated symptom delay mean 6 days SD 2 infection (discrete -dispersed gamma) infectivity profile mean 5 days SD 2 defined example_ip() dataset. serial interval relevant estimation $R_t$ symptomatic case counts example_bpm() dataset includes negative times, used EpiEstim. example_poisson_rt(): Example output sim_poisson_Rt_model() example linelist output poisson model simulation defined $R_t$. generated using example_ip() infectivity profile example_poisson_growth_rate(): Example output sim_poisson_model() simulation dataset determined step function growth rates. useful demonstrating growth rate estimators. example_poisson_rt_smooth(): Example output sim_poisson_Rt_model() Output poisson model simulation smooth function $R_t$ defined R(t) = e^(sin(t/80*pi)^4-0.25)). relatively unchallenging test data set pose problem smooth estimators. example_poisson_rt_2class(): Two class example using sim_poisson_Rt_model() Two smooth $R_t$ based incidence timeseries one growing time varying Rt exp(sin(t / 80 * pi)^4 - 0.25) offset 10 days: exp(sin((t - 10) / 80 * pi)^4 - 0.25). simple relative growth test example_delayed_observation(): Example output sim_branching_process() sim_apply_delay() simulates might observed outbreak average 5 day delay reporting hospital admissions. configuration outbreak example_bpm(), summary data describes whole history admissions observed, observed given time point. triangular set data counts right censored observation time.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/example_fns.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example generators â€” example_fns","text":"","code":"suppressWarnings({   example_poisson_age_stratified() %>% dplyr::glimpse()   example_ip() %>% dplyr::glimpse()   example_bpm() %>% dplyr::glimpse()   example_serial() %>% dplyr::glimpse()   example_poisson_rt() %>% dplyr::glimpse()   example_poisson_growth_rate() %>% dplyr::glimpse()   example_poisson_rt_smooth() %>% dplyr::glimpse()   example_poisson_rt_2class() %>% dplyr::glimpse()   example_ganyani_ip() %>% dplyr::glimpse()   example_du_serial() %>% dplyr::glimpse()   example_delayed_observation() %>% dplyr::glimpse() }) #> incomplete fit locfit model - try decreasing `deg` or increasing `window`. #> Rows: 26,790 #> Columns: 20 #> Groups: class [19] #> $ class            <fct> 00_04, 00_04, 00_04, 00_04, 00_04, 00_04, 00_04, 00_0â€¦ #> $ time             <t[day]> 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44â€¦ #> $ incidence.fit    <dbl> -1.612905, -1.803708, -1.959326, -2.082483, -2.175902â€¦ #> $ incidence.se.fit <dbl> 1.0533915, 0.9003108, 0.7844360, 0.7012956, 0.6463539â€¦ #> $ incidence.0.025  <dbl> 0.02528574, 0.02820419, 0.03029440, 0.03152429, 0.031â€¦ #> $ incidence.0.05   <dbl> 0.03523977, 0.03745604, 0.03878940, 0.03932042, 0.039â€¦ #> $ incidence.0.25   <dbl> 0.09793934, 0.08972926, 0.08304107, 0.07765344, 0.073â€¦ #> $ incidence.0.5    <dbl> 0.19930774, 0.16468709, 0.14095339, 0.12462043, 0.113â€¦ #> $ incidence.0.75   <dbl> 0.40559365, 0.30226304, 0.23925342, 0.19999437, 0.175â€¦ #> $ incidence.0.95   <dbl> 1.1272371, 0.7240980, 0.5121982, 0.3949666, 0.3286558â€¦ #> $ incidence.0.975  <dbl> 1.5709871, 0.9616244, 0.6558260, 0.4926439, 0.4028982â€¦ #> $ growth.fit       <dbl> -0.2093030305, -0.1855586041, -0.1593989278, -0.13168â€¦ #> $ growth.se.fit    <dbl> 0.22418245, 0.20710820, 0.19030250, 0.17387303, 0.157â€¦ #> $ growth.0.025     <dbl> -0.64869255, -0.59148321, -0.53238498, -0.47246827, -â€¦ #> $ growth.0.05      <dbl> -0.57805034, -0.52622127, -0.47241869, -0.41767908, -â€¦ #> $ growth.0.25      <dbl> -0.360511792, -0.325250959, -0.287756014, -0.24895896â€¦ #> $ growth.0.5       <dbl> -0.2093030305, -0.1855586041, -0.1593989278, -0.13168â€¦ #> $ growth.0.75      <dbl> -0.058094269, -0.045866249, -0.031041841, -0.01440780â€¦ #> $ growth.0.95      <dbl> 0.15944428, 0.15510406, 0.15362083, 0.15431230, 0.156â€¦ #> $ growth.0.975     <dbl> 0.23008649, 0.22036600, 0.21358712, 0.20910150, 0.206â€¦ #> Rows: 1,800 #> Columns: 5 #> Groups: boot [100] #> $ tau         <int> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, â€¦ #> $ a0          <dbl> 0.0, 0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5, 10.â€¦ #> $ a1          <dbl> 0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5, 10.5, 11â€¦ #> $ probability <dbl> 0.000000e+00, 7.677533e-03, 9.291725e-02, 2.043664e-01, 2.â€¦ #> $ boot        <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2â€¦ #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> complete #> Rows: 36,813 #> Columns: 8 #> $ time                <t[day]> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,â€¦ #> $ id                  <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,â€¦ #> $ generation_interval <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NAâ€¦ #> $ infector            <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NAâ€¦ #> $ generation          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,â€¦ #> $ symptom_onset       <lgl> FALSE, FALSE, TRUE, TRUE, TRUE, TRUE, FALSE, TRUE,â€¦ #> $ symptom_onset_delay <dbl> NA, NA, 6, 6, 5, 5, NA, 6, NA, 11, 6, NA, 5, 8, NAâ€¦ #> $ symptom_onset_time  <t[day]> NA, NA, 6, 6, 5, 5, NA, 6, NA, 11, 6, NA, 5, 8,â€¦ #> Rows: 2,394 #> Columns: 5 #> Groups: boot [100] #> $ tau         <dbl> -7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, â€¦ #> $ a0          <dbl> -7.5, -6.5, -5.5, -4.5, -3.5, -2.5, -1.5, -0.5, 0.5, 1.5, â€¦ #> $ a1          <dbl> -6.5, -5.5, -4.5, -3.5, -2.5, -1.5, -0.5, 0.5, 1.5, 2.5, 3â€¦ #> $ probability <dbl> 9.138864e-06, 2.057870e-03, 1.033504e-03, 5.130966e-03, 7.â€¦ #> $ boot        <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1â€¦ #> Rows: 81 #> Columns: 6 #> Groups: statistic [1] #> $ time      <t[day]> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,â€¦ #> $ rt        <dbl> 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, â€¦ #> $ imports   <dbl> 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,â€¦ #> $ rate      <dbl> 30.0000000, 0.7045695, 5.7984339, 12.9399338, 17.4968560, 20â€¦ #> $ count     <int> 27, 0, 5, 12, 16, 15, 20, 30, 32, 43, 53, 62, 88, 90, 112, 1â€¦ #> $ statistic <chr> \"infections\", \"infections\", \"infections\", \"infections\", \"infâ€¦ #> Rows: 105 #> Columns: 6 #> Groups: statistic [1] #> $ time      <t[day]> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,â€¦ #> $ growth    <dbl> 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, â€¦ #> $ imports   <dbl> 100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0â€¦ #> $ rate      <dbl> 100.0000, 110.5171, 122.1403, 134.9859, 149.1825, 164.8721, â€¦ #> $ count     <int> 94, 93, 131, 136, 153, 157, 188, 196, 223, 247, 268, 320, 32â€¦ #> $ statistic <chr> \"infections\", \"infections\", \"infections\", \"infections\", \"infâ€¦ #> Rows: 161 #> Columns: 6 #> Groups: statistic [1] #> $ time      <t[day]> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,â€¦ #> $ rt        <dbl> 0.7788008, 0.7788026, 0.7788303, 0.7789494, 0.7792673, 0.779â€¦ #> $ imports   <dbl> 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,â€¦ #> $ rate      <dbl> 30.0000000, 0.2194882, 1.8028493, 3.9734539, 5.0843677, 5.01â€¦ #> $ count     <int> 29, 0, 0, 6, 3, 9, 5, 3, 4, 6, 10, 0, 1, 1, 2, 5, 2, 2, 1, 3â€¦ #> $ statistic <chr> \"infections\", \"infections\", \"infections\", \"infections\", \"infâ€¦ #> Rows: 322 #> Columns: 8 #> Groups: class [2] #> $ time      <t[day]> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,â€¦ #> $ rt        <dbl> 0.7788008, 0.7788026, 0.7788303, 0.7789494, 0.7792673, 0.779â€¦ #> $ imports   <dbl> 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,â€¦ #> $ rate      <dbl> 30.0000000, 0.2194882, 1.8028493, 3.9734539, 5.0843677, 5.01â€¦ #> $ count     <int> 33, 0, 0, 1, 4, 5, 5, 3, 3, 3, 2, 7, 5, 1, 3, 4, 3, 3, 4, 4,â€¦ #> $ statistic <chr> \"infections\", \"infections\", \"infections\", \"infections\", \"infâ€¦ #> $ class     <fct> one, one, one, one, one, one, one, one, one, one, one, one, â€¦ #> $ denom     <int> 64, 0, 2, 9, 9, 10, 15, 5, 4, 8, 3, 14, 10, 3, 9, 5, 6, 7, 1â€¦ #> Rows: 2,400 #> Columns: 5 #> Groups: boot [100] #> $ tau         <int> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, â€¦ #> $ a0          <dbl> 0.0, 0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5, 10.â€¦ #> $ a1          <dbl> 0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5, 10.5, 11â€¦ #> $ probability <dbl> 0.000000e+00, 3.213194e-04, 2.011007e-02, 1.168491e-01, 2.â€¦ #> $ boot        <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1â€¦ #> Rows: 2,528 #> Columns: 5 #> Groups: boot [100] #> $ tau         <dbl> -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, â€¦ #> $ a0          <dbl> -5.5, -4.5, -3.5, -2.5, -1.5, -0.5, 0.5, 1.5, 2.5, 3.5, 4.â€¦ #> $ a1          <dbl> -4.5, -3.5, -2.5, -1.5, -0.5, 0.5, 1.5, 2.5, 3.5, 4.5, 5.5â€¦ #> $ probability <dbl> 0.007822933, 0.003372250, 0.014498957, 0.014498957, 0.0567â€¦ #> $ boot        <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1â€¦ #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> complete #> Rows: 3,321 #> Columns: 4 #> Groups: obs_time, statistic [81] #> $ statistic <chr> \"admitted\", \"admitted\", \"admitted\", \"admitted\", \"admitted\", â€¦ #> $ obs_time  <t[day]> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,â€¦ #> $ time      <t[day]> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, â€¦ #> $ count     <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, â€¦"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/fdmy.html","id":null,"dir":"Reference","previous_headings":"","what":"Format date as dmy â€” fdmy","title":"Format date as dmy â€” fdmy","text":"Format date dmy","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/fdmy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format date as dmy â€” fdmy","text":"","code":"fdmy(date)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/fdmy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format date as dmy â€” fdmy","text":"date date convert","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/fdmy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Format date as dmy â€” fdmy","text":"formatted date","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/fdmy.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Format date as dmy â€” fdmy","text":"","code":"fdmy(Sys.Date()) #> [1] \"11 Dec 2025\""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/format_ip.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a summary of an infectivity profile â€” format_ip","title":"Print a summary of an infectivity profile â€” format_ip","text":"Print summary infectivity profile","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/format_ip.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a summary of an infectivity profile â€” format_ip","text":"","code":"format_ip(ip = i_empirical_ip)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/format_ip.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a summary of an infectivity profile â€” format_ip","text":"ip infectivity profile summarise. a0 a1 columns optional tau given. - dataframe columns: boot (anything + default(1)) - bootstrap identifier probability (proportion) - probability new event period. a0 (double) - beginning time period (days) a1 (double) - end time period (days) Minimally grouped : boot (groupings allowed).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/format_ip.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print a summary of an infectivity profile â€” format_ip","text":"infectivity profile description","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/format_ip.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print a summary of an infectivity profile â€” format_ip","text":"","code":"format_ip(example_ganyani_ip()) #> [1] \"PDF: mean: 5.2 [3.98 â€” 6.82]; sd: 2.06 [0.644 â€” 3.19]; 100 bootstraps\""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/gam_delayed_reporting.html","id":null,"dir":"Reference","previous_headings":"","what":"Delayed GAM reporting model function generator â€” gam_delayed_reporting","title":"Delayed GAM reporting model function generator â€” gam_delayed_reporting","text":"Delayed GAM reporting model function generator","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/gam_delayed_reporting.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delayed GAM reporting model function generator â€” gam_delayed_reporting","text":"","code":"gam_delayed_reporting(   window,   max_delay = 40,   ...,   knots_fn = ~gam_knots(.x, window, ...) )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/gam_delayed_reporting.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delayed GAM reporting model function generator â€” gam_delayed_reporting","text":"window controls knot spacing GAM (default) max_delay maximum delay expect model ... Named arguments passed gam_knots k alternative window, k given behaviour knots similar default mgcv::s(...,k=...) parameter. knots_fn function takes data input returns set integers time points GAM knots, s(time) term. default provides roughly equally spaced grid determined window, user supplied function anything. input function raw dataframe data considered one model fit. guaranteed least time count column. possible ","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/gam_delayed_reporting.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Delayed GAM reporting model function generator â€” gam_delayed_reporting","text":"list 2 entries - model_fn predict suitable input poisson_gam_model(model_fn = ..., predict=...).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/gam_delayed_reporting.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Delayed GAM reporting model function generator â€” gam_delayed_reporting","text":"function used configure delayed reporting GAM model. model form: count ~ s(time, bs = \"cr\", k = length(kts)) + s(log(tau), k = 4, pc = max_delay) tau difference time series observation time time data point time series, multiple observations time series. function helps specify knots GAM maximum expected delay","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/gam_delayed_reporting.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Delayed GAM reporting model function generator â€” gam_delayed_reporting","text":"","code":"data = example_delayed_observation() %>% dplyr::group_by(obs_time) cfg = gam_delayed_reporting(14,40) fit = cfg$model_fn(data) summary(fit) #>  #> Family: Negative Binomial(793.435)  #> Link function: log  #>  #> Formula: #> count ~ s(time, bs = \"cr\", k = length(kts)) + s(log(tau), k = 4,  #>     pc = max_delay) #>  #> Parametric coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)  1.99774    0.01559   128.2   <2e-16 *** #> --- #> Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1 #>  #> Approximate significance of smooth terms: #>               edf Ref.df Chi.sq p-value     #> s(time)     6.969      7  51830  <2e-16 *** #> s(log(tau)) 2.998      3   5420  <2e-16 *** #> --- #> Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1 #>  #> R-sq.(adj) =   0.98   Deviance explained = 97.9% #> -REML = 7103.1  Scale est. = 1         n = 3240"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/gam_knots.html","id":null,"dir":"Reference","previous_headings":"","what":"Derive a set of knot points for a GAM from data â€” gam_knots","title":"Derive a set of knot points for a GAM from data â€” gam_knots","text":"moment nothing sophisticated. mostly equally spaced grid knots gaps start end prevent -fitting . future look number observations areas lot change add knots.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/gam_knots.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Derive a set of knot points for a GAM from data â€” gam_knots","text":"","code":"gam_knots(data = i_incidence_data, window, ..., k = NULL)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/gam_knots.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Derive a set of knot points for a GAM from data â€” gam_knots","text":"data function called incidence data - dataframe columns: count (positive_integer) - Positive case counts associated specified time frame time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` grouping allowed. window spacing knots ... currently used k alternative window, k given behaviour knots similar default mgcv::s(...,k=...) parameter.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/gam_knots.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Derive a set of knot points for a GAM from data â€” gam_knots","text":"vector times (numeric)","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/gam_knots.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Derive a set of knot points for a GAM from data â€” gam_knots","text":"","code":"gam_knots(example_poisson_rt(), 14) #> [1] 10 20 30 40 50 60 70 75 gam_knots(example_poisson_rt(), k=10) #>  [1]  0.000000  8.888889 17.777778 26.666667 35.555556 44.444444 53.333333 #>  [8] 62.222222 71.111111 80.000000"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/gam_nb_model_fn.html","id":null,"dir":"Reference","previous_headings":"","what":"Default GAM count negative binomial model. â€” gam_nb_model_fn","title":"Default GAM count negative binomial model. â€” gam_nb_model_fn","text":"function configures simple negative binomial count model using:","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/gam_nb_model_fn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Default GAM count negative binomial model. â€” gam_nb_model_fn","text":"","code":"gam_nb_model_fn(window, ..., knots_fn = ~gam_knots(.x, window, ...))"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/gam_nb_model_fn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Default GAM count negative binomial model. â€” gam_nb_model_fn","text":"window controls knot spacing GAM (default) ... Named arguments passed gam_knots k alternative window, k given behaviour knots similar default mgcv::s(...,k=...) parameter. knots_fn function takes data input returns set integers time points GAM knots, s(time) term. default provides roughly equally spaced grid determined window, user supplied function anything. input function raw dataframe data considered one model fit. guaranteed least time count column. possible ","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/gam_nb_model_fn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Default GAM count negative binomial model. â€” gam_nb_model_fn","text":"function suitable input poisson_gam_model(model_fn = ...).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/gam_nb_model_fn.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Default GAM count negative binomial model. â€” gam_nb_model_fn","text":"count ~ s(time, bs = \"cr\", k = length(kts)) control knot positions defined knots_fn window parameters.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/gam_nb_model_fn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Default GAM count negative binomial model. â€” gam_nb_model_fn","text":"","code":"model_fn = gam_nb_model_fn(14) fit = model_fn(example_poisson_rt() %>% dplyr::ungroup()) summary(fit) #>  #> Family: Negative Binomial(56.353)  #> Link function: log  #>  #> Formula: #> count ~ s(time, bs = \"cr\", k = length(kts)) #>  #> Parametric coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)  7.12349    0.01795   396.8   <2e-16 *** #> --- #> Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1 #>  #> Approximate significance of smooth terms: #>           edf Ref.df Chi.sq p-value     #> s(time) 6.815  6.986   9113  <2e-16 *** #> --- #> Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1 #>  #> R-sq.(adj) =  0.883   Deviance explained = 98.8% #> -REML = 569.87  Scale est. = 1         n = 81"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/gam_poisson_model_fn.html","id":null,"dir":"Reference","previous_headings":"","what":"Default GAM count model. â€” gam_poisson_model_fn","title":"Default GAM count model. â€” gam_poisson_model_fn","text":"function configures simple poisson count model using:","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/gam_poisson_model_fn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Default GAM count model. â€” gam_poisson_model_fn","text":"","code":"gam_poisson_model_fn(window, ..., knots_fn = ~gam_knots(.x, window, ...))"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/gam_poisson_model_fn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Default GAM count model. â€” gam_poisson_model_fn","text":"window controls knot spacing GAM (default) ... Named arguments passed gam_knots k alternative window, k given behaviour knots similar default mgcv::s(...,k=...) parameter. knots_fn function takes data input returns set integers time points GAM knots, s(time) term. default provides roughly equally spaced grid determined window, user supplied function anything. input function raw dataframe data considered one model fit. guaranteed least time count column. possible ","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/gam_poisson_model_fn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Default GAM count model. â€” gam_poisson_model_fn","text":"function suitable input poisson_gam_model(model_fn = ...).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/gam_poisson_model_fn.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Default GAM count model. â€” gam_poisson_model_fn","text":"count ~ s(time, bs = \"cr\", k = length(kts)) control knot positions defined knots_fn window parameters.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/gam_poisson_model_fn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Default GAM count model. â€” gam_poisson_model_fn","text":"","code":"model_fn = gam_poisson_model_fn(14) fit = model_fn(example_poisson_rt() %>% dplyr::ungroup()) summary(fit) #>  #> Family: quasipoisson  #> Link function: log  #>  #> Formula: #> count ~ s(time, bs = \"cr\", k = length(kts)) #>  #> Parametric coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept)   7.1308     0.1036    68.8   <2e-16 *** #> --- #> Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1 #>  #> Approximate significance of smooth terms: #>          edf Ref.df     F p-value     #> s(time) 6.51  6.907 134.6  <2e-16 *** #> --- #> Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1 #>  #> R-sq.(adj) =  0.892   Deviance explained = 96.7% #> -REML = 251.45  Scale est. = 134.47    n = 81"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/ganyani_ip.html","id":null,"dir":"Reference","previous_headings":"","what":"A COVID-19 infectivity profile based on an Ganyani et al 2020 â€” ganyani_ip","title":"A COVID-19 infectivity profile based on an Ganyani et al 2020 â€” ganyani_ip","text":"COVID-19 infectivity profile based Ganyani et al 2020 Ganyani serial interval dataset, compatible EpiEstim","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/ganyani_ip.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A COVID-19 infectivity profile based on an Ganyani et al 2020 â€” ganyani_ip","text":"","code":"data(ganyani_ip)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/ganyani_ip.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"A COVID-19 infectivity profile based on an Ganyani et al 2020 â€” ganyani_ip","text":"dataframe containing following columns: boot (anything + default(1)) - bootstrap identifier probability (proportion) - probability infection previous time period time tau (double) - time index probability relates (days) a0 - beginning time period a1 - end time period Grouped boot (exactly). dataframe containing following columns: boot (anything + default(1)) - bootstrap identifier probability (proportion) - probability infection previous time period time tau (numeric) - time index probability relates (days) a0 (numeric) - beginning time period a1 (numeric) - end time period Grouped : boot. 2400 rows 5 columns","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/ganyani_ip.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"A COVID-19 infectivity profile based on an Ganyani et al 2020 â€” ganyani_ip","text":"https://www.eurosurveillance.org/content/10.2807/1560-7917.ES.2020.25.17.2000257","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/ganyani_ip_2.html","id":null,"dir":"Reference","previous_headings":"","what":"A COVID-19 infectivity profile based on an Ganyani et al 2020 â€” ganyani_ip_2","title":"A COVID-19 infectivity profile based on an Ganyani et al 2020 â€” ganyani_ip_2","text":"version discretised manner makes incompatible EpiEstim.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/ganyani_ip_2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A COVID-19 infectivity profile based on an Ganyani et al 2020 â€” ganyani_ip_2","text":"","code":"data(ganyani_ip_2)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/ganyani_ip_2.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"A COVID-19 infectivity profile based on an Ganyani et al 2020 â€” ganyani_ip_2","text":"dataframe containing following columns: boot (anything + default(1)) - bootstrap identifier probability (proportion) - probability infection previous time period time tau (double) - time index probability relates (days) a0 - beginning time period a1 - end time period Grouped boot (exactly). dataframe containing following columns: boot (anything + default(1)) - bootstrap identifier probability (proportion) - probability infection previous time period time tau (numeric) - time index probability relates (days) a0 (numeric) - beginning time period a1 (numeric) - end time period Grouped : boot. 2800 rows 5 columns","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/ganyani_ip_2.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"A COVID-19 infectivity profile based on an Ganyani et al 2020 â€” ganyani_ip_2","text":"https://www.eurosurveillance.org/content/10.2807/1560-7917.ES.2020.25.17.2000257","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/geom_events.html","id":null,"dir":"Reference","previous_headings":"","what":"Add time series event markers to a time series plot. â€” geom_events","title":"Add time series event markers to a time series plot. â€” geom_events","text":"x axis must date.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/geom_events.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add time series event markers to a time series plot. â€” geom_events","text":"","code":"geom_events(   events = i_events,   event_label_size = 7,   event_label_colour = \"black\",   event_label_angle = -30,   event_line_colour = \"grey50\",   event_fill_colour = \"grey50\",   hide_labels = FALSE,   guide_axis = ggplot2::derive(),   x_axis_style = c(\"date\", \"time_period\"),   ... )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/geom_events.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add time series event markers to a time series plot. â€” geom_events","text":"events Significant events time spans - dataframe columns: label (character) - event label start (date) - start date, date event end (date) - end date NA single event grouping allowed. default value defined. event_label_size big make event label event_label_colour event label colour event_label_angle event label colour event_line_colour event line colour event_fill_colour event area fill hide_labels show labels guide_axis guide axis configuration labels (see ggplot2::guide_axis ggplot2::dup_axis). can used specify position amongst things. x_axis_style x-axis \"date\" count \"time_period\"s since start date (may specified ... defaults data) ... Named arguments passed ggplot2::scale_x_date name name scale. Used axis legend title. waiver(), default, name scale taken first mapping used aesthetic. NULL, legend title omitted. breaks One : NULL breaks waiver() breaks specified date_breaks Date/POSIXct vector giving positions breaks function takes limits input returns breaks output date_breaks string giving distance breaks like \"2 weeks\", \"10 years\". breaks date_breaks specified, date_breaks wins. Valid specifications 'sec', 'min', 'hour', 'day', 'week', 'month' 'year', optionally followed 's'. labels One options . Please note labels vector, highly recommended also set breaks argument vector protect unintended mismatches. NULL labels waiver() default labels computed transformation object character vector giving labels (must length breaks) expression vector (must length breaks). See ?plotmath details. function takes breaks input returns labels output. Also accepts rlang lambda function notation. date_labels string giving formatting specification labels. Codes defined strftime(). labels date_labels specified, date_labels wins. minor_breaks One : NULL breaks waiver() breaks specified date_minor_breaks Date/POSIXct vector giving positions minor breaks function takes limits input returns minor breaks output date_minor_breaks string giving distance minor breaks like \"2 weeks\", \"10 years\". minor_breaks date_minor_breaks specified, date_minor_breaks wins. Valid specifications 'sec', 'min', 'hour', 'day', 'week', 'month' 'year', optionally followed 's'. limits One : NULL use default scale range numeric vector length two providing limits scale. Use NA refer existing minimum maximum function accepts existing (automatic) limits returns new limits. Also accepts rlang lambda function notation. Note setting limits positional scales remove data outside limits. purpose zoom, use limit argument coordinate system (see coord_cartesian()). expand position scales, vector range expansion constants used add padding around data ensure placed distance away axes. Use convenience function expansion() generate values expand argument. defaults expand scale 5% side continuous variables, 0.6 units side discrete variables. oob One : Function handles limits outside scale limits (bounds). Also accepts rlang lambda function notation. default (scales::censor()) replaces bounds values NA. scales::squish() squishing bounds values range. scales::squish_infinite() squishing infinite values range. guide function used create guide name. See guides() information. position position scales, position axis. left right y axes, top bottom x axes. timezone timezone use display axes. default (NULL) uses timezone encoded data. na.value Missing values replaced value. Named arguments passed .time_period unit length one unit time. either integer number days, specification \"1 week\", another time_period. x time_period, unit different x return rescaled time_period using new units. start_date zero time date something can coerced date. x input already time_period different start_date x recalibrated use new start date. anchor relevant x vector dates, date, \"start\" \"end\" weekday name e.g. \"mon\". vector dates x use anchor find reference date time-series. provided current defaults used. (see set_defaults())","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/geom_events.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add time series event markers to a time series plot. â€” geom_events","text":"set geoms time series.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/geom_truth.html","id":null,"dir":"Reference","previous_headings":"","what":"Add a ","title":"Add a ","text":"Add \"true\" time series plot","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/geom_truth.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add a ","text":"","code":"geom_truth(   true_df = NULL,   ...,   true_col = NULL,   true_fmt = list(colour = \"red\") )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/geom_truth.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add a ","text":"true_df data frame time_period column called time value column (name given true_col). optional picked raw parameter given. ... Named arguments passed .time_period unit length one unit time. either integer number days, specification \"1 week\", another time_period. x time_period, unit different x return rescaled time_period using new units. start_date zero time date something can coerced date. x input already time_period different start_date x recalibrated use new start date. anchor relevant x vector dates, date, \"start\" \"end\" weekday name e.g. \"mon\". vector dates x use anchor find reference date time-series. provided current defaults used. (see set_defaults()) true_col column name / expression true value true_fmt list ggplot formatting apply true value timeseries","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/geom_truth.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add a ","text":"geom true value line.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/germany_covid.html","id":null,"dir":"Reference","previous_headings":"","what":"Weekly COVID-19 case counts by age group in Germany â€” germany_covid","title":"Weekly COVID-19 case counts by age group in Germany â€” germany_covid","text":"dataset weekly count COVID-19 cases age group Germany downloaded Robert Koch Institute Survstat service, formatted use growth rates. denominator calculated overall positive count age groups. data set can used calculate group-wise incidence absolute growth rates group wise proportions relative growth rates.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/germany_covid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Weekly COVID-19 case counts by age group in Germany â€” germany_covid","text":"","code":"data(germany_covid)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/germany_covid.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Weekly COVID-19 case counts by age group in Germany â€” germany_covid","text":"dataframe containing following columns: class (enum(0â€“14,15â€“19,20â€“24,25â€“29,30â€“39,40â€“49,50â€“59,60â€“69,70â€“79,80+,Unknown, .ordered=TRUE)) - age group date (.Date) - date column count (integer) - test positives age group time (time_period) - time column denom (integer) - test positives age groups Must grouped : class (groupings allowed). default value. 2070 rows 6 columns","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/germany_demographics.html","id":null,"dir":"Reference","previous_headings":"","what":"Germany demographics â€” germany_demographics","title":"Germany demographics â€” germany_demographics","text":"Derived Robert Koch Survstat service comparing counts incidence rates.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/germany_demographics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Germany demographics â€” germany_demographics","text":"","code":"data(germany_demographics)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/germany_demographics.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Germany demographics â€” germany_demographics","text":"dataframe containing following columns: class (enum(0â€“14,15â€“19,20â€“24,25â€“29,30â€“39,40â€“49,50â€“59,60â€“69,70â€“79,80+, .ordered=TRUE)) - class column population (integer) - population column Must grouped : class (groupings allowed). default value. 10 rows 2 columns","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/ggoutbreak-package.html","id":null,"dir":"Reference","previous_headings":"","what":"ggoutbreak: Estimate Incidence, Proportions and Exponential Growth Rates â€” ggoutbreak-package","title":"ggoutbreak: Estimate Incidence, Proportions and Exponential Growth Rates â€” ggoutbreak-package","text":"Simple statistical models visualisations calculating incidence, proportion, exponential growth rate, reproduction number infectious disease case time series. toolkit largely developed COVID-19 pandemic.","code":""},{"path":[]},{"path":"https://ai4ci.github.io/ggoutbreak/reference/ggoutbreak-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"ggoutbreak: Estimate Incidence, Proportions and Exponential Growth Rates â€” ggoutbreak-package","text":"Maintainer: Robert Challen rob.challen@bristol.ac.uk (ORCID) [copyright holder]","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/grapes-above-grapes.html","id":null,"dir":"Reference","previous_headings":"","what":"Insert a layer at the bottom of a ggplot â€” %above%","title":"Insert a layer at the bottom of a ggplot â€” %above%","text":"Insert layer bottom ggplot","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/grapes-above-grapes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Insert a layer at the bottom of a ggplot â€” %above%","text":"","code":"plot %above% layer"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/grapes-above-grapes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Insert a layer at the bottom of a ggplot â€” %above%","text":"plot plot add layer layer layer insert underneath plot","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/grapes-above-grapes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Insert a layer at the bottom of a ggplot â€” %above%","text":"ggplot","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/growth_rate_from_incidence.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate growth rate from modelled incidence â€” growth_rate_from_incidence","title":"Estimate growth rate from modelled incidence â€” growth_rate_from_incidence","text":"assumes modelled incidence estimate log-normal. exponential growth rate first derivative mu parameters log-normal. link scale normally distributed. function assumes time series incidence estimates uncorrelated estimate error growth rate, conservative approach resulting uncertainty growth rate might possible methods. based Savitsky-Golay filters applied normally distributed log-incidence estimates.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/growth_rate_from_incidence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate growth rate from modelled incidence â€” growth_rate_from_incidence","text":"","code":"growth_rate_from_incidence(d = i_incidence_model, window = 7, deg = 2)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/growth_rate_from_incidence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate growth rate from modelled incidence â€” growth_rate_from_incidence","text":"d modelled incidence estimate - dataframe columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` incidence.fit (double) - estimate incidence rate log scale incidence.se.fit (positive_double) - standard error incidence rate estimate log scale incidence.0.025 (positive_double) - lower confidence limit incidence rate (true scale) incidence.0.5 (positive_double) - median estimate incidence rate (true scale) incidence.0.975 (positive_double) - upper confidence limit incidence rate (true scale) grouping allowed. window width Savitsky-Golay filter - must odd deg polynomial degree filter","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/growth_rate_from_incidence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate growth rate from modelled incidence â€” growth_rate_from_incidence","text":"timeseries growth rate columns: dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period growth.fit (double) - estimate growth rate growth.se.fit (positive_double) - standard error growth rate growth.0.025 (double) - lower confidence limit growth rate growth.0.5 (double) - median estimate growth rate growth.0.975 (double) - upper confidence limit growth rate grouping allowed.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/growth_rate_from_incidence.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate growth rate from modelled incidence â€” growth_rate_from_incidence","text":"","code":"data = example_poisson_growth_rate() tmp2 = data %>%   poisson_glm_model(window=7,deg=1) %>%   growth_rate_from_incidence(window = 13, deg=1)  if(interactive()) {   plot_incidence(tmp2,       date_labels=\"%b %y\")    plot_growth_rate(       tmp2,       date_labels=\"%b %y\"     )+     sim_geom_function(data,colour=\"red\") }"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/growth_rate_from_prevalence.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate relative growth rate from estimated prevalence â€” growth_rate_from_prevalence","title":"Estimate relative growth rate from estimated prevalence â€” growth_rate_from_prevalence","text":"assumes prevalence logit-normally distributed. exponential growth rate first derivative mu parameters logit-normal. link scale normally distributed. function assumes time series incidence estimates uncorrelated estimate error growth rate, conservative approach resulting uncertainty growth rate might possible methods. based Savitsky-Golay filters applied normally distributed logit-proportion estimates.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/growth_rate_from_prevalence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate relative growth rate from estimated prevalence â€” growth_rate_from_prevalence","text":"","code":"growth_rate_from_prevalence(d = i_prevalence_model, window = 7, deg = 2)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/growth_rate_from_prevalence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate relative growth rate from estimated prevalence â€” growth_rate_from_prevalence","text":"d modelled proportion estimate - dataframe columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` prevalence.0.025 (proportion) - lower confidence limit prevalence (true scale) prevalence.0.5 (proportion) - median estimate prevalence (true scale) prevalence.0.975 (proportion) - upper confidence limit prevalence (true scale) grouping allowed. window width Savitsky-Golay filter - must odd deg polynomial degree filter","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/growth_rate_from_prevalence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate relative growth rate from estimated prevalence â€” growth_rate_from_prevalence","text":"timeseries growth rate columns: dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period proportion.fit (double) - estimate proportion logit scale proportion.se.fit (positive_double) - standard error proportion estimate logit scale proportion.0.025 (proportion) - lower confidence limit proportion (true scale) proportion.0.5 (proportion) - median estimate proportion (true scale) proportion.0.975 (proportion) - upper confidence limit proportion (true scale) relative.growth.fit (double) - estimate relative growth rate relative.growth.se.fit (positive_double) - standard error relative growth rate relative.growth.0.025 (double) - lower confidence limit relative growth rate relative.growth.0.5 (double) - median estimate relative growth rate relative.growth.0.975 (double) - upper confidence limit relative growth rate grouping allowed.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/growth_rate_from_prevalence.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate relative growth rate from estimated prevalence â€” growth_rate_from_prevalence","text":"","code":"data = example_poisson_rt_2class()  tmp = data %>%   proportion_glm_model(window=7,deg=2) %>%   dplyr::select(time, dplyr::starts_with(\"proportion\")) %>%   dplyr::rename_with(~ gsub(\"proportion\",\"prevalence\",.x)) %>%   dplyr::select(-prevalence.fit, -prevalence.se.fit) #> Adding missing grouping variables: `class`  tmp = tmp %>%   growth_rate_from_prevalence(window = 25, deg=1)  plot_growth_rate(       tmp,       date_labels=\"%b %y\"   )   data1 = ukc19::ons_infection_survey %>%   dplyr::filter(name==\"England\") %>%   timeseries(count=FALSE)  tmp2 = data1 %>%   growth_rate_from_prevalence(window = 25, deg=1)  if(interactive()) {   plot_growth_rate(       tmp2,       date_labels=\"%b %y\",       mapping = ggplot2::aes(colour=name),       events = ukc19::timeline   ) }"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/growth_rate_from_proportion.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate relative growth rate from modelled proportion â€” growth_rate_from_proportion","title":"Estimate relative growth rate from modelled proportion â€” growth_rate_from_proportion","text":"assumes modelled proportion logit-normally distributed. exponential growth rate first derivative mu parameters logit-normal. link scale normally distributed. function assumes time series incidence estimates uncorrelated estimate error growth rate, conservative approach resulting uncertainty growth rate might possible methods. based Savitsky-Golay filters applied normally distributed logit-proportion estimates.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/growth_rate_from_proportion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate relative growth rate from modelled proportion â€” growth_rate_from_proportion","text":"","code":"growth_rate_from_proportion(d = i_proportion_model, window = 7, deg = 2)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/growth_rate_from_proportion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate relative growth rate from modelled proportion â€” growth_rate_from_proportion","text":"d modelled proportion estimate - dataframe columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` proportion.fit (double) - estimate proportion logit scale proportion.se.fit (positive_double) - standard error proportion estimate logit scale proportion.0.025 (proportion) - lower confidence limit proportion (true scale) proportion.0.5 (proportion) - median estimate proportion (true scale) proportion.0.975 (proportion) - upper confidence limit proportion (true scale) grouping allowed. window width Savitsky-Golay filter - must odd deg polynomial degree filter","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/growth_rate_from_proportion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate relative growth rate from modelled proportion â€” growth_rate_from_proportion","text":"timeseries growth rate columns: dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period proportion.fit (double) - estimate proportion logit scale proportion.se.fit (positive_double) - standard error proportion estimate logit scale proportion.0.025 (proportion) - lower confidence limit proportion (true scale) proportion.0.5 (proportion) - median estimate proportion (true scale) proportion.0.975 (proportion) - upper confidence limit proportion (true scale) relative.growth.fit (double) - estimate relative growth rate relative.growth.se.fit (positive_double) - standard error relative growth rate relative.growth.0.025 (double) - lower confidence limit relative growth rate relative.growth.0.5 (double) - median estimate relative growth rate relative.growth.0.975 (double) - upper confidence limit relative growth rate grouping allowed.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/growth_rate_from_proportion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate relative growth rate from modelled proportion â€” growth_rate_from_proportion","text":"","code":"data = example_poisson_rt_2class()  tmp2 = data %>%   proportion_glm_model(window=7,deg=2) %>%   growth_rate_from_proportion(window = 13, deg=1)  if(interactive()) {   plot_proportion(tmp2,       date_labels=\"%b %y\")    plot_growth_rate(       tmp2,       date_labels=\"%b %y\"     ) }"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/infer_population.html","id":null,"dir":"Reference","previous_headings":"","what":"Infers a daily baseline population for a timeseries â€” infer_population","title":"Infers a daily baseline population for a timeseries â€” infer_population","text":"function augments timeseries population denominator. population data may static estimates, set estimates time points. population data may grouped case grouping might geographical area age group gender example. two inputs must compatible grouping (.e. groups population data must present timeseries).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/infer_population.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Infers a daily baseline population for a timeseries â€” infer_population","text":"","code":"infer_population(df = i_timeseries, pop = i_population_data)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/infer_population.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Infers a daily baseline population for a timeseries â€” infer_population","text":"df time series, grouped collection time series. - dataframe columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` grouping allowed. pop population data must grouped way df. might also time column time_period population static - dataframe columns: population (positive_integer) - Size population grouping allowed.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/infer_population.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Infers a daily baseline population for a timeseries â€” infer_population","text":"df timeseries additional population column","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/infer_population.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Infers a daily baseline population for a timeseries â€” infer_population","text":"","code":"# The COVID data already has a population column so we are just double checking: data = example_england_covid_by_age() %>%   dplyr::rename(pop_old = population)  demog = ukc19::uk_population_2019_by_5yr_age %>% dplyr::group_by(code, name, class)  data %>%   infer_population(demog) %>%   dplyr::glimpse() #> Adding missing grouping variables: `code`, `name` #> different column groupings in `modelled` and `base` parameters. #> regrouping `base` data to be compatible with `modelled` grouping #> Rows: 10,662,420 #> Columns: 12 #> Groups: class [19] #> $ class      <chr> \"00_04\", \"00_04\", \"00_04\", \"00_04\", \"00_04\", \"00_04\", \"00_0â€¦ #> $ time       <t[day]> 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, â€¦ #> $ code.x     <chr> \"E92000001\", \"E92000001\", \"E92000001\", \"E92000001\", \"E92000â€¦ #> $ date       <date> 2020-01-30, 2020-01-30, 2020-01-30, 2020-01-30, 2020-01-30â€¦ #> $ name.x     <chr> \"England\", \"England\", \"England\", \"England\", \"England\", \"Engâ€¦ #> $ codeType   <chr> \"CTRY20\", \"CTRY20\", \"CTRY20\", \"CTRY20\", \"CTRY20\", \"CTRY20\",â€¦ #> $ count      <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,â€¦ #> $ denom      <dbl> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,â€¦ #> $ pop_old    <dbl> 3299637, 3299637, 3299637, 3299637, 3299637, 3299637, 32996â€¦ #> $ code.y     <chr> \"E06000001\", \"E06000002\", \"E06000003\", \"E06000004\", \"E06000â€¦ #> $ name.y     <chr> \"Hartlepool\", \"Middlesbrough\", \"Redcar and Cleveland\", \"Stoâ€¦ #> $ population <int> 5229, 9583, 7106, 11462, 5790, 7580, 11596, 10575, 8262, 16â€¦"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/infer_prevalence.html","id":null,"dir":"Reference","previous_headings":"","what":"Infer the prevalence of disease from incidence estimates and population size. â€” infer_prevalence","title":"Infer the prevalence of disease from incidence estimates and population size. â€” infer_prevalence","text":"Log-scaled incidence estimates used generate samples incidence. convolved duration infection (probability still infected) given day (set discrete distributions) result evaluated fraction population. result fitted logit-normal (using moments) quantiles produced samples. test sensitivity used instead duration infection prevalence estimate expected proportion test positives screening test rather true prevalence. Differences proportion test positives observed may due ascertainment bias test sensitivity misspecification.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/infer_prevalence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Infer the prevalence of disease from incidence estimates and population size. â€” infer_prevalence","text":"","code":"infer_prevalence(   modelled = i_incidence_model,   pop = i_population_data,   ip = i_discrete_ip,   bootstraps = 1000,   seed = Sys.time(),   ... )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/infer_prevalence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Infer the prevalence of disease from incidence estimates and population size. â€” infer_prevalence","text":"modelled Model output processing raw dataframe something like poission_locfit_model - dataframe columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` incidence.fit (double) - estimate incidence rate log scale incidence.se.fit (positive_double) - standard error incidence rate estimate log scale incidence.0.025 (positive_double) - lower confidence limit incidence rate (true scale) incidence.0.5 (positive_double) - median estimate incidence rate (true scale) incidence.0.975 (positive_double) - upper confidence limit incidence rate (true scale) grouping allowed. pop population data must grouped way modelled. - dataframe columns: population (positive_integer) - Size population grouping allowed. ip discrete distribution representing duration infection (probability detection infection). sum one. - dataframe columns: boot (anything + default(1)) - bootstrap identifier probability (proportion) - probability new event period. tau (integer + complete) - days since index event. Minimally grouped : boot (groupings allowed). bootstraps number samples take time point. rounded whole multiple infection duration distribution length. seed random number seed reproducibility ... used","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/infer_prevalence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Infer the prevalence of disease from incidence estimates and population size. â€” infer_prevalence","text":"modelled input additional proportion columns","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/infer_prevalence.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Infer the prevalence of disease from incidence estimates and population size. â€” infer_prevalence","text":"","code":"tmp = example_poisson_rt_smooth() %>%   poisson_locfit_model(window=14) %>%   infer_prevalence(      pop = 10000,      ip = example_ip()   )  if(interactive()) {   plot_prevalence(tmp) }"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/infer_rate_ratio.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate a risk ratio from incidence â€” infer_rate_ratio","title":"Calculate a risk ratio from incidence â€” infer_rate_ratio","text":"enables incidence rates able compared baseline figure incidence. baseline come example population average average incidence time. output incidence rate ratio. incidence_baseline column rate events per unit time. time unit expected date modelled checked.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/infer_rate_ratio.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate a risk ratio from incidence â€” infer_rate_ratio","text":"","code":"infer_rate_ratio(   modelled = i_incidence_model,   base = i_baseline_incidence_data,   ... )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/infer_rate_ratio.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate a risk ratio from incidence â€” infer_rate_ratio","text":"modelled Model output something like poisson_locfit_model(). really makes sense grouped model. - dataframe columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` incidence.fit (double) - estimate incidence rate log scale incidence.se.fit (positive_double) - standard error incidence rate estimate log scale incidence.0.025 (positive_double) - lower confidence limit incidence rate (true scale) incidence.0.5 (positive_double) - median estimate incidence rate (true scale) incidence.0.975 (positive_double) - upper confidence limit incidence rate (true scale) grouping allowed. base baseline data must grouped way modelled. may time series . See example note may change future. - dataframe columns: baseline_incidence (positive_double) - Baseline raw incidence rate count data grouping allowed. ... used","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/infer_rate_ratio.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate a risk ratio from incidence â€” infer_rate_ratio","text":"dataframe incidence rate ratios classes modelled. dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period rate_ratio.0.025 (positive_double) - lower confidence limit rate ratio population group rate_ratio.0.5 (positive_double) - median estimate rate ratio population group rate_ratio.0.975 (positive_double) - upper confidence limit rate ratio population group grouping allowed.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/infer_rate_ratio.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate a risk ratio from incidence â€” infer_rate_ratio","text":"","code":"# not age stratified baseline = example_poisson_locfit() %>%   dplyr::mutate(baseline_incidence = incidence.0.5)  # age stratified rate ratios: tmp = example_poisson_age_stratified() %>%   infer_rate_ratio(baseline) %>%   dplyr::glimpse() #> Rows: 26,790 #> Columns: 24 #> Groups: class [19] #> $ class              <fct> 00_04, 00_04, 00_04, 00_04, 00_04, 00_04, 00_04, 00â€¦ #> $ time               <t[day]> 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, â€¦ #> $ incidence.fit      <dbl> -1.612905, -1.803708, -1.959326, -2.082483, -2.1759â€¦ #> $ incidence.se.fit   <dbl> 1.0533915, 0.9003108, 0.7844360, 0.7012956, 0.64635â€¦ #> $ incidence.0.025    <dbl> 0.02528574, 0.02820419, 0.03029440, 0.03152429, 0.0â€¦ #> $ incidence.0.05     <dbl> 0.03523977, 0.03745604, 0.03878940, 0.03932042, 0.0â€¦ #> $ incidence.0.25     <dbl> 0.09793934, 0.08972926, 0.08304107, 0.07765344, 0.0â€¦ #> $ incidence.0.5      <dbl> 0.19930774, 0.16468709, 0.14095339, 0.12462043, 0.1â€¦ #> $ incidence.0.75     <dbl> 0.40559365, 0.30226304, 0.23925342, 0.19999437, 0.1â€¦ #> $ incidence.0.95     <dbl> 1.1272371, 0.7240980, 0.5121982, 0.3949666, 0.32865â€¦ #> $ incidence.0.975    <dbl> 1.5709871, 0.9616244, 0.6558260, 0.4926439, 0.40289â€¦ #> $ growth.fit         <dbl> -0.2093030305, -0.1855586041, -0.1593989278, -0.131â€¦ #> $ growth.se.fit      <dbl> 0.22418245, 0.20710820, 0.19030250, 0.17387303, 0.1â€¦ #> $ growth.0.025       <dbl> -0.64869255, -0.59148321, -0.53238498, -0.47246827,â€¦ #> $ growth.0.05        <dbl> -0.57805034, -0.52622127, -0.47241869, -0.41767908,â€¦ #> $ growth.0.25        <dbl> -0.360511792, -0.325250959, -0.287756014, -0.248958â€¦ #> $ growth.0.5         <dbl> -0.2093030305, -0.1855586041, -0.1593989278, -0.131â€¦ #> $ growth.0.75        <dbl> -0.058094269, -0.045866249, -0.031041841, -0.014407â€¦ #> $ growth.0.95        <dbl> 0.15944428, 0.15510406, 0.15362083, 0.15431230, 0.1â€¦ #> $ growth.0.975       <dbl> 0.23008649, 0.22036600, 0.21358712, 0.20910150, 0.2â€¦ #> $ baseline_incidence <dbl> 6.530236, 5.968283, 5.379160, 4.794581, 4.238230, 3â€¦ #> $ rate_ratio.0.025   <dbl> 0.003872102, 0.004725680, 0.005631810, 0.006574984,â€¦ #> $ rate_ratio.0.5     <dbl> 0.03052075, 0.02759372, 0.02620361, 0.02599193, 0.0â€¦ #> $ rate_ratio.0.975   <dbl> 0.24057125, 0.16112246, 0.12191979, 0.10275015, 0.0â€¦"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/infer_risk_ratio.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate a normalised risk ratio from proportions â€” infer_risk_ratio","title":"Calculate a normalised risk ratio from proportions â€” infer_risk_ratio","text":"assumes example, case distribution proportions stratified population grouping, e.g. geography age, estimates size population time period. Normalising population proportion allows us compare relative risk outcome groups, compared expected population risk outcome evenly distributed across population. may proportions population fractions may useful compare. moment handle uncertainty.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/infer_risk_ratio.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate a normalised risk ratio from proportions â€” infer_risk_ratio","text":"","code":"infer_risk_ratio(   modelled = i_proportion_model,   base = i_baseline_proportion_data,   ... )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/infer_risk_ratio.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate a normalised risk ratio from proportions â€” infer_risk_ratio","text":"modelled Model output something like proportion_locfit_model() - dataframe columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` proportion.fit (double) - estimate proportion logit scale proportion.se.fit (positive_double) - standard error proportion estimate logit scale proportion.0.025 (proportion) - lower confidence limit proportion (true scale) proportion.0.5 (proportion) - median estimate proportion (true scale) proportion.0.975 (proportion) - upper confidence limit proportion (true scale) grouping allowed. base baseline data must grouped way modelled. may time series . - dataframe columns: baseline_proportion (proportion) - Baseline proportion comparison grouping allowed. ... used","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/infer_risk_ratio.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate a normalised risk ratio from proportions â€” infer_risk_ratio","text":"dataframe relative risk / risk ratio columns. dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period risk_ratio.0.025 (positive_double) - lower confidence limit excess risk ratio population group risk_ratio.0.5 (positive_double) - median estimate excess risk ratio population group risk_ratio.0.975 (positive_double) - upper confidence limit excess risk ratio population group grouping allowed.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/infer_risk_ratio.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate a normalised risk ratio from proportions â€” infer_risk_ratio","text":"","code":"demog = ukc19::uk_population_2019_by_5yr_age %>%   dplyr::filter(name == \"England\")   tmp = example_proportion_age_stratified() %>%   infer_risk_ratio(demog) %>%   dplyr::glimpse() #> Adding missing grouping variables: `name`, `code`, `codeType` #> different column groupings in `modelled` and `base` parameters. #> regrouping `base` data to be compatible with `modelled` grouping #> Rows: 26,790 #> Columns: 27 #> Groups: class [19] #> $ class                  <chr> \"00_04\", \"00_04\", \"00_04\", \"00_04\", \"00_04\", \"0â€¦ #> $ time                   <t[day]> 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, â€¦ #> $ proportion.fit         <dbl> -4.153966, -4.030468, -3.909366, -3.789972, -3.â€¦ #> $ proportion.se.fit      <dbl> 2.786922, 2.612521, 2.449106, 2.296631, 2.15505â€¦ #> $ proportion.0.025       <dbl> 6.663374e-05, 1.061114e-04, 1.649795e-04, 2.506â€¦ #> $ proportion.0.05        <dbl> 0.0001603414, 0.0002416732, 0.0003568686, 0.000â€¦ #> $ proportion.0.25        <dbl> 0.002390842, 0.003040809, 0.003829202, 0.004777â€¦ #> $ proportion.0.5         <dbl> 0.01545928, 0.01745590, 0.01965899, 0.02209692,â€¦ #> $ proportion.0.75        <dbl> 0.09328110, 0.09377845, 0.09470714, 0.09613571,â€¦ #> $ proportion.0.95        <dbl> 0.6059008, 0.5662942, 0.5297285, 0.4969123, 0.4â€¦ #> $ proportion.0.975       <dbl> 0.7872289, 0.7483779, 0.7090538, 0.6706974, 0.6â€¦ #> $ relative.growth.fit    <dbl> 0.12492549, 0.12510534, 0.12559852, 0.12633546,â€¦ #> $ relative.growth.se.fit <dbl> 0.2055049, 0.2043951, 0.2013519, 0.1968045, 0.1â€¦ #> $ relative.growth.0.025  <dbl> -0.2778567, -0.2755017, -0.2690439, -0.2593943,â€¦ #> $ relative.growth.0.05   <dbl> -0.2131000, -0.2110947, -0.2055958, -0.1973791,â€¦ #> $ relative.growth.0.25   <dbl> -0.013685471, -0.012757065, -0.010211256, -0.00â€¦ #> $ relative.growth.0.5    <dbl> 0.12492549, 0.12510534, 0.12559852, 0.12633546,â€¦ #> $ relative.growth.0.75   <dbl> 0.26353645, 0.26296775, 0.26140830, 0.25907808,â€¦ #> $ relative.growth.0.95   <dbl> 0.46295099, 0.46130538, 0.45679289, 0.45005005,â€¦ #> $ relative.growth.0.975  <dbl> 0.5277077, 0.5257124, 0.5202409, 0.5120652, 0.5â€¦ #> $ name                   <chr> \"England\", \"England\", \"England\", \"England\", \"Enâ€¦ #> $ code                   <chr> \"E92000001\", \"E92000001\", \"E92000001\", \"E920000â€¦ #> $ codeType               <chr> \"CTRY20\", \"CTRY20\", \"CTRY20\", \"CTRY20\", \"CTRY20â€¦ #> $ baseline_proportion    <dbl> 0.05862169, 0.05862169, 0.05862169, 0.05862169,â€¦ #> $ risk_ratio.0.025       <dbl> 0.001136674, 0.001810105, 0.002814308, 0.004275â€¦ #> $ risk_ratio.0.5         <dbl> 0.2637127, 0.2977720, 0.3353535, 0.3769410, 0.4â€¦ #> $ risk_ratio.0.975       <dbl> 13.428968, 12.766228, 12.095416, 11.441113, 10.â€¦  if(interactive()) {   plot_growth_phase(tmp,duration = 14*4)+   ggplot2::scale_colour_viridis_d()+   ggplot2::coord_cartesian(xlim=c(-0.25,0.25),ylim=c(0.02,20)) }"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/integer_breaks.html","id":null,"dir":"Reference","previous_headings":"","what":"Strictly integer breaks for continuous scale â€” integer_breaks","title":"Strictly integer breaks for continuous scale â€” integer_breaks","text":"Strictly integer breaks continuous scale","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/integer_breaks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Strictly integer breaks for continuous scale â€” integer_breaks","text":"","code":"integer_breaks(n = 5, ...)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/integer_breaks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Strictly integer breaks for continuous scale â€” integer_breaks","text":"n number breaks ... arguments methods.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/integer_breaks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Strictly integer breaks for continuous scale â€” integer_breaks","text":"ggplot breaks function","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/inv_wallinga_lipsitch.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate a growth rate from a reproduction number and an infectivity profile, â€” inv_wallinga_lipsitch","title":"Calculate a growth rate from a reproduction number and an infectivity profile, â€” inv_wallinga_lipsitch","text":"solves relationship $R_t$ growth rates described Wallinga Lipsitch, get growth rate $R_t$ infectivity profile.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/inv_wallinga_lipsitch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate a growth rate from a reproduction number and an infectivity profile, â€” inv_wallinga_lipsitch","text":"","code":"inv_wallinga_lipsitch(   Rt,   y = i_empirical_ip,   a1 = seq(0.5, length.out = length(y)),   a0 = dplyr::lag(a1, default = 0) )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/inv_wallinga_lipsitch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate a growth rate from a reproduction number and an infectivity profile, â€” inv_wallinga_lipsitch","text":"Rt vector reproduction numbers y empirical infectivity profile probability vector dataframe format: dataframe containing following columns: boot (anything + default(1)) - bootstrap identifier probability (proportion) - probability new event period. a0 (double) - beginning time period (days) a1 (double) - end time period (days) Minimally grouped : boot (groupings allowed). a1 end time infectivity profile probability estimate (defaults 0.5,1.5,2.5,...). a0 start time infectivity profile probability estimate (defaults 0,0.5,1.5,...).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/inv_wallinga_lipsitch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate a growth rate from a reproduction number and an infectivity profile, â€” inv_wallinga_lipsitch","text":"vector growth rates","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/inv_wallinga_lipsitch.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate a growth rate from a reproduction number and an infectivity profile, â€” inv_wallinga_lipsitch","text":"function uses single empirical distribution infectivity profile / generation time. multiple provided average central value chosen (.e. propagate uncertainty infectivity profile)","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/inv_wallinga_lipsitch.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate a growth rate from a reproduction number and an infectivity profile, â€” inv_wallinga_lipsitch","text":"","code":"inv_wallinga_lipsitch(Rt=seq(0.5,2.5,length.out=9), y=example_ip()) #> [1] -0.13146405 -0.05656638  0.00000000  0.04589395  0.08478342  0.11865588 #> [7]  0.14875936  0.17591664  0.20070417"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/is.Date.html","id":null,"dir":"Reference","previous_headings":"","what":"Check whether vector is a date â€” is.Date","title":"Check whether vector is a date â€” is.Date","text":"Check whether vector date","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/is.Date.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check whether vector is a date â€” is.Date","text":"","code":"is.Date(x)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/is.Date.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check whether vector is a date â€” is.Date","text":"x vector check","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/is.Date.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check whether vector is a date â€” is.Date","text":"TRUE dates, FALSE otherwise","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/is.Date.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check whether vector is a date â€” is.Date","text":"","code":"is.Date(Sys.Date()) #> [1] TRUE"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/julian.time_period.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Parts of a POSIXt or Date Object â€” julian.time_period","title":"Extract Parts of a POSIXt or Date Object â€” julian.time_period","text":"Extract weekday, month quarter, Julian time   (days since origin).  generic functions: methods   internal date-time classes documented .","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/julian.time_period.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Parts of a POSIXt or Date Object â€” julian.time_period","text":"","code":"# S3 method for class 'time_period' julian(x, ...)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/julian.time_period.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Parts of a POSIXt or Date Object â€” julian.time_period","text":"x object inheriting class \"POSIXt\" \"Date\". ... arguments methods.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/julian.time_period.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Parts of a POSIXt or Date Object â€” julian.time_period","text":"weekdays months return character   vector names locale use, .e., Sys.getlocale(\"LC_TIME\"). quarters returns character vector \"Q1\"   \"Q4\". julian returns number days (possibly fractional)   since origin, origin \"origin\" attribute.   time calculations R done ignoring leap-seconds.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/julian.time_period.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Extract Parts of a POSIXt or Date Object â€” julian.time_period","text":"components day month year   easy compute: just use .POSIXlt extract   relevant component.  Alternatively (especially components   desired character strings), use strftime.","code":""},{"path":[]},{"path":"https://ai4ci.github.io/ggoutbreak/reference/julian.time_period.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Parts of a POSIXt or Date Object â€” julian.time_period","text":"","code":"## first two are locale dependent: weekdays(.leap.seconds) #>  [1] \"Saturday\"  \"Monday\"    \"Tuesday\"   \"Wednesday\" \"Thursday\"  \"Saturday\"  #>  [7] \"Sunday\"    \"Monday\"    \"Tuesday\"   \"Wednesday\" \"Thursday\"  \"Friday\"    #> [13] \"Monday\"    \"Friday\"    \"Monday\"    \"Tuesday\"   \"Wednesday\" \"Thursday\"  #> [19] \"Friday\"    \"Monday\"    \"Tuesday\"   \"Friday\"    \"Sunday\"    \"Thursday\"  #> [25] \"Sunday\"    \"Wednesday\" \"Sunday\"    months  (.leap.seconds) #>  [1] \"July\"    \"January\" \"January\" \"January\" \"January\" \"January\" \"January\" #>  [8] \"January\" \"January\" \"July\"    \"July\"    \"July\"    \"July\"    \"January\" #> [15] \"January\" \"January\" \"July\"    \"July\"    \"July\"    \"January\" \"July\"    #> [22] \"January\" \"January\" \"January\" \"July\"    \"July\"    \"January\" quarters(.leap.seconds) #>  [1] \"Q3\" \"Q1\" \"Q1\" \"Q1\" \"Q1\" \"Q1\" \"Q1\" \"Q1\" \"Q1\" \"Q3\" \"Q3\" \"Q3\" \"Q3\" \"Q1\" \"Q1\" #> [16] \"Q1\" \"Q3\" \"Q3\" \"Q3\" \"Q1\" \"Q3\" \"Q1\" \"Q1\" \"Q1\" \"Q3\" \"Q3\" \"Q1\"  ## Show how easily you get month, day, year, day (of {month, week, yr}), ... : ## (remember to count from 0 (!): mon = 0..11, wday = 0..6,  etc !!)  ##' Transform (Time-)Date vector  to  convenient data frame : dt2df <- function(dt, dName = deparse(substitute(dt))) {     DF <- as.data.frame(unclass(as.POSIXlt( dt )))     `names<-`(cbind(dt, DF, deparse.level=0L), c(dName, names(DF))) } ## e.g., dt2df(.leap.seconds)    # date+time #>    .leap.seconds sec min hour mday mon year wday yday isdst zone gmtoff #> 1     1972-07-01   0   0    0    1   6   72    6  182     0  GMT      0 #> 2     1973-01-01   0   0    0    1   0   73    1    0     0  GMT      0 #> 3     1974-01-01   0   0    0    1   0   74    2    0     0  GMT      0 #> 4     1975-01-01   0   0    0    1   0   75    3    0     0  GMT      0 #> 5     1976-01-01   0   0    0    1   0   76    4    0     0  GMT      0 #> 6     1977-01-01   0   0    0    1   0   77    6    0     0  GMT      0 #> 7     1978-01-01   0   0    0    1   0   78    0    0     0  GMT      0 #> 8     1979-01-01   0   0    0    1   0   79    1    0     0  GMT      0 #> 9     1980-01-01   0   0    0    1   0   80    2    0     0  GMT      0 #> 10    1981-07-01   0   0    0    1   6   81    3  181     0  GMT      0 #> 11    1982-07-01   0   0    0    1   6   82    4  181     0  GMT      0 #> 12    1983-07-01   0   0    0    1   6   83    5  181     0  GMT      0 #> 13    1985-07-01   0   0    0    1   6   85    1  181     0  GMT      0 #> 14    1988-01-01   0   0    0    1   0   88    5    0     0  GMT      0 #> 15    1990-01-01   0   0    0    1   0   90    1    0     0  GMT      0 #> 16    1991-01-01   0   0    0    1   0   91    2    0     0  GMT      0 #> 17    1992-07-01   0   0    0    1   6   92    3  182     0  GMT      0 #> 18    1993-07-01   0   0    0    1   6   93    4  181     0  GMT      0 #> 19    1994-07-01   0   0    0    1   6   94    5  181     0  GMT      0 #> 20    1996-01-01   0   0    0    1   0   96    1    0     0  GMT      0 #> 21    1997-07-01   0   0    0    1   6   97    2  181     0  GMT      0 #> 22    1999-01-01   0   0    0    1   0   99    5    0     0  GMT      0 #> 23    2006-01-01   0   0    0    1   0  106    0    0     0  GMT      0 #> 24    2009-01-01   0   0    0    1   0  109    4    0     0  GMT      0 #> 25    2012-07-01   0   0    0    1   6  112    0  182     0  GMT      0 #> 26    2015-07-01   0   0    0    1   6  115    3  181     0  GMT      0 #> 27    2017-01-01   0   0    0    1   0  117    0    0     0  GMT      0 dt2df(Sys.Date() + 0:9) # date #>    Sys.Date() + 0:9 sec min hour mday mon year wday yday isdst zone gmtoff #> 1        2025-12-11   0   0    0   11  11  125    4  344     0  UTC      0 #> 2        2025-12-12   0   0    0   12  11  125    5  345     0  UTC      0 #> 3        2025-12-13   0   0    0   13  11  125    6  346     0  UTC      0 #> 4        2025-12-14   0   0    0   14  11  125    0  347     0  UTC      0 #> 5        2025-12-15   0   0    0   15  11  125    1  348     0  UTC      0 #> 6        2025-12-16   0   0    0   16  11  125    2  349     0  UTC      0 #> 7        2025-12-17   0   0    0   17  11  125    3  350     0  UTC      0 #> 8        2025-12-18   0   0    0   18  11  125    4  351     0  UTC      0 #> 9        2025-12-19   0   0    0   19  11  125    5  352     0  UTC      0 #> 10       2025-12-20   0   0    0   20  11  125    6  353     0  UTC      0  ##' Even simpler:  Date -> Matrix - dropping time info {sec,min,hour, isdst} d2mat <- function(x) simplify2array(unclass(as.POSIXlt(x))[4:7]) ## e.g., d2mat(seq(as.Date(\"2000-02-02\"), by=1, length.out=30)) # has R 1.0.0's release date #>       mday mon year wday #>  [1,]    2   1  100    3 #>  [2,]    3   1  100    4 #>  [3,]    4   1  100    5 #>  [4,]    5   1  100    6 #>  [5,]    6   1  100    0 #>  [6,]    7   1  100    1 #>  [7,]    8   1  100    2 #>  [8,]    9   1  100    3 #>  [9,]   10   1  100    4 #> [10,]   11   1  100    5 #> [11,]   12   1  100    6 #> [12,]   13   1  100    0 #> [13,]   14   1  100    1 #> [14,]   15   1  100    2 #> [15,]   16   1  100    3 #> [16,]   17   1  100    4 #> [17,]   18   1  100    5 #> [18,]   19   1  100    6 #> [19,]   20   1  100    0 #> [20,]   21   1  100    1 #> [21,]   22   1  100    2 #> [22,]   23   1  100    3 #> [23,]   24   1  100    4 #> [24,]   25   1  100    5 #> [25,]   26   1  100    6 #> [26,]   27   1  100    0 #> [27,]   28   1  100    1 #> [28,]   29   1  100    2 #> [29,]    1   2  100    3 #> [30,]    2   2  100    4  # \\donttest{ ## Julian Day Number (JDN, https://en.wikipedia.org/wiki/Julian_day) ## is the number of days since noon UTC on the first day of 4317 BCE. ## in the proleptic Julian calendar.  To more recently, in ## 'Terrestrial Time' which differs from UTC by a few seconds ## See https://en.wikipedia.org/wiki/Terrestrial_Time julian(Sys.Date(), -2440588) # from a day #> [1] 2461021 #> attr(,\"origin\") #> [1] -2440588 floor(as.numeric(julian(Sys.time())) + 2440587.5) # from a date-time #> [1] 2461021 # }"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/labels.time_period.html","id":null,"dir":"Reference","previous_headings":"","what":"Label a time period â€” labels.time_period","title":"Label a time period â€” labels.time_period","text":"Create set labels time period based start duration period. format configurable using start end dates dfmt ifmt parameters, however time period names used preference.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/labels.time_period.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Label a time period â€” labels.time_period","text":"","code":"# S3 method for class 'time_period' labels(   object,   ...,   dfmt = \"%d/%b\",   ifmt = \"{start} â€” {end}\",   na.value = \"Unknown\" )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/labels.time_period.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Label a time period â€” labels.time_period","text":"object set decimal times time_period ... used dfmt strptime format specification format date ifmt glue spec referring start end period formatted date na.value label NA times","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/labels.time_period.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Label a time period â€” labels.time_period","text":"set character labels time","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/labels.time_period.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Label a time period â€” labels.time_period","text":"","code":"eg = as.time_period(Sys.Date()+0:10*7, unit=\"1 week\", anchor=\"start\")  labels(eg) #>  [1] \"11/Dec â€” 17/Dec\" \"18/Dec â€” 24/Dec\" \"25/Dec â€” 31/Dec\" \"01/Jan â€” 07/Jan\" #>  [5] \"08/Jan â€” 14/Jan\" \"15/Jan â€” 21/Jan\" \"22/Jan â€” 28/Jan\" \"29/Jan â€” 04/Feb\" #>  [9] \"05/Feb â€” 11/Feb\" \"12/Feb â€” 18/Feb\" \"19/Feb â€” 25/Feb\" labels(eg, ifmt=\"{start}\", dfmt=\"%d/%b/%y\") #>  [1] \"11/Dec/25\" \"18/Dec/25\" \"25/Dec/25\" \"01/Jan/26\" \"08/Jan/26\" \"15/Jan/26\" #>  [7] \"22/Jan/26\" \"29/Jan/26\" \"05/Feb/26\" \"12/Feb/26\" \"19/Feb/26\" labels(eg, ifmt=\"until {end}\", dfmt=\"%d %b %Y\") #>  [1] \"until 17 Dec 2025\" \"until 24 Dec 2025\" \"until 31 Dec 2025\" #>  [4] \"until 07 Jan 2026\" \"until 14 Jan 2026\" \"until 21 Jan 2026\" #>  [7] \"until 28 Jan 2026\" \"until 04 Feb 2026\" \"until 11 Feb 2026\" #> [10] \"until 18 Feb 2026\" \"until 25 Feb 2026\"  # labels retained in constructor: eg2 = Sys.Date()+0:10*7 names(eg2) = paste0(\"week \",0:10) labels(eg2) #>  [1] \"week 0\"  \"week 1\"  \"week 2\"  \"week 3\"  \"week 4\"  \"week 5\"  \"week 6\"  #>  [8] \"week 7\"  \"week 8\"  \"week 9\"  \"week 10\" labels(as.time_period(eg2, anchor=\"start\")) #>  [1] \"week 0\"  \"week 1\"  \"week 2\"  \"week 3\"  \"week 4\"  \"week 5\"  \"week 6\"  #>  [8] \"week 7\"  \"week 8\"  \"week 9\"  \"week 10\""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/linelist.html","id":null,"dir":"Reference","previous_headings":"","what":"Coerce an object to a ggoutbreak compatible case linelist. â€” linelist","title":"Coerce an object to a ggoutbreak compatible case linelist. â€” linelist","text":"Coerce object ggoutbreak compatible case linelist.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/linelist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coerce an object to a ggoutbreak compatible case linelist. â€” linelist","text":"","code":"linelist(x, ...)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/linelist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coerce an object to a ggoutbreak compatible case linelist. â€” linelist","text":"x object coerce ... Named arguments passed .time_period unit length one unit time. either integer number days, specification \"1 week\", another time_period. x time_period, unit different x return rescaled time_period using new units. start_date zero time date something can coerced date. x input already time_period different start_date x recalibrated use new start date. anchor relevant x vector dates, date, \"start\" \"end\" weekday name e.g. \"mon\". vector dates x use anchor find reference date time-series. provided current defaults used. (see set_defaults())","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/linelist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coerce an object to a ggoutbreak compatible case linelist. â€” linelist","text":"minimally time stamped linelist dataframe dataframe containing following columns: time (ggoutbreak::time_period) - set events timestamp time_period grouping allowed.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/linelist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coerce an object to a ggoutbreak compatible case linelist. â€” linelist","text":"","code":"(Sys.Date()+stats::runif(100)*7) %>% linelist() #> # A tibble: 100 Ã— 1 #>         time #>    <t[week]> #>  1     310.9 #>  2       311 #>  3     310.9 #>  4       311 #>  5     310.7 #>  6       311 #>  7     311.1 #>  8     310.8 #>  9     310.2 #> 10     310.8 #> # â„¹ 90 more rows"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/logit-norm.html","id":null,"dir":"Reference","previous_headings":"","what":"Logit-normal distribution â€” logit-norm","title":"Logit-normal distribution â€” logit-norm","text":"logit-normal distribution support 0 1.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/logit-norm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logit-normal distribution â€” logit-norm","text":"n number observations x vector quantiles (0<x<1) q vector quantiles (0<q<1) p vector probabilities log logical; TRUE, probabilities p given log(p). log.p logical; TRUE, probabilities p given log(p). lower.tail logical; TRUE (default), probabilities P[X<=x] otherwise P[X>x]. meanlogit mean logit scale sdlogit sd logit scale prob.0.5 median true scale kappa dispersion parameter 0 (none) 1 maximum dispersion","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/logit-norm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Logit-normal distribution â€” logit-norm","text":"vector probabilities, quantiles, densities samples.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/logit_trans.html","id":null,"dir":"Reference","previous_headings":"","what":"logit scale â€” logit_trans","title":"logit scale â€” logit_trans","text":"Perform logit scaling correct axis formatting. used directly ggplot (e.g. ggplot2::scale_y_continuous(trans = \"logit\") )","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/logit_trans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"logit scale â€” logit_trans","text":"","code":"logit_trans(n = 5, ...)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/logit_trans.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"logit scale â€” logit_trans","text":"n number breaks ... used, compatibility","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/logit_trans.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"logit scale â€” logit_trans","text":"scales object","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/logit_trans.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"logit scale â€” logit_trans","text":"","code":"dplyr::tibble(pvalue = c(0.001, 0.05, 0.1), fold_change = 1:3) %>%  ggplot2::ggplot(ggplot2::aes(fold_change , pvalue)) +  ggplot2::geom_point() +  ggplot2::scale_y_continuous(trans = \"logit\")"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/make_empirical_ip.html","id":null,"dir":"Reference","previous_headings":"","what":"Recover a long format infectivity profile from an EpiEstim style matrix â€” make_empirical_ip","title":"Recover a long format infectivity profile from an EpiEstim style matrix â€” make_empirical_ip","text":"Recover long format infectivity profile EpiEstim style matrix","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/make_empirical_ip.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Recover a long format infectivity profile from an EpiEstim style matrix â€” make_empirical_ip","text":"","code":"make_empirical_ip(omega, normalise = TRUE)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/make_empirical_ip.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Recover a long format infectivity profile from an EpiEstim style matrix â€” make_empirical_ip","text":"omega matrix probabilities, starting time zero, columns representing one possible infectivity profile, fist value probability time zero (0.5). Alternatively can vector probabilities one single profile, resulting 1 bootstrap. normalise probability mass function? case make sum equal one (default). FALSE input matrix, vector clipped maximum value one. number PMF scaled value.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/make_empirical_ip.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Recover a long format infectivity profile from an EpiEstim style matrix â€” make_empirical_ip","text":"long format ip delay distribution","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/make_empirical_ip.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Recover a long format infectivity profile from an EpiEstim style matrix â€” make_empirical_ip","text":"","code":"format_ip(make_empirical_ip(c(0,0,1,1,1,2,2,2,1,1))) #> [1] \"mean: 5.64; sd: 2.03\""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/make_fixed_ip.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a simple discrete infectivity profile from a gamma distribution â€” make_fixed_ip","title":"Generate a simple discrete infectivity profile from a gamma distribution â€” make_fixed_ip","text":"Generate simple discrete infectivity profile gamma distribution","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/make_fixed_ip.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a simple discrete infectivity profile from a gamma distribution â€” make_fixed_ip","text":"","code":"make_fixed_ip(mean, sd = sqrt(mean), epiestim_compat = FALSE)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/make_fixed_ip.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a simple discrete infectivity profile from a gamma distribution â€” make_fixed_ip","text":"mean mean gamma distribution sd sd gamma distribution epiestim_compat discretisation support EpiEstim (.e. Pr(x<1) = 0)","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/make_fixed_ip.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a simple discrete infectivity profile from a gamma distribution â€” make_fixed_ip","text":"discrete infectivity profile 1 bootstrap","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/make_fixed_ip.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a simple discrete infectivity profile from a gamma distribution â€” make_fixed_ip","text":"","code":"tmp = make_fixed_ip(5,2)  if(interactive()) {   plot_ip(tmp, alpha=1) }"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/make_gamma_ip.html","id":null,"dir":"Reference","previous_headings":"","what":"Make an infectivity profile from published data â€” make_gamma_ip","title":"Make an infectivity profile from published data â€” make_gamma_ip","text":"infectivity profile typically fitted data MCMC reported median 95% credible intervals, mean, SD (usually) gamma distribution. function generates discrete infectivity probability distribution representing chance infectee infected specific day infector infected (given infectee infected).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/make_gamma_ip.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make an infectivity profile from published data â€” make_gamma_ip","text":"","code":"make_gamma_ip(   median_of_mean,   lower_ci_of_mean = median_of_mean,   upper_ci_of_mean = median_of_mean,   median_of_sd = sqrt(median_of_mean),   lower_ci_of_sd = median_of_sd,   upper_ci_of_sd = median_of_sd,   correlation = NA,   n_boots = 100,   epiestim_compat = FALSE,   epiestim_sampler = epiestim_compat,   z_crit = 0.95,   seed = Sys.time() )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/make_gamma_ip.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make an infectivity profile from published data â€” make_gamma_ip","text":"median_of_mean, lower_ci_of_mean, upper_ci_of_mean Quantiles infectivity profile mean. median_of_sd, lower_ci_of_sd, upper_ci_of_sd Quantiles infectivity profile SD. correlation correlation mean sd. optional inferred provided. n_boots number samples generate. epiestim_compat Use EpiEstim generate infectivity profiles. true value results infectivity profile probability 0 day 0. false infectivity profile may include density zero even negative values. epiestim_sampler Use EpiEstim generate random samples using independent truncated normal distributions mean SD based parameters . FALSE use log normal distributions correlation. z_crit width confidence intervals (defaults 95%). seed RNG seed","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/make_gamma_ip.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make an infectivity profile from published data â€” make_gamma_ip","text":"long format infectivity profile data frame, list dataframes input vector.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/make_gamma_ip.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Make an infectivity profile from published data â€” make_gamma_ip","text":"EpiEstim generates distributions sampling truncated normal distribution mean sd. means sds thus produced discretised using gamma distribution offset 1 day, enforce probability infection day zero zero. constraint changes shape distribution somewhat may cause small bias (although ground truth evaluate). function two different sampling discretisation strategy provided. sampler uses log-normal distributions mean SD degree correlation. discretizer assigns probabilities direct CDF gamma distribution without offset. results non zero values probability time zero can used Rt estimation methods can handle zero/negative serial intervals (e.g. rt_from_incidence rt_from_renewal, rt_from_growth_rate). alternative follows EpiEstims algorithm.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/make_gamma_ip.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make an infectivity profile from published data â€” make_gamma_ip","text":"","code":"# COVID-19 estimates from Ganyani et al 2020. tmp = make_gamma_ip(5.2, 3.78, 6.78, 1.72, 0.91, 3.93,   epiestim_sampler=FALSE, epiestim_compat=FALSE)  tmp %>%   dplyr::group_by(boot) %>%   dplyr::summarise(     mean = sum(tau*probability),     sd = sqrt(sum((tau-sum(tau*probability))^2*probability))   ) %>%   dplyr::summarise(     mean = sprintf(\"%1.2f [%1.2f-%1.2f]\",       stats::quantile(mean,0.5),       stats::quantile(mean,0.025),       stats::quantile(mean,0.975)),     sd = sprintf(\"%1.2f [%1.2f-%1.2f]\",       stats::quantile(sd,0.5),       stats::quantile(sd,0.025),       stats::quantile(sd,0.975))   ) #> # A tibble: 1 Ã— 2 #>   mean             sd               #>   <chr>            <chr>            #> 1 5.26 [4.18-6.99] 1.90 [0.89-4.17]  if(interactive()) {   plot_ip(tmp, alpha=0.1) +     ggplot2::coord_cartesian(xlim=c(0,15)) }  means = c(3,4,5) ips = make_gamma_ip(means)  if (interactive()) {   purrr::map2(ips,means, ~ .x %>% dplyr::mutate(label = sprintf(\"Mean: %1.2f\",.y))) %>%     purrr::map( ~ plot_ip(.x,alpha=0.1)+ggplot2::facet_wrap(~label)) }"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/make_posterior_ip.html","id":null,"dir":"Reference","previous_headings":"","what":"Make an infectivity profile from posterior samples â€” make_posterior_ip","title":"Make an infectivity profile from posterior samples â€” make_posterior_ip","text":"infectivity profile typically fitted data MCMC gamma distribution. function generates discrete infectivity probability distribution representing chance infectee infected specific day infector infected (given infectee infected), posterior samples.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/make_posterior_ip.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make an infectivity profile from posterior samples â€” make_posterior_ip","text":"","code":"make_posterior_ip(   ...,   mean,   sd,   shape,   rate,   scale,   epiestim_compat = FALSE,   n_boots = 100 )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/make_posterior_ip.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make an infectivity profile from posterior samples â€” make_posterior_ip","text":"... used, must empty mean vector gamma distribution means sd vector gamma distribution sds shape vector gamma distribution shape parameters rate vector gamma distribution rate parameters scale vector gamma distribution scale parameters epiestim_compat Use EpiEstim generate infectivity profiles. true value results infectivity profile probability 0 day 0. n_boots posterior samples limit maximum n_boots ip distributions created (randomly sampled).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/make_posterior_ip.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make an infectivity profile from posterior samples â€” make_posterior_ip","text":"long format ip delay distribution","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/make_posterior_ip.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Make an infectivity profile from posterior samples â€” make_posterior_ip","text":"using EpiEstim coarseDataTools::dic.fit.mcmc output MCMC S4 object samples slot, containing dataframe shape=var1 scale=var2 columns. use output make_posterior_ip invoke like : .call(make_posterior_ip, SI_fit_clever@samples %>% dplyr::rename(shape=var1, scale=var2)) N.b. one combination mean sd, shape rate, shape scale, required.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/make_posterior_ip.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make an infectivity profile from posterior samples â€” make_posterior_ip","text":"","code":"tmp = make_posterior_ip(   mean = stats::rnorm(100,5,0.1),   sd = stats::rnorm(100,1.5,0.1) ) tmp %>% dplyr::glimpse() #> Rows: 1,400 #> Columns: 5 #> Groups: boot [100] #> $ tau         <int> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 0, 1, 2, 3, â€¦ #> $ a0          <dbl> 0.0, 0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5, 10.â€¦ #> $ a1          <dbl> 0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5, 10.5, 11â€¦ #> $ probability <dbl> 4.834025e-09, 3.592446e-04, 2.028943e-02, 1.283010e-01, 2.â€¦ #> $ boot        <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2â€¦ if (interactive()) plot_ip(tmp)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/make_resampled_ip.html","id":null,"dir":"Reference","previous_headings":"","what":"Re-sample an empirical IP distribution direct from data â€” make_resampled_ip","title":"Re-sample an empirical IP distribution direct from data â€” make_resampled_ip","text":"Suits larger contact tracing data sets delay 2 events may may precisely known.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/make_resampled_ip.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Re-sample an empirical IP distribution direct from data â€” make_resampled_ip","text":"","code":"make_resampled_ip(   tau,   min_tau = pmax(tau - 0.5, truncate),   max_tau = tau + 0.5,   add_noise = TRUE,   truncate = 0,   n_boots = 100,   seed = Sys.time() )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/make_resampled_ip.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Re-sample an empirical IP distribution direct from data â€” make_resampled_ip","text":"tau delay first second events min_tau minimum delay interval censored delays max_tau maximum delay interval censored delays add_noise adds noise date point replicate truncate minimum realistic value parameter n_boots number replicates generate seed random number seed reproducibility","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/make_resampled_ip.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Re-sample an empirical IP distribution direct from data â€” make_resampled_ip","text":"long format ip delay distribution","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/make_resampled_ip.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Re-sample an empirical IP distribution direct from data â€” make_resampled_ip","text":"","code":"tau = rgamma2(100, 5,2) ip = make_resampled_ip(min_tau = tau-1, max_tau = tau+1, seed = 100) if(interactive()) {   plot_ip(ip,alpha=0.1) }"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/max_date.html","id":null,"dir":"Reference","previous_headings":"","what":"The maximum of a set of dates â€” max_date","title":"The maximum of a set of dates â€” max_date","text":"max.Date returns integer -Inf set NA dates. usually inconvenient.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/max_date.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The maximum of a set of dates â€” max_date","text":"","code":"max_date(x, ...)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/max_date.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The maximum of a set of dates â€” max_date","text":"x vector dates ... ignored","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/max_date.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The maximum of a set of dates â€” max_date","text":"date. `0001-01-01â€œ well defined minimum.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/max_date.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The maximum of a set of dates â€” max_date","text":"","code":"max_date(NA) #> [1] \"1-01-01\""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/min_date.html","id":null,"dir":"Reference","previous_headings":"","what":"The minimum of a set of dates â€” min_date","title":"The minimum of a set of dates â€” min_date","text":"min.Date returns integer Inf set NA dates. usually inconvenient.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/min_date.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The minimum of a set of dates â€” min_date","text":"","code":"min_date(x, ...)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/min_date.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The minimum of a set of dates â€” min_date","text":"x vector dates ... ignored","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/min_date.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The minimum of a set of dates â€” min_date","text":"date. 9999-12-31 well defined minimum.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/min_date.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The minimum of a set of dates â€” min_date","text":"","code":"min_date(NA) #> [1] \"9999-12-31\""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/months.time_period.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Parts of a POSIXt or Date Object â€” months.time_period","title":"Extract Parts of a POSIXt or Date Object â€” months.time_period","text":"Extract weekday, month quarter, Julian time   (days since origin).  generic functions: methods   internal date-time classes documented .","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/months.time_period.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Parts of a POSIXt or Date Object â€” months.time_period","text":"","code":"# S3 method for class 'time_period' months(x, abbreviate = FALSE)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/months.time_period.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Parts of a POSIXt or Date Object â€” months.time_period","text":"x object inheriting class \"POSIXt\" \"Date\". abbreviate logical vector (possibly recycled).  names     abbreviated?","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/months.time_period.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Parts of a POSIXt or Date Object â€” months.time_period","text":"weekdays months return character   vector names locale use, .e., Sys.getlocale(\"LC_TIME\"). quarters returns character vector \"Q1\"   \"Q4\". julian returns number days (possibly fractional)   since origin, origin \"origin\" attribute.   time calculations R done ignoring leap-seconds.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/months.time_period.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Extract Parts of a POSIXt or Date Object â€” months.time_period","text":"components day month year   easy compute: just use .POSIXlt extract   relevant component.  Alternatively (especially components   desired character strings), use strftime.","code":""},{"path":[]},{"path":"https://ai4ci.github.io/ggoutbreak/reference/months.time_period.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Parts of a POSIXt or Date Object â€” months.time_period","text":"","code":"## first two are locale dependent: weekdays(.leap.seconds) #>  [1] \"Saturday\"  \"Monday\"    \"Tuesday\"   \"Wednesday\" \"Thursday\"  \"Saturday\"  #>  [7] \"Sunday\"    \"Monday\"    \"Tuesday\"   \"Wednesday\" \"Thursday\"  \"Friday\"    #> [13] \"Monday\"    \"Friday\"    \"Monday\"    \"Tuesday\"   \"Wednesday\" \"Thursday\"  #> [19] \"Friday\"    \"Monday\"    \"Tuesday\"   \"Friday\"    \"Sunday\"    \"Thursday\"  #> [25] \"Sunday\"    \"Wednesday\" \"Sunday\"    months  (.leap.seconds) #>  [1] \"July\"    \"January\" \"January\" \"January\" \"January\" \"January\" \"January\" #>  [8] \"January\" \"January\" \"July\"    \"July\"    \"July\"    \"July\"    \"January\" #> [15] \"January\" \"January\" \"July\"    \"July\"    \"July\"    \"January\" \"July\"    #> [22] \"January\" \"January\" \"January\" \"July\"    \"July\"    \"January\" quarters(.leap.seconds) #>  [1] \"Q3\" \"Q1\" \"Q1\" \"Q1\" \"Q1\" \"Q1\" \"Q1\" \"Q1\" \"Q1\" \"Q3\" \"Q3\" \"Q3\" \"Q3\" \"Q1\" \"Q1\" #> [16] \"Q1\" \"Q3\" \"Q3\" \"Q3\" \"Q1\" \"Q3\" \"Q1\" \"Q1\" \"Q1\" \"Q3\" \"Q3\" \"Q1\"  ## Show how easily you get month, day, year, day (of {month, week, yr}), ... : ## (remember to count from 0 (!): mon = 0..11, wday = 0..6,  etc !!)  ##' Transform (Time-)Date vector  to  convenient data frame : dt2df <- function(dt, dName = deparse(substitute(dt))) {     DF <- as.data.frame(unclass(as.POSIXlt( dt )))     `names<-`(cbind(dt, DF, deparse.level=0L), c(dName, names(DF))) } ## e.g., dt2df(.leap.seconds)    # date+time #>    .leap.seconds sec min hour mday mon year wday yday isdst zone gmtoff #> 1     1972-07-01   0   0    0    1   6   72    6  182     0  GMT      0 #> 2     1973-01-01   0   0    0    1   0   73    1    0     0  GMT      0 #> 3     1974-01-01   0   0    0    1   0   74    2    0     0  GMT      0 #> 4     1975-01-01   0   0    0    1   0   75    3    0     0  GMT      0 #> 5     1976-01-01   0   0    0    1   0   76    4    0     0  GMT      0 #> 6     1977-01-01   0   0    0    1   0   77    6    0     0  GMT      0 #> 7     1978-01-01   0   0    0    1   0   78    0    0     0  GMT      0 #> 8     1979-01-01   0   0    0    1   0   79    1    0     0  GMT      0 #> 9     1980-01-01   0   0    0    1   0   80    2    0     0  GMT      0 #> 10    1981-07-01   0   0    0    1   6   81    3  181     0  GMT      0 #> 11    1982-07-01   0   0    0    1   6   82    4  181     0  GMT      0 #> 12    1983-07-01   0   0    0    1   6   83    5  181     0  GMT      0 #> 13    1985-07-01   0   0    0    1   6   85    1  181     0  GMT      0 #> 14    1988-01-01   0   0    0    1   0   88    5    0     0  GMT      0 #> 15    1990-01-01   0   0    0    1   0   90    1    0     0  GMT      0 #> 16    1991-01-01   0   0    0    1   0   91    2    0     0  GMT      0 #> 17    1992-07-01   0   0    0    1   6   92    3  182     0  GMT      0 #> 18    1993-07-01   0   0    0    1   6   93    4  181     0  GMT      0 #> 19    1994-07-01   0   0    0    1   6   94    5  181     0  GMT      0 #> 20    1996-01-01   0   0    0    1   0   96    1    0     0  GMT      0 #> 21    1997-07-01   0   0    0    1   6   97    2  181     0  GMT      0 #> 22    1999-01-01   0   0    0    1   0   99    5    0     0  GMT      0 #> 23    2006-01-01   0   0    0    1   0  106    0    0     0  GMT      0 #> 24    2009-01-01   0   0    0    1   0  109    4    0     0  GMT      0 #> 25    2012-07-01   0   0    0    1   6  112    0  182     0  GMT      0 #> 26    2015-07-01   0   0    0    1   6  115    3  181     0  GMT      0 #> 27    2017-01-01   0   0    0    1   0  117    0    0     0  GMT      0 dt2df(Sys.Date() + 0:9) # date #>    Sys.Date() + 0:9 sec min hour mday mon year wday yday isdst zone gmtoff #> 1        2025-12-11   0   0    0   11  11  125    4  344     0  UTC      0 #> 2        2025-12-12   0   0    0   12  11  125    5  345     0  UTC      0 #> 3        2025-12-13   0   0    0   13  11  125    6  346     0  UTC      0 #> 4        2025-12-14   0   0    0   14  11  125    0  347     0  UTC      0 #> 5        2025-12-15   0   0    0   15  11  125    1  348     0  UTC      0 #> 6        2025-12-16   0   0    0   16  11  125    2  349     0  UTC      0 #> 7        2025-12-17   0   0    0   17  11  125    3  350     0  UTC      0 #> 8        2025-12-18   0   0    0   18  11  125    4  351     0  UTC      0 #> 9        2025-12-19   0   0    0   19  11  125    5  352     0  UTC      0 #> 10       2025-12-20   0   0    0   20  11  125    6  353     0  UTC      0  ##' Even simpler:  Date -> Matrix - dropping time info {sec,min,hour, isdst} d2mat <- function(x) simplify2array(unclass(as.POSIXlt(x))[4:7]) ## e.g., d2mat(seq(as.Date(\"2000-02-02\"), by=1, length.out=30)) # has R 1.0.0's release date #>       mday mon year wday #>  [1,]    2   1  100    3 #>  [2,]    3   1  100    4 #>  [3,]    4   1  100    5 #>  [4,]    5   1  100    6 #>  [5,]    6   1  100    0 #>  [6,]    7   1  100    1 #>  [7,]    8   1  100    2 #>  [8,]    9   1  100    3 #>  [9,]   10   1  100    4 #> [10,]   11   1  100    5 #> [11,]   12   1  100    6 #> [12,]   13   1  100    0 #> [13,]   14   1  100    1 #> [14,]   15   1  100    2 #> [15,]   16   1  100    3 #> [16,]   17   1  100    4 #> [17,]   18   1  100    5 #> [18,]   19   1  100    6 #> [19,]   20   1  100    0 #> [20,]   21   1  100    1 #> [21,]   22   1  100    2 #> [22,]   23   1  100    3 #> [23,]   24   1  100    4 #> [24,]   25   1  100    5 #> [25,]   26   1  100    6 #> [26,]   27   1  100    0 #> [27,]   28   1  100    1 #> [28,]   29   1  100    2 #> [29,]    1   2  100    3 #> [30,]    2   2  100    4  # \\donttest{ ## Julian Day Number (JDN, https://en.wikipedia.org/wiki/Julian_day) ## is the number of days since noon UTC on the first day of 4317 BCE. ## in the proleptic Julian calendar.  To more recently, in ## 'Terrestrial Time' which differs from UTC by a few seconds ## See https://en.wikipedia.org/wiki/Terrestrial_Time julian(Sys.Date(), -2440588) # from a day #> [1] 2461021 #> attr(,\"origin\") #> [1] -2440588 floor(as.numeric(julian(Sys.time())) + 2440587.5) # from a date-time #> [1] 2461021 # }"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/multinomial_nnet_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Multinomial time-series model. â€” multinomial_nnet_model","title":"Multinomial time-series model. â€” multinomial_nnet_model","text":"Takes list times, classes counts, e.g. COGUK variant like data set time, (multinomial) class (e.g. variant) count count time period. Fits quadratic B-spline time proportion data using nnet::multinom, approx one degree freedom per class per window units time series.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/multinomial_nnet_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multinomial time-series model. â€” multinomial_nnet_model","text":"","code":"multinomial_nnet_model(   d = i_multinomial_input,   ...,   window = 14,   frequency = \"1 day\",   predict = TRUE,   .progress = interactive() )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/multinomial_nnet_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multinomial time-series model. â€” multinomial_nnet_model","text":"d multi-class count input dataframe - dataframe columns: class (factor) - factor specifying type observation. things like variant, serotype, multinomial model. missing data points ignored. count (positive_integer) - Positive case counts associated specified time frame time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` Minimally grouped : class (groupings allowed). ... used window number data points knots, smaller values result less smoothing, large value . frequency temporal density output estimates. predict result prediction. false return model. .progress show CLI progress bar","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/multinomial_nnet_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multinomial time-series model. â€” multinomial_nnet_model","text":"new dataframe time (time period), class, proportion.0.5, model object","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/multinomial_nnet_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multinomial time-series model. â€” multinomial_nnet_model","text":"Additional groupings treated distinct proportions models.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/multinomial_nnet_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multinomial time-series model. â€” multinomial_nnet_model","text":"","code":"data = example_poisson_rt_2class() tmp = data %>% multinomial_nnet_model(window=14) #> # weights:  28 (13 variable) #> initial  value 44413.405594  #> iter  10 value 39246.733943 #> iter  20 value 38298.920341 #> iter  20 value 38298.920309 #> iter  20 value 38298.920308 #> final  value 38298.920308  #> converged  if (interactive()) {   plot_multinomial(tmp, date_labels=\"%b %y\") }"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/normalise_count.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate a normalised count per capita â€” normalise_count","title":"Calculate a normalised count per capita â€” normalise_count","text":"assumes positive disease counts stratified population grouping, e.g. geography age, estimates size population time period. Normalising population size allows us compare groups.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/normalise_count.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate a normalised count per capita â€” normalise_count","text":"","code":"normalise_count(   raw = i_incidence_data,   pop = i_population_data,   ...,   population_unit = 1e+05,   normalise_time = FALSE )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/normalise_count.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate a normalised count per capita â€” normalise_count","text":"raw count data - dataframe columns: count (positive_integer) - Positive case counts associated specified time frame time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` grouping allowed. pop population data must grouped way raw. - dataframe columns: population (positive_integer) - Size population grouping allowed. ... used population_unit population unit want count data normalised e.g. per 100K normalise_time default behaviour normalising keep time units input data. parameter set TRUE incidence rates calculated per year. given lubridate period string e.g. \"1 week\" incidence calculated time period.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/normalise_count.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate a normalised count per capita â€” normalise_count","text":"dataframe incidence rates per unit capita. dataframe containing following columns: population (positive_integer) - Size population count (positive_integer) - Positive case counts associated specified time frame time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period grouping allowed.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/normalise_count.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate a normalised count per capita â€” normalise_count","text":"","code":"data = example_england_covid_by_age() demog = ukc19::uk_population_2019_by_5yr_age  data %>%   normalise_count(demog) %>%   dplyr::glimpse() #> Rows: 26,790 #> Columns: 12 #> Groups: class [19] #> $ class            <fct> 00_04, 05_09, 10_14, 15_19, 20_24, 25_29, 30_34, 35_3â€¦ #> $ time             <t[day]> 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32â€¦ #> $ code             <chr> \"E92000001\", \"E92000001\", \"E92000001\", \"E92000001\", \"â€¦ #> $ date             <date> 2020-01-30, 2020-01-30, 2020-01-30, 2020-01-30, 2020â€¦ #> $ name             <chr> \"England\", \"England\", \"England\", \"England\", \"England\"â€¦ #> $ codeType         <chr> \"CTRY20\", \"CTRY20\", \"CTRY20\", \"CTRY20\", \"CTRY20\", \"CTâ€¦ #> $ count            <int> 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,â€¦ #> $ denom            <dbl> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,â€¦ #> $ population       <dbl> 3299637, 3538206, 3354246, 3090232, 3487863, 3801409,â€¦ #> $ count.per_capita <dbl> 0.00000000, 0.00000000, 0.00000000, 0.00000000, 0.028â€¦ #> $ population_unit  <dbl> 1e+05, 1e+05, 1e+05, 1e+05, 1e+05, 1e+05, 1e+05, 1e+0â€¦ #> $ time_unit        <Period> 1d 0H 0M 0S, 1d 0H 0M 0S, 1d 0H 0M 0S, 1d 0H 0M 0Sâ€¦"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/normalise_incidence.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate a normalised incidence rate per capita â€” normalise_incidence","title":"Calculate a normalised incidence rate per capita â€” normalise_incidence","text":"assumes positive disease counts stratified population grouping, e.g. geography age, estimates size population time period. Normalising population size allows us compare groups.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/normalise_incidence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate a normalised incidence rate per capita â€” normalise_incidence","text":"","code":"normalise_incidence(   modelled = i_incidence_model,   pop = i_population_data,   ...,   population_unit = 1e+05,   normalise_time = FALSE )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/normalise_incidence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate a normalised incidence rate per capita â€” normalise_incidence","text":"modelled Model output processing raw dataframe something like poission_locfit_model - dataframe columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` incidence.fit (double) - estimate incidence rate log scale incidence.se.fit (positive_double) - standard error incidence rate estimate log scale incidence.0.025 (positive_double) - lower confidence limit incidence rate (true scale) incidence.0.5 (positive_double) - median estimate incidence rate (true scale) incidence.0.975 (positive_double) - upper confidence limit incidence rate (true scale) grouping allowed. pop population data must grouped way modelled. - dataframe columns: population (positive_integer) - Size population grouping allowed. ... used population_unit population unit want incidence e.g. per 100K normalise_time default behaviour incidence keep time units input data. parameter set TRUE incidence rates calculated per year. given lubridate period string e.g. \"1 day\" incidence calculated time period.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/normalise_incidence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate a normalised incidence rate per capita â€” normalise_incidence","text":"dataframe incidence rates per unit capita. dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period incidence.per_capita.fit (double) - estimate incidence per capita rate log scale incidence.per_capita.se.fit (positive_double) - standard error incidence per capita rate estimate log scale incidence.per_capita.0.025 (positive_double) - lower confidence limit incidence per capita rate (true scale) incidence.per_capita.0.5 (positive_double) - median estimate incidence per capita rate (true scale) incidence.per_capita.0.975 (positive_double) - upper confidence limit incidence per capita rate (true scale) population_unit (double) - population unit per capita incidence rate calculated time_unit (lubridate::.period) - time period per capita incidence rate calculated grouping allowed.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/normalise_incidence.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate a normalised incidence rate per capita â€” normalise_incidence","text":"","code":"model = example_poisson_age_stratified() demog = ukc19::uk_population_2019_by_5yr_age  model %>%   normalise_incidence(demog) %>%   dplyr::glimpse() #> Adding missing grouping variables: `name`, `code`, `codeType` #> different column groupings in `modelled` and `base` parameters. #> regrouping `base` data to be compatible with `modelled` grouping #> Rows: 10,662,420 #> Columns: 31 #> Groups: class [19] #> $ class                       <chr> \"00_04\", \"00_04\", \"00_04\", \"00_04\", \"00_04â€¦ #> $ time                        <t[day]> 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,â€¦ #> $ incidence.fit               <dbl> -1.612905, -1.612905, -1.612905, -1.612905â€¦ #> $ incidence.se.fit            <dbl> 1.053391, 1.053391, 1.053391, 1.053391, 1.â€¦ #> $ incidence.0.025             <dbl> 0.02528574, 0.02528574, 0.02528574, 0.0252â€¦ #> $ incidence.0.05              <dbl> 0.03523977, 0.03523977, 0.03523977, 0.0352â€¦ #> $ incidence.0.25              <dbl> 0.09793934, 0.09793934, 0.09793934, 0.0979â€¦ #> $ incidence.0.5               <dbl> 0.1993077, 0.1993077, 0.1993077, 0.1993077â€¦ #> $ incidence.0.75              <dbl> 0.4055937, 0.4055937, 0.4055937, 0.4055937â€¦ #> $ incidence.0.95              <dbl> 1.127237, 1.127237, 1.127237, 1.127237, 1.â€¦ #> $ incidence.0.975             <dbl> 1.570987, 1.570987, 1.570987, 1.570987, 1.â€¦ #> $ growth.fit                  <dbl> -0.209303, -0.209303, -0.209303, -0.209303â€¦ #> $ growth.se.fit               <dbl> 0.2241824, 0.2241824, 0.2241824, 0.2241824â€¦ #> $ growth.0.025                <dbl> -0.6486925, -0.6486925, -0.6486925, -0.648â€¦ #> $ growth.0.05                 <dbl> -0.5780503, -0.5780503, -0.5780503, -0.578â€¦ #> $ growth.0.25                 <dbl> -0.3605118, -0.3605118, -0.3605118, -0.360â€¦ #> $ growth.0.5                  <dbl> -0.209303, -0.209303, -0.209303, -0.209303â€¦ #> $ growth.0.75                 <dbl> -0.05809427, -0.05809427, -0.05809427, -0.â€¦ #> $ growth.0.95                 <dbl> 0.1594443, 0.1594443, 0.1594443, 0.1594443â€¦ #> $ growth.0.975                <dbl> 0.2300865, 0.2300865, 0.2300865, 0.2300865â€¦ #> $ name                        <chr> \"Hartlepool\", \"Middlesbrough\", \"Redcar andâ€¦ #> $ code                        <chr> \"E06000001\", \"E06000002\", \"E06000003\", \"E0â€¦ #> $ codeType                    <chr> \"LAD19\", \"LAD19\", \"LAD19\", \"LAD19\", \"LAD19â€¦ #> $ population                  <int> 5229, 9583, 7106, 11462, 5790, 7580, 11596â€¦ #> $ incidence.per_capita.0.025  <dbl> 0.48356745, 0.26386040, 0.35583651, 0.2206â€¦ #> $ incidence.per_capita.0.5    <dbl> 3.8115842, 2.0798052, 2.8047810, 1.7388565â€¦ #> $ incidence.per_capita.0.975  <dbl> 30.043738, 16.393479, 22.107896, 13.706047â€¦ #> $ incidence.per_capita.fit    <dbl> 1.33804490, 0.73227426, 1.03132546, 0.5532â€¦ #> $ incidence.per_capita.se.fit <dbl> 1.053391, 1.053391, 1.053391, 1.053391, 1.â€¦ #> $ population_unit             <dbl> 1e+05, 1e+05, 1e+05, 1e+05, 1e+05, 1e+05, â€¦ #> $ time_unit                   <Period> 1d 0H 0M 0S, 1d 0H 0M 0S, 1d 0H 0M 0S, â€¦"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/omega_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a infectivity profile matrix from a long format â€” omega_matrix","title":"Generate a infectivity profile matrix from a long format â€” omega_matrix","text":"converts long format infectivity profile something work EpiEstim. general ggoutbreak conversion internally. provided utility examples mostly.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/omega_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a infectivity profile matrix from a long format â€” omega_matrix","text":"","code":"omega_matrix(ip = i_discrete_ip, epiestim_compat = TRUE)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/omega_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a infectivity profile matrix from a long format â€” omega_matrix","text":"ip long format infectivity profile - dataframe columns: boot (anything + default(1)) - bootstrap identifier probability (proportion) - probability new event period. tau (integer + complete) - days since index event. Minimally grouped : boot (groupings allowed). epiestim_compat ensure matrix works EpiEstim's si_from_sample method making probability time zero equal zero.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/omega_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a infectivity profile matrix from a long format â€” omega_matrix","text":"matrix 0:max(tau) rows 1:max(boot) columns.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/omega_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a infectivity profile matrix from a long format â€” omega_matrix","text":"","code":"omega_matrix(example_ip()) #>             boot.1       boot.2       boot.3       boot.4       boot.5 #>  [1,] 0.000000e+00 0.000000e+00 0.0000000000 0.000000e+00 0.000000e+00 #>  [2,] 7.677533e-03 4.184484e-04 0.0140500744 3.879250e-04 7.526397e-03 #>  [3,] 9.291725e-02 1.813812e-02 0.1046338997 2.227981e-02 9.442324e-02 #>  [4,] 2.043664e-01 9.230062e-02 0.1809500713 1.229569e-01 2.100911e-01 #>  [5,] 2.268502e-01 1.796117e-01 0.1898102498 2.309453e-01 2.318273e-01 #>  [6,] 1.833768e-01 2.112346e-01 0.1605625298 2.425320e-01 1.844411e-01 #>  [7,] 1.241137e-01 1.846491e-01 0.1206750683 1.800831e-01 1.221454e-01 #>  [8,] 7.504208e-02 1.331164e-01 0.0841748031 1.066530e-01 7.198976e-02 #>  [9,] 4.197525e-02 8.388998e-02 0.0557756827 5.393305e-02 3.915034e-02 #> [10,] 2.218114e-02 4.788837e-02 0.0355981082 2.428026e-02 2.007592e-02 #> [11,] 1.122399e-02 2.534381e-02 0.0220801720 1.000047e-02 9.843690e-03 #> [12,] 5.488918e-03 1.263459e-02 0.0133909251 3.839760e-03 4.659313e-03 #> [13,] 2.611286e-03 6.001426e-03 0.0079749802 1.392949e-03 2.143457e-03 #> [14,] 1.214373e-03 2.739158e-03 0.0046788999 4.821980e-04 9.631838e-04 #> [15,] 5.540821e-04 1.209025e-03 0.0027108306 1.604913e-04 4.243777e-04 #> [16,] 2.487464e-04 5.186508e-04 0.0015538888 5.166060e-05 1.838752e-04 #> [17,] 1.101234e-04 2.170966e-04 0.0008825539 1.615724e-05 7.852955e-05 #> [18,] 4.816494e-05 8.895148e-05 0.0004972622 4.928334e-06 3.312050e-05 #>             boot.6       boot.7       boot.8       boot.9      boot.10 #>  [1,] 0.0000000000 0.000000e+00 0.0000000000 0.000000e+00 0.000000e+00 #>  [2,] 0.0010693021 2.789247e-03 0.0285487735 8.376028e-05 8.544732e-04 #>  [3,] 0.0296756651 5.225867e-02 0.1470322686 1.150323e-02 2.968015e-02 #>  [4,] 0.1156510062 1.559865e-01 0.1997222056 9.883226e-02 1.272837e-01 #>  [5,] 0.1908943929 2.135242e-01 0.1835657684 2.354013e-01 2.136520e-01 #>  [6,] 0.2041656160 1.999387e-01 0.1439792770 2.708088e-01 2.207492e-01 #>  [7,] 0.1698309920 1.507670e-01 0.1036320670 1.990858e-01 1.717519e-01 #>  [8,] 0.1201387928 9.897287e-02 0.0706750878 1.088086e-01 1.112291e-01 #>  [9,] 0.0759332148 5.902414e-02 0.0464475760 4.826935e-02 6.339668e-02 #> [10,] 0.0441850007 3.280974e-02 0.0297126245 1.835557e-02 3.289873e-02 #> [11,] 0.0241363367 1.728467e-02 0.0186207185 6.202430e-03 1.589089e-02 #> [12,] 0.0125435084 8.728618e-03 0.0114823561 1.909109e-03 7.253581e-03 #> [13,] 0.0062612434 4.259719e-03 0.0069887070 5.448888e-04 3.162964e-03 #> [14,] 0.0030231308 2.021013e-03 0.0042081345 1.461239e-04 1.328154e-03 #> [15,] 0.0014194912 9.364489e-04 0.0025110990 3.719014e-05 5.403237e-04 #> [16,] 0.0006508702 4.252645e-04 0.0014869791 9.053479e-06 2.139743e-04 #> [17,] 0.0002923972 1.898053e-04 0.0008747341 2.121144e-06 8.279348e-05 #> [18,] 0.0001290395 8.344685e-05 0.0005116233 4.806800e-07 3.139542e-05 #>            boot.11      boot.12      boot.13      boot.14      boot.15 #>  [1,] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.0000000000 #>  [2,] 1.479224e-02 9.300358e-03 1.640893e-03 1.521200e-03 0.0377552540 #>  [3,] 1.283081e-01 1.087101e-01 5.246507e-02 3.721842e-02 0.1732055051 #>  [4,] 2.264344e-01 2.268979e-01 1.945690e-01 1.323704e-01 0.2143386747 #>  [5,] 2.208562e-01 2.365227e-01 2.694367e-01 2.035060e-01 0.1842008757 #>  [6,] 1.656469e-01 1.787775e-01 2.236164e-01 2.057033e-01 0.1368963546 #>  [7,] 1.074576e-01 1.129017e-01 1.376763e-01 1.632791e-01 0.0940719937 #>  [8,] 6.360375e-02 6.361613e-02 6.991054e-02 1.109443e-01 0.0615473547 #>  [9,] 3.534588e-02 3.313576e-02 3.105330e-02 6.767128e-02 0.0389351166 #> [10,] 1.875894e-02 1.629650e-02 1.250444e-02 3.813506e-02 0.0240339379 #> [11,] 9.612912e-03 7.671727e-03 4.671849e-03 2.022915e-02 0.0145614312 #> [12,] 4.792060e-03 3.489304e-03 1.645437e-03 1.023103e-02 0.0086937687 #> [13,] 2.336244e-03 1.543515e-03 5.525431e-04 4.978718e-03 0.0051293915 #> [14,] 1.118259e-03 6.673163e-04 1.783935e-04 2.346940e-03 0.0029969673 #> [15,] 5.270889e-04 2.830151e-04 5.572854e-05 1.077202e-03 0.0017367682 #> [16,] 2.452119e-04 1.180844e-04 1.692792e-05 4.833170e-04 0.0009994866 #> [17,] 1.127993e-04 4.858121e-05 5.019407e-06 2.126548e-04 0.0005717524 #> [18,] 5.138252e-05 1.974386e-05 1.457434e-06 9.198772e-05 0.0003253670 #>            boot.16      boot.17      boot.18      boot.19      boot.20 #>  [1,] 0.0000000000 0.0000000000 0.0000000000 0.000000e+00 0.000000e+00 #>  [2,] 0.0016996564 0.0030047001 0.0027652700 1.833881e-03 4.693477e-03 #>  [3,] 0.0421750530 0.0496607178 0.0484661289 4.252390e-02 7.348588e-02 #>  [4,] 0.1476610154 0.1414855294 0.1423502263 1.444289e-01 1.898801e-01 #>  [5,] 0.2190799925 0.1949704849 0.1983680681 2.129348e-01 2.306766e-01 #>  [6,] 0.2112228185 0.1897617177 0.1929463796 2.071615e-01 1.952382e-01 #>  [7,] 0.1588181831 0.1516238691 0.1529676100 1.586827e-01 1.346719e-01 #>  [8,] 0.1017696394 0.1067990890 0.1064040924 1.042406e-01 8.152930e-02 #>  [9,] 0.0583627852 0.0689381600 0.0676049868 6.155395e-02 4.509957e-02 #> [10,] 0.0308539946 0.0417436034 0.0401961525 3.361555e-02 2.335448e-02 #> [11,] 0.0153281770 0.0240727610 0.0227190657 1.729437e-02 1.150021e-02 #> [12,] 0.0072508299 0.0133584958 0.0123383387 8.488602e-03 5.442797e-03 #> [13,] 0.0032967261 0.0071860114 0.0064879552 4.010986e-03 2.494760e-03 #> [14,] 0.0014507365 0.0037677404 0.0033219873 1.836715e-03 1.113695e-03 #> [15,] 0.0006211428 0.0019334406 0.0016633724 8.192254e-04 4.862795e-04 #> [16,] 0.0002598173 0.0009741615 0.0008172012 3.573067e-04 2.083650e-04 #> [17,] 0.0001065185 0.0004831534 0.0003949683 1.528643e-04 8.784574e-05 #> [18,] 0.0000429137 0.0002363644 0.0001881968 6.431105e-05 3.651654e-05 #>            boot.21     boot.22      boot.23      boot.24      boot.25 #>  [1,] 0.000000e+00 0.000000000 0.000000e+00 0.000000e+00 0.000000e+00 #>  [2,] 9.332891e-03 0.061318962 1.043755e-04 4.953968e-03 1.252013e-03 #>  [3,] 1.022630e-01 0.199145058 1.039234e-02 7.643928e-02 3.453768e-02 #>  [4,] 2.108509e-01 0.203906705 8.062162e-02 1.946379e-01 1.309865e-01 #>  [5,] 2.254156e-01 0.164201659 1.937563e-01 2.330544e-01 2.073971e-01 #>  [6,] 1.784158e-01 0.120852859 2.432313e-01 1.945087e-01 2.110390e-01 #>  [7,] 1.194171e-01 0.084780913 2.058114e-01 1.323573e-01 1.662299e-01 #>  [8,] 7.186652e-02 0.057721180 1.343050e-01 7.907024e-02 1.110168e-01 #>  [9,] 4.019370e-02 0.038500931 7.302394e-02 4.317168e-02 6.611007e-02 #> [10,] 2.130787e-02 0.025300425 3.470205e-02 2.206989e-02 3.619138e-02 #> [11,] 1.084434e-02 0.016438228 1.487331e-02 1.073000e-02 1.857881e-02 #> [12,] 5.344630e-03 0.010585353 5.875369e-03 5.014514e-03 9.065872e-03 #> [13,] 2.566658e-03 0.006767470 2.172649e-03 2.269804e-03 4.246174e-03 #> [14,] 1.206515e-03 0.004300988 7.608025e-04 1.000720e-03 1.922639e-03 #> [15,] 5.570719e-04 0.002719866 2.544992e-04 4.315662e-04 8.462041e-04 #> [16,] 2.533191e-04 0.001712725 8.188276e-05 1.826527e-04 3.635528e-04 #> [17,] 1.136904e-04 0.001074593 2.547630e-05 7.606466e-05 1.529787e-04 #> [18,] 5.044528e-05 0.000672083 7.698555e-06 3.123428e-05 6.321765e-05 #>            boot.26      boot.27      boot.28      boot.29      boot.30 #>  [1,] 0.000000e+00 0.0000000000 0.0000000000 0.0000000000 0.000000e+00 #>  [2,] 2.988272e-03 0.0135707237 0.0179566678 0.0402588554 4.567568e-03 #>  [3,] 5.523195e-02 0.1057634618 0.1201794161 0.1873784565 6.726541e-02 #>  [4,] 1.622191e-01 0.1863079560 0.1923028668 0.2280479740 1.723622e-01 #>  [5,] 2.181213e-01 0.1951537305 0.1916760482 0.1892171342 2.153630e-01 #>  [6,] 2.005066e-01 0.1631645607 0.1563404997 0.1346937915 1.914548e-01 #>  [7,] 1.483967e-01 0.1204994695 0.1142674235 0.0882754684 1.404381e-01 #>  [8,] 9.560509e-02 0.0822843205 0.0779384577 0.0549355488 9.113485e-02 #>  [9,] 5.595302e-02 0.0532389949 0.0506921566 0.0329958915 5.433696e-02 #> [10,] 3.052232e-02 0.0331165792 0.0318470835 0.0193127945 3.045016e-02 #> [11,] 1.577951e-02 0.0199909124 0.0194861514 0.0110838915 1.627602e-02 #> [12,] 7.819782e-03 0.0117859063 0.0116775678 0.0062636049 8.381656e-03 #> [13,] 3.744961e-03 0.0068172510 0.0068815503 0.0034957200 4.188330e-03 #> [14,] 1.743627e-03 0.0038817296 0.0039995207 0.0019310008 2.041613e-03 #> [15,] 7.928448e-04 0.0021812883 0.0022976703 0.0010575085 9.746877e-04 #> [16,] 3.533331e-04 0.0012120708 0.0013070089 0.0005749114 4.571588e-04 #> [17,] 1.547592e-04 0.0006670327 0.0007371851 0.0003105822 2.111772e-04 #> [18,] 6.677013e-05 0.0003640121 0.0004127257 0.0001668659 9.626445e-05 #>            boot.31      boot.32      boot.33      boot.34      boot.35 #>  [1,] 0.000000e+00 0.000000e+00 0.0000000000 0.000000e+00 0.0000000000 #>  [2,] 1.417077e-03 2.412331e-03 0.0211305326 2.446991e-03 0.0075158077 #>  [3,] 3.940577e-02 5.691140e-02 0.1441701765 4.902957e-02 0.0733248095 #>  [4,] 1.465270e-01 1.839975e-01 0.2226805305 1.524307e-01 0.1534941737 #>  [5,] 2.232736e-01 2.468026e-01 0.2070594694 2.135372e-01 0.1822258210 #>  [6,] 2.162484e-01 2.127856e-01 0.1550747283 2.023052e-01 0.1679003577 #>  [7,] 1.610723e-01 1.422368e-01 0.1031730163 1.532527e-01 0.1343810383 #>  [8,] 1.012998e-01 8.074469e-02 0.0637113101 1.005913e-01 0.0983682387 #>  [9,] 5.664363e-02 4.092744e-02 0.0373785848 5.978244e-02 0.0677068298 #> [10,] 2.905692e-02 1.909285e-02 0.0211255405 3.303549e-02 0.0445517138 #> [11,] 1.395536e-02 8.360138e-03 0.0116048964 1.726853e-02 0.0283262985 #> [12,] 6.363241e-03 3.482399e-03 0.0062338508 8.639930e-03 0.0175296524 #> [13,] 2.782177e-03 1.393251e-03 0.0032887119 4.172468e-03 0.0106137617 #> [14,] 1.175040e-03 5.391861e-04 0.0017093406 1.957026e-03 0.0063116143 #> [15,] 4.820654e-04 2.029259e-04 0.0008774244 8.957036e-04 0.0036969851 #> [16,] 1.929421e-04 7.458232e-05 0.0004456354 4.014982e-04 0.0021378152 #> [17,] 7.559750e-05 2.685758e-05 0.0002242747 1.767712e-04 0.0012225965 #> [18,] 2.907691e-05 9.501334e-06 0.0001119767 7.662322e-05 0.0006924862 #>            boot.36      boot.37      boot.38      boot.39      boot.40 #>  [1,] 0.000000e+00 0.000000e+00 0.0000000000 0.000000e+00 0.000000e+00 #>  [2,] 4.221589e-04 3.417375e-04 0.0216662535 1.707855e-03 2.956394e-03 #>  [3,] 2.997143e-02 1.855140e-02 0.1369282354 4.910111e-02 5.571837e-02 #>  [4,] 1.685429e-01 1.032911e-01 0.2072318946 1.772741e-01 1.647513e-01 #>  [5,] 2.879235e-01 2.036781e-01 0.1966275009 2.514619e-01 2.211080e-01 #>  [6,] 2.543035e-01 2.305500e-01 0.1533208246 2.209869e-01 2.018093e-01 #>  [7,] 1.509454e-01 1.876168e-01 0.1074073789 1.470776e-01 1.478327e-01 #>  [8,] 6.908274e-02 1.231284e-01 0.0703383454 8.183818e-02 9.407353e-02 #>  [9,] 2.636236e-02 6.952865e-02 0.0439781763 4.021280e-02 5.430354e-02 #> [10,] 8.801320e-03 3.515025e-02 0.0265835975 1.803772e-02 2.918667e-02 #> [11,] 2.652881e-03 1.632749e-02 0.0156610044 7.546862e-03 1.485508e-02 #> [12,] 7.377023e-04 7.093867e-03 0.0090413860 2.988998e-03 7.242976e-03 #> [13,] 1.921998e-04 2.919882e-03 0.0051351455 1.132487e-03 3.411063e-03 #> [14,] 4.745650e-05 1.149393e-03 0.0028775288 4.136813e-04 1.561113e-03 #> [15,] 1.120155e-05 4.358228e-04 0.0015943388 1.465499e-04 6.975174e-04 #> [16,] 2.544647e-06 1.600713e-04 0.0008749207 5.058037e-05 3.053570e-04 #> [17,] 5.593218e-07 5.720059e-05 0.0004761722 1.706990e-05 1.313486e-04 #> [18,] 1.194669e-07 1.995807e-05 0.0002572965 5.649381e-06 5.564166e-05 #>            boot.41      boot.42      boot.43      boot.44      boot.45 #>  [1,] 0.0000000000 0.0000000000 0.0000000000 0.0000000000 0.0000000000 #>  [2,] 0.0062119371 0.0120302656 0.0079254705 0.0014207590 0.0159815693 #>  [3,] 0.0776312520 0.1062153209 0.0886392063 0.0344882007 0.1169328389 #>  [4,] 0.1799199426 0.1976598642 0.1903707465 0.1237705479 0.1959319089 #>  [5,] 0.2130218150 0.2076292787 0.2146188303 0.1941669151 0.1977873929 #>  [6,] 0.1846521690 0.1693290583 0.1801367838 0.2015815424 0.1605818484 #>  [7,] 0.1343795504 0.1200553063 0.1282324686 0.1649792465 0.1156798254 #>  [8,] 0.0875020731 0.0779092756 0.0822228039 0.1158693553 0.0772790618 #>  [9,] 0.0527668997 0.0475692070 0.0490536507 0.0731768348 0.0490156605 #> [10,] 0.0300833240 0.0277801377 0.0277629469 0.0427501241 0.0299340191 #> [11,] 0.0164322682 0.0156824522 0.0150942831 0.0235310824 0.0177610373 #> [12,] 0.0086781213 0.0086198284 0.0079509835 0.0123581733 0.0103017587 #> [13,] 0.0044598904 0.0046368077 0.0040825557 0.0062485485 0.0058666691 #> [14,] 0.0022411342 0.0024503003 0.0020525496 0.0030619678 0.0032908416 #> [15,] 0.0011051735 0.0012756911 0.0010138696 0.0014615329 0.0018227083 #> [16,] 0.0005363318 0.0006557902 0.0004933369 0.0006821888 0.0009987217 #> [17,] 0.0002567110 0.0003334594 0.0002369657 0.0003123464 0.0005421754 #> [18,] 0.0001214066 0.0001679563 0.0001125482 0.0001406341 0.0002919626 #>            boot.46      boot.47      boot.48      boot.49      boot.50 #>  [1,] 0.0000000000 0.000000e+00 0.000000e+00 0.0000000000 0.000000e+00 #>  [2,] 0.0018773139 1.524538e-03 2.059709e-04 0.0009855786 2.028305e-03 #>  [3,] 0.0397419551 4.182723e-02 1.363647e-02 0.0244255135 5.200704e-02 #>  [4,] 0.1312207973 1.529669e-01 8.633563e-02 0.0930564741 1.772187e-01 #>  [5,] 0.1959704564 2.286534e-01 1.873558e-01 0.1590805019 2.458145e-01 #>  [6,] 0.1980750426 2.169874e-01 2.279365e-01 0.1825622141 2.162951e-01 #>  [7,] 0.1600705387 1.582693e-01 1.961192e-01 0.1665061439 1.463133e-01 #>  [8,] 0.1120589939 9.744165e-02 1.345290e-01 0.1309828278 8.357605e-02 #>  [9,] 0.0710131127 5.332932e-02 7.874304e-02 0.0929728958 4.245488e-02 #> [10,] 0.0418339482 2.677263e-02 4.100591e-02 0.0611967776 1.978934e-02 #> [11,] 0.0233079185 1.258266e-02 1.952524e-02 0.0380229598 8.638224e-03 #> [12,] 0.0124275680 5.614014e-03 8.662403e-03 0.0225733599 3.580558e-03 #> [13,] 0.0063949121 2.401727e-03 3.629367e-03 0.0129168951 1.423389e-03 #> [14,] 0.0031955804 9.924760e-04 1.450475e-03 0.0071700830 5.466717e-04 #> [15,] 0.0015580524 3.983726e-04 5.571518e-04 0.0038798557 2.039745e-04 #> [16,] 0.0007439169 1.559973e-04 2.069115e-04 0.0020543812 7.425865e-05 #> [17,] 0.0003488500 5.979923e-05 7.464080e-05 0.0010676458 2.646829e-05 #> [18,] 0.0001610429 2.250235e-05 2.625348e-05 0.0005458923 9.262077e-06 #>            boot.51      boot.52      boot.53      boot.54      boot.55 #>  [1,] 0.0000000000 0.000000e+00 0.000000e+00 0.000000e+00 0.0000000000 #>  [2,] 0.0135880782 4.453337e-03 1.457725e-02 2.261383e-03 0.0146452416 #>  [3,] 0.1172076178 7.118956e-02 1.250940e-01 6.165463e-02 0.1142432321 #>  [4,] 0.2110623416 1.868237e-01 2.211911e-01 2.072587e-01 0.1979991583 #>  [5,] 0.2135949468 2.296396e-01 2.180689e-01 2.696672e-01 0.2019277653 #>  [6,] 0.1675733903 1.961394e-01 1.660659e-01 2.157275e-01 0.1635735366 #>  [7,] 0.1142203358 1.363059e-01 1.096595e-01 1.301885e-01 0.1167306399 #>  [8,] 0.0712341065 8.304387e-02 6.617578e-02 6.553786e-02 0.0768971641 #>  [9,] 0.0417897007 4.619359e-02 3.753517e-02 2.909320e-02 0.0479433133 #> [10,] 0.0234455981 2.404041e-02 2.034872e-02 1.177816e-02 0.0287141336 #> [11,] 0.0127139831 1.189173e-02 1.065799e-02 4.444541e-03 0.0166789349 #> [12,] 0.0067123638 5.651645e-03 5.433006e-03 1.586802e-03 0.0094574868 #> [13,] 0.0034680163 2.600577e-03 2.709562e-03 5.417390e-04 0.0052593468 #> [14,] 0.0017601418 1.165177e-03 1.327158e-03 1.782548e-04 0.0028781958 #> [15,] 0.0008800859 5.105157e-04 6.402904e-04 5.686762e-05 0.0015540538 #> [16,] 0.0004344934 2.194680e-04 3.049610e-04 1.767138e-05 0.0008295485 #> [17,] 0.0002121728 9.281678e-05 1.436488e-04 5.368443e-06 0.0004384685 #> [18,] 0.0001026272 3.869893e-05 6.701555e-05 1.599113e-06 0.0002297800 #>            boot.56      boot.57      boot.58      boot.59      boot.60 #>  [1,] 0.0000000000 0.000000e+00 0.0000000000 0.000000e+00 0.000000e+00 #>  [2,] 0.0148178789 3.075173e-02 0.0028633075 1.868855e-03 5.439019e-03 #>  [3,] 0.1182153892 1.765303e-01 0.0517529954 4.678859e-02 8.661348e-02 #>  [4,] 0.2053196985 2.391460e-01 0.1523398587 1.612670e-01 2.171306e-01 #>  [5,] 0.2068818780 2.033952e-01 0.2087160266 2.316769e-01 2.477610e-01 #>  [6,] 0.1643889887 1.425879e-01 0.1973785477 2.141828e-01 1.934620e-01 #>  [7,] 0.1146084095 8.999479e-02 0.1511365355 1.535355e-01 1.218544e-01 #>  [8,] 0.0735695500 5.317679e-02 0.1011072225 9.345307e-02 6.692433e-02 #>  [9,] 0.0446174893 3.003209e-02 0.0615990123 5.077864e-02 3.343610e-02 #> [10,] 0.0259599418 1.641113e-02 0.0350440089 2.538812e-02 1.558786e-02 #> [11,] 0.0146346682 8.745830e-03 0.0189208752 1.191193e-02 6.893466e-03 #> [12,] 0.0080475498 4.569812e-03 0.0098032258 5.315957e-03 2.924441e-03 #> [13,] 0.0043373515 2.350080e-03 0.0049128178 2.278250e-03 1.199706e-03 #> [14,] 0.0022993078 1.192807e-03 0.0023953020 9.443279e-04 4.787340e-04 #> [15,] 0.0012021036 5.988009e-04 0.0011412503 3.806129e-04 1.866560e-04 #> [16,] 0.0006210973 2.978062e-04 0.0005331950 1.497958e-04 7.135503e-05 #> [17,] 0.0003176606 1.469229e-04 0.0002449393 5.775757e-05 2.681851e-05 #> [18,] 0.0001610374 7.197878e-05 0.0001108795 2.187610e-05 9.931896e-06 #>            boot.61      boot.62      boot.63      boot.64      boot.65 #>  [1,] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 #>  [2,] 1.223564e-03 6.830650e-03 6.880946e-05 3.421320e-03 1.447996e-02 #>  [3,] 3.916491e-02 8.781706e-02 7.349760e-03 5.860457e-02 1.250343e-01 #>  [4,] 1.544664e-01 2.007296e-01 6.170348e-02 1.646955e-01 2.217013e-01 #>  [5,] 2.372790e-01 2.277493e-01 1.623211e-01 2.165567e-01 2.186095e-01 #>  [6,] 2.240862e-01 1.862663e-01 2.246856e-01 1.973813e-01 1.662701e-01 #>  [7,] 1.593743e-01 1.267631e-01 2.104792e-01 1.460875e-01 1.095680e-01 #>  [8,] 9.438558e-02 7.675427e-02 1.524123e-01 9.465105e-02 6.594969e-02 #>  [9,] 4.921634e-02 4.287317e-02 9.208763e-02 5.592924e-02 3.729679e-02 #> [10,] 2.337483e-02 2.257697e-02 4.867535e-02 3.089361e-02 2.015463e-02 #> [11,] 1.033698e-02 1.136645e-02 2.322012e-02 1.620873e-02 1.052035e-02 #> [12,] 4.321192e-03 5.523493e-03 1.021415e-02 8.166198e-03 5.343719e-03 #> [13,] 1.726089e-03 2.608485e-03 4.207487e-03 3.981631e-03 2.655189e-03 #> [14,] 6.640988e-04 1.203172e-03 1.641694e-03 1.889586e-03 1.295586e-03 #> [15,] 2.475931e-04 5.441075e-04 6.120541e-04 8.766556e-04 6.226295e-04 #> [16,] 8.987135e-05 2.419591e-04 2.195110e-04 3.989491e-04 2.953748e-04 #> [17,] 3.187843e-05 1.060510e-04 7.614208e-05 1.785648e-04 1.385733e-04 #> [18,] 1.108324e-05 4.590085e-05 2.565521e-05 7.877729e-05 6.438389e-05 #>            boot.66      boot.67      boot.68      boot.69      boot.70 #>  [1,] 0.0000000000 0.000000e+00 0.0000000000 0.0000000000 0.000000e+00 #>  [2,] 0.0008469925 2.678084e-03 0.0787719047 0.0399215940 8.562708e-06 #>  [3,] 0.0256604828 5.494445e-02 0.2328569810 0.1844306735 2.740469e-03 #>  [4,] 0.1062507062 1.688902e-01 0.2176704999 0.2248226528 4.021497e-02 #>  [5,] 0.1834423332 2.284771e-01 0.1625546040 0.1879336530 1.468309e-01 #>  [6,] 0.2029754074 2.061854e-01 0.1117534107 0.1351266641 2.404821e-01 #>  [7,] 0.1734182440 1.475811e-01 0.0735236948 0.0895759160 2.380254e-01 #>  [8,] 0.1253836251 9.105494e-02 0.0470651225 0.0564342555 1.680184e-01 #>  [9,] 0.0807124483 5.068581e-02 0.0295690790 0.0343358002 9.330525e-02 #> [10,] 0.0477083339 2.616585e-02 0.0183256697 0.0203666249 4.336316e-02 #> [11,] 0.0264192509 1.275250e-02 0.0112404291 0.0118493902 1.757270e-02 #> [12,] 0.0138962717 5.939711e-03 0.0068386246 0.0067900063 6.389205e-03 #> [13,] 0.0070113473 2.667010e-03 0.0041333319 0.0038433948 2.127509e-03 #> [14,] 0.0034181310 1.161883e-03 0.0024847332 0.0021536134 6.587844e-04 #> [15,] 0.0016190464 4.935086e-04 0.0014869197 0.0011965707 1.919184e-04 #> [16,] 0.0007483040 2.051471e-04 0.0008863770 0.0006600510 5.307978e-05 #> [17,] 0.0003386279 8.370973e-05 0.0005266304 0.0003618435 1.403802e-05 #> [18,] 0.0001504472 3.361044e-05 0.0003119878 0.0001972963 3.570818e-06 #>            boot.71      boot.72      boot.73      boot.74      boot.75 #>  [1,] 0.000000e+00 0.000000e+00 0.000000e+00 0.0000000000 0.000000e+00 #>  [2,] 1.133172e-03 9.816227e-03 2.248439e-02 0.0389648018 8.054196e-06 #>  [3,] 3.356662e-02 1.242103e-01 1.611647e-01 0.1833012350 2.519024e-03 #>  [4,] 1.318532e-01 2.580856e-01 2.463028e-01 0.2255996522 3.708803e-02 #>  [5,] 2.114741e-01 2.522937e-01 2.174745e-01 0.1890966815 1.376737e-01 #>  [6,] 2.148188e-01 1.729711e-01 1.515766e-01 0.1358919156 2.314223e-01 #>  [7,] 1.673679e-01 9.719279e-02 9.280572e-02 0.0898742920 2.366382e-01 #>  [8,] 1.098862e-01 4.813429e-02 5.237037e-02 0.0564266865 1.733535e-01 #>  [9,] 6.405282e-02 2.185156e-02 2.794219e-02 0.0341858548 1.002318e-01 #> [10,] 3.421430e-02 9.309354e-03 1.431182e-02 0.0201803083 4.861674e-02 #> [11,] 1.709588e-02 3.778696e-03 7.106007e-03 0.0116795281 2.059989e-02 #> [12,] 8.104327e-03 1.476491e-03 3.442984e-03 0.0066553582 7.842594e-03 #> [13,] 3.681813e-03 5.594676e-04 1.635580e-03 0.0037451418 2.737624e-03 #> [14,] 1.614952e-03 2.066919e-04 7.644418e-04 0.0020858073 8.895039e-04 #> [15,] 6.878064e-04 7.475774e-05 3.524484e-04 0.0011516356 2.721245e-04 #> [16,] 2.856864e-04 2.655545e-05 1.606244e-04 0.0006311812 7.908936e-05 #> [17,] 1.161291e-04 9.287700e-06 7.247587e-05 0.0003437451 2.199290e-05 #> [18,] 4.632748e-05 3.204784e-06 3.241945e-05 0.0001861749 5.885026e-06 #>            boot.76      boot.77      boot.78      boot.79      boot.80 #>  [1,] 0.0000000000 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 #>  [2,] 0.0031298498 7.588804e-04 3.964342e-03 1.236108e-03 6.066554e-04 #>  [3,] 0.0514183580 3.055333e-02 6.637967e-02 3.582540e-02 2.411248e-02 #>  [4,] 0.1452396205 1.384420e-01 1.802599e-01 1.378720e-01 1.132217e-01 #>  [5,] 0.1981119677 2.322446e-01 2.273016e-01 2.166832e-01 2.032653e-01 #>  [6,] 0.1907278171 2.311362e-01 1.979851e-01 2.158152e-01 2.208682e-01 #>  [7,] 0.1506901363 1.692060e-01 1.397845e-01 1.649551e-01 1.786855e-01 #>  [8,] 0.1049323003 1.015077e-01 8.630478e-02 1.062945e-01 1.193912e-01 #>  [9,] 0.0669529739 5.300847e-02 4.856426e-02 6.083137e-02 6.981557e-02 #> [10,] 0.0400710066 2.500021e-02 2.553347e-02 3.191058e-02 3.701489e-02 #> [11,] 0.0228385476 1.090717e-02 1.274687e-02 1.566205e-02 1.820746e-02 #> [12,] 0.0125251036 4.475058e-03 6.109042e-03 7.294238e-03 8.441874e-03 #> [13,] 0.0066585000 1.747082e-03 2.832847e-03 3.256063e-03 3.731270e-03 #> [14,] 0.0034500154 6.546853e-04 1.278395e-03 1.403497e-03 1.585381e-03 #> [15,] 0.0017494909 2.370412e-04 5.639030e-04 5.874671e-04 6.516714e-04 #> [16,] 0.0008710511 8.335190e-05 2.439609e-04 2.398341e-04 2.604267e-04 #> [17,] 0.0004268959 2.858069e-05 1.037967e-04 9.582972e-05 1.015788e-04 #> [18,] 0.0002063653 9.587763e-06 4.352488e-05 3.758069e-05 3.879276e-05 #>            boot.81      boot.82      boot.83      boot.84      boot.85 #>  [1,] 0.000000e+00 0.000000e+00 0.0000000000 0.0000000000 0.000000e+00 #>  [2,] 1.692311e-04 1.617176e-02 0.0052883223 0.0125346018 2.044063e-03 #>  [3,] 1.341078e-02 1.367830e-01 0.0693627724 0.1097644168 4.611011e-02 #>  [4,] 9.143773e-02 2.347950e-01 0.1678834562 0.2020324117 1.525366e-01 #>  [5,] 2.021218e-01 2.227881e-01 0.2065748497 0.2096547022 2.191228e-01 #>  [6,] 2.410408e-01 1.626837e-01 0.1853881019 0.1688538658 2.079014e-01 #>  [7,] 1.981626e-01 1.028108e-01 0.1393321866 0.1182131314 1.554241e-01 #>  [8,] 1.276354e-01 5.930830e-02 0.0935382538 0.0757443623 9.970561e-02 #>  [9,] 6.928347e-02 3.213245e-02 0.0580839031 0.0456613327 5.752097e-02 #> [10,] 3.315324e-02 1.663006e-02 0.0340680310 0.0263274945 3.070069e-02 #> [11,] 1.440342e-02 8.312006e-03 0.0191310418 0.0146735721 1.544080e-02 #> [12,] 5.797892e-03 4.042101e-03 0.0103810684 0.0079627566 7.410625e-03 #> [13,] 2.194126e-03 1.922619e-03 0.0054791903 0.0042288691 3.424550e-03 #> [14,] 7.890794e-04 8.979561e-04 0.0028266397 0.0022062919 1.533892e-03 #> [15,] 2.718982e-04 4.130225e-04 0.0014305527 0.0011340348 6.692899e-04 #> [16,] 9.034126e-05 1.875180e-04 0.0007122929 0.0005755485 2.856004e-04 #> [17,] 2.909070e-05 8.418785e-05 0.0003497182 0.0002889319 1.195564e-04 #> [18,] 9.115462e-06 3.743052e-05 0.0001696190 0.0001436758 4.921974e-05 #>            boot.86      boot.87      boot.88      boot.89      boot.90 #>  [1,] 0.000000e+00 0.000000e+00 0.000000e+00 0.0000000000 0.000000e+00 #>  [2,] 3.895505e-03 3.011752e-05 1.829000e-02 0.0043550494 2.808103e-03 #>  [3,] 6.371319e-02 4.650177e-03 1.382231e-01 0.0639144090 6.206699e-02 #>  [4,] 1.726975e-01 4.809663e-02 2.255741e-01 0.1651330242 1.918277e-01 #>  [5,] 2.205967e-01 1.455130e-01 2.134172e-01 0.2096740053 2.490864e-01 #>  [6,] 1.963228e-01 2.207879e-01 1.594096e-01 0.1902155210 2.097576e-01 #>  [7,] 1.423452e-01 2.191636e-01 1.045695e-01 0.1427284192 1.377470e-01 #>  [8,] 9.054885e-02 1.641726e-01 6.320358e-02 0.0948882328 7.712257e-02 #>  [9,] 5.261507e-02 1.008285e-01 3.611075e-02 0.0580196005 3.866246e-02 #> [10,] 2.861305e-02 5.346192e-02 1.980171e-02 0.0333691882 1.787527e-02 #> [11,] 1.479324e-02 2.532147e-02 1.052428e-02 0.0183158490 7.769535e-03 #> [12,] 7.349629e-03 1.096879e-02 5.457568e-03 0.0096899956 3.216686e-03 #> [13,] 3.535837e-03 4.419940e-03 2.774480e-03 0.0049762715 1.280423e-03 #> [14,] 1.656510e-03 1.677737e-03 1.387573e-03 0.0024936326 4.934295e-04 #> [15,] 7.589791e-04 6.056763e-04 6.844950e-04 0.0012241265 1.850528e-04 #> [16,] 3.412266e-04 2.095101e-04 3.337462e-04 0.0005904990 6.781556e-05 #> [17,] 1.509302e-04 6.985324e-05 1.611014e-04 0.0002805867 2.436256e-05 #> [18,] 6.581881e-05 2.255577e-05 7.708802e-05 0.0001315893 8.602034e-06 #>            boot.91      boot.92      boot.93      boot.94      boot.95 #>  [1,] 0.000000e+00 0.000000e+00 0.0000000000 0.0000000000 0.000000e+00 #>  [2,] 3.760619e-04 1.135114e-02 0.0135729497 0.0076062026 1.021571e-02 #>  [3,] 1.832351e-02 1.130577e-01 0.1081461623 0.0830448466 1.021486e-01 #>  [4,] 9.779505e-02 2.184780e-01 0.1915056167 0.1788432041 2.025227e-01 #>  [5,] 1.918313e-01 2.244011e-01 0.1992561286 0.2059247675 2.163809e-01 #>  [6,] 2.214760e-01 1.732242e-01 0.1644719930 0.1782685721 1.749151e-01 #>  [7,] 1.868426e-01 1.141011e-01 0.1195034829 0.1316254220 1.210924e-01 #>  [8,] 1.285150e-01 6.797509e-02 0.0801101518 0.0878523963 7.599178e-02 #>  [9,] 7.664972e-02 3.778891e-02 0.0508063722 0.0546913053 4.456924e-02 #> [10,] 4.116328e-02 1.997293e-02 0.0309437143 0.0323574369 2.487968e-02 #> [11,] 2.040042e-02 1.015792e-02 0.0182740003 0.0184150072 1.337518e-02 #> [12,] 9.489502e-03 5.012010e-03 0.0105329856 0.0101646732 6.980388e-03 #> [13,] 4.193536e-03 2.413218e-03 0.0059532515 0.0054738144 3.556817e-03 #> [14,] 1.776392e-03 1.138741e-03 0.0033108267 0.0028883047 1.776934e-03 #> [15,] 7.262298e-04 5.283381e-04 0.0018164822 0.0014982312 8.731578e-04 #> [16,] 2.880609e-04 2.416324e-04 0.0009851847 0.0007659580 4.230583e-04 #> [17,] 1.113244e-04 1.091499e-04 0.0005290442 0.0003867214 2.025088e-04 #> [18,] 4.205914e-05 4.877708e-05 0.0002816531 0.0001931366 9.591982e-05 #>            boot.96      boot.97      boot.98      boot.99     boot.100 #>  [1,] 0.000000e+00 0.000000e+00 0.0000000000 0.000000e+00 0.0000000000 #>  [2,] 7.439827e-03 4.272211e-03 0.0004214937 1.381070e-02 0.0582268656 #>  [3,] 8.806486e-02 8.009477e-02 0.0167834671 1.297587e-01 0.1948015585 #>  [4,] 1.941474e-01 2.185071e-01 0.0832394974 2.361068e-01 0.2033357076 #>  [5,] 2.197138e-01 2.569108e-01 0.1635121404 2.288363e-01 0.1654037347 #>  [6,] 1.827612e-01 1.996414e-01 0.1986016252 1.671463e-01 0.1224919780 #>  [7,] 1.279663e-01 1.225016e-01 0.1819028229 1.043776e-01 0.0862783818 #>  [8,] 8.031402e-02 6.463367e-02 0.1387293960 5.903202e-02 0.0588988675 #>  [9,] 4.674165e-02 3.072006e-02 0.0931159213 3.118559e-02 0.0393557732 #> [10,] 2.574287e-02 1.352716e-02 0.0568958880 1.567508e-02 0.0258902895 #> [11,] 1.359385e-02 5.619383e-03 0.0323527935 7.585881e-03 0.0168310924 #> [12,] 6.944543e-03 2.229704e-03 0.0173816990 3.563291e-03 0.0108401365 #> [13,] 3.454033e-03 8.525432e-04 0.0089192374 1.633960e-03 0.0069292412 #> [14,] 1.680468e-03 3.161717e-04 0.0044065502 7.345390e-04 0.0044019001 #> [15,] 8.026031e-04 1.142907e-04 0.0021088735 3.247617e-04 0.0027818510 #> [16,] 3.773450e-04 4.042437e-05 0.0009822906 1.415703e-04 0.0017502681 #> [17,] 1.750224e-04 1.403258e-05 0.0004469898 6.096660e-05 0.0010970329 #> [18,] 8.022891e-05 4.792404e-06 0.0001993138 2.597842e-05 0.0006853214"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/pbeta2.html","id":null,"dir":"Reference","previous_headings":"","what":"The Beta Distribution â€” pbeta2","title":"The Beta Distribution â€” pbeta2","text":"Density, distribution function, quantile function random   generation Beta distribution parameters shape1   shape2 (optional non-centrality parameter ncp).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/pbeta2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The Beta Distribution â€” pbeta2","text":"","code":"pbeta2(q, prob, kappa, lower.tail = TRUE, log.p = FALSE)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/pbeta2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The Beta Distribution â€” pbeta2","text":"q vector quantiles prob mean probability (vectorised) kappa coefficient variation. 0 variability 1 maximally variability (vectorised) lower.tail logical; TRUE (default), probabilities P[X<=x] otherwise P[X>x]. log.p logical; TRUE, probabilities p given log(p).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/pbeta2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The Beta Distribution â€” pbeta2","text":"dbeta gives density, pbeta distribution   function, qbeta quantile function, rbeta   generates random deviates. Invalid arguments result return value NaN, warning. length result determined n   rbeta, maximum lengths   numerical arguments functions. numerical arguments n recycled   length result.  first elements logical   arguments used.","code":""},{"path":[]},{"path":"https://ai4ci.github.io/ggoutbreak/reference/pbeta2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The Beta Distribution â€” pbeta2","text":"","code":"pbeta2(c(0.25,0.5,0.75), 0.5, 0.25) #> [1] 0.0001270637 0.5000000000 0.9998729363"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/pcgamma.html","id":null,"dir":"Reference","previous_headings":"","what":"Cumulative probability: gamma distribution constrained to have mean > sd â€” pcgamma","title":"Cumulative probability: gamma distribution constrained to have mean > sd â€” pcgamma","text":"following conversion describes parameters mean kappa","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/pcgamma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cumulative probability: gamma distribution constrained to have mean > sd â€” pcgamma","text":"","code":"pcgamma(q, mean, kappa = 1/mean, lower.tail = TRUE, log.p = FALSE)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/pcgamma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cumulative probability: gamma distribution constrained to have mean > sd â€” pcgamma","text":"q vector quantiles mean mean value true scale (vectorised) kappa coefficient variation. 0 variability 1 maximally variability (vectorised) lower.tail logical; TRUE (default), probabilities P[X<=x] otherwise P[X>x]. log.p logical; TRUE, probabilities p given log(p).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/pcgamma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cumulative probability: gamma distribution constrained to have mean > sd â€” pcgamma","text":"dgamma gives density,   pgamma gives distribution function,   qgamma gives quantile function,   rgamma generates random deviates. Invalid arguments result return value NaN, warning. length result determined n   rgamma, maximum lengths   numerical arguments functions. numerical arguments n recycled   length result.  first elements logical   arguments used.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/pcgamma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cumulative probability: gamma distribution constrained to have mean > sd â€” pcgamma","text":"$$ \\text{shape:} \\alpha = \\frac{1}{\\kappa} \\\\ \\text{rate:} \\beta = \\frac{1}{\\mu \\times \\kappa} \\\\ \\text{scale:} \\sigma = \\mu \\times \\kappa \\\\ $$","code":""},{"path":[]},{"path":"https://ai4ci.github.io/ggoutbreak/reference/pcgamma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cumulative probability: gamma distribution constrained to have mean > sd â€” pcgamma","text":"","code":"pcgamma(seq(0,4,0.25), 2, 0.5) #>  [1] 0.00000000 0.02649902 0.09020401 0.17335853 0.26424112 0.35536421 #>  [7] 0.44217460 0.52212166 0.59399415 0.65745252 0.71270250 0.76027052 #> [13] 0.80085173 0.83520962 0.86411177 0.88829071 0.90842181"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/pgamma2.html","id":null,"dir":"Reference","previous_headings":"","what":"The Gamma Distribution â€” pgamma2","title":"The Gamma Distribution â€” pgamma2","text":"Density, distribution function, quantile function random   generation Gamma distribution parameters shape   scale.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/pgamma2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The Gamma Distribution â€” pgamma2","text":"","code":"pgamma2(q, mean, sd = sqrt(mean), lower.tail = TRUE, log.p = FALSE)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/pgamma2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The Gamma Distribution â€” pgamma2","text":"q vector quantiles mean mean value true scale (vectorised) sd standard deviation true scale (vectorised) lower.tail logical; TRUE (default), probabilities P[X<=x] otherwise P[X>x]. log.p logical; TRUE, probabilities p given log(p).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/pgamma2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The Gamma Distribution â€” pgamma2","text":"dgamma gives density,   pgamma gives distribution function,   qgamma gives quantile function,   rgamma generates random deviates. Invalid arguments result return value NaN, warning. length result determined n   rgamma, maximum lengths   numerical arguments functions. numerical arguments n recycled   length result.  first elements logical   arguments used.","code":""},{"path":[]},{"path":"https://ai4ci.github.io/ggoutbreak/reference/pgamma2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The Gamma Distribution â€” pgamma2","text":"","code":"pgamma2(seq(0,4,0.25), 2, 1) #>  [1] 0.000000000 0.001751623 0.018988157 0.065642454 0.142876540 0.242423867 #>  [7] 0.352768111 0.463367332 0.566529880 0.657704044 0.734974085 0.798300801 #> [13] 0.848796117 0.888150388 0.918234584 0.940854540 0.957619888"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator â€” %>%","title":"Pipe operator â€” %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator â€” %>%","text":"","code":"lhs %>% rhs"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator â€” %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator â€” %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plnorm2.html","id":null,"dir":"Reference","previous_headings":"","what":"The Log Normal Distribution â€” plnorm2","title":"The Log Normal Distribution â€” plnorm2","text":"Density, distribution function, quantile function random   generation log normal distribution whose logarithm mean   equal meanlog standard deviation equal sdlog.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plnorm2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The Log Normal Distribution â€” plnorm2","text":"","code":"plnorm2(q, mean = 1, sd = sqrt(exp(1) - 1), lower.tail = TRUE, log.p = FALSE)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plnorm2.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"The Log Normal Distribution â€” plnorm2","text":"dlnorm calculated definition (â€˜Detailsâ€™).   [pqr]lnorm based relationship normal. Consequently, model single point mass exp(meanlog)   boundary case sdlog = 0.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plnorm2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The Log Normal Distribution â€” plnorm2","text":"q vector quantiles mean mean value true scale (vectorised) sd standard deviation true scale (vectorised) lower.tail logical; TRUE (default), probabilities     \\(P[X \\le x]\\), otherwise, \\(P[X > x]\\). log.p logical; TRUE, probabilities p given log(p).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plnorm2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The Log Normal Distribution â€” plnorm2","text":"dlnorm gives density,   plnorm gives distribution function,   qlnorm gives quantile function,   rlnorm generates random deviates. length result determined n   rlnorm, maximum lengths   numerical arguments functions. numerical arguments n recycled   length result.  first elements logical   arguments used.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plnorm2.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The Log Normal Distribution â€” plnorm2","text":"log normal distribution density   $$     f(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma x} e^{-(\\log(x) - \\mu)^2/2 \\sigma^2}%   $$   \\(\\mu\\) \\(\\sigma\\) mean standard   deviation logarithm.   mean \\(E(X) = exp(\\mu + 1/2 \\sigma^2)\\),   median \\(med(X) = exp(\\mu)\\), variance   \\(Var(X) = exp(2\\mu + \\sigma^2)(exp(\\sigma^2) - 1)\\)   hence coefficient variation   \\(\\sqrt{exp(\\sigma^2) - 1}\\)   approximately \\(\\sigma\\) small (e.g., \\(\\sigma < 1/2\\)).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plnorm2.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"The Log Normal Distribution â€” plnorm2","text":"cumulative hazard \\(H(t) = - \\log(1 - F(t))\\)   -plnorm(t, r, lower = FALSE, log = TRUE).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plnorm2.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"The Log Normal Distribution â€” plnorm2","text":"Becker, R. ., Chambers, J. M. Wilks, . R. (1988)   New S Language.   Wadsworth & Brooks/Cole. Johnson, N. L., Kotz, S. Balakrishnan, N. (1995)   Continuous Univariate Distributions, volume 1, chapter 14.   Wiley, New York.","code":""},{"path":[]},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plnorm2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The Log Normal Distribution â€” plnorm2","text":"","code":"plnorm2(seq(0,4,0.25), 2, 1) #>  [1] 0.000000e+00 1.550937e-05 3.482566e-03 3.287216e-02 1.091319e-01 #>  [6] 2.239928e-01 3.546433e-01 4.814610e-01 5.933575e-01 6.863496e-01 #> [11] 7.607047e-01 8.186775e-01 8.631396e-01 8.968813e-01 9.223215e-01 #> [16] 9.414327e-01 9.557664e-01"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plogitnorm.html","id":null,"dir":"Reference","previous_headings":"","what":"Logit-normal distribution â€” plogitnorm","title":"Logit-normal distribution â€” plogitnorm","text":"logit-normal distribution support 0 1.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plogitnorm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logit-normal distribution â€” plogitnorm","text":"","code":"plogitnorm(q, meanlogit = 0, sdlogit = 1, lower.tail = TRUE, log.p = FALSE)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plogitnorm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logit-normal distribution â€” plogitnorm","text":"q vector quantiles (0<q<1) meanlogit mean logit scale sdlogit sd logit scale lower.tail logical; TRUE (default), probabilities P[X<=x] otherwise P[X>x]. log.p logical; TRUE, probabilities p given log(p).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plogitnorm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Logit-normal distribution â€” plogitnorm","text":"vector probabilities, quantiles, densities samples.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plogitnorm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Logit-normal distribution â€” plogitnorm","text":"","code":"plogitnorm(seq(0.1,0.9,0.1), 0, 1) #> [1] 0.01400221 0.08282852 0.19841456 0.34256783 0.50000000 0.65743217 0.80158544 #> [8] 0.91717148 0.98599779"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plogitnorm2.html","id":null,"dir":"Reference","previous_headings":"","what":"Logit-normal distribution â€” plogitnorm2","title":"Logit-normal distribution â€” plogitnorm2","text":"logit-normal distribution support 0 1.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plogitnorm2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logit-normal distribution â€” plogitnorm2","text":"","code":"plogitnorm2(   q,   prob.0.5 = 0.5,   kappa = 1 - exp(-1),   lower.tail = TRUE,   log.p = FALSE )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plogitnorm2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logit-normal distribution â€” plogitnorm2","text":"q vector quantiles (0<q<1) prob.0.5 median true scale kappa dispersion parameter 0 (none) 1 maximum dispersion lower.tail logical; TRUE (default), probabilities P[X<=x] otherwise P[X>x]. log.p logical; TRUE, probabilities p given log(p).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plogitnorm2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Logit-normal distribution â€” plogitnorm2","text":"vector probabilities, quantiles, densities samples.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plogitnorm2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Logit-normal distribution â€” plogitnorm2","text":"","code":"plogitnorm2(seq(0.1,0.9,0.1), 0.75, 0.2) #> [1] 1.143062e-49 4.194162e-29 1.385603e-18 7.897412e-12 4.253902e-07 #> [6] 9.472742e-04 1.300308e-01 9.013399e-01 9.999996e-01 plogitnorm2(qlogitnorm2(seq(0.1,0.9,0.1), 0.75, 0.2), 0.75, 0.2) #> [1] 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_cases.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a line-list of cases as a histogram â€” plot_cases","title":"Plot a line-list of cases as a histogram â€” plot_cases","text":"Plot line-list cases histogram","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_cases.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a line-list of cases as a histogram â€” plot_cases","text":"","code":"plot_cases(   raw,   ...,   mapping = .check_for_aes(raw, ..., class_aes = \"fill\"),   events = i_events )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_cases.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a line-list of cases as a histogram â€” plot_cases","text":"raw raw case data either summarised count line-list - EITHER: dataframe columns: count (positive_integer) - Positive case counts associated specified time frame time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` grouping allowed. columns: time (ggoutbreak::time_period) - set events timestamp `time_period` grouping allowed. ... Named arguments passed geom_events events Significant events time spans - dataframe columns: label (character) - event label start (date) - start date, date event end (date) - end date NA single event grouping allowed. default value defined. mapping ggplot2::aes mapping. importantly setting fill something multiple types event plot. class column present mapping default using . events Significant events time spans - dataframe columns: label (character) - event label start (date) - start date, date event end (date) - end date NA single event grouping allowed. default value defined.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_cases.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a line-list of cases as a histogram â€” plot_cases","text":"ggplot object","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_cases.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot a line-list of cases as a histogram â€” plot_cases","text":"","code":"with_defaults(\"2025-01-01\" ,\"1 day\", {   tmp = dplyr::tibble(     time = as.time_period( rexpgrowth(100,0.05,40)),     class = rep(c(\"one\",\"two\",\"three\"), length.out=100)   ) })  if(interactive()) {   plot_cases(tmp, mapping=ggplot2::aes(fill = class),linewidth=0.1,colour=\"white\") }"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_counts.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a raw case count timeseries â€” plot_counts","title":"Plot a raw case count timeseries â€” plot_counts","text":"Plot raw case count timeseries","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_counts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a raw case count timeseries â€” plot_counts","text":"","code":"plot_counts(raw, ..., mapping = .check_for_aes(raw, ...), events = i_events)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_counts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a raw case count timeseries â€” plot_counts","text":"raw raw count data, raw count data normalised population ( see normalise_count()) - EITHER: dataframe columns: population (positive_integer) - Size population count (positive_integer) - Positive case counts associated specified time frame time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` population_unit (double) - population unit per capita incidence rate calculated time_unit (lubridate::.period) - time period per capita incidence rate calculated grouping allowed. columns: count (positive_integer) - Positive case counts associated specified time frame time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` grouping allowed. ... Named arguments passed geom_events events Significant events time spans - dataframe columns: label (character) - event label start (date) - start date, date event end (date) - end date NA single event grouping allowed. default value defined. mapping ggplot2::aes mapping. importantly setting colour something multiple incidence timeseries plot events Significant events time spans - dataframe columns: label (character) - event label start (date) - start date, date event end (date) - end date NA single event grouping allowed. default value defined.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_counts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a raw case count timeseries â€” plot_counts","text":"ggplot object","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_counts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot a raw case count timeseries â€” plot_counts","text":"","code":"# example code  tmp = example_england_covid_by_age() %>%   time_aggregate(count=sum(count)) %>%   normalise_count(pop=56489700, population_unit=1000, normalise_time=TRUE)  # normalised by England population (56489700 people)  if(interactive()) {   plot_counts(tmp, colour=\"blue\",size=0.25) }"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_growth_phase.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot an incidence or proportion versus growth phase diagram â€” plot_growth_phase","title":"Plot an incidence or proportion versus growth phase diagram â€” plot_growth_phase","text":"Plot incidence proportion versus growth phase diagram","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_growth_phase.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot an incidence or proportion versus growth phase diagram â€” plot_growth_phase","text":"","code":"plot_growth_phase(   modelled,   timepoints = NULL,   duration = max(dplyr::count(modelled)$n),   interval = 7,   mapping = if (interfacer::is_col_present(modelled, class)) {      ggplot2::aes(colour =     class)  } else {      ggplot2::aes()  },   cis = TRUE,   ... )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_growth_phase.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot an incidence or proportion versus growth phase diagram â€” plot_growth_phase","text":"modelled Growth rates incidence / proportion timeseries outputs functions proportion_locfit_model, poisson_locfit_model, similar. - EITHER: dataframe columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` incidence.per_capita.fit (double) - estimate incidence per capita rate log scale incidence.per_capita.se.fit (positive_double) - standard error incidence per capita rate estimate log scale incidence.per_capita.0.025 (positive_double) - lower confidence limit incidence per capita rate (true scale) incidence.per_capita.0.5 (positive_double) - median estimate incidence per capita rate (true scale) incidence.per_capita.0.975 (positive_double) - upper confidence limit incidence per capita rate (true scale) population_unit (double) - population unit per capita incidence rate calculated time_unit (lubridate::.period) - time period per capita incidence rate calculated growth.fit (double) - estimate growth rate growth.se.fit (positive_double) - standard error growth rate growth.0.025 (double) - lower confidence limit growth rate growth.0.5 (double) - median estimate growth rate growth.0.975 (double) - upper confidence limit growth rate grouping allowed. columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` incidence.fit (double) - estimate incidence rate log scale incidence.se.fit (positive_double) - standard error incidence rate estimate log scale incidence.0.025 (positive_double) - lower confidence limit incidence rate (true scale) incidence.0.5 (positive_double) - median estimate incidence rate (true scale) incidence.0.975 (positive_double) - upper confidence limit incidence rate (true scale) growth.fit (double) - estimate growth rate growth.se.fit (positive_double) - standard error growth rate growth.0.025 (double) - lower confidence limit growth rate growth.0.5 (double) - median estimate growth rate growth.0.975 (double) - upper confidence limit growth rate grouping allowed. columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` risk_ratio.0.025 (positive_double) - lower confidence limit excess risk ratio population group risk_ratio.0.5 (positive_double) - median estimate excess risk ratio population group risk_ratio.0.975 (positive_double) - upper confidence limit excess risk ratio population group proportion.fit (double) - estimate proportion logit scale proportion.se.fit (positive_double) - standard error proportion estimate logit scale proportion.0.025 (proportion) - lower confidence limit proportion (true scale) proportion.0.5 (proportion) - median estimate proportion (true scale) proportion.0.975 (proportion) - upper confidence limit proportion (true scale) relative.growth.fit (double) - estimate relative growth rate relative.growth.se.fit (positive_double) - standard error relative growth rate relative.growth.0.025 (double) - lower confidence limit relative growth rate relative.growth.0.5 (double) - median estimate relative growth rate relative.growth.0.975 (double) - upper confidence limit relative growth rate grouping allowed. columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` proportion.fit (double) - estimate proportion logit scale proportion.se.fit (positive_double) - standard error proportion estimate logit scale proportion.0.025 (proportion) - lower confidence limit proportion (true scale) proportion.0.5 (proportion) - median estimate proportion (true scale) proportion.0.975 (proportion) - upper confidence limit proportion (true scale) relative.growth.fit (double) - estimate relative growth rate relative.growth.se.fit (positive_double) - standard error relative growth rate relative.growth.0.025 (double) - lower confidence limit relative growth rate relative.growth.0.5 (double) - median estimate relative growth rate relative.growth.0.975 (double) - upper confidence limit relative growth rate grouping allowed. NULL timepoints time points (Date time_period vector) dates plot phase diagrams. multiple result sequence plots facets. NULL (default) last time point series duration length growth rate phase trail interval length time markers phase plot mapping ggplot2::aes() mapping cis logical; phases marked confidence intervals? ... Named arguments passed geom_events events Significant events time spans - dataframe columns: label (character) - event label start (date) - start date, date event end (date) - end date NA single event grouping allowed. default value defined. Named arguments passed ggplot2::facet_wrap facets set variables expressions quoted vars() defining faceting groups rows columns dimension. variables can named (names passed labeller). compatibility classic interface, can also formula character vector. Use either one sided formula, ~+ b, character vector, c(\"\", \"b\"). nrow,ncol Number rows columns. scales scales fixed (\"fixed\", default), free (\"free\"), free one dimension (\"free_x\", \"free_y\")? space \"fixed\" (default), panels size number rows columns layout can arbitrary. \"free_x\", panels widths proportional length x-scale, layout constrained one row. \"free_y\", panels heights proportional length y-scale, layout constrained one column. shrink TRUE, shrink scales fit output statistics, raw data. FALSE, range raw data statistical summary. labeller function takes one data frame labels returns list data frame character vectors. input column corresponds one factor. Thus one vars(cyl, ). output column gets displayed one separate line strip label. function inherit \"labeller\" S3 class compatibility labeller(). can use different labeling functions different kind labels, example use label_parsed() formatting facet labels. label_value() used default, check details pointers options. .table .table argument now absorbed dir argument via two letter options. TRUE, facets laid like table highest values bottom-right. FALSE, facets laid like plot highest value top-right. switch default, labels displayed top right plot. \"x\", top labels displayed bottom. \"y\", right-hand side labels displayed left. Can also set \"\". drop TRUE, default, factor levels used data automatically dropped. FALSE, factor levels shown, regardless whether appear data. dir Direction: either \"h\" horizontal, default, \"v\", vertical. \"h\" \"v\" combined .table set final layout. Alternatively, combination \"t\" (top) \"b\" (bottom) \"l\" (left) \"r\" (right) set layout directly. two letters give starting position first letter gives growing direction. example \"rt\" place first panel top-right starts filling panels right--left. strip.position default, labels displayed top plot. Using strip.position possible place labels either four sides setting strip.position = c(\"top\",   \"bottom\", \"left\", \"right\") axes Determines axes drawn case fixed scales. \"margins\" (default), axes drawn exterior margins. \"all_x\" \"all_y\" draw respective axes interior panels , whereas \"\" draw axes panels. axis.labels Determines whether draw labels interior axes scale fixed axis argument \"margins\". \"\" (default), interior axes get labels. \"margins\", exterior axes get labels, interior axes get none. \"all_x\" \"all_y\", draws labels interior axes x- y-direction respectively.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_growth_phase.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot an incidence or proportion versus growth phase diagram â€” plot_growth_phase","text":"ggplot","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_growth_phase.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot an incidence or proportion versus growth phase diagram â€” plot_growth_phase","text":"","code":"data = example_poisson_rt_2class() tmp2 = data %>% poisson_locfit_model()  timepoints = as.Date(tmp2$time[c(40,80,120,160)])  if(interactive()) {   plot_growth_phase(tmp2, timepoints, duration=108) }"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_growth_rate.html","id":null,"dir":"Reference","previous_headings":"","what":"Growth rate timeseries diagram â€” plot_growth_rate","title":"Growth rate timeseries diagram â€” plot_growth_rate","text":"Growth rate timeseries diagram","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_growth_rate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Growth rate timeseries diagram â€” plot_growth_rate","text":"","code":"plot_growth_rate(   modelled,   ...,   mapping = .check_for_aes(modelled, ...),   events = i_events )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_growth_rate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Growth rate timeseries diagram â€” plot_growth_rate","text":"modelled growth rate dataframe. - EITHER: dataframe columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` growth.fit (double) - estimate growth rate growth.se.fit (positive_double) - standard error growth rate growth.0.025 (double) - lower confidence limit growth rate growth.0.5 (double) - median estimate growth rate growth.0.975 (double) - upper confidence limit growth rate grouping allowed. columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` relative.growth.fit (double) - estimate relative growth rate relative.growth.se.fit (positive_double) - standard error relative growth rate relative.growth.0.025 (double) - lower confidence limit relative growth rate relative.growth.0.5 (double) - median estimate relative growth rate relative.growth.0.975 (double) - upper confidence limit relative growth rate grouping allowed. ... Named arguments passed geom_events events Significant events time spans - dataframe columns: label (character) - event label start (date) - start date, date event end (date) - end date NA single event grouping allowed. default value defined. Named arguments passed geom_truth true_df data frame time_period column called time value column (name given true_col). optional picked raw parameter given. true_col column name / expression true value true_fmt list ggplot formatting apply true value timeseries ... Named arguments passed .time_period unit length one unit time. either integer number days, specification \"1 week\", another time_period. x time_period, unit different x return rescaled time_period using new units. start_date zero time date something can coerced date. x input already time_period different start_date x recalibrated use new start date. anchor relevant x vector dates, date, \"start\" \"end\" weekday name e.g. \"mon\". vector dates x use anchor find reference date time-series. provided current defaults used. (see set_defaults()) mapping ggplot2::aes mapping. importantly setting colour something multiple incidence time series plot events Significant events time spans - dataframe columns: label (character) - event label start (date) - start date, date event end (date) - end date NA single event grouping allowed. default value defined.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_growth_rate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Growth rate timeseries diagram â€” plot_growth_rate","text":"ggplot","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_growth_rate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Growth rate timeseries diagram â€” plot_growth_rate","text":"","code":"data = example_poisson_rt_2class() tmp2 = data %>% poisson_locfit_model()  if(interactive()) {   plot_growth_rate(tmp2) }"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_incidence.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot an incidence timeseries â€” plot_incidence","title":"Plot an incidence timeseries â€” plot_incidence","text":"Plot incidence timeseries","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_incidence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot an incidence timeseries â€” plot_incidence","text":"","code":"plot_incidence(   modelled,   raw = i_incidence_data,   ...,   mapping = .check_for_aes(modelled, ...),   events = i_events )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_incidence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot an incidence timeseries â€” plot_incidence","text":"modelled optional estimate incidence time series. modelled missing estimated raw using poisson_locfit_model. case parameters window deg may supplied control fit. modelled can also output normalise_incidence case plot uses per capita rates calculated function. - EITHER: dataframe columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` incidence.per_capita.fit (double) - estimate incidence per capita rate log scale incidence.per_capita.se.fit (positive_double) - standard error incidence per capita rate estimate log scale incidence.per_capita.0.025 (positive_double) - lower confidence limit incidence per capita rate (true scale) incidence.per_capita.0.5 (positive_double) - median estimate incidence per capita rate (true scale) incidence.per_capita.0.975 (positive_double) - upper confidence limit incidence per capita rate (true scale) population_unit (double) - population unit per capita incidence rate calculated time_unit (lubridate::.period) - time period per capita incidence rate calculated grouping allowed. columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` incidence.fit (double) - estimate incidence rate log scale incidence.se.fit (positive_double) - standard error incidence rate estimate log scale incidence.0.025 (positive_double) - lower confidence limit incidence rate (true scale) incidence.0.5 (positive_double) - median estimate incidence rate (true scale) incidence.0.975 (positive_double) - upper confidence limit incidence rate (true scale) grouping allowed. raw raw count data (optional - given overlaid points top modelled estimate) - dataframe columns: count (positive_integer) - Positive case counts associated specified time frame time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` grouping allowed. ... Named arguments passed geom_events events Significant events time spans - dataframe columns: label (character) - event label start (date) - start date, date event end (date) - end date NA single event grouping allowed. default value defined. Named arguments passed poisson_locfit_model window number data points defining bandwidth estimate, smaller values result less smoothing, large value . default value 14 calibrated data provided daily frequency, weekly data lower value may preferred. - default 14 deg polynomial degree (min 1) - higher degree results less smoothing, lower values result smoothing. degree 1 fitting linear model piece wise. - default 2 frequency density output estimates time period 7 days 2 weeks. - default 1 day Named arguments passed geom_truth true_df data frame time_period column called time value column (name given true_col). optional picked raw parameter given. true_col column name / expression true value true_fmt list ggplot formatting apply true value timeseries ... Named arguments passed .time_period unit length one unit time. either integer number days, specification \"1 week\", another time_period. x time_period, unit different x return rescaled time_period using new units. start_date zero time date something can coerced date. x input already time_period different start_date x recalibrated use new start date. anchor relevant x vector dates, date, \"start\" \"end\" weekday name e.g. \"mon\". vector dates x use anchor find reference date time-series. provided current defaults used. (see set_defaults()) mapping ggplot2::aes mapping. importantly setting colour something multiple incidence timeseries plot events Significant events time spans - dataframe columns: label (character) - event label start (date) - start date, date event end (date) - end date NA single event grouping allowed. default value defined.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_incidence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot an incidence timeseries â€” plot_incidence","text":"ggplot object","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_incidence.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot an incidence timeseries â€” plot_incidence","text":"","code":"# example code  tmp = example_poisson_rt_2class() tmp2 = tmp %>% poisson_locfit_model()  if(interactive()) {   plot_incidence(tmp2,tmp,size=0.25) }"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_ip.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot an infectivity profile â€” plot_ip","title":"Plot an infectivity profile â€” plot_ip","text":"Plot infectivity profile","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_ip.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot an infectivity profile â€” plot_ip","text":"","code":"plot_ip(ip = i_empirical_ip, alpha = NULL, ...)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_ip.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot an infectivity profile â€” plot_ip","text":"ip long format infectivity profile - dataframe columns: boot (anything + default(1)) - bootstrap identifier probability (proportion) - probability new event period. a0 (double) - beginning time period (days) a1 (double) - end time period (days) Minimally grouped : boot (groupings allowed). alpha alpha value bootstrap lines ... passed onto geom_segment controlling line thickness, alpha etc.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_ip.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot an infectivity profile â€” plot_ip","text":"ggplot object","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_ip.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot an infectivity profile â€” plot_ip","text":"","code":"if(interactive()) {   plot_ip(example_ganyani_ip()) }"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_multinomial.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a multinomial proportions model â€” plot_multinomial","title":"Plot a multinomial proportions model â€” plot_multinomial","text":"multinomial proportions model tell proportion class versus others data set. case denominator total count across across classes.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_multinomial.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a multinomial proportions model â€” plot_multinomial","text":"","code":"plot_multinomial(   modelled = i_multinomial_proportion_model,   ...,   mapping = ggplot2::aes(fill = class),   events = i_events,   normalise = FALSE )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_multinomial.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a multinomial proportions model â€” plot_multinomial","text":"modelled multinomial count data - dataframe columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` class (factor) - factor specifying type observation. things like variant, serotype, multinomial model. missing data points ignored. proportion.0.5 (proportion) - median estimate proportion (true scale) Must grouped : class (exactly). ... Named arguments passed geom_events events Significant events time spans - dataframe columns: label (character) - event label start (date) - start date, date event end (date) - end date NA single event grouping allowed. default value defined. mapping ggplot2::aes mapping. Usually left default events Significant events time spans - dataframe columns: label (character) - event label start (date) - start date, date event end (date) - end date NA single event grouping allowed. default value defined. normalise make sure probabilities add one - can bad idea know may missing values, hand proportions models guaranteed add one.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_multinomial.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a multinomial proportions model â€” plot_multinomial","text":"ggplot","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_multinomial.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot a multinomial proportions model â€” plot_multinomial","text":"","code":"tmp = example_proportion_age_stratified() %>%   dplyr::group_by(class) %>%   dplyr::glimpse() #> Rows: 26,790 #> Columns: 20 #> Groups: class [19] #> $ class                  <fct> 00_04, 00_04, 00_04, 00_04, 00_04, 00_04, 00_04â€¦ #> $ time                   <t[day]> 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, â€¦ #> $ proportion.fit         <dbl> -4.153966, -4.030468, -3.909366, -3.789972, -3.â€¦ #> $ proportion.se.fit      <dbl> 2.786922, 2.612521, 2.449106, 2.296631, 2.15505â€¦ #> $ proportion.0.025       <dbl> 6.663374e-05, 1.061114e-04, 1.649795e-04, 2.506â€¦ #> $ proportion.0.05        <dbl> 0.0001603414, 0.0002416732, 0.0003568686, 0.000â€¦ #> $ proportion.0.25        <dbl> 0.002390842, 0.003040809, 0.003829202, 0.004777â€¦ #> $ proportion.0.5         <dbl> 0.01545928, 0.01745590, 0.01965899, 0.02209692,â€¦ #> $ proportion.0.75        <dbl> 0.09328110, 0.09377845, 0.09470714, 0.09613571,â€¦ #> $ proportion.0.95        <dbl> 0.6059008, 0.5662942, 0.5297285, 0.4969123, 0.4â€¦ #> $ proportion.0.975       <dbl> 0.7872289, 0.7483779, 0.7090538, 0.6706974, 0.6â€¦ #> $ relative.growth.fit    <dbl> 0.12492549, 0.12510534, 0.12559852, 0.12633546,â€¦ #> $ relative.growth.se.fit <dbl> 0.2055049, 0.2043951, 0.2013519, 0.1968045, 0.1â€¦ #> $ relative.growth.0.025  <dbl> -0.2778567, -0.2755017, -0.2690439, -0.2593943,â€¦ #> $ relative.growth.0.05   <dbl> -0.2131000, -0.2110947, -0.2055958, -0.1973791,â€¦ #> $ relative.growth.0.25   <dbl> -0.013685471, -0.012757065, -0.010211256, -0.00â€¦ #> $ relative.growth.0.5    <dbl> 0.12492549, 0.12510534, 0.12559852, 0.12633546,â€¦ #> $ relative.growth.0.75   <dbl> 0.26353645, 0.26296775, 0.26140830, 0.25907808,â€¦ #> $ relative.growth.0.95   <dbl> 0.46295099, 0.46130538, 0.45679289, 0.45005005,â€¦ #> $ relative.growth.0.975  <dbl> 0.5277077, 0.5257124, 0.5202409, 0.5120652, 0.5â€¦  if(interactive()) {   plot_multinomial(tmp, normalise=TRUE)+     ggplot2::scale_fill_viridis_d() }"},{"path":[]},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_prevalence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a timeseries of disease prevalence â€” plot_prevalence","text":"","code":"plot_prevalence(   modelled = i_prevalence_model,   raw = i_proportion_data,   ...,   mapping = .check_for_aes(modelled, ...),   events = i_events )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_prevalence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a timeseries of disease prevalence â€” plot_prevalence","text":"modelled Prevalence estimates - dataframe columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` prevalence.0.025 (proportion) - lower confidence limit prevalence (true scale) prevalence.0.5 (proportion) - median estimate prevalence (true scale) prevalence.0.975 (proportion) - upper confidence limit prevalence (true scale) grouping allowed. raw Raw proportion data - dataframe columns: denom (positive_integer) - Total test counts associated specified time frame count (positive_integer) - Positive case counts associated specified time frame time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` grouping allowed. ... Named arguments passed geom_events events Significant events time spans - dataframe columns: label (character) - event label start (date) - start date, date event end (date) - end date NA single event grouping allowed. default value defined. mapping ggplot2::aes mapping. importantly setting colour something multiple incidence timeseries plot events Significant events time spans - dataframe columns: label (character) - event label start (date) - start date, date event end (date) - end date NA single event grouping allowed. default value defined.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_prevalence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a timeseries of disease prevalence â€” plot_prevalence","text":"ggplot object","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_prevalence.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot a timeseries of disease prevalence â€” plot_prevalence","text":"","code":"if(interactive()) {    plot_prevalence(     ukc19::ons_infection_survey %>%       dplyr::mutate(time = as.time_period(date,\"1 day\")),     mapping = ggplot2::aes(colour=name)) }"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_proportion.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a proportions timeseries â€” plot_proportion","title":"Plot a proportions timeseries â€” plot_proportion","text":"Plot proportions timeseries","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_proportion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a proportions timeseries â€” plot_proportion","text":"","code":"plot_proportion(   modelled = i_proportion_model,   raw = i_proportion_data,   ...,   mapping = .check_for_aes(modelled, ...),   events = i_events )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_proportion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a proportions timeseries â€” plot_proportion","text":"modelled Proportion model estimates - dataframe columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` proportion.fit (double) - estimate proportion logit scale proportion.se.fit (positive_double) - standard error proportion estimate logit scale proportion.0.025 (proportion) - lower confidence limit proportion (true scale) proportion.0.5 (proportion) - median estimate proportion (true scale) proportion.0.975 (proportion) - upper confidence limit proportion (true scale) grouping allowed. raw Raw count data denominator - dataframe columns: denom (positive_integer) - Total test counts associated specified time frame count (positive_integer) - Positive case counts associated specified time frame time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` grouping allowed. ... Named arguments passed geom_events events Significant events time spans - dataframe columns: label (character) - event label start (date) - start date, date event end (date) - end date NA single event grouping allowed. default value defined. mapping ggplot2::aes mapping. importantly setting colour something multiple incidence timeseries plot events Significant events time spans - dataframe columns: label (character) - event label start (date) - start date, date event end (date) - end date NA single event grouping allowed. default value defined.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_proportion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a proportions timeseries â€” plot_proportion","text":"ggplot object","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_proportion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot a proportions timeseries â€” plot_proportion","text":"","code":"tmp = example_poisson_rt_2class() %>%   proportion_locfit_model(window=21) %>%   dplyr::glimpse() #> Rows: 322 #> Columns: 20 #> Groups: class [2] #> $ class                  <fct> one, one, one, one, one, one, one, one, one, onâ€¦ #> $ time                   <t[day]> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13â€¦ #> $ proportion.fit         <dbl> -0.33057858, -0.28970647, -0.24935786, -0.20927â€¦ #> $ proportion.se.fit      <dbl> 0.3042480, 0.2900854, 0.2765568, 0.2637498, 0.2â€¦ #> $ proportion.0.025       <dbl> 0.2835553, 0.2977023, 0.3118683, 0.3260266, 0.3â€¦ #> $ proportion.0.05        <dbl> 0.3034290, 0.3171599, 0.3308699, 0.3445458, 0.3â€¦ #> $ proportion.0.25        <dbl> 0.3691673, 0.3809858, 0.3927201, 0.4043992, 0.4â€¦ #> $ proportion.0.5         <dbl> 0.4180999, 0.4280757, 0.4379816, 0.4478722, 0.4â€¦ #> $ proportion.0.75        <dbl> 0.4686994, 0.4765056, 0.4842994, 0.4921569, 0.5â€¦ #> $ proportion.0.95        <dbl> 0.5423644, 0.5467237, 0.5512042, 0.5559049, 0.5â€¦ #> $ proportion.0.975       <dbl> 0.5660459, 0.5692644, 0.5726530, 0.5763161, 0.5â€¦ #> $ relative.growth.fit    <dbl> 0.04122094, 0.04136694, 0.04176321, 0.04234719,â€¦ #> $ relative.growth.se.fit <dbl> 0.02126269, 0.02121428, 0.02108289, 0.02088926,â€¦ #> $ relative.growth.0.025  <dbl> -0.0004531581, -0.0002122864, 0.0004415081, 0.0â€¦ #> $ relative.growth.0.05   <dbl> 0.006246934, 0.006472552, 0.007084944, 0.007987â€¦ #> $ relative.growth.0.25   <dbl> 0.02687948, 0.02705812, 0.02754302, 0.02825760,â€¦ #> $ relative.growth.0.5    <dbl> 0.04122094, 0.04136694, 0.04176321, 0.04234719,â€¦ #> $ relative.growth.0.75   <dbl> 0.05556240, 0.05567575, 0.05598340, 0.05643677,â€¦ #> $ relative.growth.0.95   <dbl> 0.07619495, 0.07626132, 0.07644147, 0.07670695,â€¦ #> $ relative.growth.0.975  <dbl> 0.08289504, 0.08294616, 0.08308490, 0.08328938,â€¦  if(interactive()) {   plot_proportion(tmp)+     ggplot2::scale_fill_viridis_d(aesthetics = c(\"fill\",\"colour\")) }"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_proportions.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a raw case count proportion timeseries â€” plot_proportions","title":"Plot a raw case count proportion timeseries â€” plot_proportions","text":"Plot raw case count proportion timeseries","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_proportions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a raw case count proportion timeseries â€” plot_proportions","text":"","code":"plot_proportions(   raw = i_proportion_data,   ...,   mapping = .check_for_aes(raw, ...),   events = i_events )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_proportions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a raw case count proportion timeseries â€” plot_proportions","text":"raw raw count denominator data - dataframe columns: denom (positive_integer) - Total test counts associated specified time frame count (positive_integer) - Positive case counts associated specified time frame time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` grouping allowed. ... Named arguments passed geom_events event_label_size big make event label event_label_colour event label colour event_label_angle event label colour event_line_colour event line colour event_fill_colour event area fill hide_labels show labels guide_axis guide axis configuration labels (see ggplot2::guide_axis ggplot2::dup_axis). can used specify position amongst things. ... Named arguments passed ggplot2::scale_x_date name name scale. Used axis legend title. waiver(), default, name scale taken first mapping used aesthetic. NULL, legend title omitted. breaks One : NULL breaks waiver() breaks specified date_breaks Date/POSIXct vector giving positions breaks function takes limits input returns breaks output date_breaks string giving distance breaks like \"2 weeks\", \"10 years\". breaks date_breaks specified, date_breaks wins. Valid specifications 'sec', 'min', 'hour', 'day', 'week', 'month' 'year', optionally followed 's'. labels One : NULL labels waiver() default labels computed transformation object character vector giving labels (must length breaks) expression vector (must length breaks). See ?plotmath details. function takes breaks input returns labels output. Also accepts rlang lambda function notation. date_labels string giving formatting specification labels. Codes defined strftime(). labels date_labels specified, date_labels wins. minor_breaks One : NULL breaks waiver() breaks specified date_minor_breaks Date/POSIXct vector giving positions minor breaks function takes limits input returns minor breaks output date_minor_breaks string giving distance minor breaks like \"2 weeks\", \"10 years\". minor_breaks date_minor_breaks specified, date_minor_breaks wins. Valid specifications 'sec', 'min', 'hour', 'day', 'week', 'month' 'year', optionally followed 's'. limits One : NULL use default scale range numeric vector length two providing limits scale. Use NA refer existing minimum maximum function accepts existing (automatic) limits returns new limits. Also accepts rlang lambda function notation. Note setting limits positional scales remove data outside limits. purpose zoom, use limit argument coordinate system (see coord_cartesian()). expand position scales, vector range expansion constants used add padding around data ensure placed distance away axes. Use convenience function expansion() generate values expand argument. defaults expand scale 5% side continuous variables, 0.6 units side discrete variables. oob One : Function handles limits outside scale limits (bounds). Also accepts rlang lambda function notation. default (scales::censor()) replaces bounds values NA. scales::squish() squishing bounds values range. scales::squish_infinite() squishing infinite values range. guide function used create guide name. See guides() information. position position scales, position axis. left right y axes, top bottom x axes. sec.axis sec_axis() used specify secondary axis. timezone timezone use display axes. default (NULL) uses timezone encoded data. na.value Missing values replaced value. mapping ggplot2::aes mapping. importantly setting colour something multiple incidence timeseries plot events Significant events time spans - dataframe columns: label (character) - event label start (date) - start date, date event end (date) - end date NA single event grouping allowed. default value defined.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_proportions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a raw case count proportion timeseries â€” plot_proportions","text":"ggplot object","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_proportions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot a raw case count proportion timeseries â€” plot_proportions","text":"","code":"# example code  tmp = tibble::tibble(   time = as.time_period(1:10, \"1 day\"),   count = 101:110 ) %>% dplyr::mutate(   denom = count*time )  if(interactive()) {   plot_proportions(tmp)+ggplot2::geom_line() }"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_proportions_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a raw case count proportion timeseries â€” plot_proportions_data","title":"Plot a raw case count proportion timeseries â€” plot_proportions_data","text":"Plot raw case count proportion timeseries","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_proportions_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a raw case count proportion timeseries â€” plot_proportions_data","text":"","code":"plot_proportions_data(   raw = i_proportion_data,   ...,   mapping = .check_for_aes(raw, ...),   events = i_events )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_proportions_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a raw case count proportion timeseries â€” plot_proportions_data","text":"raw raw count denominator data - dataframe columns: denom (positive_integer) - Total test counts associated specified time frame count (positive_integer) - Positive case counts associated specified time frame time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` grouping allowed. ... Named arguments passed geom_events events Significant events time spans - dataframe columns: label (character) - event label start (date) - start date, date event end (date) - end date NA single event grouping allowed. default value defined. mapping ggplot2::aes mapping. importantly setting colour something multiple count timeseries data events Significant events time spans - dataframe columns: label (character) - event label start (date) - start date, date event end (date) - end date NA single event grouping allowed. default value defined.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_proportions_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a raw case count proportion timeseries â€” plot_proportions_data","text":"ggplot object","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_proportions_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot a raw case count proportion timeseries â€” plot_proportions_data","text":"","code":"tmp = example_england_covid_by_age() %>%   dplyr::filter(class %in% c(\"50_54\",\"80_84\"))  if(interactive()) {   plot_proportions_data(tmp, mapping= ggplot2::aes(colour=class))+ggplot2::geom_line() }"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_rt.html","id":null,"dir":"Reference","previous_headings":"","what":"Reproduction number timeseries diagram â€” plot_rt","title":"Reproduction number timeseries diagram â€” plot_rt","text":"Reproduction number timeseries diagram","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_rt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reproduction number timeseries diagram â€” plot_rt","text":"","code":"plot_rt(   modelled = i_reproduction_number,   ...,   mapping = .check_for_aes(modelled, ...),   events = i_events )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_rt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reproduction number timeseries diagram â€” plot_rt","text":"modelled modelled Rt estimate - dataframe columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` rt.fit (double) - estimate reproduction number rt.se.fit (positive_double) - standard error reproduction number rt.0.025 (double) - lower confidence limit reproduction number rt.0.5 (double) - median estimate reproduction number rt.0.975 (double) - upper confidence limit reproduction number grouping allowed. ... Named arguments passed geom_events events Significant events time spans - dataframe columns: label (character) - event label start (date) - start date, date event end (date) - end date NA single event grouping allowed. default value defined. Named arguments passed geom_truth true_df data frame time_period column called time value column (name given true_col). optional picked raw parameter given. true_col column name / expression true value true_fmt list ggplot formatting apply true value timeseries ... Named arguments passed .time_period unit length one unit time. either integer number days, specification \"1 week\", another time_period. x time_period, unit different x return rescaled time_period using new units. start_date zero time date something can coerced date. x input already time_period different start_date x recalibrated use new start date. anchor relevant x vector dates, date, \"start\" \"end\" weekday name e.g. \"mon\". vector dates x use anchor find reference date time-series. provided current defaults used. (see set_defaults()) mapping ggplot2::aes mapping. importantly setting colour something multiple incidence time series plot events Significant events time spans - dataframe columns: label (character) - event label start (date) - start date, date event end (date) - end date NA single event grouping allowed. default value defined.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_rt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reproduction number timeseries diagram â€” plot_rt","text":"ggplot timeseries","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/plot_rt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reproduction number timeseries diagram â€” plot_rt","text":"","code":"# example code if (interactive()) {  tmp2 = example_poisson_locfit() %>%   dplyr::filter(as.Date(time) >= \"2021-01-01\" & as.Date(time) < \"2022-01-01\") %>%   rt_from_incidence(ip = example_ganyani_ip())  # comparing RT from growth rates with England consensus Rt # (N.B. offset by 14 days to align with estimates):  plot_rt(tmp2,colour=\"blue\")+   ggplot2::geom_errorbar(     data= ukc19::spim_consensus %>%       dplyr::filter(date-14 >= \"2021-01-01\" & date-14 < \"2022-01-01\"),     mapping=ggplot2::aes(x=date-14,ymin=rt.low,ymax=rt.high),     colour=\"red\")  }"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/pnbinom2.html","id":null,"dir":"Reference","previous_headings":"","what":"The Negative Binomial Distribution â€” pnbinom2","title":"The Negative Binomial Distribution â€” pnbinom2","text":"Density, distribution function, quantile function random   generation negative binomial distribution parameters   size prob.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/pnbinom2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The Negative Binomial Distribution â€” pnbinom2","text":"","code":"pnbinom2(q, mean, sd = sqrt(mean), lower.tail = TRUE, log.p = FALSE)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/pnbinom2.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"The Negative Binomial Distribution â€” pnbinom2","text":"dnbinom computes via binomial probabilities, using code   contributed Catherine Loader (see dbinom). pnbinom uses pbeta. qnbinom uses Cornishâ€“Fisher Expansion include skewness   correction normal approximation, followed search. rnbinom uses derivation gamma mixture Poisson   distributions, see Devroye, L. (1986) Non-Uniform Random Variate Generation.   Springer-Verlag, New York. Page 480.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/pnbinom2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The Negative Binomial Distribution â€” pnbinom2","text":"q vector quantiles. mean mean value true scale (vectorised) sd standard deviation true scale (vectorised) lower.tail logical; TRUE (default), probabilities     \\(P[X \\le x]\\), otherwise, \\(P[X > x]\\). log.p logical; TRUE, probabilities p given log(p).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/pnbinom2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The Negative Binomial Distribution â€” pnbinom2","text":"dnbinom gives density,   pnbinom gives distribution function,   qnbinom gives quantile function,   rnbinom generates random deviates. Invalid size prob result return value   NaN, warning. length result determined n   rnbinom, maximum lengths   numerical arguments functions. numerical arguments n recycled   length result.  first elements logical   arguments used. rnbinom returns vector type integer unless generated   values exceed maximum representable integer double   values returned.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/pnbinom2.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The Negative Binomial Distribution â€” pnbinom2","text":"negative binomial distribution size \\(= n\\)   prob \\(= p\\) density   $$     p(x) = \\frac{\\Gamma(x+n)}{\\Gamma(n) x!} p^n (1-p)^x$$   \\(x = 0, 1, 2, \\ldots\\), \\(n > 0\\) \\(0 < p \\le 1\\). represents number failures occur sequence   Bernoulli trials target number successes reached.   mean \\(\\mu = n(1-p)/p\\) variance \\(n(1-p)/p^2\\). negative binomial distribution can also arise mixture   Poisson distributions mean distributed gamma distribution   (see pgamma) scale parameter (1 - prob)/prob   shape parameter size.  (definition allows non-integer   values size.) alternative parametrization (often used ecology)   mean mu (see ), size, dispersion   parameter, prob = size/(size+mu).  variance   mu + mu^2/size parametrization. element x integer, result dnbinom   zero, warning. case size == 0 distribution concentrated zero.   limiting distribution size approaching zero,   even mu rather prob held constant.  Notice   though, mean limit distribution 0, whatever   value mu. quantile defined smallest value \\(x\\)   \\(F(x) \\ge p\\), \\(F\\) distribution function.","code":""},{"path":[]},{"path":"https://ai4ci.github.io/ggoutbreak/reference/pnbinom2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The Negative Binomial Distribution â€” pnbinom2","text":"","code":"pnbinom2(0:5, 2, sqrt(2)) #> [1] 0.1353353 0.4060058 0.6766764 0.8571235 0.9473470 0.9834364"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/pnull.html","id":null,"dir":"Reference","previous_headings":"","what":"Null distributions always returns NA â€” pnull","title":"Null distributions always returns NA â€” pnull","text":"Null distributions always returns NA","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/pnull.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Null distributions always returns NA â€” pnull","text":"","code":"pnull(q, ...)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/pnull.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Null distributions always returns NA â€” pnull","text":"q vector quantiles ... used","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/pnull.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Null distributions always returns NA â€” pnull","text":"","code":"pnull(c(0.25,0.5,0.75), 0.5, 0.25) #> [1] NA NA NA"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/poisson_gam_model.censored.html","id":null,"dir":"Reference","previous_headings":"","what":"Poisson model for censored data â€” poisson_gam_model.censored","title":"Poisson model for censored data â€” poisson_gam_model.censored","text":"Poisson model censored data","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/poisson_gam_model.censored.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Poisson model for censored data â€” poisson_gam_model.censored","text":"","code":"poisson_gam_model.censored(   d = i_censored_incidence_data,   model_fn = gam_delayed_reporting(...)$model_fn,   ...,   frequency = \"1 day\",   predict = gam_delayed_reporting(...)$predict,   ip = i_discrete_ip,   quick = FALSE,   .progress = interactive() )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/poisson_gam_model.censored.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Poisson model for censored data â€” poisson_gam_model.censored","text":"model_fn function takes data relating one time series (e.g. input data d group group basis) returns fitted GAM. default creates delayed reporting model gam_delayed_reporting(). ... Named arguments passed gam_delayed_reporting window controls knot spacing GAM (default) max_delay maximum delay expect model knots_fn function takes data input returns set integers time points GAM knots, s(time) term. default provides roughly equally spaced grid determined window, user supplied function anything. input function raw dataframe data considered one model fit. guaranteed least time count column. possible predict GAM model model_fn introduces variables need know values fixed prediction. named list defaults variables model supplied model_fn. defaults used prediction. may supplied part model function generator ( e.g. gam_delayed_reporting(...)$predict). set exactly FALSE prediction performed list column fitted GAM models returned instead.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/poisson_gam_model.html","id":null,"dir":"Reference","previous_headings":"","what":"GAM poisson time-series model â€” poisson_gam_model","title":"GAM poisson time-series model â€” poisson_gam_model","text":"function lets user supply fitting function models incidence, provides set machinery applying groups, extracting incidence, growth rates, optionally reproduction numbers fit(s). advanced estimators far configuration GAM models, aims provide sensible defaults option bring model.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/poisson_gam_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"GAM poisson time-series model â€” poisson_gam_model","text":"","code":"poisson_gam_model(   d,   ...,   frequency = \"1 day\",   ip = i_discrete_ip,   quick = FALSE,   .progress = interactive() )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/poisson_gam_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"GAM poisson time-series model â€” poisson_gam_model","text":"d input data - EITHER: dataframe columns: count (positive_integer) - Positive case counts associated specified time frame time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` obs_time (ggoutbreak::time_period) - time observation time series, `time_period` Minimally grouped : obs_time (groupings allowed). columns: count (positive_integer) - Positive case counts associated specified time frame time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` grouping allowed. ... Named arguments passed poisson_gam_model.censored model_fn function takes data relating one time series (e.g. input data d group group basis) returns fitted GAM. default creates delayed reporting model gam_delayed_reporting(). predict GAM model model_fn introduces variables need know values fixed prediction. named list defaults variables model supplied model_fn. defaults used prediction. may supplied part model function generator ( e.g. gam_delayed_reporting(...)$predict). set exactly FALSE prediction performed list column fitted GAM models returned instead. Named arguments passed poisson_gam_model.incidence model_fn function takes data relating one time series (e.g. input data d group group basis) returns fitted GAM. default creates simple poisson model based count alone (gam_poisson_model_fn()). predict GAM model model_fn introduces variables need know values fixed prediction. named list defaults variables model supplied model_fn. defaults used prediction. may supplied part model function generator ( e.g. gam_delayed_reporting(...)$predict). set exactly FALSE prediction performed list column fitted GAM models returned instead. frequency density output estimates time period 7 days 2 weeks. ip infectivity profile (optional) given (default) Rt value estimated - dataframe columns: boot (anything + default(1)) - bootstrap identifier probability (proportion) - probability new event period. tau (integer + complete) - days since index event. Minimally grouped : boot (groupings allowed). quick ip provided, quick TRUE Rt estimation done assuming independence quicker less accurate. Setting false use full variance-covariance matrix. .progress show CLI progress bar","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/poisson_gam_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"GAM poisson time-series model â€” poisson_gam_model","text":"dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period incidence.fit (double) - estimate incidence rate log scale incidence.se.fit (positive_double) - standard error incidence rate estimate log scale incidence.0.025 (positive_double) - lower confidence limit incidence rate (true scale) incidence.0.5 (positive_double) - median estimate incidence rate (true scale) incidence.0.975 (positive_double) - upper confidence limit incidence rate (true scale) growth.fit (double) - estimate growth rate growth.se.fit (positive_double) - standard error growth rate growth.0.025 (double) - lower confidence limit growth rate growth.0.5 (double) - median estimate growth rate growth.0.975 (double) - upper confidence limit growth rate grouping allowed. additionally ip given: dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period rt.fit (double) - estimate reproduction number rt.se.fit (positive_double) - standard error reproduction number rt.0.025 (double) - lower confidence limit reproduction number rt.0.5 (double) - median estimate reproduction number rt.0.975 (double) - upper confidence limit reproduction number grouping allowed.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/poisson_gam_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"GAM poisson time-series model â€” poisson_gam_model","text":"","code":"# Simple poisson model data = example_poisson_rt_smooth() tmp2 = poisson_gam_model(data,window=7,ip=example_ip(),quick=TRUE) #> Rt estimation using GAM (approx and assuming independence)  if (interactive()) {   plot_incidence(     tmp2,     date_labels=\"%b %y\",     raw=data   )    plot_rt(     tmp2,     date_labels=\"%b %y\"   )+   sim_geom_function(data,colour=\"red\") }    # example with delayed observation model. # This data is all the day by day observations of the whole timeseries from # the beginning of the outbreak. data2 = example_delayed_observation() model = gam_delayed_reporting(window = 14) tmp3 = data2 %>% poisson_gam_model(   model_fn = model$model_fn,   predict = model$predict,   ip=example_ip()) #> Rt estimation using GAM (exact with modelled covariance)  if (interactive()) {   plot_incidence(tmp3)+     ggplot2::geom_line(       data=data2 %>% dplyr::filter(obs_time %% 10 == 0),       mapping = ggplot2::aes(x=as.Date(time),y=count,colour=as.factor(obs_time))     )    plot_rt(tmp3) }"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/poisson_gam_model.incidence.html","id":null,"dir":"Reference","previous_headings":"","what":"Poisson model for incidence data â€” poisson_gam_model.incidence","title":"Poisson model for incidence data â€” poisson_gam_model.incidence","text":"Poisson model incidence data","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/poisson_gam_model.incidence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Poisson model for incidence data â€” poisson_gam_model.incidence","text":"","code":"poisson_gam_model.incidence(   d = i_incidence_input,   model_fn = gam_poisson_model_fn(...),   ...,   frequency = \"1 day\",   predict = list(),   ip = i_discrete_ip,   quick = FALSE,   .progress = interactive() )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/poisson_gam_model.incidence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Poisson model for incidence data â€” poisson_gam_model.incidence","text":"model_fn function takes data relating one time series (e.g. input data d group group basis) returns fitted GAM. default creates simple poisson model based count alone (gam_poisson_model_fn()). predict GAM model model_fn introduces variables need know values fixed prediction. named list defaults variables model supplied model_fn. defaults used prediction. may supplied part model function generator ( e.g. gam_delayed_reporting(...)$predict). set exactly FALSE prediction performed list column fitted GAM models returned instead.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/poisson_glm_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Poisson time-series model. â€” poisson_glm_model","title":"Poisson time-series model. â€” poisson_glm_model","text":"uses generalised linear model fit quasi-poisson model time varying rate natural cubic spline approx one degree freedom per window units time series.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/poisson_glm_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Poisson time-series model. â€” poisson_glm_model","text":"","code":"poisson_glm_model(   d = i_incidence_input,   ...,   window = 14,   frequency = \"1 day\",   .progress = interactive() )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/poisson_glm_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Poisson time-series model. â€” poisson_glm_model","text":"d Count model input - dataframe columns: count (positive_integer) - Positive case counts associated specified time frame time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` grouping allowed. ... used present allow proportion model used group_modify window number data points defining bandwidth estimate, smaller values result less smoothing, large value . default value 14 calibrated data provided daily frequency, weekly data lower value may preferred. - default 14 frequency density output estimates time period 7 days 2 weeks. - default 1 day .progress show CLI progress bar","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/poisson_glm_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Poisson time-series model. â€” poisson_glm_model","text":"dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period incidence.fit (double) - estimate incidence rate log scale incidence.se.fit (positive_double) - standard error incidence rate estimate log scale incidence.0.025 (positive_double) - lower confidence limit incidence rate (true scale) incidence.0.5 (positive_double) - median estimate incidence rate (true scale) incidence.0.975 (positive_double) - upper confidence limit incidence rate (true scale) grouping allowed.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/poisson_glm_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Poisson time-series model. â€” poisson_glm_model","text":"","code":"data = example_poisson_growth_rate()  tmp2 = data %>% poisson_glm_model(window=7,deg=2) tmp3 = data %>% poisson_glm_model(window=14,deg=1)  comp = dplyr::bind_rows(   tmp2 %>% dplyr::mutate(class=\"7:2\"),   tmp3 %>% dplyr::mutate(class=\"14:1\"), ) %>% dplyr::group_by(class)  if (interactive()) {   plot_incidence(comp, date_labels=\"%b %y\", raw=data, true_col=rate) }"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/poisson_locfit_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Poisson time-series model. â€” poisson_locfit_model","title":"Poisson time-series model. â€” poisson_locfit_model","text":"Takes list times counts fits quasi-poisson model fitted log link function count data using local regression using package locfit.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/poisson_locfit_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Poisson time-series model. â€” poisson_locfit_model","text":"","code":"poisson_locfit_model(   d = i_incidence_input,   ...,   window = 14,   deg = 2,   frequency = \"1 day\",   predict = TRUE,   ip = i_discrete_ip,   quick = FALSE,   .progress = interactive() )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/poisson_locfit_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Poisson time-series model. â€” poisson_locfit_model","text":"d input data - dataframe columns: count (positive_integer) - Positive case counts associated specified time frame time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` grouping allowed. ... used present allow proportion model used group_modify window number data points defining bandwidth estimate, smaller values result less smoothing, large value . default value 14 calibrated data provided daily frequency, weekly data lower value may preferred. - default 14 deg polynomial degree (min 1) - higher degree results less smoothing, lower values result smoothing. degree 1 fitting linear model piece wise. - default 2 frequency density output estimates time period 7 days 2 weeks. - default 1 day predict result prediction dataframe. false return locfit models (advanced). - default TRUE ip infectivity profile (optional) given (default) Rt value estimated - dataframe columns: boot (anything + default(1)) - bootstrap identifier probability (proportion) - probability new event period. tau (integer + complete) - days since index event. Minimally grouped : boot (groupings allowed). quick ip provided, quick TRUE Rt estimation done assuming independence quicker less accurate. Setting false use full variance-covariance matrix. .progress show CLI progress bar","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/poisson_locfit_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Poisson time-series model. â€” poisson_locfit_model","text":"dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period incidence.fit (double) - estimate incidence rate log scale incidence.se.fit (positive_double) - standard error incidence rate estimate log scale incidence.0.025 (positive_double) - lower confidence limit incidence rate (true scale) incidence.0.5 (positive_double) - median estimate incidence rate (true scale) incidence.0.975 (positive_double) - upper confidence limit incidence rate (true scale) growth.fit (double) - estimate growth rate growth.se.fit (positive_double) - standard error growth rate growth.0.025 (double) - lower confidence limit growth rate growth.0.5 (double) - median estimate growth rate growth.0.975 (double) - upper confidence limit growth rate grouping allowed.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/poisson_locfit_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Poisson time-series model. â€” poisson_locfit_model","text":"results incidence rate estimate plus absolute exponential growth rate estimate based time unit input data (e.g. daily data rate cases per day growth rate daily).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/poisson_locfit_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Poisson time-series model. â€” poisson_locfit_model","text":"","code":"data = example_poisson_rt() tmp = data %>% poisson_locfit_model(window=14,deg=2, ip=example_ip(), quick=TRUE) #> Rt estimation using Locfit (approx and assuming independence) #> Estimates were assumed to be independent, but more that 1% of estimates #> are at risk of Rt underestimation by more that 0.05 (absolute). #> We advise re-running supplying a full variance-covariance matrix, or #> a value to the `raw` parameter, or setting `quick=FALSE`. plot_rt(tmp,     raw = data,     true_col = rt)   data = example_poisson_growth_rate() tmp2 = data %>% poisson_locfit_model(window=7,deg=1) tmp3 = data %>% poisson_locfit_model(window=14,deg=2)    comp = dplyr::bind_rows(   tmp2 %>% dplyr::mutate(class=\"7:1\"),   tmp3 %>% dplyr::mutate(class=\"14:2\"), ) %>% dplyr::group_by(class)  if (interactive()) {   plot_incidence(     comp,     date_labels=\"%b %y\",     raw=data,     true_col = rate   )    plot_growth_rate(     comp,     date_labels=\"%b %y\",     raw = data,     true_col = growth   )   # sim_geom_function(data,colour=\"black\") }"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/proportion_glm_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Binomial time-series model. â€” proportion_glm_model","title":"Binomial time-series model. â€” proportion_glm_model","text":"uses generalised linear model fit quasi-binomial model time varying rate natural cubic spline approx one degree freedom per window units time series.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/proportion_glm_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Binomial time-series model. â€” proportion_glm_model","text":"","code":"proportion_glm_model(   d = i_proportion_input,   ...,   window = 14,   frequency = \"1 day\",   .progress = interactive() )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/proportion_glm_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Binomial time-series model. â€” proportion_glm_model","text":"d Proportion model input - dataframe columns: denom (positive_integer) - Total test counts associated specified time frame count (positive_integer) - Positive case counts associated specified time frame time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` grouping allowed. ... used present allow proportion model used group_modify window number data points defining bandwidth estimate, smaller values result less smoothing, large value . default value 14 calibrated data provided daily frequency, weekly data lower value may preferred. - default 14 frequency density output estimates time period 7 days 2 weeks. - default 1 day .progress show CLI progress bar","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/proportion_glm_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Binomial time-series model. â€” proportion_glm_model","text":"dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period proportion.fit (double) - estimate proportion logit scale proportion.se.fit (positive_double) - standard error proportion estimate logit scale proportion.0.025 (proportion) - lower confidence limit proportion (true scale) proportion.0.5 (proportion) - median estimate proportion (true scale) proportion.0.975 (proportion) - upper confidence limit proportion (true scale) grouping allowed.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/proportion_glm_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Binomial time-series model. â€” proportion_glm_model","text":"","code":"data = example_poisson_rt_2class()  tmp2 = data %>% proportion_glm_model(window=7,deg=2) tmp3 = data %>% proportion_glm_model(window=14,deg=1)  comp = dplyr::bind_rows(   tmp2 %>% dplyr::mutate(model=\"7:2\"),   tmp3 %>% dplyr::mutate(model=\"14:1\"), ) %>% dplyr::group_by(model,class)  if (interactive()) {   plot_proportion(       comp,       date_labels=\"%b %y\",       mapping=ggplot2::aes(colour=model),       raw=data    )+    ggplot2::facet_wrap(~class) }  # TODO: deal with error conditions # \"observations with zero weight not used for calculating dispersion"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/proportion_locfit_model.html","id":null,"dir":"Reference","previous_headings":"","what":"A binomial proportion estimate and associated exponential growth rate â€” proportion_locfit_model","title":"A binomial proportion estimate and associated exponential growth rate â€” proportion_locfit_model","text":"takes list times, counts denominator fits quasi-binomial model using logit link function proportion data using local regression using package locfit.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/proportion_locfit_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A binomial proportion estimate and associated exponential growth rate â€” proportion_locfit_model","text":"","code":"proportion_locfit_model(   d = i_proportion_input,   ...,   window = 14,   deg = 1,   frequency = \"1 day\",   predict = TRUE,   .progress = interactive() )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/proportion_locfit_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A binomial proportion estimate and associated exponential growth rate â€” proportion_locfit_model","text":"d input - dataframe columns: denom (positive_integer) - Total test counts associated specified time frame count (positive_integer) - Positive case counts associated specified time frame time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` grouping allowed. ... used present allow proportion model used group_modify window number data points defining bandwidth estimate, smaller values result less smoothing, large value . default value 14 calibrated data provided daily frequency, weekly data lower value may preferred. - default 14 deg polynomial degree (min 1) - higher degree results less smoothing, lower values result smoothing. degree 1 fitting linear model piece wise. - default 2 frequency density output estimates time period 7 days 2 weeks. - default 1 day predict result prediction dataframe. false return locfit models (advanced). - default TRUE .progress show CLI progress bar","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/proportion_locfit_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A binomial proportion estimate and associated exponential growth rate â€” proportion_locfit_model","text":"dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period proportion.fit (double) - estimate proportion logit scale proportion.se.fit (positive_double) - standard error proportion estimate logit scale proportion.0.025 (proportion) - lower confidence limit proportion (true scale) proportion.0.5 (proportion) - median estimate proportion (true scale) proportion.0.975 (proportion) - upper confidence limit proportion (true scale) relative.growth.fit (double) - estimate relative growth rate relative.growth.se.fit (positive_double) - standard error relative growth rate relative.growth.0.025 (double) - lower confidence limit relative growth rate relative.growth.0.5 (double) - median estimate relative growth rate relative.growth.0.975 (double) - upper confidence limit relative growth rate grouping allowed.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/proportion_locfit_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"A binomial proportion estimate and associated exponential growth rate â€” proportion_locfit_model","text":"expects d contain one combination : time count denom columns - e.g. tests conducted. results one versus others comparison binomial proportion estimate plus relative growth rate estimate specifying much quicker growing compared growth denominator. denominator maybe sum subgroups denom = sum(count), e.g. situation multiple variants disease circulating. case relative growth subgroup compared overall. can make one-versus-others comparison making denominator exclude current item (e.g. denom = sum(count)-count). denominator can also used express size population tested. gives us relative growth rate different essence previous may better estimate true growth rate situation testing effort variable, capacity saturated.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/proportion_locfit_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A binomial proportion estimate and associated exponential growth rate â€” proportion_locfit_model","text":"","code":"data = example_poisson_rt_2class()  tmp2 = data %>% proportion_locfit_model(window=7,deg=2) tmp3 = data %>% proportion_locfit_model(window=14,deg=1)  comp = dplyr::bind_rows(   tmp2 %>% dplyr::mutate(model=\"7:2\"),   tmp3 %>% dplyr::mutate(model=\"14:1\"), ) %>% dplyr::group_by(model,class)  if (interactive()) {   plot_proportion(     comp,     date_labels=\"%b %y\",     mapping=ggplot2::aes(colour=model),     raw=data   )+ggplot2::facet_wrap(~class) }"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/pwedge.html","id":null,"dir":"Reference","previous_headings":"","what":"Wedge distribution â€” pwedge","title":"Wedge distribution â€” pwedge","text":"wedge distribution support 0 1 linear probability density function support.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/pwedge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wedge distribution â€” pwedge","text":"","code":"pwedge(q, a, log.p = FALSE)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/pwedge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wedge distribution â€” pwedge","text":"q vector quantiles gradient -2 (left skewed) 2 (right skewed) log.p logical; TRUE, probabilities p given log(p).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/pwedge.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Wedge distribution â€” pwedge","text":"vector probabilities, quantiles, densities samples.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/pwedge.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Wedge distribution â€” pwedge","text":"rwedge can combined quantile functions skew standard distributions, introduce correlation weight certain parts distribution.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/pwedge.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Wedge distribution â€” pwedge","text":"","code":"pwedge(seq(0,1,0.1), a=1) #>  [1] 0.5 0.6 0.7 0.8 0.9 1.0 1.1 1.2 1.3 1.4 1.5 dwedge(seq(0,1,0.1), a=1) #>  [1] 0.000 0.055 0.120 0.195 0.280 0.375 0.480 0.595 0.720 0.855 1.000 qwedge(c(0.25,0.5,0.75), a=-1) #> [1] 0.1771243 0.3819660 0.6339746  stats::cor(   stats::qnorm(rwedge(1000, a=2)),   stats::qnorm(rwedge(1000, a=-2)) ) #> [1] 0.01054418"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qbeta2.html","id":null,"dir":"Reference","previous_headings":"","what":"The Beta Distribution â€” qbeta2","title":"The Beta Distribution â€” qbeta2","text":"Density, distribution function, quantile function random   generation Beta distribution parameters shape1   shape2 (optional non-centrality parameter ncp).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qbeta2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The Beta Distribution â€” qbeta2","text":"","code":"qbeta2(p, prob, kappa, lower.tail = TRUE, log.p = FALSE)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qbeta2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The Beta Distribution â€” qbeta2","text":"p vector probabilities prob mean probability (vectorised) kappa coefficient variation. 0 variability 1 maximally variability (vectorised) lower.tail logical; TRUE (default), probabilities P[X<=x] otherwise P[X>x]. log.p logical; TRUE, probabilities p given log(p).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qbeta2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The Beta Distribution â€” qbeta2","text":"dbeta gives density, pbeta distribution   function, qbeta quantile function, rbeta   generates random deviates. Invalid arguments result return value NaN, warning. length result determined n   rbeta, maximum lengths   numerical arguments functions. numerical arguments n recycled   length result.  first elements logical   arguments used.","code":""},{"path":[]},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qbeta2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The Beta Distribution â€” qbeta2","text":"","code":"qbeta2(c(0.25,0.5,0.75), 0.5, 0.25) #> [1] 0.4506664 0.5000000 0.5493336"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qcgamma.html","id":null,"dir":"Reference","previous_headings":"","what":"Quantile: gamma distribution constrained to have mean > sd â€” qcgamma","title":"Quantile: gamma distribution constrained to have mean > sd â€” qcgamma","text":"following conversion describes parameters mean kappa","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qcgamma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quantile: gamma distribution constrained to have mean > sd â€” qcgamma","text":"","code":"qcgamma(p, mean, kappa = 1/mean, lower.tail = TRUE, log.p = FALSE)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qcgamma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quantile: gamma distribution constrained to have mean > sd â€” qcgamma","text":"p vector probabilities mean mean value true scale (vectorised) kappa coefficient variation. 0 variability 1 maximally variability (vectorised) lower.tail logical; TRUE (default), probabilities P[X<=x] otherwise P[X>x]. log.p logical; TRUE, probabilities p given log(p).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qcgamma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Quantile: gamma distribution constrained to have mean > sd â€” qcgamma","text":"dgamma gives density,   pgamma gives distribution function,   qgamma gives quantile function,   rgamma generates random deviates. Invalid arguments result return value NaN, warning. length result determined n   rgamma, maximum lengths   numerical arguments functions. numerical arguments n recycled   length result.  first elements logical   arguments used.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qcgamma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Quantile: gamma distribution constrained to have mean > sd â€” qcgamma","text":"$$ \\text{shape:} \\alpha = \\frac{1}{\\kappa} \\\\ \\text{rate:} \\beta = \\frac{1}{\\mu \\times \\kappa} \\\\ \\text{scale:} \\sigma = \\mu \\times \\kappa \\\\ $$","code":""},{"path":[]},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qcgamma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quantile: gamma distribution constrained to have mean > sd â€” qcgamma","text":"","code":"qcgamma(c(0.25,0.5,0.75), 2, 0.5) #> [1] 0.9612788 1.6783470 2.6926345"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qgamma2.html","id":null,"dir":"Reference","previous_headings":"","what":"The Gamma Distribution â€” qgamma2","title":"The Gamma Distribution â€” qgamma2","text":"Density, distribution function, quantile function random   generation Gamma distribution parameters shape   scale.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qgamma2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The Gamma Distribution â€” qgamma2","text":"","code":"qgamma2(p, mean, sd = sqrt(mean), lower.tail = TRUE, log.p = FALSE)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qgamma2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The Gamma Distribution â€” qgamma2","text":"p vector probabilities mean mean value true scale (vectorised) sd standard deviation true scale (vectorised) lower.tail logical; TRUE (default), probabilities P[X<=x] otherwise P[X>x]. log.p logical; TRUE, probabilities p given log(p).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qgamma2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The Gamma Distribution â€” qgamma2","text":"dgamma gives density,   pgamma gives distribution function,   qgamma gives quantile function,   rgamma generates random deviates. Invalid arguments result return value NaN, warning. length result determined n   rgamma, maximum lengths   numerical arguments functions. numerical arguments n recycled   length result.  first elements logical   arguments used.","code":""},{"path":[]},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qgamma2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The Gamma Distribution â€” qgamma2","text":"","code":"qgamma2(c(0.25,0.5,0.75), 2, 1) #> [1] 1.267660 1.836030 2.554714"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qlnorm2.html","id":null,"dir":"Reference","previous_headings":"","what":"The Log Normal Distribution â€” qlnorm2","title":"The Log Normal Distribution â€” qlnorm2","text":"Density, distribution function, quantile function random   generation log normal distribution whose logarithm mean   equal meanlog standard deviation equal sdlog.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qlnorm2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The Log Normal Distribution â€” qlnorm2","text":"","code":"qlnorm2(p, mean = 1, sd = sqrt(exp(1) - 1), lower.tail = TRUE, log.p = FALSE)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qlnorm2.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"The Log Normal Distribution â€” qlnorm2","text":"dlnorm calculated definition (â€˜Detailsâ€™).   [pqr]lnorm based relationship normal. Consequently, model single point mass exp(meanlog)   boundary case sdlog = 0.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qlnorm2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The Log Normal Distribution â€” qlnorm2","text":"p vector probabilities. mean mean value true scale (vectorised) sd standard deviation true scale (vectorised) lower.tail logical; TRUE (default), probabilities     \\(P[X \\le x]\\), otherwise, \\(P[X > x]\\). log.p logical; TRUE, probabilities p given log(p).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qlnorm2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The Log Normal Distribution â€” qlnorm2","text":"dlnorm gives density,   plnorm gives distribution function,   qlnorm gives quantile function,   rlnorm generates random deviates. length result determined n   rlnorm, maximum lengths   numerical arguments functions. numerical arguments n recycled   length result.  first elements logical   arguments used.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qlnorm2.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The Log Normal Distribution â€” qlnorm2","text":"log normal distribution density   $$     f(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma x} e^{-(\\log(x) - \\mu)^2/2 \\sigma^2}%   $$   \\(\\mu\\) \\(\\sigma\\) mean standard   deviation logarithm.   mean \\(E(X) = exp(\\mu + 1/2 \\sigma^2)\\),   median \\(med(X) = exp(\\mu)\\), variance   \\(Var(X) = exp(2\\mu + \\sigma^2)(exp(\\sigma^2) - 1)\\)   hence coefficient variation   \\(\\sqrt{exp(\\sigma^2) - 1}\\)   approximately \\(\\sigma\\) small (e.g., \\(\\sigma < 1/2\\)).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qlnorm2.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"The Log Normal Distribution â€” qlnorm2","text":"cumulative hazard \\(H(t) = - \\log(1 - F(t))\\)   -plnorm(t, r, lower = FALSE, log = TRUE).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qlnorm2.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"The Log Normal Distribution â€” qlnorm2","text":"Becker, R. ., Chambers, J. M. Wilks, . R. (1988)   New S Language.   Wadsworth & Brooks/Cole. Johnson, N. L., Kotz, S. Balakrishnan, N. (1995)   Continuous Univariate Distributions, volume 1, chapter 14.   Wiley, New York.","code":""},{"path":[]},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qlnorm2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The Log Normal Distribution â€” qlnorm2","text":"","code":"qlnorm2(c(0.25,0.5,0.72), 2, 1) #> [1] 1.300774 1.788854 2.355843"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qlogitnorm.html","id":null,"dir":"Reference","previous_headings":"","what":"Logit-normal distribution â€” qlogitnorm","title":"Logit-normal distribution â€” qlogitnorm","text":"logit-normal distribution support 0 1.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qlogitnorm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logit-normal distribution â€” qlogitnorm","text":"","code":"qlogitnorm(p, meanlogit = 0, sdlogit = 1, lower.tail = TRUE, log.p = FALSE)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qlogitnorm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logit-normal distribution â€” qlogitnorm","text":"p vector probabilities meanlogit mean logit scale sdlogit sd logit scale lower.tail logical; TRUE (default), probabilities P[X<=x] otherwise P[X>x]. log.p logical; TRUE, probabilities p given log(p).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qlogitnorm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Logit-normal distribution â€” qlogitnorm","text":"vector probabilities, quantiles, densities samples.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qlogitnorm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Logit-normal distribution â€” qlogitnorm","text":"","code":"qlogitnorm(c(0.25,0.5,0.75), 0, 1) #> [1] 0.3374922 0.5000000 0.6625078"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qlogitnorm2.html","id":null,"dir":"Reference","previous_headings":"","what":"Logit-normal distribution â€” qlogitnorm2","title":"Logit-normal distribution â€” qlogitnorm2","text":"logit-normal distribution support 0 1.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qlogitnorm2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logit-normal distribution â€” qlogitnorm2","text":"","code":"qlogitnorm2(   p,   prob.0.5 = 0.5,   kappa = 1 - exp(-1),   lower.tail = TRUE,   log.p = FALSE )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qlogitnorm2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logit-normal distribution â€” qlogitnorm2","text":"p vector probabilities prob.0.5 median true scale kappa dispersion parameter 0 (none) 1 maximum dispersion lower.tail logical; TRUE (default), probabilities P[X<=x] otherwise P[X>x]. log.p logical; TRUE, probabilities p given log(p).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qlogitnorm2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Logit-normal distribution â€” qlogitnorm2","text":"vector probabilities, quantiles, densities samples.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qlogitnorm2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Logit-normal distribution â€” qlogitnorm2","text":"","code":"qlnorm2(c(0.25,0.5,0.72), 2, 1) #> [1] 1.300774 1.788854 2.355843"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qnbinom2.html","id":null,"dir":"Reference","previous_headings":"","what":"The Negative Binomial Distribution â€” qnbinom2","title":"The Negative Binomial Distribution â€” qnbinom2","text":"Density, distribution function, quantile function random   generation negative binomial distribution parameters   size prob.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qnbinom2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The Negative Binomial Distribution â€” qnbinom2","text":"","code":"qnbinom2(p, mean, sd = sqrt(mean), lower.tail = TRUE, log.p = FALSE)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qnbinom2.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"The Negative Binomial Distribution â€” qnbinom2","text":"dnbinom computes via binomial probabilities, using code   contributed Catherine Loader (see dbinom). pnbinom uses pbeta. qnbinom uses Cornishâ€“Fisher Expansion include skewness   correction normal approximation, followed search. rnbinom uses derivation gamma mixture Poisson   distributions, see Devroye, L. (1986) Non-Uniform Random Variate Generation.   Springer-Verlag, New York. Page 480.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qnbinom2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The Negative Binomial Distribution â€” qnbinom2","text":"p vector probabilities. mean mean value true scale (vectorised) sd standard deviation true scale (vectorised) lower.tail logical; TRUE (default), probabilities     \\(P[X \\le x]\\), otherwise, \\(P[X > x]\\). log.p logical; TRUE, probabilities p given log(p).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qnbinom2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The Negative Binomial Distribution â€” qnbinom2","text":"dnbinom gives density,   pnbinom gives distribution function,   qnbinom gives quantile function,   rnbinom generates random deviates. Invalid size prob result return value   NaN, warning. length result determined n   rnbinom, maximum lengths   numerical arguments functions. numerical arguments n recycled   length result.  first elements logical   arguments used. rnbinom returns vector type integer unless generated   values exceed maximum representable integer double   values returned.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qnbinom2.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The Negative Binomial Distribution â€” qnbinom2","text":"negative binomial distribution size \\(= n\\)   prob \\(= p\\) density   $$     p(x) = \\frac{\\Gamma(x+n)}{\\Gamma(n) x!} p^n (1-p)^x$$   \\(x = 0, 1, 2, \\ldots\\), \\(n > 0\\) \\(0 < p \\le 1\\). represents number failures occur sequence   Bernoulli trials target number successes reached.   mean \\(\\mu = n(1-p)/p\\) variance \\(n(1-p)/p^2\\). negative binomial distribution can also arise mixture   Poisson distributions mean distributed gamma distribution   (see pgamma) scale parameter (1 - prob)/prob   shape parameter size.  (definition allows non-integer   values size.) alternative parametrization (often used ecology)   mean mu (see ), size, dispersion   parameter, prob = size/(size+mu).  variance   mu + mu^2/size parametrization. element x integer, result dnbinom   zero, warning. case size == 0 distribution concentrated zero.   limiting distribution size approaching zero,   even mu rather prob held constant.  Notice   though, mean limit distribution 0, whatever   value mu. quantile defined smallest value \\(x\\)   \\(F(x) \\ge p\\), \\(F\\) distribution function.","code":""},{"path":[]},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qnbinom2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The Negative Binomial Distribution â€” qnbinom2","text":"","code":"qnbinom2(c(0.25,0.5,0.75), 5, sqrt(5)) #> [1] 4 6 8"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qnull.html","id":null,"dir":"Reference","previous_headings":"","what":"Null distributions always returns NA â€” qnull","title":"Null distributions always returns NA â€” qnull","text":"Null distributions always returns NA","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qnull.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Null distributions always returns NA â€” qnull","text":"","code":"qnull(p, ...)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qnull.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Null distributions always returns NA â€” qnull","text":"p vector probabilities ... used","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qnull.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Null distributions always returns NA â€” qnull","text":"","code":"qnull(c(0.25,0.5,0.75), 0.5, 0.25) #> [1] NA NA NA"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/quantify_lag.html","id":null,"dir":"Reference","previous_headings":"","what":"Identify estimate lags in a model â€” quantify_lag","title":"Identify estimate lags in a model â€” quantify_lag","text":"specific parameter set parameters can estimated pipeline. function applies pipeline synthetic epidemic sawtooth incidence resulting stepped growth rate function. lag synthetic input estimate assessed minimising root mean square error input estimated based different lag offsets.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/quantify_lag.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identify estimate lags in a model â€” quantify_lag","text":"","code":"quantify_lag(pipeline, ip = i_empirical_ip, lags = -10:30)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/quantify_lag.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identify estimate lags in a model â€” quantify_lag","text":"pipeline function taking input dataset infectivity profile inputs producing estimate output. whole parametrised pipeline including inputs. can purrr style function, case .x variable input dataset .y infectivity profile. ip infectivity profile. - dataframe columns: boot (anything + default(1)) - bootstrap identifier probability (proportion) - probability new event period. a0 (double) - beginning time period (days) a1 (double) - end time period (days) Minimally grouped : boot (groupings allowed). lags vector delays test. Defaults -10 +30 days","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/quantify_lag.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identify estimate lags in a model â€” quantify_lag","text":"lag analysis dataframe containing estimate type lag days estimate behind actual observation","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/quantify_lag.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Identify estimate lags in a model â€” quantify_lag","text":"","code":"set_default_start(\"2025-01-01\") #> [1] \"2020-01-01\" # lags from a locfit incidence model with Rt estimation. # This model has no estimator lag: pipeline = ~ .x %>% poisson_locfit_model() %>% rt_from_incidence(ip = .y) quantify_lag(pipeline, ip = example_ip()) #> Rt from incidence: assuming independence and approximating quantiles.  #> (N.B. this message will only be displayed once.) #> # A tibble: 3 Ã— 2 #> # Groups:   estimate [3] #>   estimate    lag #> * <chr>     <int> #> 1 growth        0 #> 2 incidence     0 #> 3 rt            0  # lags from an epiestim Rt estimation # this model's lags depend on the infectivity profile. # In this case it is 8 days pipeline2 =  ~ .x %>% rt_epiestim(ip = .y) quantify_lag(pipeline2, ip=example_ip() ) #> # A tibble: 1 Ã— 2 #> # Groups:   estimate [1] #>   estimate   lag #> * <chr>    <int> #> 1 rt           8"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/quarters.time_period.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Parts of a POSIXt or Date Object â€” quarters.time_period","title":"Extract Parts of a POSIXt or Date Object â€” quarters.time_period","text":"Extract weekday, month quarter, Julian time   (days since origin).  generic functions: methods   internal date-time classes documented .","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/quarters.time_period.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Parts of a POSIXt or Date Object â€” quarters.time_period","text":"","code":"# S3 method for class 'time_period' quarters(x, ...)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/quarters.time_period.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Parts of a POSIXt or Date Object â€” quarters.time_period","text":"x object inheriting class \"POSIXt\" \"Date\". ... arguments methods.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/quarters.time_period.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Parts of a POSIXt or Date Object â€” quarters.time_period","text":"weekdays months return character   vector names locale use, .e., Sys.getlocale(\"LC_TIME\"). quarters returns character vector \"Q1\"   \"Q4\". julian returns number days (possibly fractional)   since origin, origin \"origin\" attribute.   time calculations R done ignoring leap-seconds.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/quarters.time_period.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Extract Parts of a POSIXt or Date Object â€” quarters.time_period","text":"components day month year   easy compute: just use .POSIXlt extract   relevant component.  Alternatively (especially components   desired character strings), use strftime.","code":""},{"path":[]},{"path":"https://ai4ci.github.io/ggoutbreak/reference/quarters.time_period.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Parts of a POSIXt or Date Object â€” quarters.time_period","text":"","code":"## first two are locale dependent: weekdays(.leap.seconds) #>  [1] \"Saturday\"  \"Monday\"    \"Tuesday\"   \"Wednesday\" \"Thursday\"  \"Saturday\"  #>  [7] \"Sunday\"    \"Monday\"    \"Tuesday\"   \"Wednesday\" \"Thursday\"  \"Friday\"    #> [13] \"Monday\"    \"Friday\"    \"Monday\"    \"Tuesday\"   \"Wednesday\" \"Thursday\"  #> [19] \"Friday\"    \"Monday\"    \"Tuesday\"   \"Friday\"    \"Sunday\"    \"Thursday\"  #> [25] \"Sunday\"    \"Wednesday\" \"Sunday\"    months  (.leap.seconds) #>  [1] \"July\"    \"January\" \"January\" \"January\" \"January\" \"January\" \"January\" #>  [8] \"January\" \"January\" \"July\"    \"July\"    \"July\"    \"July\"    \"January\" #> [15] \"January\" \"January\" \"July\"    \"July\"    \"July\"    \"January\" \"July\"    #> [22] \"January\" \"January\" \"January\" \"July\"    \"July\"    \"January\" quarters(.leap.seconds) #>  [1] \"Q3\" \"Q1\" \"Q1\" \"Q1\" \"Q1\" \"Q1\" \"Q1\" \"Q1\" \"Q1\" \"Q3\" \"Q3\" \"Q3\" \"Q3\" \"Q1\" \"Q1\" #> [16] \"Q1\" \"Q3\" \"Q3\" \"Q3\" \"Q1\" \"Q3\" \"Q1\" \"Q1\" \"Q1\" \"Q3\" \"Q3\" \"Q1\"  ## Show how easily you get month, day, year, day (of {month, week, yr}), ... : ## (remember to count from 0 (!): mon = 0..11, wday = 0..6,  etc !!)  ##' Transform (Time-)Date vector  to  convenient data frame : dt2df <- function(dt, dName = deparse(substitute(dt))) {     DF <- as.data.frame(unclass(as.POSIXlt( dt )))     `names<-`(cbind(dt, DF, deparse.level=0L), c(dName, names(DF))) } ## e.g., dt2df(.leap.seconds)    # date+time #>    .leap.seconds sec min hour mday mon year wday yday isdst zone gmtoff #> 1     1972-07-01   0   0    0    1   6   72    6  182     0  GMT      0 #> 2     1973-01-01   0   0    0    1   0   73    1    0     0  GMT      0 #> 3     1974-01-01   0   0    0    1   0   74    2    0     0  GMT      0 #> 4     1975-01-01   0   0    0    1   0   75    3    0     0  GMT      0 #> 5     1976-01-01   0   0    0    1   0   76    4    0     0  GMT      0 #> 6     1977-01-01   0   0    0    1   0   77    6    0     0  GMT      0 #> 7     1978-01-01   0   0    0    1   0   78    0    0     0  GMT      0 #> 8     1979-01-01   0   0    0    1   0   79    1    0     0  GMT      0 #> 9     1980-01-01   0   0    0    1   0   80    2    0     0  GMT      0 #> 10    1981-07-01   0   0    0    1   6   81    3  181     0  GMT      0 #> 11    1982-07-01   0   0    0    1   6   82    4  181     0  GMT      0 #> 12    1983-07-01   0   0    0    1   6   83    5  181     0  GMT      0 #> 13    1985-07-01   0   0    0    1   6   85    1  181     0  GMT      0 #> 14    1988-01-01   0   0    0    1   0   88    5    0     0  GMT      0 #> 15    1990-01-01   0   0    0    1   0   90    1    0     0  GMT      0 #> 16    1991-01-01   0   0    0    1   0   91    2    0     0  GMT      0 #> 17    1992-07-01   0   0    0    1   6   92    3  182     0  GMT      0 #> 18    1993-07-01   0   0    0    1   6   93    4  181     0  GMT      0 #> 19    1994-07-01   0   0    0    1   6   94    5  181     0  GMT      0 #> 20    1996-01-01   0   0    0    1   0   96    1    0     0  GMT      0 #> 21    1997-07-01   0   0    0    1   6   97    2  181     0  GMT      0 #> 22    1999-01-01   0   0    0    1   0   99    5    0     0  GMT      0 #> 23    2006-01-01   0   0    0    1   0  106    0    0     0  GMT      0 #> 24    2009-01-01   0   0    0    1   0  109    4    0     0  GMT      0 #> 25    2012-07-01   0   0    0    1   6  112    0  182     0  GMT      0 #> 26    2015-07-01   0   0    0    1   6  115    3  181     0  GMT      0 #> 27    2017-01-01   0   0    0    1   0  117    0    0     0  GMT      0 dt2df(Sys.Date() + 0:9) # date #>    Sys.Date() + 0:9 sec min hour mday mon year wday yday isdst zone gmtoff #> 1        2025-12-11   0   0    0   11  11  125    4  344     0  UTC      0 #> 2        2025-12-12   0   0    0   12  11  125    5  345     0  UTC      0 #> 3        2025-12-13   0   0    0   13  11  125    6  346     0  UTC      0 #> 4        2025-12-14   0   0    0   14  11  125    0  347     0  UTC      0 #> 5        2025-12-15   0   0    0   15  11  125    1  348     0  UTC      0 #> 6        2025-12-16   0   0    0   16  11  125    2  349     0  UTC      0 #> 7        2025-12-17   0   0    0   17  11  125    3  350     0  UTC      0 #> 8        2025-12-18   0   0    0   18  11  125    4  351     0  UTC      0 #> 9        2025-12-19   0   0    0   19  11  125    5  352     0  UTC      0 #> 10       2025-12-20   0   0    0   20  11  125    6  353     0  UTC      0  ##' Even simpler:  Date -> Matrix - dropping time info {sec,min,hour, isdst} d2mat <- function(x) simplify2array(unclass(as.POSIXlt(x))[4:7]) ## e.g., d2mat(seq(as.Date(\"2000-02-02\"), by=1, length.out=30)) # has R 1.0.0's release date #>       mday mon year wday #>  [1,]    2   1  100    3 #>  [2,]    3   1  100    4 #>  [3,]    4   1  100    5 #>  [4,]    5   1  100    6 #>  [5,]    6   1  100    0 #>  [6,]    7   1  100    1 #>  [7,]    8   1  100    2 #>  [8,]    9   1  100    3 #>  [9,]   10   1  100    4 #> [10,]   11   1  100    5 #> [11,]   12   1  100    6 #> [12,]   13   1  100    0 #> [13,]   14   1  100    1 #> [14,]   15   1  100    2 #> [15,]   16   1  100    3 #> [16,]   17   1  100    4 #> [17,]   18   1  100    5 #> [18,]   19   1  100    6 #> [19,]   20   1  100    0 #> [20,]   21   1  100    1 #> [21,]   22   1  100    2 #> [22,]   23   1  100    3 #> [23,]   24   1  100    4 #> [24,]   25   1  100    5 #> [25,]   26   1  100    6 #> [26,]   27   1  100    0 #> [27,]   28   1  100    1 #> [28,]   29   1  100    2 #> [29,]    1   2  100    3 #> [30,]    2   2  100    4  # \\donttest{ ## Julian Day Number (JDN, https://en.wikipedia.org/wiki/Julian_day) ## is the number of days since noon UTC on the first day of 4317 BCE. ## in the proleptic Julian calendar.  To more recently, in ## 'Terrestrial Time' which differs from UTC by a few seconds ## See https://en.wikipedia.org/wiki/Terrestrial_Time julian(Sys.Date(), -2440588) # from a day #> [1] 2461021 #> attr(,\"origin\") #> [1] -2440588 floor(as.numeric(julian(Sys.time())) + 2440587.5) # from a date-time #> [1] 2461021 # }"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qwedge.html","id":null,"dir":"Reference","previous_headings":"","what":"Wedge distribution â€” qwedge","title":"Wedge distribution â€” qwedge","text":"wedge distribution support 0 1 linear probability density function support.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qwedge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wedge distribution â€” qwedge","text":"","code":"qwedge(p, a, lower.tail = TRUE, log.p = FALSE)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qwedge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wedge distribution â€” qwedge","text":"p vector probabilities gradient -2 (left skewed) 2 (right skewed) lower.tail logical; TRUE (default), probabilities P[X<=x] otherwise P[X>x]. log.p logical; TRUE, probabilities p given log(p).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qwedge.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Wedge distribution â€” qwedge","text":"vector probabilities, quantiles, densities samples.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qwedge.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Wedge distribution â€” qwedge","text":"rwedge can combined quantile functions skew standard distributions, introduce correlation weight certain parts distribution.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/qwedge.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Wedge distribution â€” qwedge","text":"","code":"pwedge(seq(0,1,0.1), a=1) #>  [1] 0.5 0.6 0.7 0.8 0.9 1.0 1.1 1.2 1.3 1.4 1.5 dwedge(seq(0,1,0.1), a=1) #>  [1] 0.000 0.055 0.120 0.195 0.280 0.375 0.480 0.595 0.720 0.855 1.000 qwedge(c(0.25,0.5,0.75), a=-1) #> [1] 0.1771243 0.3819660 0.6339746  stats::cor(   stats::qnorm(rwedge(1000, a=2)),   stats::qnorm(rwedge(1000, a=-2)) ) #> [1] -0.01401685"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rbern.html","id":null,"dir":"Reference","previous_headings":"","what":"A random Bernoulli sample as a logical value â€” rbern","title":"A random Bernoulli sample as a logical value â€” rbern","text":"random Bernoulli sample logical value","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rbern.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A random Bernoulli sample as a logical value â€” rbern","text":"","code":"rbern(n, prob)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rbern.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A random Bernoulli sample as a logical value â€” rbern","text":"n number observations prob mean probability (vectorised)","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rbern.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A random Bernoulli sample as a logical value â€” rbern","text":"vector logical values size n","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rbern.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A random Bernoulli sample as a logical value â€” rbern","text":"","code":"table(rbern(100, 0.25)) #>  #> FALSE  TRUE  #>    73    27"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rbeta2.html","id":null,"dir":"Reference","previous_headings":"","what":"The Beta Distribution â€” rbeta2","title":"The Beta Distribution â€” rbeta2","text":"Density, distribution function, quantile function random   generation Beta distribution parameters shape1   shape2 (optional non-centrality parameter ncp).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rbeta2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The Beta Distribution â€” rbeta2","text":"","code":"rbeta2(n, prob, kappa)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rbeta2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The Beta Distribution â€” rbeta2","text":"n number observations prob mean probability (vectorised) kappa coefficient variation. 0 variability 1 maximally variability (vectorised)","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rbeta2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The Beta Distribution â€” rbeta2","text":"dbeta gives density, pbeta distribution   function, qbeta quantile function, rbeta   generates random deviates. Invalid arguments result return value NaN, warning. length result determined n   rbeta, maximum lengths   numerical arguments functions. numerical arguments n recycled   length result.  first elements logical   arguments used.","code":""},{"path":[]},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rbeta2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The Beta Distribution â€” rbeta2","text":"","code":"rbeta2(3, c(0.1,0.5,0.9),0.1) #> [1] 0.1165689 0.5079711 0.9029945"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rcategorical.html","id":null,"dir":"Reference","previous_headings":"","what":"Sampling from the multinomial equivalent of the Bernoulli distribution â€” rcategorical","title":"Sampling from the multinomial equivalent of the Bernoulli distribution â€” rcategorical","text":"Sampling multinomial equivalent Bernoulli distribution","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rcategorical.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sampling from the multinomial equivalent of the Bernoulli distribution â€” rcategorical","text":"","code":"rcategorical(n, prob, factor = FALSE)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rcategorical.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sampling from the multinomial equivalent of the Bernoulli distribution â€” rcategorical","text":"n sample size prob (optionally named) vector probabilities normalised sum 1 factor FALSE factor levels either taken names prob first, character vector .","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rcategorical.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sampling from the multinomial equivalent of the Bernoulli distribution â€” rcategorical","text":"vector random class labels length n. Labels come names prob character vector factor.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rcategorical.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sampling from the multinomial equivalent of the Bernoulli distribution â€” rcategorical","text":"","code":"prob = c(\"one\"=0.1,\"two\"=0.2,\"seven\"=0.7) table(rcategorical(1000,prob)) #>  #>   one seven   two  #>    83   700   217  rcategorical(10,prob,factor=TRUE) #>  [1] one   one   one   seven seven one   seven seven seven two   #> Levels: one two seven rcategorical(10,rep(1,26),factor=letters) #>  [1] o u f r f l w j i w #> Levels: a b c d e f g h i j k l m n o p q r s t u v w x y z"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rcgamma.html","id":null,"dir":"Reference","previous_headings":"","what":"Sampling: gamma distribution constrained to have mean > sd â€” rcgamma","title":"Sampling: gamma distribution constrained to have mean > sd â€” rcgamma","text":"following conversion describes parameters mean kappa","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rcgamma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sampling: gamma distribution constrained to have mean > sd â€” rcgamma","text":"","code":"rcgamma(n, mean, kappa = 1/mean)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rcgamma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sampling: gamma distribution constrained to have mean > sd â€” rcgamma","text":"n number observations mean mean value true scale (vectorised) kappa coefficient variation. 0 variability 1 maximally variability (vectorised)","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rcgamma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sampling: gamma distribution constrained to have mean > sd â€” rcgamma","text":"dgamma gives density,   pgamma gives distribution function,   qgamma gives quantile function,   rgamma generates random deviates. Invalid arguments result return value NaN, warning. length result determined n   rgamma, maximum lengths   numerical arguments functions. numerical arguments n recycled   length result.  first elements logical   arguments used.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rcgamma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sampling: gamma distribution constrained to have mean > sd â€” rcgamma","text":"$$ \\text{shape:} \\alpha = \\frac{1}{\\kappa} \\\\ \\text{rate:} \\beta = \\frac{1}{\\mu \\times \\kappa} \\\\ \\text{scale:} \\sigma = \\mu \\times \\kappa \\\\ $$","code":""},{"path":[]},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rcgamma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sampling: gamma distribution constrained to have mean > sd â€” rcgamma","text":"","code":"rcgamma(10, 2, 0.5) #>  [1] 0.8583552 2.0635676 2.2472948 1.6251910 1.1314753 2.9139310 1.4479930 #>  [8] 4.2213040 2.2316691 2.3661440"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rdiscgamma.html","id":null,"dir":"Reference","previous_headings":"","what":"Random count data from a discrete gamma distribution â€” rdiscgamma","title":"Random count data from a discrete gamma distribution â€” rdiscgamma","text":"count data -dispersed can use gamma distribution rounded nearest whole number. method discretisation make_gamma_ip, suits delay distributions less variability can represented Poisson negative binomial distribution.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rdiscgamma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random count data from a discrete gamma distribution â€” rdiscgamma","text":"","code":"rdiscgamma(n, mean, sd, kappa)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rdiscgamma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random count data from a discrete gamma distribution â€” rdiscgamma","text":"n number observations mean mean value true scale (vectorised) sd standard deviation true scale (vectorised) kappa coefficient variation. 0 variability 1 maximally variability (vectorised)","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rdiscgamma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Random count data from a discrete gamma distribution â€” rdiscgamma","text":"integer valued vector gamma distribution.","code":""},{"path":[]},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rdiscgamma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Random count data from a discrete gamma distribution â€” rdiscgamma","text":"","code":"rdiscgamma(10, 2, 1) #>  [1] 5 3 2 2 1 2 2 3 3 3"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/reband_discrete.html","id":null,"dir":"Reference","previous_headings":"","what":"Reband any discrete distribution â€” reband_discrete","title":"Reband any discrete distribution â€” reband_discrete","text":"e.g. age banded population, discrete probability distribution e.g. serial interval distribution. method fits monotonically increasing spline cumulative distribution (including upper lower limits) interpolating using spline new cut points.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/reband_discrete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reband any discrete distribution â€” reband_discrete","text":"","code":"reband_discrete(   x,   y,   xout,   xlim = c(0, NA),   ytotal = c(0, sum(y)),   digits = 0,   labelling = c(\"positive_integer\", \"inclusive\", \"exclusive\"),   sep = \"-\" )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/reband_discrete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reband any discrete distribution â€” reband_discrete","text":"x set upper limits bands, e.g. age: 0-14;15-64;65-79;80+ 15,65,80,NA y set quantities band e.g. population figures xout set new upper limits xlim Upper lower limits x. last band e.g 80+ input want know 85+ band output kind maximum upper limit needed interpolate . ytotal upper lower limits y. interpolation values fall outside x minimum maximum limits y given . c(0,1) probability distribution, example. digits xout value continuous many significant figures put labels labelling xout values interpretable inclusive upper limit, exclusive upper limit, upper limit `positive_integerâ€œ quantity sep separator names e.g. 18-24 18 24","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/reband_discrete.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reband any discrete distribution â€” reband_discrete","text":"re-banded set discrete values, guaranteed sum y","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/reband_discrete.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reband any discrete distribution â€” reband_discrete","text":"","code":"england_demographics = ukc19::uk_population_2019_by_10yr_age %>%   dplyr::filter(name==\"England\")  ul = stringr::str_extract(england_demographics$class, \"_([0-9]+)\",group = 1) %>%   as.numeric() # ul is currently inclusive so add 1: ul = ul + 1  tmp = reband_discrete(   ul, england_demographics$population,   c(5,10,15,40,80), xlim=c(0,120))  tmp #>      0-4      5-9    10-14    15-39    40-79      80+  #>  3443507  3394336  3194025 18081321 25336808  2836964   sum(tmp) #> [1] 56286961 sum(england_demographics$population) #> [1] 56286961"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/reparam-dist.html","id":null,"dir":"Reference","previous_headings":"","what":"Re-parametrised distributions â€” reparam-dist","title":"Re-parametrised distributions â€” reparam-dist","text":"Re-parametrised distributions","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/reparam-dist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Re-parametrised distributions â€” reparam-dist","text":"n number observations x vector quantiles q vector quantiles p vector probabilities log logical; TRUE, probabilities p given log(p). log.p logical; TRUE, probabilities p given log(p). lower.tail logical; TRUE (default), probabilities P[X<=x] otherwise P[X>x]. prob mean probability (vectorised) prob.0.5 median probability (vectorised) kappa coefficient variation. 0 variability 1 maximally variability (vectorised) mean mean value true scale (vectorised) sd standard deviation true scale (vectorised) ... used","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rescale_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Rescale a timeseries in the temporal dimension â€” rescale_model","title":"Rescale a timeseries in the temporal dimension â€” rescale_model","text":"Sometimes may , example, modelled incidence growth rates weekly data resulting cases per week growth rate per week. may wish use estimate reproduction number, using algorithms assume daily incidence. everything dependence time, things proportions, prevalence change.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rescale_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rescale a timeseries in the temporal dimension â€” rescale_model","text":"","code":"rescale_model(df = i_timeseries, time_unit)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rescale_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rescale a timeseries in the temporal dimension â€” rescale_model","text":"df data frame containing modelled output. modify following columns present: dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period incidence.fit (double) - estimate incidence rate log scale incidence.se.fit (positive_double) - standard error incidence rate estimate log scale incidence.0.025 (positive_double) - lower confidence limit incidence rate (true scale) incidence.0.5 (positive_double) - median estimate incidence rate (true scale) incidence.0.975 (positive_double) - upper confidence limit incidence rate (true scale) grouping allowed. dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period growth.fit (double) - estimate growth rate growth.se.fit (positive_double) - standard error growth rate growth.0.025 (double) - lower confidence limit growth rate growth.0.5 (double) - median estimate growth rate growth.0.975 (double) - upper confidence limit growth rate grouping allowed. dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period proportion.fit (double) - estimate proportion logit scale proportion.se.fit (positive_double) - standard error proportion estimate logit scale proportion.0.025 (proportion) - lower confidence limit proportion (true scale) proportion.0.5 (proportion) - median estimate proportion (true scale) proportion.0.975 (proportion) - upper confidence limit proportion (true scale) relative.growth.fit (double) - estimate relative growth rate relative.growth.se.fit (positive_double) - standard error relative growth rate relative.growth.0.025 (double) - lower confidence limit relative growth rate relative.growth.0.5 (double) - median estimate relative growth rate relative.growth.0.975 (double) - upper confidence limit relative growth rate grouping allowed. time_unit lubridate period string \"1 day\"","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rescale_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rescale a timeseries in the temporal dimension â€” rescale_model","text":"time series different time unit, adjusted incidence growth rate figures.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rescale_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rescale a timeseries in the temporal dimension â€” rescale_model","text":"","code":"sim = sim_poisson_model(time_unit = \"1 week\") incidence = sim %>% poisson_locfit_model(frequency = \"1 day\", deg = 2, window=5) incidence2 = incidence %>% rescale_model(time_unit = \"1 day\") incidence2 %>% dplyr::glimpse() #> Rows: 727 #> Columns: 20 #> Groups: statistic [1] #> $ statistic        <chr> \"infections\", \"infections\", \"infections\", \"infectionsâ€¦ #> $ time             <t[day]> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,â€¦ #> $ incidence.fit    <dbl> 2.602330, 2.619494, 2.636412, 2.653095, 2.669555, 2.6â€¦ #> $ incidence.se.fit <dbl> 0.08919687, 0.08304502, 0.07751475, 0.07257184, 0.068â€¦ #> $ incidence.0.025  <dbl> 11.33061, 11.66659, 11.99495, 12.31548, 12.62804, 12.â€¦ #> $ incidence.0.05   <dbl> 81.57514, 83.83139, 86.04082, 88.20250, 90.31602, 92.â€¦ #> $ incidence.0.25   <dbl> 88.95032, 90.86650, 92.76221, 94.63774, 96.49360, 98.â€¦ #> $ incidence.0.5    <dbl> 13.49515, 13.72878, 13.96302, 14.19792, 14.43354, 14.â€¦ #> $ incidence.0.75   <dbl> 100.3238, 101.6380, 102.9872, 104.3713, 105.7897, 107â€¦ #> $ incidence.0.95   <dbl> 109.3940, 110.1674, 111.0325, 111.9862, 113.0257, 114â€¦ #> $ incidence.0.975  <dbl> 16.07319, 16.15548, 16.25399, 16.36808, 16.49719, 16.â€¦ #> $ growth.fit       <dbl> 0.01742825, 0.01727977, 0.01711183, 0.01692751, 0.016â€¦ #> $ growth.se.fit    <dbl> 0.008068884, 0.007744598, 0.007420038, 0.007096142, 0â€¦ #> $ growth.0.025     <dbl> 0.001613532, 0.002100635, 0.002568820, 0.003019323, 0â€¦ #> $ growth.0.05      <dbl> 0.02909285, 0.03178727, 0.03434865, 0.03678774, 0.039â€¦ #> $ growth.0.25      <dbl> 0.08390112, 0.08439282, 0.08474961, 0.08498862, 0.085â€¦ #> $ growth.0.5       <dbl> 0.01742825, 0.01727977, 0.01711183, 0.01692751, 0.016â€¦ #> $ growth.0.75      <dbl> 0.1600944, 0.1575239, 0.1548160, 0.1519965, 0.1490914â€¦ #> $ growth.0.95      <dbl> 0.2149027, 0.2101295, 0.2052169, 0.2001974, 0.1951031â€¦ #> $ growth.0.975     <dbl> 0.03324297, 0.03245890, 0.03165483, 0.03083569, 0.030â€¦"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rexpgrowth.html","id":null,"dir":"Reference","previous_headings":"","what":"Randomly sample incident times in an exponentially growing process â€” rexpgrowth","title":"Randomly sample incident times in an exponentially growing process â€” rexpgrowth","text":"Randomly sample incident times exponentially growing process","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rexpgrowth.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Randomly sample incident times in an exponentially growing process â€” rexpgrowth","text":"","code":"rexpgrowth(n, r, t_end, t_start = 0)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rexpgrowth.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Randomly sample incident times in an exponentially growing process â€” rexpgrowth","text":"n number items sample r exponential growth rate (per unit time) t_end end observation period t_start start observation period","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rexpgrowth.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Randomly sample incident times in an exponentially growing process â€” rexpgrowth","text":"vector n samples exponential growth process","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rexpgrowth.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Randomly sample incident times in an exponentially growing process â€” rexpgrowth","text":"","code":"graphics::hist(rexpgrowth(1000,0.1,40), breaks=40)  graphics::hist(rexpgrowth(1000,-0.1,40), breaks=40)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rexpgrowthI0.html","id":null,"dir":"Reference","previous_headings":"","what":"Randomly sample incident times in an exponentially growing process with initial case load â€” rexpgrowthI0","title":"Randomly sample incident times in an exponentially growing process with initial case load â€” rexpgrowthI0","text":"Randomly sample incident times exponentially growing process initial case load","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rexpgrowthI0.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Randomly sample incident times in an exponentially growing process with initial case load â€” rexpgrowthI0","text":"","code":"rexpgrowthI0(I0, r, t_end, t_start = 0)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rexpgrowthI0.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Randomly sample incident times in an exponentially growing process with initial case load â€” rexpgrowthI0","text":"I0 expected number cases observed first day r exponential growth rate (per unit time) t_end end observation period t_start start observation period","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rexpgrowthI0.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Randomly sample incident times in an exponentially growing process with initial case load â€” rexpgrowthI0","text":"vector n samples exponential growth process","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rexpgrowthI0.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Randomly sample incident times in an exponentially growing process with initial case load â€” rexpgrowthI0","text":"","code":"graphics::hist(rexpgrowthI0(10,0.1,20), breaks=40)  graphics::hist(rexpgrowthI0(1000,-0.1,40), breaks=40)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rgamma2.html","id":null,"dir":"Reference","previous_headings":"","what":"The Gamma Distribution â€” rgamma2","title":"The Gamma Distribution â€” rgamma2","text":"Density, distribution function, quantile function random   generation Gamma distribution parameters shape   scale.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rgamma2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The Gamma Distribution â€” rgamma2","text":"","code":"rgamma2(n, mean, sd = sqrt(mean))"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rgamma2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The Gamma Distribution â€” rgamma2","text":"n number observations mean mean value true scale (vectorised) sd standard deviation true scale (vectorised)","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rgamma2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The Gamma Distribution â€” rgamma2","text":"dgamma gives density,   pgamma gives distribution function,   qgamma gives quantile function,   rgamma generates random deviates. Invalid arguments result return value NaN, warning. length result determined n   rgamma, maximum lengths   numerical arguments functions. numerical arguments n recycled   length result.  first elements logical   arguments used.","code":""},{"path":[]},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rgamma2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The Gamma Distribution â€” rgamma2","text":"","code":"rgamma2(10, 2, 1) #>  [1] 1.0862935 2.2233210 1.6541772 1.0078365 2.1321339 3.1695478 0.7653657 #>  [8] 3.0183174 3.9632970 1.4411757"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rlnorm2.html","id":null,"dir":"Reference","previous_headings":"","what":"The Log Normal Distribution â€” rlnorm2","title":"The Log Normal Distribution â€” rlnorm2","text":"Density, distribution function, quantile function random   generation log normal distribution whose logarithm mean   equal meanlog standard deviation equal sdlog.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rlnorm2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The Log Normal Distribution â€” rlnorm2","text":"","code":"rlnorm2(n, mean = 1, sd = sqrt(exp(1) - 1))"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rlnorm2.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"The Log Normal Distribution â€” rlnorm2","text":"dlnorm calculated definition (â€˜Detailsâ€™).   [pqr]lnorm based relationship normal. Consequently, model single point mass exp(meanlog)   boundary case sdlog = 0.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rlnorm2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The Log Normal Distribution â€” rlnorm2","text":"n number observations. length(n) > 1, length     taken number required. mean mean value true scale (vectorised) sd standard deviation true scale (vectorised)","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rlnorm2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The Log Normal Distribution â€” rlnorm2","text":"dlnorm gives density,   plnorm gives distribution function,   qlnorm gives quantile function,   rlnorm generates random deviates. length result determined n   rlnorm, maximum lengths   numerical arguments functions. numerical arguments n recycled   length result.  first elements logical   arguments used.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rlnorm2.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The Log Normal Distribution â€” rlnorm2","text":"log normal distribution density   $$     f(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma x} e^{-(\\log(x) - \\mu)^2/2 \\sigma^2}%   $$   \\(\\mu\\) \\(\\sigma\\) mean standard   deviation logarithm.   mean \\(E(X) = exp(\\mu + 1/2 \\sigma^2)\\),   median \\(med(X) = exp(\\mu)\\), variance   \\(Var(X) = exp(2\\mu + \\sigma^2)(exp(\\sigma^2) - 1)\\)   hence coefficient variation   \\(\\sqrt{exp(\\sigma^2) - 1}\\)   approximately \\(\\sigma\\) small (e.g., \\(\\sigma < 1/2\\)).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rlnorm2.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"The Log Normal Distribution â€” rlnorm2","text":"cumulative hazard \\(H(t) = - \\log(1 - F(t))\\)   -plnorm(t, r, lower = FALSE, log = TRUE).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rlnorm2.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"The Log Normal Distribution â€” rlnorm2","text":"Becker, R. ., Chambers, J. M. Wilks, . R. (1988)   New S Language.   Wadsworth & Brooks/Cole. Johnson, N. L., Kotz, S. Balakrishnan, N. (1995)   Continuous Univariate Distributions, volume 1, chapter 14.   Wiley, New York.","code":""},{"path":[]},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rlnorm2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The Log Normal Distribution â€” rlnorm2","text":"","code":"rlnorm2(10, 2, 1) #>  [1] 2.3646323 1.8832683 2.5133625 2.8559743 2.2160680 0.9203143 0.8065008 #>  [8] 1.2014679 2.6817160 1.8452828"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rlogitnorm.html","id":null,"dir":"Reference","previous_headings":"","what":"Logit-normal distribution â€” rlogitnorm","title":"Logit-normal distribution â€” rlogitnorm","text":"logit-normal distribution support 0 1.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rlogitnorm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logit-normal distribution â€” rlogitnorm","text":"","code":"rlogitnorm(n, meanlogit = 0, sdlogit = 1)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rlogitnorm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logit-normal distribution â€” rlogitnorm","text":"n number observations meanlogit mean logit scale sdlogit sd logit scale","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rlogitnorm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Logit-normal distribution â€” rlogitnorm","text":"vector probabilities, quantiles, densities samples.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rlogitnorm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Logit-normal distribution â€” rlogitnorm","text":"","code":"rlogitnorm(10, 0, 1) #>  [1] 0.60611671 0.21137710 0.54511759 0.68739382 0.71449537 0.48584213 #>  [7] 0.66074007 0.52711086 0.07422444 0.61497256"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rlogitnorm2.html","id":null,"dir":"Reference","previous_headings":"","what":"Logit-normal distribution â€” rlogitnorm2","title":"Logit-normal distribution â€” rlogitnorm2","text":"logit-normal distribution support 0 1.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rlogitnorm2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logit-normal distribution â€” rlogitnorm2","text":"","code":"rlogitnorm2(n, prob.0.5 = 0.5, kappa = 1 - exp(-1))"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rlogitnorm2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logit-normal distribution â€” rlogitnorm2","text":"n number observations prob.0.5 median true scale kappa dispersion parameter 0 (none) 1 maximum dispersion","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rlogitnorm2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Logit-normal distribution â€” rlogitnorm2","text":"vector probabilities, quantiles, densities samples.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rlogitnorm2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Logit-normal distribution â€” rlogitnorm2","text":"","code":"mean(rlogitnorm2(10000,0.75,0.2)) #> [1] 0.7478397"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rnbinom2.html","id":null,"dir":"Reference","previous_headings":"","what":"The Negative Binomial Distribution â€” rnbinom2","title":"The Negative Binomial Distribution â€” rnbinom2","text":"Density, distribution function, quantile function random   generation negative binomial distribution parameters   size prob.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rnbinom2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The Negative Binomial Distribution â€” rnbinom2","text":"","code":"rnbinom2(n, mean, sd = sqrt(mean))"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rnbinom2.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"The Negative Binomial Distribution â€” rnbinom2","text":"dnbinom computes via binomial probabilities, using code   contributed Catherine Loader (see dbinom). pnbinom uses pbeta. qnbinom uses Cornishâ€“Fisher Expansion include skewness   correction normal approximation, followed search. rnbinom uses derivation gamma mixture Poisson   distributions, see Devroye, L. (1986) Non-Uniform Random Variate Generation.   Springer-Verlag, New York. Page 480.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rnbinom2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The Negative Binomial Distribution â€” rnbinom2","text":"n number observations.  length(n) > 1, length     taken number required. mean mean value true scale (vectorised) sd standard deviation true scale (vectorised)","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rnbinom2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The Negative Binomial Distribution â€” rnbinom2","text":"dnbinom gives density,   pnbinom gives distribution function,   qnbinom gives quantile function,   rnbinom generates random deviates. Invalid size prob result return value   NaN, warning. length result determined n   rnbinom, maximum lengths   numerical arguments functions. numerical arguments n recycled   length result.  first elements logical   arguments used. rnbinom returns vector type integer unless generated   values exceed maximum representable integer double   values returned.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rnbinom2.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The Negative Binomial Distribution â€” rnbinom2","text":"negative binomial distribution size \\(= n\\)   prob \\(= p\\) density   $$     p(x) = \\frac{\\Gamma(x+n)}{\\Gamma(n) x!} p^n (1-p)^x$$   \\(x = 0, 1, 2, \\ldots\\), \\(n > 0\\) \\(0 < p \\le 1\\). represents number failures occur sequence   Bernoulli trials target number successes reached.   mean \\(\\mu = n(1-p)/p\\) variance \\(n(1-p)/p^2\\). negative binomial distribution can also arise mixture   Poisson distributions mean distributed gamma distribution   (see pgamma) scale parameter (1 - prob)/prob   shape parameter size.  (definition allows non-integer   values size.) alternative parametrization (often used ecology)   mean mu (see ), size, dispersion   parameter, prob = size/(size+mu).  variance   mu + mu^2/size parametrization. element x integer, result dnbinom   zero, warning. case size == 0 distribution concentrated zero.   limiting distribution size approaching zero,   even mu rather prob held constant.  Notice   though, mean limit distribution 0, whatever   value mu. quantile defined smallest value \\(x\\)   \\(F(x) \\ge p\\), \\(F\\) distribution function.","code":""},{"path":[]},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rnbinom2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The Negative Binomial Distribution â€” rnbinom2","text":"","code":"rnbinom2(10, 5, sqrt(5)) #>  [1] 5 6 7 4 2 6 8 7 7 6"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rnull.html","id":null,"dir":"Reference","previous_headings":"","what":"Null distributions always returns NA â€” rnull","title":"Null distributions always returns NA â€” rnull","text":"Null distributions always returns NA","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rnull.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Null distributions always returns NA â€” rnull","text":"","code":"rnull(n, ...)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rnull.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Null distributions always returns NA â€” rnull","text":"n number observations ... used","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rnull.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Null distributions always returns NA â€” rnull","text":"","code":"rnull(3, c(0.1,0.5,0.9),0.1) #> [1] NA NA NA"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_cori.html","id":null,"dir":"Reference","previous_headings":"","what":"Reproduction number estimate using the Cori method â€” rt_cori","title":"Reproduction number estimate using the Cori method â€” rt_cori","text":"Calculate reproduction number estimate incidence data using reimplementation Cori method empirical generation time distribution. uses mixture distribution transmit uncertainty generation time estimates. number changes compared original EpiEstim implementation made. Firstly technical limitation infectivity profile strictly positive time. allows use serial intervals secondary potentially delayed observations. Secondly implementation tolerate missing count values (NA values must filtered though). Thirdly given time point t applies Rt estimates window spans time point t rather end time point t, tends address lag issues original, fourthly implementation allows multiple window widths calculated parallel aggregated. tends increase uncertainty result particularly time dimension, addresses issue seem EpiEstim pandemic. Finally quite bit quicker, especially approximate quantiles needed.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_cori.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reproduction number estimate using the Cori method â€” rt_cori","text":"","code":"rt_cori(   df = i_incidence_input,   ip = i_discrete_ip,   window = 14,   mean_prior = 1,   std_prior = 2,   ...,   epiestim_compat = FALSE,   approx = FALSE,   .progress = interactive() )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_cori.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reproduction number estimate using the Cori method â€” rt_cori","text":"df count data. Extra groups allowed. - dataframe columns: count (positive_integer) - Positive case counts associated specified time frame time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` grouping allowed. ip long format infectivity profile. - dataframe columns: boot (anything + default(1)) - bootstrap identifier probability (proportion) - probability new event period. tau (integer + complete) - days since index event. Minimally grouped : boot (groupings allowed). window widths Cori method window include estimate. can vector values windows calculated aggregated. mean_prior prior $R_t$ estimate. sample size low $R_t$ estimate revert prior. EpiEstim default high number allow detection insufficient data tends create anomalies early part infection time series. possible value $R_0$ fact also poor choice value $R_t$ case numbers drop low value. std_prior prior $R_t$ SD. ... used epiestim_compat produce estimate Rt using windows end time t rather windows span time t. option selected can also one value window. approx approximate quantiles mixture distribution gamma distribution first mean SD. .progress show CLI progress bar","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_cori.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reproduction number estimate using the Cori method â€” rt_cori","text":"dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period rt.fit (double) - estimate reproduction number rt.se.fit (positive_double) - standard error reproduction number rt.0.025 (double) - lower confidence limit reproduction number rt.0.5 (double) - median estimate reproduction number rt.0.975 (double) - upper confidence limit reproduction number grouping allowed.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_cori.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Reproduction number estimate using the Cori method â€” rt_cori","text":"still issues large $R_t$ estimates early part time series, resul tof renewal equaltion method. calculate reproduction number group input dataframe.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_cori.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reproduction number estimate using the Cori method â€” rt_cori","text":"","code":"data = example_poisson_rt_smooth()  tmp2 = data %>% rt_cori(ip=example_ip(), epiestim_compat = TRUE) tmp3 = data %>% rt_cori(ip=example_ip(), window=c(5:14), approx=TRUE)  comp = dplyr::bind_rows(   tmp2 %>% dplyr::mutate(class = \"EpiEstim\"),   tmp3 %>% dplyr::mutate(class = \"Cori+\") ) %>% dplyr::group_by(class)  if (interactive()) {   plot_rt(comp, date_labels=\"%b %y\")+sim_geom_function(data,colour=\"black\")+     ggplot2::coord_cartesian(ylim=c(0.5,3.0)) }"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_epiestim.html","id":null,"dir":"Reference","previous_headings":"","what":"EpiEstim reproduction number wrapper function â€” rt_epiestim","title":"EpiEstim reproduction number wrapper function â€” rt_epiestim","text":"Calculate reproduction number estimate incidence data using EpiEstim library empirical generation time distribution. uses resampling transmit uncertainty generation time estimates. quite slow time series depending number bootstraps samples infectivity profile.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_epiestim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"EpiEstim reproduction number wrapper function â€” rt_epiestim","text":"","code":"rt_epiestim(   df = i_incidence_input,   ip = i_discrete_ip,   bootstraps = 2000,   window = 14,   mean_prior = 1,   std_prior = 2,   ...,   .progress = interactive() )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_epiestim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"EpiEstim reproduction number wrapper function â€” rt_epiestim","text":"df Count data. Extra groups allowed. - dataframe columns: count (positive_integer) - Positive case counts associated specified time frame time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` grouping allowed. ip infectivity profile - dataframe columns: boot (anything + default(1)) - bootstrap identifier probability (proportion) - probability new event period. tau (integer + complete) - days since index event. Minimally grouped : boot (groupings allowed). bootstraps number bootstraps take calculate point. window width EpiEstim window mean_prior prior $R_t$ estimate. sample size low $R_t$ estimate revert prior. EpiEstim default high number allow detection insufficient data tends create anomalies early part infection time series. possible value $R_0$ fact also poor choice value $R_t$ case numbers drop low value. std_prior prior $R_t$ SD. ... used .progress show CLI progress bar","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_epiestim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"EpiEstim reproduction number wrapper function â€” rt_epiestim","text":"dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period rt.fit (double) - estimate reproduction number rt.se.fit (positive_double) - standard error reproduction number rt.0.025 (double) - lower confidence limit reproduction number rt.0.5 (double) - median estimate reproduction number rt.0.975 (double) - upper confidence limit reproduction number grouping allowed.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_epiestim.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"EpiEstim reproduction number wrapper function â€” rt_epiestim","text":"calculate reproduction number group input dataframe.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_epiestim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"EpiEstim reproduction number wrapper function â€” rt_epiestim","text":"","code":"data = example_poisson_rt_smooth()  tmp2 = data %>%    rt_epiestim(ip=example_ip())  if (interactive()) {   plot_rt(tmp2, date_labels=\"%b %y\")+sim_geom_function(data,colour=\"red\") }"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_from_growth_rate.html","id":null,"dir":"Reference","previous_headings":"","what":"Wallinga-Lipsitch reproduction number from growth rates â€” rt_from_growth_rate","title":"Wallinga-Lipsitch reproduction number from growth rates â€” rt_from_growth_rate","text":"Calculate reproduction number estimate growth rate using Wallinga Lipsitch 2007 estimation using empirical generation time distribution. uses resampling transmit uncertainty growth rate estimates. also handles time-series daily cadence (although experimental). reproduction number estimate neither instantaneous (backward looking) case (forward looking) reproduction number somewhere two, method looks flux infection single point time.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_from_growth_rate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wallinga-Lipsitch reproduction number from growth rates â€” rt_from_growth_rate","text":"","code":"rt_from_growth_rate(   df = i_growth_rate,   ip = i_empirical_ip,   bootstraps = 1000,   seed = Sys.time(),   .progress = interactive() )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_from_growth_rate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wallinga-Lipsitch reproduction number from growth rates â€” rt_from_growth_rate","text":"df Growth rate estimates - dataframe columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` growth.fit (double) - estimate growth rate growth.se.fit (positive_double) - standard error growth rate growth.0.025 (double) - lower confidence limit growth rate growth.0.5 (double) - median estimate growth rate growth.0.975 (double) - upper confidence limit growth rate grouping allowed. ip Infectivity profile - dataframe columns: boot (anything + default(1)) - bootstrap identifier probability (proportion) - probability new event period. a0 (double) - beginning time period (days) a1 (double) - end time period (days) Minimally grouped : boot (groupings allowed). bootstraps number bootstraps take calculate point. seed random number generator seed .progress show CLI progress bar","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_from_growth_rate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Wallinga-Lipsitch reproduction number from growth rates â€” rt_from_growth_rate","text":"dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period rt.fit (double) - estimate reproduction number rt.se.fit (positive_double) - standard error reproduction number rt.0.025 (double) - lower confidence limit reproduction number rt.0.5 (double) - median estimate reproduction number rt.0.975 (double) - upper confidence limit reproduction number grouping allowed.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_from_growth_rate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Wallinga-Lipsitch reproduction number from growth rates â€” rt_from_growth_rate","text":"method quite slow compared others default non deterministic.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_from_growth_rate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Wallinga-Lipsitch reproduction number from growth rates â€” rt_from_growth_rate","text":"","code":"data = example_poisson_rt_smooth()  tmp = data %>%   poisson_locfit_model() %>%   rt_from_growth_rate(ip=example_ip())  if (interactive()) {   plot_rt(tmp, date_labels=\"%b %y\")+sim_geom_function(data,colour=\"red\") }"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_from_incidence.html","id":null,"dir":"Reference","previous_headings":"","what":"Reproduction number from modelled incidence â€” rt_from_incidence","title":"Reproduction number from modelled incidence â€” rt_from_incidence","text":"Calculate reproduction number estimate modelled incidence using methods described vignette \"Estimating reproduction number modelled incidence\" using set empirical generation time distributions. assumes modelled incidence time unit ip distribution, daily, case rescale_model() may able fix .","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_from_incidence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reproduction number from modelled incidence â€” rt_from_incidence","text":"","code":"rt_from_incidence(   df = i_incidence_model,   ip = i_discrete_ip,   raw = i_incidence_data,   approx = TRUE,   .progress = interactive() )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_from_incidence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reproduction number from modelled incidence â€” rt_from_incidence","text":"df modelled incidence estimate - dataframe columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` incidence.fit (double) - estimate incidence rate log scale incidence.se.fit (positive_double) - standard error incidence rate estimate log scale incidence.0.025 (positive_double) - lower confidence limit incidence rate (true scale) incidence.0.5 (positive_double) - median estimate incidence rate (true scale) incidence.0.975 (positive_double) - upper confidence limit incidence rate (true scale) grouping allowed. ip infectivity profile (aka generation time distribution) - dataframe columns: boot (anything + default(1)) - bootstrap identifier probability (proportion) - probability new event period. tau (integer + complete) - days since index event. Minimally grouped : boot (groupings allowed). raw raw data modelled incidence based . optional. given algorithm assume independence, faster estimate (much faster long time-series), uncertain Rt estimates. circumstances assumption independence can cause underestimation Rt. risk warning given, parameter may need supplied. - dataframe columns: count (positive_integer) - Positive case counts associated specified time frame time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` grouping allowed. approx use faster, approximate, estimate quantiles .progress show CLI progress bar","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_from_incidence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reproduction number from modelled incidence â€” rt_from_incidence","text":"dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period rt.fit (double) - estimate reproduction number rt.se.fit (positive_double) - standard error reproduction number rt.0.025 (double) - lower confidence limit reproduction number rt.0.5 (double) - median estimate reproduction number rt.0.975 (double) - upper confidence limit reproduction number grouping allowed.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_from_incidence.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Reproduction number from modelled incidence â€” rt_from_incidence","text":"N.B. certain estimators (e.g. poisson_gam_model(), poisson_locfit_model()) version function called automatically infectivity profile supplied. inbuilt version preferred function estimators, full covariance matrix may used initial part outbreak can predicted accurately. function supporting count models ggoutbreak. rolling incidence estimates want Rt estimate rt_incidence_timeseries_implementation() maybe better suited task.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_from_incidence.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reproduction number from modelled incidence â€” rt_from_incidence","text":"","code":"tmp = example_poisson_rt_smooth() %>%   poisson_locfit_model() %>%   rt_from_incidence(     ip = example_ip(),     raw = example_poisson_rt_smooth(),     approx=FALSE  ) #> Rt from incidence: inferring vcov from residuals.  #> (N.B. this message will only be displayed once.)  # This will assume independence and tmp2 = example_poisson_rt_smooth()%>%   poisson_locfit_model() %>%   rt_from_incidence(ip = example_ip(), approx=TRUE) #> Estimates were assumed to be independent, but more that 1% of estimates #> are at risk of Rt underestimation by more that 0.05 (absolute). #> We advise re-running supplying a full variance-covariance matrix, or #> a value to the `raw` parameter, or setting `quick=FALSE`.  #> (N.B. this message will only be displayed once.)  plot_data = dplyr::bind_rows(   tmp %>% dplyr::mutate(class = \"exact\"),   tmp2 %>% dplyr::mutate(class = \"approx\"), ) %>% dplyr::group_by(class)  if (interactive()) {   plot_rt(plot_data, date_labels=\"%b %y\")+    sim_geom_function(example_poisson_rt_smooth())+    ggplot2::coord_cartesian(ylim=c(0.5,3))+    ggplot2::facet_wrap(~class) }"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_from_renewal.html","id":null,"dir":"Reference","previous_headings":"","what":"Reproduction number from renewal equation applied to modelled incidence using statistical re-sampling â€” rt_from_renewal","title":"Reproduction number from renewal equation applied to modelled incidence using statistical re-sampling â€” rt_from_renewal","text":"Calculate reproduction number estimate modelled incidence estimates, statistical sampling log-normally distributed incidence estimate, get I_t ~ Poisson(I_0 e^{rt})  model using log link function. combined uncertain infectivity profile specified multiple discrete empirical distributions, calculate range possible values $R_t$.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_from_renewal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reproduction number from renewal equation applied to modelled incidence using statistical re-sampling â€” rt_from_renewal","text":"","code":"rt_from_renewal(   df = i_incidence_model,   ip = i_discrete_ip,   bootstraps = 1000,   seed = Sys.time(),   .progress = interactive() )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_from_renewal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reproduction number from renewal equation applied to modelled incidence using statistical re-sampling â€” rt_from_renewal","text":"df modelled incidence estimate - dataframe columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` incidence.fit (double) - estimate incidence rate log scale incidence.se.fit (positive_double) - standard error incidence rate estimate log scale incidence.0.025 (positive_double) - lower confidence limit incidence rate (true scale) incidence.0.5 (positive_double) - median estimate incidence rate (true scale) incidence.0.975 (positive_double) - upper confidence limit incidence rate (true scale) grouping allowed. ip infectivity profile - dataframe columns: boot (anything + default(1)) - bootstrap identifier probability (proportion) - probability new event period. tau (integer + complete) - days since index event. Minimally grouped : boot (groupings allowed). bootstraps number samples take time point. rounded whole multiple infectivity profile distribution length. seed random number seed reproducibility .progress show CLI progress bar","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_from_renewal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reproduction number from renewal equation applied to modelled incidence using statistical re-sampling â€” rt_from_renewal","text":"dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period rt.fit (double) - estimate reproduction number rt.se.fit (positive_double) - standard error reproduction number rt.0.025 (double) - lower confidence limit reproduction number rt.0.5 (double) - median estimate reproduction number rt.0.975 (double) - upper confidence limit reproduction number grouping allowed.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_from_renewal.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Reproduction number from renewal equation applied to modelled incidence using statistical re-sampling â€” rt_from_renewal","text":"method moderately slow non deterministic default.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_from_renewal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reproduction number from renewal equation applied to modelled incidence using statistical re-sampling â€” rt_from_renewal","text":"","code":"data = example_poisson_rt_smooth()  tmp2 = data %>%    poisson_locfit_model() %>%    rt_from_renewal(ip=example_ip())  if (interactive()) {   plot_rt(tmp2, date_labels=\"%b %y\")+sim_geom_function(data,colour=\"red\") }"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_incidence_reference_implementation.html","id":null,"dir":"Reference","previous_headings":"","what":"Reference implementation of the Rt from modelled incidence algorithm â€” rt_incidence_reference_implementation","title":"Reference implementation of the Rt from modelled incidence algorithm â€” rt_incidence_reference_implementation","text":"function estimates reproduction number specific point time given time series log-normally distributed incidence estimates, set infectivity profiles. version algorithm works single time point optimised running whole time series. please see rt_incidence_timeseries_implementation().","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_incidence_reference_implementation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reference implementation of the Rt from modelled incidence algorithm â€” rt_incidence_reference_implementation","text":"","code":"rt_incidence_reference_implementation(   mu_t,   vcov_ij = diag(sigma_t^2),   omega,   sigma_t = NULL,   tau_offset = 0 )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_incidence_reference_implementation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reference implementation of the Rt from modelled incidence algorithm â€” rt_incidence_reference_implementation","text":"mu_t vector meanlog parameters lognormal distribution modelled incidence. vector length k. vcov_ij log scale variance-covariance matrix predictions. optional given sigma_t given inferred assuming independence estimates. matrix dimensions k * k omega matrix (vector) representing infectivity profile discrete time probability distribution. must k * n matrix vector length k. n columns individual estimate infectivity profile (N.B. format EpiEstim). EpiEstim first row matrix must zero represents delay zero. constraint apply . sigma_t vcov_ij given must supplied sdlog log normal incidence estimate tau_offset cases infectivity profile support delays 0:(k-1) Rt estimate made time (k-1). negative component serial interval used proxy support -tau_offset:(k-tau_offset-1).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_incidence_reference_implementation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reference implementation of the Rt from modelled incidence algorithm â€” rt_incidence_reference_implementation","text":"list following items: time_Rt: time point Rt esitmate (usually k-1) mean_Rt_star: mean Rt estimate var_Rt_star: variance Rt estimate meanlog_Rt_star: log normal parameter approximate distribution Rt sdlog_Rt_star: log normal parameter approximate distribution Rt mu_Rt_mix: vector log normal parameters exact mixture distribution Rt sigma_Rt_mix: vector log normal parameters exact mixture distribution Rt quantile_Rt_fn: log-normal mixture quantile function Rt Quantiles can either obtained quantile function e.g. qlnorm(p, meanlog_Rt_star, sdlog_Rt_star)","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_incidence_reference_implementation.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Reference implementation of the Rt from modelled incidence algorithm â€” rt_incidence_reference_implementation","text":"N.B. description algorithm given : https://ai4ci.github.io/ggoutbreak/articles/rt--incidence.html","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_incidence_reference_implementation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reference implementation of the Rt from modelled incidence algorithm â€” rt_incidence_reference_implementation","text":"","code":"data = example_poisson_rt_smooth()  omega = omega_matrix(example_ip()) k = nrow(omega)  pred_time = 50 index = pred_time-k:1+1  # we will try and estimate the Rt at time k+10: print(data$rt[pred_time]) #> [1] 1.690049  # first we need a set of incidence estimates # in the simplest example we use a GLM:  newdata = dplyr::tibble(time = 1:100)    model = stats::glm(count ~ splines::bs(time,df=8), family = \"poisson\", data=data) pred = stats::predict(model, newdata, se.fit = TRUE)  # I've picked a df to make this example work. In real life you would need # to validate the incidence model is sensible and not over fitting # before using it to estimate RT: # ggplot2::ggplot()+ #   ggplot2::geom_point(data=data, ggplot2::aes(x=time, y=count))+ #   ggplot2::geom_line( #     data = newdata %>% dplyr::mutate(fit = exp(pred$fit) #     ), ggplot2::aes(x=time,y=fit))  mu_t = pred$fit[index] sigma_t = pred$se.fit[index]  # prediction vcov is not simple from GLM models. rt_est = rt_incidence_reference_implementation(mu_t=mu_t,sigma_t = sigma_t, omega = omega)  # quantiles from a mixture distribution: rt_est$quantile_Rt_fn(c(0.025,0.5,0.975)) #>  q.0.025    q.0.5  q.0.975  #> 1.463875 1.631201 1.868113  # and from the rough estimate based on matching of moments: stats::qlnorm(c(0.025,0.5,0.975), rt_est$meanlog_Rt_star, rt_est$sdlog_Rt_star) #> [1] 1.445694 1.636032 1.851430  # GLM do not produce vcov matrices we can estimate them if we have access to # the data: vcov_glm = vcov_from_residuals(data$count[1:100], pred$fit, pred$se.fit)$vcov_matrix vcov_glm_ij = vcov_glm[index, index]  # Using an estimated vcov we get very similar answers: rt_est_vcov = rt_incidence_reference_implementation(mu_t=mu_t,vcov_ij = vcov_glm_ij, omega = omega) rt_est_vcov$quantile_Rt_fn(c(0.025,0.5,0.975)) #>  q.0.025    q.0.5  q.0.975  #> 1.463050 1.631217 1.869455  # In theory assuming independence leads to excess uncertainty and possible # underestimation bias. In most situations though this appears low risk.  # Lets do the same with a GAM: model2 = mgcv::gam(count ~ s(time), family = \"poisson\", data=data) pred2 = stats::predict(model2, newdata, se.fit = TRUE)  # we can get prediction level vcov from GAMs easily Xp = stats::predict(model2, newdata, type = \"lpmatrix\") pred_vcov = Xp %*% stats::vcov(model2) %*% t(Xp) vcov_ij = pred_vcov[index, index] mu_t2 = pred2$fit[index]  rt_est2 = rt_incidence_reference_implementation(mu_t=mu_t2, vcov_ij=vcov_ij, omega = omega) rt_est2$quantile_Rt_fn(c(0.025,0.5,0.975)) #>  q.0.025    q.0.5  q.0.975  #> 1.473898 1.635784 1.887385   # How does this compare to EpiEstim: # N.B. setting seed to make deterministic withr::with_seed(100, {   epi = EpiEstim::estimate_R(     data$count,     method = \"si_from_sample\",     si_sample = omega,     config = EpiEstim::make_config(       method = \"si_from_sample\",       t_start = pred_time-7,       t_end = pred_time,       n2 = 100)   ) })  epi$R %>%   dplyr::select(`Quantile.0.025(R)`, `Median(R)`, `Quantile.0.975(R)`) #>   Quantile.0.025(R) Median(R) Quantile.0.975(R) #> 1          1.674906  1.970005          2.370261"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_incidence_timeseries_implementation.html","id":null,"dir":"Reference","previous_headings":"","what":"Time series implementation of the Rt from modelled incidence algorithm â€” rt_incidence_timeseries_implementation","title":"Time series implementation of the Rt from modelled incidence algorithm â€” rt_incidence_timeseries_implementation","text":"function estimates reproduction number time series given log-normally distributed incidence estimates, set infectivity profiles. version algorithm optimised running single time series. algorithm produce Rt estimates least ","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_incidence_timeseries_implementation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Time series implementation of the Rt from modelled incidence algorithm â€” rt_incidence_timeseries_implementation","text":"","code":"rt_incidence_timeseries_implementation(   time,   mu,   vcov = NULL,   sigma = NULL,   ip = i_discrete_ip,   tidy = FALSE,   ... )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_incidence_timeseries_implementation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Time series implementation of the Rt from modelled incidence algorithm â€” rt_incidence_timeseries_implementation","text":"time set time points numeric vector. vector length k. mu time series meanlog parameters lognormal distribution modelled incidence. vector length k. vcov log scale variance-covariance matrix predictions. optional given sigma_t given inferred assuming independence estimates. matrix dimensions k * k sigma vcov given must supplied sdlog log normal incidence estimate. case estimates made assuming estimate independence. vector length k. Checks made determine risk bias, can make slower using full covariance matrix. ip long format infectivity profile dataframe. - dataframe columns: boot (anything + default(1)) - bootstrap identifier probability (proportion) - probability new event period. tau (integer + complete) - days since index event. Minimally grouped : boot (groupings allowed). tidy want detailed raw output (FALSE - default) summary output quantiles predicted. ... passed onto output formatter tidy=TRUE, moment approx = FALSE","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_incidence_timeseries_implementation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Time series implementation of the Rt from modelled incidence algorithm â€” rt_incidence_timeseries_implementation","text":"dataframe k rows following columns: time_Rt: time point Rt estimate (usually k-1) mean_Rt_star: mean Rt estimate var_Rt_star: variance Rt estimate meanlog_Rt_star: log normal parameter approximate distribution Rt sdlog_Rt_star: log normal parameter approximate distribution Rt mu_Rt_mix: list vectors log normal parameters exact mixture distribution Rt sigma_Rt_mix: list vectors log normal parameters exact mixture distribution Rt Approximate quantiles can obtained e.g. qlnorm(0.5, meanlog_Rt_star, sdlog_Rt_star) Alternatively tidy true output post processed conform : dataframe containing following columns: time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period rt.fit (double) - estimate reproduction number rt.se.fit (positive_double) - standard error reproduction number rt.0.025 (double) - lower confidence limit reproduction number rt.0.5 (double) - median estimate reproduction number rt.0.975 (double) - upper confidence limit reproduction number grouping allowed.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_incidence_timeseries_implementation.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Time series implementation of the Rt from modelled incidence algorithm â€” rt_incidence_timeseries_implementation","text":"N.B. description algorithm given : https://ai4ci.github.io/ggoutbreak/articles/rt--incidence.html","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rt_incidence_timeseries_implementation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Time series implementation of the Rt from modelled incidence algorithm â€” rt_incidence_timeseries_implementation","text":"","code":"data = example_poisson_rt_smooth() ip = example_ip()  # first we need a set of incidence estimates # we fit a poisson model to counts using a GAM: model = mgcv::gam(count ~ s(time), family = \"poisson\", data=data) ip_len = max(ip$tau) newdata = dplyr::tibble(time = -ip_len:100)  pred = stats::predict(model, newdata, se.fit = TRUE)  # we can get prediction vcov from GAMs fairly easily Xp = stats::predict(model, newdata, type = \"lpmatrix\") pred_vcov = Xp %*% stats::vcov(model) %*% t(Xp)  # Now we estimate rt rt_est = rt_incidence_timeseries_implementation(   time = newdata$time,   mu = pred$fit,   vcov = pred_vcov,   ip = ip)  # Lets compare epiestim on the same data withr::with_seed(100, {   epi = EpiEstim::estimate_R(     data$count,     method = \"si_from_sample\",     si_sample = omega_matrix(ip),     config = EpiEstim::make_config(       method = \"si_from_sample\",       t_start = 10:100-7,       t_end = 10:100,       n2 = 100)   ) })  ggplot2::ggplot()+   ggplot2::geom_line(     data=data %>% dplyr::filter(time<100),     ggplot2::aes(x=time,y=rt), colour=\"black\")+   ggplot2::geom_line(     data = rt_est, ggplot2::aes(x=time, y=mean_Rt_star, colour=\"gam+rt\"))+   ggplot2::geom_line(     data = epi$R, ggplot2::aes(x=t_end, y=`Mean(R)`, colour=\"epiestim\")) #> Don't know how to automatically pick scale for object of type #> <time_period/vctrs_vctr>. Defaulting to continuous.   # mean bias of GAM+rt estimate: mean(data$rt[seq_along(rt_est$mean_Rt_star)] - rt_est$mean_Rt_star) #> [1] 0.0199856"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rwedge.html","id":null,"dir":"Reference","previous_headings":"","what":"Wedge distribution â€” rwedge","title":"Wedge distribution â€” rwedge","text":"wedge distribution support 0 1 linear probability density function support.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rwedge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wedge distribution â€” rwedge","text":"","code":"rwedge(n, a)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rwedge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wedge distribution â€” rwedge","text":"n number observations gradient -2 (left skewed) 2 (right skewed)","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rwedge.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Wedge distribution â€” rwedge","text":"vector probabilities, quantiles, densities samples.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rwedge.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Wedge distribution â€” rwedge","text":"rwedge can combined quantile functions skew standard distributions, introduce correlation weight certain parts distribution.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/rwedge.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Wedge distribution â€” rwedge","text":"","code":"pwedge(seq(0,1,0.1), a=1) #>  [1] 0.5 0.6 0.7 0.8 0.9 1.0 1.1 1.2 1.3 1.4 1.5 dwedge(seq(0,1,0.1), a=1) #>  [1] 0.000 0.055 0.120 0.195 0.280 0.375 0.480 0.595 0.720 0.855 1.000 qwedge(c(0.25,0.5,0.75), a=-1) #> [1] 0.1771243 0.3819660 0.6339746  stats::cor(   stats::qnorm(rwedge(1000, a=2)),   stats::qnorm(rwedge(1000, a=-2)) ) #> [1] 0.04059007"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/scale_x_log1p.html","id":null,"dir":"Reference","previous_headings":"","what":"A log1p x scale â€” scale_x_log1p","title":"A log1p x scale â€” scale_x_log1p","text":"log1p x scale","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/scale_x_log1p.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A log1p x scale â€” scale_x_log1p","text":"","code":"scale_x_log1p(..., n = 5, base = 10, dp = 0)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/scale_x_log1p.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A log1p x scale â€” scale_x_log1p","text":"... arguments passed scale_(x|y)_continuous() n number major breaks base base logarithm dp decimal points","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/scale_x_log1p.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A log1p x scale â€” scale_x_log1p","text":"ggplot scale","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/scale_x_logit.html","id":null,"dir":"Reference","previous_headings":"","what":"A logit x scale â€” scale_x_logit","title":"A logit x scale â€” scale_x_logit","text":"logit x scale","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/scale_x_logit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A logit x scale â€” scale_x_logit","text":"","code":"scale_x_logit(...)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/scale_x_logit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A logit x scale â€” scale_x_logit","text":"... arguments passed scale_(x|y)_continuous()","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/scale_x_logit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A logit x scale â€” scale_x_logit","text":"ggplot scale","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/scale_y_log1p.html","id":null,"dir":"Reference","previous_headings":"","what":"A log1p y scale â€” scale_y_log1p","title":"A log1p y scale â€” scale_y_log1p","text":"log1p y scale","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/scale_y_log1p.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A log1p y scale â€” scale_y_log1p","text":"","code":"scale_y_log1p(..., n = 5, base = 10, dp = 0)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/scale_y_log1p.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A log1p y scale â€” scale_y_log1p","text":"... arguments passed scale_(x|y)_continuous() n number major breaks base base logarithm dp decimal points","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/scale_y_log1p.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A log1p y scale â€” scale_y_log1p","text":"ggplot scale","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/scale_y_logit.html","id":null,"dir":"Reference","previous_headings":"","what":"A logit y scale â€” scale_y_logit","title":"A logit y scale â€” scale_y_logit","text":"logit y scale","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/scale_y_logit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A logit y scale â€” scale_y_logit","text":"","code":"scale_y_logit(...)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/scale_y_logit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A logit y scale â€” scale_y_logit","text":"... arguments passed scale_(x|y)_continuous()","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/scale_y_logit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A logit y scale â€” scale_y_logit","text":"ggplot scale","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/score_estimate.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate scoring statistics from predictions. â€” score_estimate","title":"Calculate scoring statistics from predictions. â€” score_estimate","text":"performs range continuous scoring metrics estimate time-point using cumulative distribution functions estimate. Point quality metrics calculated estimate provided summarised. Summarisation performed using bootstrap resampling generate confidence intervals summary statistics, presented median +/1 95% CI.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/score_estimate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate scoring statistics from predictions. â€” score_estimate","text":"","code":"score_estimate(   est,   obs,   lags = NULL,   summarise_by = est %>% dplyr::groups(),   bootstraps = 1000,   raw_bootstraps = FALSE,   seed = 100 )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/score_estimate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate scoring statistics from predictions. â€” score_estimate","text":"est dataframe estimates incidence, growth rate reproduction number based simulation data known parameters. group est expected contain multiple estimates group scored separately. Estimates est must form column named XXX.cdf containing cumulative distribution function estimate XXX.link containing link function specification (one identity,log logit). generated default ggoutbreak estimators triggered setting option: options(\"ggoutbreak.keep_cdf\"=TRUE) running estimator. CDFs generated analytical, estimator generates parametrised output (mixture thereof), empirical estimator uses resampling, inferred estimator produces quantiles . obs dataframe ground truth, sharing grouping columns est least one column(s) named XXX.obs XXX e.g. rt,growth incidence column group predicted est (.e. obs column XXX.obs, est must one called XXX.cdf). lags data frame estimate types lags output quantify_lag() multiple models included columns must match obs. must 2 columns, one called estimate values matching incidence,rt,growth,proportion,relative.growth, lag column, (whole) number days. summarise_by default every group treated separately. can overridden dplyr specification groupings want see final summarised output (e.g. want differentiate performance particular type scenario timeframe). exactly FALSE function return raw point estimates. bootstraps number bootstrap replicates draw assessing metric confidence. FALSE bootstrapping done metrics returned confidence intervals. raw_bootstraps (defaults FALSE) return summary metrics bootstrap rather quantiles summary metrics. seed random seed reproducibility","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/score_estimate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate scoring statistics from predictions. â€” score_estimate","text":"dataframe scoring metrics, one row per group. includes following columns: mean_quantile_bias - average universal residuals. Lower values better. mean_trans_bias - bias link function scale. link - link function mean_bias - bias natural scale (may interpreted additive multiplicative depending link) pit_was - unadjusted probability integral transform histogram Wasserstein distance uniform (lower values better). unbiased_pit_was - PIT Wasserstein distance uniform, adjusted estimator bias (lower values better). measure calibration. directed_pit_was - PIT Wasserstein distance uniform, directed away centre, adjusted estimator bias (values closer zero better, positive values indicate overconfidence, negative values excessively conservative estimates). percent_iqr_coverage - percentage estimators include true value IQR. perfectly calibrated estimate 0.5. Lower values reflect overconfidence, higher values reflect excessively conservative estimates. measure calibration influenced bias. unbiased_percent_iqr_coverage - percentage estimators include true value IQR adjusted bias. 0.5. measure calibration, tells direction (smaller numbers -confident, larger values excessively conservative). mean_prediction_interval_width_50 - prediction interval width measure sharpness (smaller values sharper). Sharper estimators superior unbiased well calibrated. mean_crps - mean value continuous rank probability score point estimate (lower values better) mean_unbiased_crps - mean value continuous rank probability score point estimate assessed adjustment bias (lower values better) threshold_misclassification_probability - metric natural threshold like 1 Rt measures probable estimate propose epidemic shrinking growing vice versa. Lower better outputs possible summarise_by false.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/score_estimate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate scoring statistics from predictions. â€” score_estimate","text":"","code":"data = example_poisson_rt_smooth()  pipeline = ~ .x %>% poisson_locfit_model(ip = .y, quick=TRUE) lags = quantify_lag(pipeline, ip = example_ip()) #> Rt estimation using Locfit (approx and assuming independence)  withr::with_options(list(\"ggoutbreak.keep_cdf\"=TRUE),{    est = data %>% poisson_locfit_model(ip = example_ip(), quick=TRUE) }) #> Rt estimation using Locfit (approx and assuming independence) #> Estimates were assumed to be independent, but more that 1% of estimates #> are at risk of Rt underestimation by more that 0.05 (absolute). #> We advise re-running supplying a full variance-covariance matrix, or #> a value to the `raw` parameter, or setting `quick=FALSE`.  if (interactive()) plot_rt(est)+sim_geom_function(data, colour=\"red\")  obs = data %>% dplyr::mutate(rt.obs = rt, incidence.obs = rate) score_estimate(est,obs,lags) %>% dplyr::glimpse() #> estimates match true observations using columns: statistic,time #> matching ground truth observations for: rt,incidence #> Rows: 2 #> Columns: 58 #> Groups: link, statistic, .type [2] #> $ link                                          <chr> \"log\", \"log\" #> $ statistic                                     <chr> \"infections\", \"infectionâ€¦ #> $ .type                                         <chr> \"incidence\", \"rt\" #> $ mean_crps.0.025                               <dbl> 3.21782117, 0.04837831 #> $ mean_crps.0.25                                <dbl> 3.67838047, 0.05761117 #> $ mean_crps.0.5                                 <dbl> 3.94836855, 0.06306065 #> $ mean_crps.0.75                                <dbl> 4.25836841, 0.06896325 #> $ mean_crps.0.975                               <dbl> 4.85983296, 0.07941303 #> $ threshold_misclassification_probability.0.025 <dbl> NA, 0.003492902 #> $ threshold_misclassification_probability.0.25  <dbl> NA, 0.004801876 #> $ threshold_misclassification_probability.0.5   <dbl> NA, 0.005663844 #> $ threshold_misclassification_probability.0.75  <dbl> NA, 0.006601401 #> $ threshold_misclassification_probability.0.975 <dbl> NA, 0.008548549 #> $ mean_trans_bias.0.025                         <dbl> -0.03932336, -0.12444109 #> $ mean_trans_bias.0.25                          <dbl> -0.01635998, -0.09288908 #> $ mean_trans_bias.0.5                           <dbl> 0.0000477014, -0.0756842â€¦ #> $ mean_trans_bias.0.75                          <dbl> 0.02091896, -0.05999008 #> $ mean_trans_bias.0.975                         <dbl> 0.06618486, -0.03284903 #> $ mean_bias.0.025                               <dbl> 0.9687548, 0.9276912 #> $ mean_bias.0.25                                <dbl> 1.0067972, 0.9457355 #> $ mean_bias.0.5                                 <dbl> 1.2837259, 0.9558659 #> $ mean_bias.0.75                                <dbl> 1.5640856, 0.9651901 #> $ mean_bias.0.975                               <dbl> 1.9461215, 0.9814167 #> $ mean_quantile_bias.0.025                      <dbl> -0.21723959, -0.09106206 #> $ mean_quantile_bias.0.25                       <dbl> -0.14910455, -0.04287315 #> $ mean_quantile_bias.0.5                        <dbl> -0.11461270, -0.01784693 #> $ mean_quantile_bias.0.75                       <dbl> -0.082103994, 0.007517602 #> $ mean_quantile_bias.0.975                      <dbl> -0.01704358, 0.05698413 #> $ mean_prediction_interval_width_50.0.025       <dbl> 4.8570437, 0.1233357 #> $ mean_prediction_interval_width_50.0.25        <dbl> 5.3252001, 0.1340493 #> $ mean_prediction_interval_width_50.0.5         <dbl> 5.5936187, 0.1397408 #> $ mean_prediction_interval_width_50.0.75        <dbl> 5.8583160, 0.1454413 #> $ mean_prediction_interval_width_50.0.975       <dbl> 6.3619715, 0.1560621 #> $ pit_was.0.025                                 <dbl> 0.04169608, 0.03916000 #> $ pit_was.0.25                                  <dbl> 0.06170105, 0.05120671 #> $ pit_was.0.5                                   <dbl> 0.07598819, 0.05811761 #> $ pit_was.0.75                                  <dbl> 0.08981801, 0.06470482 #> $ pit_was.0.975                                 <dbl> 0.11638225, 0.07897469 #> $ unbiased_pit_was.0.025                        <dbl> 0.1323706, 0.1399726 #> $ unbiased_pit_was.0.25                         <dbl> 0.1681051, 0.1669565 #> $ unbiased_pit_was.0.5                          <dbl> 0.1837494, 0.1798616 #> $ unbiased_pit_was.0.75                         <dbl> 0.1992547, 0.1936935 #> $ unbiased_pit_was.0.975                        <dbl> 0.227905, 0.222787 #> $ directed_pit_was.0.025                        <dbl> -0.02227773, -0.06882064 #> $ directed_pit_was.0.25                         <dbl> -0.001731458, -0.0470520â€¦ #> $ directed_pit_was.0.5                          <dbl> 0.008796109, -0.034922490 #> $ directed_pit_was.0.75                         <dbl> 0.01837417, -0.02477326 #> $ directed_pit_was.0.975                        <dbl> 0.03782334, -0.00453361 #> $ percent_iqr_coverage.0.025                    <dbl> 0.3787267, 0.5900621 #> $ percent_iqr_coverage.0.25                     <dbl> 0.4285714, 0.6397516 #> $ percent_iqr_coverage.0.5                      <dbl> 0.4534161, 0.6645963 #> $ percent_iqr_coverage.0.75                     <dbl> 0.4782609, 0.6894410 #> $ percent_iqr_coverage.0.975                    <dbl> 0.5279503, 0.7329193 #> $ unbiased_percent_iqr_coverage.0.025           <dbl> 0.2360248, 0.2981366 #> $ unbiased_percent_iqr_coverage.0.25            <dbl> 0.2857143, 0.3478261 #> $ unbiased_percent_iqr_coverage.0.5             <dbl> 0.3105590, 0.3726708 #> $ unbiased_percent_iqr_coverage.0.75            <dbl> 0.3354037, 0.3975155 #> $ unbiased_percent_iqr_coverage.0.975           <dbl> 0.3788820, 0.4409938"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/set_defaults.html","id":null,"dir":"Reference","previous_headings":"","what":"Set or reset the default origin and unit for time periods â€” set_defaults","title":"Set or reset the default origin and unit for time periods â€” set_defaults","text":"function generally needed, called automatically first date conversion performed. information given default origin decided start first use time_period class session. helps keep defaults consistent single run, specified.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/set_defaults.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set or reset the default origin and unit for time periods â€” set_defaults","text":"","code":"set_defaults(start_date, unit)  with_defaults(start_date, unit, expr)  set_default_start(date)  set_default_unit(unit)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/set_defaults.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set or reset the default origin and unit for time periods â€” set_defaults","text":"start_date zero time date something can coerced date. x input already time_period different start_date x recalibrated use new start date. unit length one unit time. either integer number days, specification \"1 week\", another time_period. x time_period, unit different x return rescaled time_period using new units. expr expression evaluate defaults set provided values. date date, something can cast one, represents day zero outbreak.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/set_defaults.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set or reset the default origin and unit for time periods â€” set_defaults","text":"depending methods original default start date / original default unit, list result evaluating expression expr","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/set_defaults.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Set or reset the default origin and unit for time periods â€” set_defaults","text":"with_defaults(): Set defaults temporarily execute expression set_default_unit(): Set default unit ","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/set_defaults.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set or reset the default origin and unit for time periods â€” set_defaults","text":"","code":"# set default origin and cadence: old = set_defaults(\"2025-01-01\", \"1 week\")  # this sets the default for interpreting underqualified time_periods: print(as.time_period(1:10)) #> time unit: week, origin: 2025-01-01 (a Wednesday) #> 1 2 3 4 5 6 7 8 9 10  # The default can always be overridden on a case by case basis: print(as.time_period(1:10, unit=\"1 day\")) #> time unit: day, origin: 2025-01-01 (a Wednesday) #> 1 2 3 4 5 6 7 8 9 10  # or for a whole expression: with_defaults(\"2020-01-01\", \"1 day\", {   print(as.time_period(1:10)) }) #> time unit: day, origin: 2020-01-01 (a Wednesday) #> 1 2 3 4 5 6 7 8 9 10  # components can be changed individually, firstly origin: set_default_start(\"2025-01-01\") #> [1] \"2025-01-01\" print(as.time_period(1:10)) #> time unit: week, origin: 2025-01-01 (a Wednesday) #> 1 2 3 4 5 6 7 8 9 10  # now cadence: set_default_unit(\"1 day\") #> [1] \"7d 0H 0M 0S\" print(as.time_period(1:10)) #> time unit: day, origin: 2025-01-01 (a Wednesday) #> 1 2 3 4 5 6 7 8 9 10  # clear the values: set_defaults(NULL,NULL)  # A sufficiently qualified call will set the defaults: defined = as.time_period(as.Date(\"2024-01-01\")+0:10*7, anchor=\"start\") #> No `unit` specified. Inferring default from input: week (N.B. use `set_default_unit(...)` to change)  #> (N.B. this message will only be displayed once.) inherit = as.time_period(0:10)  all(defined == inherit) #> [1] TRUE  # restoring the original values (which might be null) set_defaults(old)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_apply_ascertainment.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply a ascertainment bias to the observed case counts. â€” sim_apply_ascertainment","title":"Apply a ascertainment bias to the observed case counts. â€” sim_apply_ascertainment","text":"Apply ascertainment bias observed case counts.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_apply_ascertainment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply a ascertainment bias to the observed case counts. â€” sim_apply_ascertainment","text":"","code":"sim_apply_ascertainment(df = i_sim_count_data, fn_asc = ~1, seed = Sys.time())"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_apply_ascertainment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply a ascertainment bias to the observed case counts. â€” sim_apply_ascertainment","text":"df count dataframe e.g. sim_poisson_model() sim_summarise_linelist() - dataframe columns: statistic (character) - identifier statistic, whether infections, admissions, deaths count (positive_integer) - Positive case counts associated specified time frame time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` Minimally grouped : statistic (groupings allowed). fn_asc function takes single input vector t returns probability ascertainment, e.g. ~ stats::rbeta(.x, 20, 80) ~ rbeta2(.x,prob=<probability>,kappa=<dispersion>). cfg_weekly_proportion_rng() seed RNG seed","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_apply_ascertainment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply a ascertainment bias to the observed case counts. â€” sim_apply_ascertainment","text":"dataframe original column, count column modified include ascertainment bias.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_apply_ascertainment.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply a ascertainment bias to the observed case counts. â€” sim_apply_ascertainment","text":"","code":"with_defaults(\"2025-01-01\" ,\"1 day\", {   dplyr::tibble(     statistic = \"incidence\",     time=as.time_period(1:10,\"1 day\"),     count=rep(100,10)   ) %>%   dplyr::group_by(statistic) %>%   sim_apply_ascertainment(~ ifelse(.x<=5,0.1,0.9)) })"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_apply_delay.count_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply delay distributions to count data â€” sim_apply_delay.count_data","title":"Apply delay distributions to count data â€” sim_apply_delay.count_data","text":"function uses convolution time delay functions (can function time, e.g. weekly periodicity) incident infections generate realistic looking outbreak metrics, including admission, death, symptom onset testing.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_apply_delay.count_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply delay distributions to count data â€” sim_apply_delay.count_data","text":"","code":"sim_apply_delay.count_data(   df,   ...,   fn_p_symptomatic = ~0.5,   fn_symptom_profile = cfg_gamma_ip_fn(~5),   fn_p_admitted = ~0.1,   fn_admission_profile = cfg_weekly_ip_fn(c(8, 8, 8, 8, 8, 9.5, 9)),   fn_p_died = ~0.05,   fn_death_profile = cfg_gamma_ip_fn(~14),   fn_p_tested = ~0.8,   fn_sample_profile = cfg_weekly_ip_fn(c(1, 1, 1, 1, 1, 1.5, 1.4)),   fn_result_profile = cfg_weekly_ip_fn(c(1, 1, 1, 1, 1, 1.6, 1.5)),   seed = Sys.time() )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_apply_delay.count_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply delay distributions to count data â€” sim_apply_delay.count_data","text":"df output sim_poisson_model() sim_summarise_linelist(), including count column time column ... Named arguments passed sim_apply_delay.linelist fn_symptom_delay,fn_admission_delay,fn_death_delay function calculates time event onset infection. called vector infection times first parameter (time) columns df also available well symptomatic,died,admitted flags. function must vectorised inputs (consume additional inputs ...). purrr style lambda OK e.g. ~ stats::rgamma(.x, shape = 3), first parameter infection time. discrete probability profile can use cfg_ip_sampler_rng(ip_symptoms). fn_sample_delay function returns time either symptom onset (symptomatic) infection (asymptomatic) sample taken. (N.B. might better screening test probability plus screening test frequency rather overloading .) fn_result_delay Identical functions except first parameter sample_time rather time infection. time sampling result available. Named arguments passed sim_apply_delay.count_data fn_symptom_profile,fn_admission_profile,fn_death_profile function takes time returns probability density symptoms, admissions, deaths time since infection (.e. tau) ip delay distribution. possible good idea pre-compute distributions need assigned every line input can slow. fn_sample_profile function takes time returns probability density test sample taken time since symptoms. fn_result_profile function takes time returns probability density test result available time since test sampling. fn_p_symptomatic, fn_p_admitted, fn_p_died, fn_p_tested Function returns probability 0 1 row input dataframe. purrr style lambda OK (e.g. ~ 1 always true) first parameter time infection. function must vectorised inputs (consume additional inputs ...) fn_symptom_profile, fn_admission_profile, fn_death_profile function takes time returns probability density symptoms, admissions, deaths time since infection (.e. tau) ip delay distribution. possible good idea pre-compute distributions need assigned every line input can slow. fn_sample_profile function takes time returns probability density test sample taken time since symptoms. fn_result_profile function takes time returns probability density test result available time since test sampling. seed RNG seed reproducibility","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_apply_delay.count_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply delay distributions to count data â€” sim_apply_delay.count_data","text":"long format set counts infections, symptom, admitted, death, sample (tests taken), results (test results).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_apply_delay.count_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply delay distributions to count data â€” sim_apply_delay.count_data","text":"","code":"tmp = sim_poisson_model(seed=100) %>% sim_apply_delay()  if(interactive()) {   plot_counts(tmp, mapping=ggplot2::aes(colour=statistic))+     ggplot2::geom_line() }"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_apply_delay.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply delay distribution to count or linelist data â€” sim_apply_delay","title":"Apply delay distribution to count or linelist data â€” sim_apply_delay","text":"Events include symptom onset, admission, death, test sampling, test processing","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_apply_delay.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply delay distribution to count or linelist data â€” sim_apply_delay","text":"","code":"sim_apply_delay(   df,   ...,   fn_p_symptomatic = ~0.5,   fn_p_admitted = ~0.1,   fn_p_died = ~0.05,   fn_p_tested = ~0.8,   seed = Sys.time() )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_apply_delay.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply delay distribution to count or linelist data â€” sim_apply_delay","text":"df line list dataframe arising e.g. sim_branching_process() - EITHER: dataframe columns: id (unique_id) - Patient level unique id time (ggoutbreak::time_period) - Time infection. `time_period` grouping allowed. columns: statistic (character) - identifier statistic, whether infections, admissions, deaths count (positive_integer) - Positive case counts associated specified time frame time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` Minimally grouped : statistic (groupings allowed). ... Named arguments passed sim_apply_delay.linelist fn_symptom_delay,fn_admission_delay,fn_death_delay function calculates time event onset infection. called vector infection times first parameter (time) columns df also available well symptomatic,died,admitted flags. function must vectorised inputs (consume additional inputs ...). purrr style lambda OK e.g. ~ stats::rgamma(.x, shape = 3), first parameter infection time. discrete probability profile can use cfg_ip_sampler_rng(ip_symptoms). fn_sample_delay function returns time either symptom onset (symptomatic) infection (asymptomatic) sample taken. (N.B. might better screening test probability plus screening test frequency rather overloading .) fn_result_delay Identical functions except first parameter sample_time rather time infection. time sampling result available. Named arguments passed sim_apply_delay.count_data fn_symptom_profile,fn_admission_profile,fn_death_profile function takes time returns probability density symptoms, admissions, deaths time since infection (.e. tau) ip delay distribution. possible good idea pre-compute distributions need assigned every line input can slow. fn_sample_profile function takes time returns probability density test sample taken time since symptoms. fn_result_profile function takes time returns probability density test result available time since test sampling. fn_p_symptomatic, fn_p_admitted, fn_p_died, fn_p_tested Function returns probability 0 1 row input dataframe. purrr style lambda OK (e.g. ~ 1 always true) first parameter time infection. function must vectorised inputs (consume additional inputs ...) seed RNG seed reproducibility","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_apply_delay.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply delay distribution to count or linelist data â€” sim_apply_delay","text":"Depends input, either: wide format line list additional XX, XX_time XX_delay columns, set statistics generated. long format set counts different statistics .e. infections, symptoms, admission, death, sample (tests taken), results (test results) .","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_apply_delay.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply delay distribution to count or linelist data â€” sim_apply_delay","text":"","code":"tmp = sim_branching_process(   changes = dplyr::tibble(t = c(0,20,40,60,80,110), R = c(1.8,1.5,0.9,1.5,0.8,1.2)),   max_time = 120,   seed = 100 ) #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> complete  tmp2 = tmp %>% sim_apply_delay() tmp2 %>% dplyr::glimpse() #> Rows: 35,205 #> Columns: 19 #> $ time                <t[day]> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,â€¦ #> $ id                  <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,â€¦ #> $ generation_interval <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NAâ€¦ #> $ infector            <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NAâ€¦ #> $ generation          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,â€¦ #> $ symptom             <lgl> FALSE, TRUE, FALSE, TRUE, TRUE, TRUE, TRUE, FALSE,â€¦ #> $ symptom_delay       <dbl> NA, 4.3770664, NA, 1.6301613, 2.2334772, 3.1298409â€¦ #> $ symptom_time        <t[day]> NA, 4.38, NA, 1.63, 2.23, 3.13, 11.1, NA, 10.47â€¦ #> $ admitted            <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, Fâ€¦ #> $ admitted_delay      <dbl> NA, NA, NA, NA, NA, NA, NA, NA, 7.436457, NA, NA, â€¦ #> $ admitted_time       <t[day]> NA, NA, NA, NA, NA, NA, NA, NA, 7.44, NA, NA, Nâ€¦ #> $ death               <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, Fâ€¦ #> $ death_delay         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NAâ€¦ #> $ death_time          <t[day]> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,â€¦ #> $ tested              <lgl> TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRâ€¦ #> $ sample_delay        <dbl> 2.25790754, 0.45958964, 0.58263980, 0.41155650, 0.â€¦ #> $ sample_time         <t[day]> 2.26, 0.46, 0.58, 0.41, 0.07, 0.01, 1.6, 1.36, â€¦ #> $ result_delay        <dbl> 2.25790754, 0.45958964, 0.58263980, 0.41155650, 0.â€¦ #> $ result_time         <t[day]> 4.52, 0.92, 1.17, 0.82, 0.14, 0.03, 3.2, 2.73, â€¦"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_apply_delay.linelist.html","id":null,"dir":"Reference","previous_headings":"","what":"Augment a line list of infection with a set of events â€” sim_apply_delay.linelist","title":"Augment a line list of infection with a set of events â€” sim_apply_delay.linelist","text":"Events include symptom onset, admission, death, test sampling, test processing","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_apply_delay.linelist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Augment a line list of infection with a set of events â€” sim_apply_delay.linelist","text":"","code":"sim_apply_delay.linelist(   df = i_sim_linelist,   ...,   fn_p_symptomatic = ~0.5,   fn_symptom_delay = ~rgamma2(.x, mean = 5),   fn_p_admitted = ~0.1,   fn_admission_delay = cfg_weekly_gamma_rng(c(8, 8, 8, 8, 8, 9.5, 9)),   fn_p_died = ~0.05,   fn_death_delay = ~rgamma2(.x, mean = 14),   fn_p_tested = ~0.8,   fn_sample_delay = cfg_weekly_gamma_rng(c(1, 1, 1, 1, 1, 1.5, 1.4)),   fn_result_delay = cfg_weekly_gamma_rng(c(1, 1, 1, 1, 1, 1.6, 1.5)),   seed = Sys.time() )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_apply_delay.linelist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Augment a line list of infection with a set of events â€” sim_apply_delay.linelist","text":"df line list dataframe arising e.g. sim_branching_process() - dataframe columns: id (unique_id) - Patient level unique id time (ggoutbreak::time_period) - Time infection. `time_period` grouping allowed. ... Named arguments passed sim_apply_delay.linelist fn_symptom_delay,fn_admission_delay,fn_death_delay function calculates time event onset infection. called vector infection times first parameter (time) columns df also available well symptomatic,died,admitted flags. function must vectorised inputs (consume additional inputs ...). purrr style lambda OK e.g. ~ stats::rgamma(.x, shape = 3), first parameter infection time. discrete probability profile can use cfg_ip_sampler_rng(ip_symptoms). fn_sample_delay function returns time either symptom onset (symptomatic) infection (asymptomatic) sample taken. (N.B. might better screening test probability plus screening test frequency rather overloading .) fn_result_delay Identical functions except first parameter sample_time rather time infection. time sampling result available. Named arguments passed sim_apply_delay.count_data fn_symptom_profile,fn_admission_profile,fn_death_profile function takes time returns probability density symptoms, admissions, deaths time since infection (.e. tau) ip delay distribution. possible good idea pre-compute distributions need assigned every line input can slow. fn_sample_profile function takes time returns probability density test sample taken time since symptoms. fn_result_profile function takes time returns probability density test result available time since test sampling. fn_p_symptomatic, fn_p_admitted, fn_p_died, fn_p_tested Function returns probability 0 1 row input dataframe. purrr style lambda OK (e.g. ~ 1 always true) first parameter time infection. function must vectorised inputs (consume additional inputs ...) fn_symptom_delay, fn_admission_delay, fn_death_delay, function calculates time event onset infection. called vector infection times first parameter (time) columns df also available well symptomatic,died,admitted flags. function must vectorised inputs (consume additional inputs ...). purrr style lambda OK e.g. ~ stats::rgamma(.x, shape = 3), first parameter infection time. discrete probability profile can use cfg_ip_sampler_rng(ip_symptoms). fn_sample_delay function returns time either symptom onset (symptomatic) infection (asymptomatic) sample taken. (N.B. might better screening test probability plus screening test frequency rather overloading .) fn_result_delay Identical functions except first parameter sample_time rather time infection. time sampling result available. seed RNG seed reproducibility","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_apply_delay.linelist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Augment a line list of infection with a set of events â€” sim_apply_delay.linelist","text":"line list additional time delay columns.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_apply_delay.linelist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Augment a line list of infection with a set of events â€” sim_apply_delay.linelist","text":"","code":"tmp = sim_branching_process(   changes = dplyr::tibble(t = c(0,20,40,60,80,110), R = c(1.8,1.5,0.9,1.5,0.8,1.2)),   max_time = 120,   seed = 100 ) #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> complete  tmp2 = tmp %>% sim_apply_delay() tmp2 %>% dplyr::glimpse() #> Rows: 35,205 #> Columns: 19 #> $ time                <t[day]> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,â€¦ #> $ id                  <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,â€¦ #> $ generation_interval <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NAâ€¦ #> $ infector            <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NAâ€¦ #> $ generation          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,â€¦ #> $ symptom             <lgl> FALSE, FALSE, FALSE, TRUE, FALSE, TRUE, TRUE, TRUEâ€¦ #> $ symptom_delay       <dbl> NA, NA, NA, 4.9253245, NA, 8.0370335, 4.4965400, 0â€¦ #> $ symptom_time        <t[day]> NA, NA, NA, 4.93, NA, 8.04, 4.5, 0.67, 5.1, NA,â€¦ #> $ admitted            <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, Fâ€¦ #> $ admitted_delay      <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 8.3546â€¦ #> $ admitted_time       <t[day]> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 8.3â€¦ #> $ death               <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, Fâ€¦ #> $ death_delay         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NAâ€¦ #> $ death_time          <t[day]> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,â€¦ #> $ tested              <lgl> FALSE, FALSE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, â€¦ #> $ sample_delay        <dbl> NA, NA, 0.6481758, 4.1093855, 2.5986856, 0.1081633â€¦ #> $ sample_time         <t[day]> NA, NA, 0.65, 4.11, 2.6, 0.11, 0.6, 3.21, 1.33,â€¦ #> $ result_delay        <dbl> NA, NA, 0.6481758, 4.1093855, 2.5986856, 0.1081633â€¦ #> $ result_time         <t[day]> NA, NA, 1.3, 8.22, 5.2, 0.22, 1.2, 6.42, 2.66, â€¦"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_branching_process.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a line list from a branching process model parametrised by reproduction number â€” sim_branching_process","title":"Generate a line list from a branching process model parametrised by reproduction number â€” sim_branching_process","text":"Generate line list branching process model parametrised reproduction number","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_branching_process.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a line list from a branching process model parametrised by reproduction number â€” sim_branching_process","text":"","code":"sim_branching_process(   changes = dplyr::tibble(t = c(0, 40), rt = c(2, 0.8)),   max_time = 80,   seed = Sys.time(),   fn_Rt = cfg_step_fn(changes),   fn_ip = ~example_ip(),   fn_kappa = ~1,   imports_df = NULL,   fn_imports = ~ifelse(.x == 0, 30, 0),   fn_list_next_gen = list(),   max_size = 10000,   ... )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_branching_process.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a line list from a branching process model parametrised by reproduction number â€” sim_branching_process","text":"changes dataframe containing t time column R reproduction number parameter. parameter optional fn_Rt specified max_time maximum duration simulation seed random seed fn_Rt can specified instead changes df. vectorised function accepts time parameter returns reproduction number. changes specified takes preference. fn_ip function takes input vector t (/class) returns infectivity profile times t. fn_kappa vectorised function taking t imported case metadata returning dispersion parameter controlling likelihood individual super-spreading. must 1 Inf 1 standard poisson dispersion larger values representing dispersion. imports_df data frame containing minimally time count columns plus metadata imports additional columns. Metadata columns can inform fn_Rt,fn_kappa fn_ip functions additional parameters. fn_imports time varying function defines number infected importations. imports_df defined used instead fn_list_next_gen named list functions. name corresponds metadata columns simulation, function purrr style mapping replace old value named column new one. function can generated cfg_transition_fn() transition probability matrix involved, can specified directly case_when style function. function must vectorised assume grouping structure. function named parameters can reference metadata columns, time (t). rcategorical() function may useful scenario. max_size maximum size single generation. generation exceeds limit branching process terminates warning simulation incomplete. ... used","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_branching_process.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a line list from a branching process model parametrised by reproduction number â€” sim_branching_process","text":"line list cases simulated outbreak dataframe containing following columns: id (unique_id) - Patient level unique id time (ggoutbreak::time_period) - Time infection. `time_period` grouping possible.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_branching_process.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a line list from a branching process model parametrised by reproduction number â€” sim_branching_process","text":"","code":"tmp = sim_branching_process(   changes = dplyr::tibble(t = c(0,40), R = c(1.5,0.8)),   max_time = 120,   seed = 100,   fn_imports = ~ ifelse(.x<10,1,0) ) #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> complete  if(interactive()) {   plot_cases(tmp, mapping=ggplot2::aes(fill=as.factor(generation)),linewidth=0.1, colour=\"white\") }  # imports can also be specified as a dataframe, which allows additional # metadata in the line list. An example of which is as follows: imports_df = dplyr::tribble(   ~time, ~variant, ~count,   0:4, \"wild-type\", 100,   10:14, \"alpha\", 5, )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_convolution.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply a time varying probability and convolution to count data â€” sim_convolution","title":"Apply a time varying probability and convolution to count data â€” sim_convolution","text":"Standard convolution assumes one delay distribution. actually see reality delays can depend factors, including day week. function applies convolution input time-series convolution expressed function (usually time, can anything input dataframe). convolution sampled using poisson negative binomial","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_convolution.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply a time varying probability and convolution to count data â€” sim_convolution","text":"","code":"sim_convolution(   df = i_sim_count_data,   p_fn,   delay_fn,   ...,   input = \"infections\",   output,   kappa = 1,   from = c(\"count\", \"rate\") )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_convolution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply a time varying probability and convolution to count data â€” sim_convolution","text":"df count dataframe e.g. sim_poisson_model() sim_summarise_linelist() - dataframe columns: statistic (character) - identifier statistic, whether infections, admissions, deaths count (positive_integer) - Positive case counts associated specified time frame time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` Minimally grouped : statistic (groupings allowed). p_fn function takes time parameter potentially returns probability observation given something occurs. -op parameter ~ 1. delay_fn function takes time returns probability observation (given occurred) time since infection (.e. tau) ip delay distribution. sum 1 (e.g. mapping incidence prevalence) combination p_fn delay_fn less easy interpret. behave sensibly p changes halfway convolution. See cfg_weekly_ip_fn() cfg_gamma_ip_fn() helper functions construct parameter. -op parameter ~ ifelse(.x==0,1,0). ... used input input statistic output output statistic kappa dispersion. scaled poisson dispersion 1. Values must 0 (dispersion), 1 (poisson dispersion) greater 1 -dispersion. Controls base future counts previous counts underlying rate, defaults count rate possibility want base convolution theoretical value rather observed cases. Either way convolution generates new rate turn sampled poisson negative binomial count.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_convolution.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply a time varying probability and convolution to count data â€” sim_convolution","text":"return result applying convolution data.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_convolution.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply a time varying probability and convolution to count data â€” sim_convolution","text":"","code":"weekday_delay = make_fixed_ip(mean = 5, sd = 2) weekend_delay = make_fixed_ip(mean = 6, sd = 2)  delay_fn = ~ ifelse(.x %% 7 %in% c(6,7), list(weekend_delay), list(weekday_delay)) p_fn = ~ ifelse(.x < 20, 0.5, 0.75)  data = dplyr::tibble(     time=1:40,     count = rep(100,40),     rate = rep(100,40),     statistic=\"infections\") %>% dplyr::group_by(statistic) delayed = data %>%     sim_convolution(p_fn,delay_fn,output=\"delayed\") %>%     dplyr::filter(statistic==\"delayed\") if (interactive()) ggplot2::ggplot(delayed,ggplot2::aes(x=time))+   ggplot2::geom_line(ggplot2::aes(y=rate))+   ggplot2::geom_line(ggplot2::aes(y=count))  # other example delay functions delay_fn = cfg_gamma_ip_fn( ~ ifelse(.x<5, 8, 4))"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_delay.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply a time-varying probability and delay function to linelist data â€” sim_delay","title":"Apply a time-varying probability and delay function to linelist data â€” sim_delay","text":"Apply time-varying probability delay function linelist data","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_delay.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply a time-varying probability and delay function to linelist data â€” sim_delay","text":"","code":"sim_delay(   df = i_sim_linelist,   p_fn,   delay_fn,   input = \"time\",   output = \"event\",   seed = Sys.time() )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_delay.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply a time-varying probability and delay function to linelist data â€” sim_delay","text":"df line list dataframe arising e.g. sim_branching_process() - dataframe columns: id (unique_id) - Patient level unique id time (ggoutbreak::time_period) - Time infection. `time_period` grouping allowed. p_fn Function returns probability 0 1 row input dataframe. purrr style lambda OK (e.g. ~ 1 always true) first parameter time infection. function must vectorised inputs (consume additional inputs ...) delay_fn function calculates time event onset input time. called vector infection times first parameter (time) columns df also available well symptomatic,died,admitted flags. function must vectorised inputs (consume additional inputs ...). purrr style lambda OK e.g. ~ stats::rgamma(.x, shape = 3), first parameter infection time. discrete probability profile can use cfg_ip_sampler_rng(ip_symptoms) without tilde. input time column calculate delay . output output column set name (defaults \"event\") seed RNG seed reproducibility","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_delay.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply a time-varying probability and delay function to linelist data â€” sim_delay","text":"line list extra columns prefix given output, specifying whether event observed, delay simulation time.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_delay.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply a time-varying probability and delay function to linelist data â€” sim_delay","text":"","code":"tmp = sim_branching_process(   changes = dplyr::tibble(t = c(0,20,40,60,80,110), R = c(1.8,1.5,0.9,1.5,0.8,1.2)),   max_time = 120,   seed = 100 ) #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> complete  tmp2 = tmp %>% sim_delay(   p_fn = ~ rbern(.x, 0.8),   delay_fn = ~ rgamma2(.x, mean = 5), ) tmp2 %>% dplyr::glimpse() #> Rows: 35,205 #> Columns: 8 #> $ time                <t[day]> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,â€¦ #> $ id                  <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,â€¦ #> $ generation_interval <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NAâ€¦ #> $ infector            <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NAâ€¦ #> $ generation          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,â€¦ #> $ event               <lgl> TRUE, TRUE, TRUE, FALSE, TRUE, TRUE, TRUE, FALSE, â€¦ #> $ event_delay         <dbl> 2.906903, 8.446592, 6.541336, NA, 8.186022, 2.4223â€¦ #> $ event_time          <t[day]> 2.91, 8.45, 6.54, NA, 8.19, 2.42, 4.4, NA, 2.41â€¦"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_delayed_observation.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply a right censoring to count data. â€” sim_delayed_observation","title":"Apply a right censoring to count data. â€” sim_delayed_observation","text":"Delayed observations means , example case attributed disease delay right censoring data. can complex patterns right censoring example observations batched published weekly. COVID UK death data published frequently retrospectively reported monthly intervals, depending patient died, lead complex time dependent biases death data. Given description delay, function simulate effect count data. another example delays reporting test results run Christmas resulted case rates apparently dropping schools broke . affected timing 2021 Christmas lockdown.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_delayed_observation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply a right censoring to count data. â€” sim_delayed_observation","text":"","code":"sim_delayed_observation(   df = i_sim_count_data,   delay_fn,   ...,   input = \"infections\",   output = input,   max_time = max(df$time) )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_delayed_observation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply a right censoring to count data. â€” sim_delayed_observation","text":"df count dataframe e.g. sim_poisson_model() sim_summarise_linelist() delay_fn function takes time returns probability observation (given occurred) time since infection (.e. tau) ip delay distribution. sum 1 (e.g. mapping incidence prevalence) behave fraction events observed (observed multiple times). See cfg_weekly_ip_fn() cfg_gamma_ip_fn() helper functions construct parameter. ... used input input statistic (defaults count) output output column name (defaults input) max_time date censoring taking place.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_delayed_observation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply a right censoring to count data. â€” sim_delayed_observation","text":"result applying right censoring data.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_delayed_observation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply a right censoring to count data. â€” sim_delayed_observation","text":"","code":"weekday_delay = make_fixed_ip(mean = 5, sd = 2) weekend_delay = make_fixed_ip(mean = 7, sd = 2)  delay_fn = ~ ifelse(.x %% 7 %in% c(6,7), list(weekend_delay), list(weekday_delay))  data = dplyr::tibble(time=1:40, count = rep(100,40), statistic=\"infections\") %>%   dplyr::group_by(statistic) %>%   sim_delayed_observation(delay_fn,output=\"delayed\")  if (interactive()) ggplot2::ggplot(data,ggplot2::aes(x=time,colour=statistic))+   ggplot2::geom_line(ggplot2::aes(y=count))"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_events.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract the events dataframe from a simulation output â€” sim_events","title":"Extract the events dataframe from a simulation output â€” sim_events","text":"simulations include details major changes simulation input parameters, particularly step functions. set events can directly represented ggoutbreak plot using events parameter","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_events.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract the events dataframe from a simulation output â€” sim_events","text":"","code":"sim_events(df)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_events.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract the events dataframe from a simulation output â€” sim_events","text":"df output ggoutbreak simulation","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_events.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract the events dataframe from a simulation output â€” sim_events","text":"events dataframe","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_events.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract the events dataframe from a simulation output â€” sim_events","text":"","code":"sim_events(example_poisson_rt()) #> # A tibble: 2 Ã— 4 #> # Groups:   statistic [1] #>   statistic  label   start      end   #>   <chr>      <chr>   <date>     <lgl> #> 1 infections Rt=2.50 2025-01-01 NA    #> 2 infections Rt=0.80 2025-02-10 NA"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_geom_function.html","id":null,"dir":"Reference","previous_headings":"","what":"The principal input function to a ggoutbreak simulation as a ggplot2 layer. â€” sim_geom_function","title":"The principal input function to a ggoutbreak simulation as a ggplot2 layer. â€” sim_geom_function","text":"simulations typically parameterised time varying $R_t$ growth rate, relationship embedded simulation outputs. Plotting value default ggoutbreak plots requires extracting function rescaling align dates, function .","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_geom_function.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The principal input function to a ggoutbreak simulation as a ggplot2 layer. â€” sim_geom_function","text":"","code":"sim_geom_function(df, ...)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_geom_function.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The principal input function to a ggoutbreak simulation as a ggplot2 layer. â€” sim_geom_function","text":"df output ggoutbreak simulation, typically going input estimator. ... Named arguments passed ggplot2::geom_function mapping Set aesthetic mappings created aes(). specified inherit.aes = TRUE (default), combined default mapping top level plot. must supply mapping plot mapping. data Ignored stat_function(), use. stat statistical transformation use data layer. using geom_*() function construct layer, stat argument can used override default coupling geoms stats. stat argument accepts following: Stat ggproto subclass, example StatCount. string naming stat. give stat string, strip function name stat_ prefix. example, use stat_count(), give stat \"count\". information ways specify stat, see layer stat documentation. position position adjustment use data layer. can used various ways, including prevent overplotting improving display. position argument accepts following: result calling position function, position_jitter(). method allows passing extra arguments position. string naming position adjustment. give position string, strip function name position_ prefix. example, use position_jitter(), give position \"jitter\". information ways specify position, see layer position documentation. ... arguments passed layer()'s params argument. arguments broadly fall one 4 categories . Notably, arguments position argument, aesthetics required can passed .... Unknown arguments part 4 categories ignored. Static aesthetics mapped scale, fixed value apply layer whole. example, colour = \"red\" linewidth = 3. geom's documentation Aesthetics section lists available options. 'required' aesthetics passed params. Please note passing unmapped aesthetics vectors technically possible, order required length guaranteed parallel input data. constructing layer using stat_*() function, ... argument can used pass parameters geom part layer. example stat_density(geom = \"area\", outline.type = \"\"). geom's documentation lists parameters can accept. Inversely, constructing layer using geom_*() function, ... argument can used pass parameters stat part layer. example geom_area(stat = \"density\", adjust = 0.5). stat's documentation lists parameters can accept. key_glyph argument layer() may also passed .... can one functions described key glyphs, change display layer legend. arrow Arrow specification, created grid::arrow(). arrow.fill fill colour use arrow head (closed). NULL means use colour aesthetic. lineend Line end style (round, butt, square). linejoin Line join style (round, mitre, bevel). linemitre Line mitre limit (number greater 1). na.rm FALSE, default, missing values removed warning. TRUE, missing values silently removed. show.legend logical. layer included legends? NA, default, includes aesthetics mapped. FALSE never includes, TRUE always includes. can also named logical vector finely select aesthetics display. include legend keys levels, even data exists, use TRUE.  NA, levels shown legend, unobserved levels omitted. inherit.aes FALSE, overrides default aesthetics, rather combining . useful helper functions define data aesthetics inherit behaviour default plot specification, e.g. annotation_borders(). geom geometric object use display data layer. using stat_*() function construct layer, geom argument can used override default coupling stats geoms. geom argument accepts following: Geom ggproto subclass, example GeomPoint. string naming geom. give geom string, strip function name geom_ prefix. example, use geom_point(), give geom \"point\". information ways specify geom, see layer geom documentation. fun Function use. Either 1) anonymous function base rlang formula syntax (see rlang::as_function()) 2) quoted character name referencing function; see examples. Must vectorised. xlim Optionally, specify range function. n Number points interpolate along x axis. args List additional arguments passed function defined fun.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_geom_function.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The principal input function to a ggoutbreak simulation as a ggplot2 layer. â€” sim_geom_function","text":"geom_function parameter","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_geom_function.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The principal input function to a ggoutbreak simulation as a ggplot2 layer. â€” sim_geom_function","text":"","code":"ggplot2::ggplot()+   sim_geom_function(example_poisson_rt(), xlim=as.Date(\"2019-12-29\")+c(0,80))+   ggplot2::scale_x_date()"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_multinomial.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a multinomial outbreak defined by per class growth rates and a poisson model â€” sim_multinomial","title":"Generate a multinomial outbreak defined by per class growth rates and a poisson model â€” sim_multinomial","text":"Generate multinomial outbreak defined per class growth rates poisson model","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_multinomial.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a multinomial outbreak defined by per class growth rates and a poisson model â€” sim_multinomial","text":"","code":"sim_multinomial(   changes = dplyr::tibble(t = c(0, 20, 40, 60, 80), variant1 = c(0.1, 0, -0.1, 0, 0.1),     variant2 = c(0.15, 0.05, -0.05, -0.01, 0.05), variant3 = c(0, 0.05, -0.05, +0.05,     -0.05), ),   initial = c(100, 100, 100),   time_unit = \"1 day\",   ... )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_multinomial.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a multinomial outbreak defined by per class growth rates and a poisson model â€” sim_multinomial","text":"changes list time points column t growth rates per week per class, columns. initial size initial outbreak per class. one entry per class time_unit e.g. daily weekly time series: \"1 day\", \"7 days\" ... Named arguments passed sim_poisson_model fn_imports function takes input vector t returns number imported cases times t. seed random seed kappa dispersion parameter. 1 dispersion (compared poisson), smaller values mean dispersion. max_time desired length time series, fn_growth function takes input vector t returns growth rates times t","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_multinomial.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a multinomial outbreak defined by per class growth rates and a poisson model â€” sim_multinomial","text":"case count time series including class, count time columns","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_multinomial.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a multinomial outbreak defined by per class growth rates and a poisson model â€” sim_multinomial","text":"","code":"if (interactive()) {   plot_counts(     sim_multinomial() %>% dplyr::glimpse()   ) }"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_poisson_Rt_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate an outbreak case count series defined by Reproduction number using a poisson model. â€” sim_poisson_Rt_model","title":"Generate an outbreak case count series defined by Reproduction number using a poisson model. â€” sim_poisson_Rt_model","text":"Generate outbreak case count series defined Reproduction number using poisson model.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_poisson_Rt_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate an outbreak case count series defined by Reproduction number using a poisson model. â€” sim_poisson_Rt_model","text":"","code":"sim_poisson_Rt_model(   changes = dplyr::tibble(t = c(0, 40), rt = c(2.5, 0.8)),   kappa = 1,   max_time = 80,   seed = Sys.time(),   fn_Rt = cfg_step_fn(changes),   fn_imports = ~ifelse(.x == 0, 30, 0),   fn_ip = ~example_ip(),   time_unit = \"1 day\" )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_poisson_Rt_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate an outbreak case count series defined by Reproduction number using a poisson model. â€” sim_poisson_Rt_model","text":"changes dataframe holding change time points (t) reproduction number (rt) columns kappa dispersion parameter. 1 dispersion (compared poisson), smaller values mean dispersion. max_time desired length time series, seed random seed fn_Rt function takes input vector t returns instantaneous reproduction number time t fn_imports function takes input vector t returns number imported cases times t. fn_ip function takes input vector t returns infectivity profile times t. time_unit e.g. daily weekly time series: \"1 day\", \"7 days\"","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_poisson_Rt_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate an outbreak case count series defined by Reproduction number using a poisson model. â€” sim_poisson_Rt_model","text":"dataframe case counts dataframe containing following columns: statistic (character) - identifier statistic, whether infections, admissions, deaths count (positive_integer) - Positive case counts associated specified time frame time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` Minimally grouped : statistic (groupings may present).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_poisson_Rt_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate an outbreak case count series defined by Reproduction number using a poisson model. â€” sim_poisson_Rt_model","text":"","code":"tmp = sim_poisson_Rt_model(kappa=1, seed=100, fn_imports = ~ ifelse(.x %in% c(0,50),100,0))  if (interactive()) {   ggplot2::ggplot(tmp,ggplot2::aes(x=time,y=count))+ggplot2::geom_point()+     ggplot2::geom_line() }"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_poisson_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate an outbreak case count series defined by growth rates using a poisson model. â€” sim_poisson_model","title":"Generate an outbreak case count series defined by growth rates using a poisson model. â€” sim_poisson_model","text":"Generate outbreak case count series defined growth rates using poisson model.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_poisson_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate an outbreak case count series defined by growth rates using a poisson model. â€” sim_poisson_model","text":"","code":"sim_poisson_model(   changes = dplyr::tibble(t = c(0, 20, 40, 60, 80), growth = c(0.1, 0, -0.1, 0, 0.1)),   kappa = 1,   max_time = 104,   seed = Sys.time(),   fn_growth = cfg_step_fn(changes),   fn_imports = ~ifelse(.x == 0, 100, 0),   time_unit = \"1 day\" )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_poisson_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate an outbreak case count series defined by growth rates using a poisson model. â€” sim_poisson_model","text":"changes dataframe holding change time points (t) growth rate per week (growth) columns kappa dispersion parameter. 1 dispersion (compared poisson), smaller values mean dispersion. max_time desired length time series, seed random seed fn_growth function takes input vector t returns growth rates times t fn_imports function takes input vector t returns number imported cases times t. time_unit e.g. daily weekly time series: \"1 day\", \"7 days\"","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_poisson_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate an outbreak case count series defined by growth rates using a poisson model. â€” sim_poisson_model","text":"dataframe case counts dataframe containing following columns: statistic (character) - identifier statistic, whether infections, admissions, deaths count (positive_integer) - Positive case counts associated specified time frame time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` Minimally grouped : statistic (groupings may present).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_poisson_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate an outbreak case count series defined by growth rates using a poisson model. â€” sim_poisson_model","text":"","code":"tmp2 = sim_poisson_model(seed=100, fn_imports = ~ ifelse(.x %in% c(0,50),100,0))  if (interactive()) {   ggplot2::ggplot(tmp2)+ggplot2::geom_point(ggplot2::aes(x=time,y=count)) }"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_seir_model.html","id":null,"dir":"Reference","previous_headings":"","what":"SEIR model with time-varying transmission parameter â€” sim_seir_model","title":"SEIR model with time-varying transmission parameter â€” sim_seir_model","text":"function simulates SEIR (Susceptible-Exposed-Infectious-Recovered) model transmission rate (beta) varies time.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_seir_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"SEIR model with time-varying transmission parameter â€” sim_seir_model","text":"","code":"sim_seir_model(   changes = dplyr::tibble(t = c(0, 30), dBeta = c(1, 0.5)),   mean_latent_period,   mean_gen_time,   R0 = 2.5,   fn_dBeta = cfg_step_fn(changes),   N = 10000,   imports = 10,   max_time = 104,   seed = Sys.time() )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_seir_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"SEIR model with time-varying transmission parameter â€” sim_seir_model","text":"changes dataframe holding change time points (t) proportional increase transmission rate dBeta column mean_latent_period Mean time infection becoming infectious (E ), assumed exponentially distributed. mean_gen_time average generation time (latent period+infectious duration). R0 initial reproduction number fn_dBeta function time t returns multiple transmission rate time point. Transmission (beta) time zero defined R0 infectious duration, multiplied time factor. N Total population size. Defaults 10,000. imports Initial number infectious individuals. Defaults 10. max_time Maximum simulation time (days time units). Defaults 100. seed random seed","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_seir_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"SEIR model with time-varying transmission parameter â€” sim_seir_model","text":"dataframe containing following columns: statistic (character) - identifier statistic, whether infections, admissions, deaths count (positive_integer) - Positive case counts associated specified time frame time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period Minimally grouped : statistic (groupings allowed).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_seir_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"SEIR model with time-varying transmission parameter â€” sim_seir_model","text":"latent period (time infection becoming infectious) assumed exponentially distributed. infectious period derived given mean generation time latent period. model assumes: Latent period ~ Exponential(sigma), sigma = 1 / mean_latent_period Infectious period ~ Exponential(gamma), gamma = 1 / (mean_gen_time - mean_latent_period) Generation time ~ Exponential(sigma) + Exponential(gamma) beta0 = R0 * gamma Transmission rate beta(t) = fn_dBeta(t) * beta0 generation time defined sum latent infectious periods.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_seir_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"SEIR model with time-varying transmission parameter â€” sim_seir_model","text":"","code":"# Example: Lockdown after day 30  seir_output <- sim_seir_model(   mean_latent_period = 4,   mean_gen_time = 7,   R0 = 2.5,   fn_dBeta = function(t) ifelse(t < 30, 1, 0.5) )  if (interactive()) {   plot_ip(attr(seir_output,\"ip\"))   plot_counts(seir_output) }"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_summarise_linelist.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarise a line list â€” sim_summarise_linelist","title":"Summarise a line list â€” sim_summarise_linelist","text":"function converts line list daily count incident cases, plus infections, admissions, deaths, test samples, test results present. Censoring counts can also defined. Whilst summarising various network measures forward looking case reproduction number also calculated.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_summarise_linelist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarise a line list â€” sim_summarise_linelist","text":"","code":"sim_summarise_linelist(   df = i_sim_linelist,   ...,   censoring = list(admitted = function(t) rgamma2(t, mean = 5), death = function(t)     rgamma2(t, mean = 10), sample = function(t, result_delay) result_delay),   max_time = max(df$time) )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_summarise_linelist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarise a line list â€” sim_summarise_linelist","text":"df line list dataframe arising e.g. sim_branching_process() - dataframe columns: id (unique_id) - Patient level unique id time (ggoutbreak::time_period) - Time infection. `time_period` grouping allowed. ... grouping include summarisation. censoring named list column names (without _time suffix) kind created sim_delay() sim_apply_delay(), associated function defining delay reporting column experiences. function t (.x purrr lambda) refer XX_time column, .e. whenever event reported happened time simulation infection time. N.B. since infection observed censor . max_time censoring time observation. vector multiple time series output","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_summarise_linelist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarise a line list â€” sim_summarise_linelist","text":"count data frame additional statistics. dataframe containing following columns: statistic (character) - identifier statistic, whether infections, admissions, deaths count (positive_integer) - Positive case counts associated specified time frame time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time `time_period` Minimally grouped : statistic (groupings may present).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_summarise_linelist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarise a line list â€” sim_summarise_linelist","text":"","code":"sim = sim_branching_process(   changes = dplyr::tibble(t = c(0,40), R = c(1.7,0.8)),   max_time = 120,   seed = 100,   fn_imports = ~ ifelse(.x==0,100,0) ) #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> . #> complete  tmp = sim %>% sim_summarise_linelist()  p1 = plot_counts(tmp)  p2 = ggplot2::ggplot(tmp, ggplot2::aes(x=as.Date(time)))+   ggplot2::geom_point(ggplot2::aes(y=rt.case,colour=\"case\"))+   ggplot2::geom_point(ggplot2::aes(y=rt.inst,colour=\"instantaneous\"))+   ggplot2::geom_line(ggplot2::aes(y=rt.weighted))+   ggplot2::coord_cartesian(ylim=c(0,3.5))+   ggplot2::xlab(NULL)  patchwork::wrap_plots(p1,p2,ncol=1,axes=\"collect\")"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_test_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a simple time-series of cases based on a growth rate step function â€” sim_test_data","title":"Generate a simple time-series of cases based on a growth rate step function â€” sim_test_data","text":"time-series statistical noise useful testing things. fixed known value infections growth rate (fixed 0.05 -0.05 per day), instantaneous reproduction number based provided infectivity profile.  fixed denominator gives known proportion relative growth rate growth rate.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_test_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a simple time-series of cases based on a growth rate step function â€” sim_test_data","text":"","code":"sim_test_data(ip = example_ip(), duration = 500, period = 50)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_test_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a simple time-series of cases based on a growth rate step function â€” sim_test_data","text":"ip infectivity profile. uncertainty collapsed central distribution. duration total length time-series period duration positive negative growth phase","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_test_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a simple time-series of cases based on a growth rate step function â€” sim_test_data","text":"time series count, incidence, growth, rt, proportion relative.growth columns","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/sim_test_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a simple time-series of cases based on a growth rate step function â€” sim_test_data","text":"","code":"sim_test_data() %>% dplyr::glimpse() #> Rows: 501 #> Columns: 8 #> $ time            <t[day]> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1â€¦ #> $ growth          <dbl> 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, â€¦ #> $ incidence       <dbl> 100.0000, 105.1271, 110.5171, 116.1834, 122.1403, 128.â€¦ #> $ rt              <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NAâ€¦ #> $ denom           <dbl> 12182, 12182, 12182, 12182, 12182, 12182, 12182, 12182â€¦ #> $ proportion      <dbl> 0.008208500, 0.008629359, 0.009071795, 0.009536916, 0.â€¦ #> $ relative.growth <dbl> 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, â€¦ #> $ count           <dbl> 100, 105, 111, 116, 122, 128, 135, 142, 149, 157, 165,â€¦"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/summarise_ip.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a single infectivity profile from multiple bootstraps â€” summarise_ip","title":"Generate a single infectivity profile from multiple bootstraps â€” summarise_ip","text":"Generate single infectivity profile multiple bootstraps","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/summarise_ip.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a single infectivity profile from multiple bootstraps â€” summarise_ip","text":"","code":"summarise_ip(ip = i_empirical_ip)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/summarise_ip.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a single infectivity profile from multiple bootstraps â€” summarise_ip","text":"ip infectivity profile summarise. a0 a1 columns optional tau given. - dataframe columns: boot (anything + default(1)) - bootstrap identifier probability (proportion) - probability new event period. a0 (double) - beginning time period (days) a1 (double) - end time period (days) Minimally grouped : boot (groupings allowed).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/summarise_ip.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a single infectivity profile from multiple bootstraps â€” summarise_ip","text":"infectivity profile","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/test_bpm.html","id":null,"dir":"Reference","previous_headings":"","what":"An example of the linelist output of the branching process model simulation â€” test_bpm","title":"An example of the linelist output of the branching process model simulation â€” test_bpm","text":"generated using example_ip() infectivity profile also includes delay symptom onset random gamma distributed quantity mean 6 standard deviation 2","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/test_bpm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"An example of the linelist output of the branching process model simulation â€” test_bpm","text":"","code":"data(test_bpm)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/test_bpm.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"An example of the linelist output of the branching process model simulation â€” test_bpm","text":"dataframe containing following columns: time (.time_period) - time column id (integer) - id per individual generation_interval (numeric) - generation_interval column infector (integer) - infector id generation (numeric) - generation column symptom_onset (logical) - flag onset symptoms symptom_onset_delay (numeric) - time onset symptoms infection symptom_onset_time (.time_period) - time symptom onset 333126 rows 8 columns","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/test_delayed_observation.html","id":null,"dir":"Reference","previous_headings":"","what":"The delayed observation dataset â€” test_delayed_observation","title":"The delayed observation dataset â€” test_delayed_observation","text":"simulates might observed outbreak average 5 day delay reporting hospital admissions. configuration outbreak ggoutbreak::test_bpm, summary data describes whole history admissions observed, observed given time point. triangular set data counts right censored observation time.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/test_delayed_observation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The delayed observation dataset â€” test_delayed_observation","text":"","code":"data(test_delayed_observation)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/test_delayed_observation.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"The delayed observation dataset â€” test_delayed_observation","text":"dataframe containing following columns: statistic (character) - statistic column (admissions) obs_time (.time_period) - time observation time-series time (.time_period) - time data point time-series count (integer) - count admissions Grouped : obs_time + statistic. 3321 rows 4 columns","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/test_ip.html","id":null,"dir":"Reference","previous_headings":"","what":"A test infectivity profile generated from a set of discretised gamma distributions with parameters mean 5 (95% CI 4-6) and sd 2 (95% CI 1.5-2.5). â€” example_ip()","title":"A test infectivity profile generated from a set of discretised gamma distributions with parameters mean 5 (95% CI 4-6) and sd 2 (95% CI 1.5-2.5). â€” example_ip()","text":"test infectivity profile generated set discretised gamma distributions parameters mean 5 (95% CI 4-6) sd 2 (95% CI 1.5-2.5).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/test_ip.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A test infectivity profile generated from a set of discretised gamma distributions with parameters mean 5 (95% CI 4-6) and sd 2 (95% CI 1.5-2.5). â€” example_ip()","text":"","code":"data(example_ip())"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/test_ip.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"A test infectivity profile generated from a set of discretised gamma distributions with parameters mean 5 (95% CI 4-6) and sd 2 (95% CI 1.5-2.5). â€” example_ip()","text":"dataframe containing following columns: boot (anything + default(1)) - bootstrap identifier probability (proportion) - probability infection previous time period time tau (numeric) - time index probability relates (days) a0 (numeric) - beginning time period a1 (numeric) - end time period Grouped : boot. 2000 rows 5 columns","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/test_poisson_growth_rate.html","id":null,"dir":"Reference","previous_headings":"","what":"A simulation dataset determined by a step function of growth rates. This is useful for demonstrating growth rate estimators. â€” test_poisson_growth_rate","title":"A simulation dataset determined by a step function of growth rates. This is useful for demonstrating growth rate estimators. â€” test_poisson_growth_rate","text":"simulation dataset determined step function growth rates. useful demonstrating growth rate estimators.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/test_poisson_growth_rate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A simulation dataset determined by a step function of growth rates. This is useful for demonstrating growth rate estimators. â€” test_poisson_growth_rate","text":"","code":"data(test_poisson_growth_rate)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/test_poisson_growth_rate.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"A simulation dataset determined by a step function of growth rates. This is useful for demonstrating growth rate estimators. â€” test_poisson_growth_rate","text":"dataframe containing following columns: time (.time_period) - time column growth (numeric) - time varying growth rate column (input parameter) imports (numeric) - imports column rate (numeric) - poisson rate column count (integer) - sampled count column statistic (character) - statistic column (infections) Minimally grouped : statistic (groupings allowed). 105 rows 6 columns","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/test_poisson_rt.html","id":null,"dir":"Reference","previous_headings":"","what":"An example of the linelist output of the poisson model simulation with defined $R_t$ â€” test_poisson_rt","title":"An example of the linelist output of the poisson model simulation with defined $R_t$ â€” test_poisson_rt","text":"generated using example_ip() infectivity profile","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/test_poisson_rt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"An example of the linelist output of the poisson model simulation with defined $R_t$ â€” test_poisson_rt","text":"","code":"test_poisson_rt()"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/test_poisson_rt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"An example of the linelist output of the poisson model simulation with defined $R_t$ â€” test_poisson_rt","text":"dataframe containing following columns: time (.time_period) - time column rt (numeric) - time varying rt column (parameters) imports (numeric) - imports column rate (numeric) - poisson rate column (underlying infection rate) count (integer) - count column statistic (character) - statistic column 81 rows 6 columns","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/test_poisson_rt_2class.html","id":null,"dir":"Reference","previous_headings":"","what":"The test_poisson_rt_2class dataset â€” test_poisson_rt_2class","title":"The test_poisson_rt_2class dataset â€” test_poisson_rt_2class","text":"test_poisson_rt_2class dataset","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/test_poisson_rt_2class.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The test_poisson_rt_2class dataset â€” test_poisson_rt_2class","text":"","code":"data(test_poisson_rt_2class)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/test_poisson_rt_2class.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"The test_poisson_rt_2class dataset â€” test_poisson_rt_2class","text":"dataframe containing following columns: time (.time_period) - time column rt (numeric) - rt column imports (numeric) - imports column rate (numeric) - rate column count (integer) - count column statistic (character) - statistic column class (enum(one,two)) - class column denom (integer) - denom column Minimally grouped : class (groupings allowed). 322 rows 8 columns","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/test_poisson_rt_smooth.html","id":null,"dir":"Reference","previous_headings":"","what":"Output of a poisson model simulation with a smooth function for $R_t$ defined as R(t) = e^(sin(t/80*pi)^4-0.25)). This is a relatively unchallenging test data set that should not pose a problem for smooth estimators. â€” test_poisson_rt_smooth","title":"Output of a poisson model simulation with a smooth function for $R_t$ defined as R(t) = e^(sin(t/80*pi)^4-0.25)). This is a relatively unchallenging test data set that should not pose a problem for smooth estimators. â€” test_poisson_rt_smooth","text":"generated using central value example_ip() infectivity profile","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/test_poisson_rt_smooth.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Output of a poisson model simulation with a smooth function for $R_t$ defined as R(t) = e^(sin(t/80*pi)^4-0.25)). This is a relatively unchallenging test data set that should not pose a problem for smooth estimators. â€” test_poisson_rt_smooth","text":"","code":"data(test_poisson_rt_smooth)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/test_poisson_rt_smooth.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Output of a poisson model simulation with a smooth function for $R_t$ defined as R(t) = e^(sin(t/80*pi)^4-0.25)). This is a relatively unchallenging test data set that should not pose a problem for smooth estimators. â€” test_poisson_rt_smooth","text":"dataframe containing following columns: time (.time_period) - time column rt (numeric) - time varying rt column (parameters) imports (numeric) - imports column rate (numeric) - poisson rate column (underlying infection rate) count (integer) - count column statistic (character) - statistic column Minimally grouped : statistic (groupings allowed). 161 rows 6 columns","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/test_serial.html","id":null,"dir":"Reference","previous_headings":"","what":"A serial interval estimated from simulated data â€” test_serial","title":"A serial interval estimated from simulated data â€” test_serial","text":"serial interval resampled first 1000 patients test_bpm dataset infector infectee symptoms. patients generated symptom delay mean 6 days SD 2 infection (discrete -dispersed gamma) infectivity profile mean 5 days SD 2 defined example_ip() dataset. serial interval relevant estimation $R_t$ symptomatic case counts test_bpm dataset includes negative times, used EpiEstim.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/test_serial.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A serial interval estimated from simulated data â€” test_serial","text":"","code":"data(test_serial)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/test_serial.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"A serial interval estimated from simulated data â€” test_serial","text":"dataframe containing following columns: tau (numeric) - time delay symptoms infector infectee a0 (numeric) - a0 column a1 (numeric) - a1 column probability (numeric) - probability column boot (integer) - boot column Minimally grouped : boot (groupings allowed). 2166 rows 5 columns","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/test_ts.html","id":null,"dir":"Reference","previous_headings":"","what":"A test time series dataset, containing no statistical noise. â€” test_ts","title":"A test time series dataset, containing no statistical noise. â€” test_ts","text":"test time series dataset, containing statistical noise.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/test_ts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A test time series dataset, containing no statistical noise. â€” test_ts","text":"","code":"data(test_ts)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/test_ts.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"A test time series dataset, containing no statistical noise. â€” test_ts","text":"dataframe containing following columns: time (.time_period) - time column growth (numeric) - growth column incidence (numeric) - incidence column rt (numeric) - rt column denom (numeric) - denom column proportion (numeric) - proportion column relative.growth (numeric) - relative.growth column count (numeric) - count column grouping allowed. 501 rows 8 columns","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/time_aggregate.html","id":null,"dir":"Reference","previous_headings":"","what":"Aggregate time series data preserving the time series â€” time_aggregate","title":"Aggregate time series data preserving the time series â€” time_aggregate","text":"function operates timeseries data linelists (see time_summarise()) line lists. granular timeseries regrouped function applied resulting dataframe ","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/time_aggregate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Aggregate time series data preserving the time series â€” time_aggregate","text":"","code":"time_aggregate(   df = i_timestamped,   ...,   .groups = NULL,   .cols = NULL,   .fns = NULL )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/time_aggregate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Aggregate time series data preserving the time series â€” time_aggregate","text":"df optionally grouped time series. Grouping include time column. grouping works differently dplyr::summarise last level non-time groups lost operation, subgroup wish aggregate included grouping. ... set dplyr::summarise statements, additional parameters .fns .groups per dplyr::summarise .cols Optional dplyr column specification data summarised. useful lots columns want summarise using function (e.g. sum usually). .cols passed dplyr::across call. .fns given .cols parameter specified columns summarise automatically identified. Date columns dropped. want .cols ... must given .fns Optional set function specifications per dplyr::across","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/time_aggregate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Aggregate time series data preserving the time series â€” time_aggregate","text":"summarised time series preserving time column, grouping structure involving one fewer levels input","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/time_aggregate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Aggregate time series data preserving the time series â€” time_aggregate","text":"","code":"example_england_covid_by_age() %>%   time_aggregate(count = sum(count), denom = sum(denom)) %>%   dplyr::glimpse() #> Rows: 1,410 #> Columns: 3 #> $ time  <t[day]> 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 4â€¦ #> $ count <dbl> 2, 2, 13, 3, 19, 0, 1, 0, 0, 5, 1, 1, 4, 2, 1, 1, 1, 1, 2, 0, 0,â€¦ #> $ denom <dbl> 38, 38, 247, 57, 361, 0, 19, 0, 0, 95, 19, 19, 76, 38, 19, 19, 1â€¦  example_england_covid_by_age() %>%   time_aggregate(.fns=mean, .cols=dplyr::where(is.numeric)) %>%   dplyr::glimpse() #> Rows: 1,410 #> Columns: 4 #> $ time       <t[day]> 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, â€¦ #> $ count      <dbl> 0.10526316, 0.10526316, 0.68421053, 0.15789474, 1.00000000,â€¦ #> $ denom      <dbl> 2, 2, 13, 3, 19, 0, 1, 0, 0, 5, 1, 1, 4, 2, 1, 1, 1, 1, 2, â€¦ #> $ population <dbl> 2962472, 2962472, 2962472, 2962472, 2962472, 2962472, 29624â€¦"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/time_summarise.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarise data from a line list to a time-series of counts. â€” time_summarise","title":"Summarise data from a line list to a time-series of counts. â€” time_summarise","text":"principally designed take record single events produce summary time-series count events group, class date. default behaviour guess cadence input data summarise event line list (set ) regular time-series counts use incidence growth rate estimates.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/time_summarise.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarise data from a line list to a time-series of counts. â€” time_summarise","text":"","code":"time_summarise(   df = i_dated,   unit,   anchor = \"start\",   rectangular = FALSE,   ...,   .fill = list(count = 0) )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/time_summarise.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarise data from a line list to a time-series of counts. â€” time_summarise","text":"df line list data want summarise, optionally grouped. grouped group treated independently. remaining columns must contain date column may contain class column. count column present counts summed, otherwise individual row counted single event (line list) unit period e.g. \"1 week\" anchor one date, \"start\" \"end\" weekday name e.g. \"mon\" always one start time periods cutting rectangular resulting time series length groups? case can sure data complete subgroups, otherwise missing data treated zero counts. important leading trailing missing data one subgroup can due reporting delay subgroup, case rectangular time series erroneously fill zero counts missing data. ... specification dplyr::summary(...) - optional, provided count = dplyr::n() count = sum(count) performed. .fill list similar tidyr::complete default values fill variables .","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/time_summarise.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarise data from a line list to a time-series of counts. â€” time_summarise","text":"output depends whether input grouped class column. detailed output : dataframe containing following columns: denom (positive_integer) - Total test counts associated specified time frame count (positive_integer) - Positive case counts associated specified time frame time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period grouping allowed. minimal output input plain list dated events: dataframe containing following columns: count (positive_integer) - Positive case counts associated specified time frame time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period grouping allowed.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/time_summarise.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summarise data from a line list to a time-series of counts. â€” time_summarise","text":"data given class column time series interpreted denominator, consisting different classes within time period. may subtypes (e.g. variants, serotypes) markers test positivity. either case resulting time series counts classes denominators combination. flexibility kinds summarisation raw data count based (e.g. means continuous variables) case slider package usually going better, time summarise look non overlapping time periods fixed lengths. another use case existing timeseries particular frequency aggregated another less frequent basis (e.g. moving daily timeseries weekly one). case input contain count column. mode checks made frequent events present summarisation result may include different numbers input periods (e.g. going weeks months may 4 5 weeks month). class column present classwise denominator calculated","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/time_summarise.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarise data from a line list to a time-series of counts. â€” time_summarise","text":"","code":"# a set of random dates with a class column: input = dplyr::tibble(   class = rep(c(\"A\",\"B\"),1000),   date = as.Date(\"2020-01-01\")+sample.int(100,2000,TRUE) )  # summarise daily counts, including denominators: daily = time_summarise(input, unit=\"1 day\") %>% dplyr::glimpse() #> Rows: 200 #> Columns: 4 #> Groups: class [2] #> $ class <chr> \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\",â€¦ #> $ time  <t[day]> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,â€¦ #> $ count <int> 8, 15, 7, 11, 11, 3, 11, 10, 7, 15, 9, 14, 8, 17, 5, 13, 6, 8, 5â€¦ #> $ denom <int> 15, 25, 16, 17, 18, 9, 16, 17, 17, 30, 20, 24, 17, 25, 16, 25, 1â€¦  # summarise weekly counts, for sample data: time_summarise(input, unit=\"1 week\") %>% dplyr::glimpse() #> Rows: 30 #> Columns: 4 #> Groups: class [2] #> $ class <chr> \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\",â€¦ #> $ time  <t[week]> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 0, 1, 2, 3â€¦ #> $ count <int> 66, 80, 57, 73, 85, 65, 65, 72, 63, 73, 66, 77, 74, 70, 14, 50, â€¦ #> $ denom <int> 116, 150, 129, 132, 164, 129, 135, 157, 137, 149, 145, 159, 145,â€¦  # summarise daily counts into weekly: time_summarise(daily, unit=\"1 week\") %>% dplyr::glimpse() #> N.B. time_summarise ignores existing time_period columns  #> (N.B. this message will only be displayed once.) #> Rows: 30 #> Columns: 4 #> Groups: class [2] #> $ class <chr> \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\",â€¦ #> $ time  <t[week]> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 0, 1, 2, 3â€¦ #> $ count <int> 66, 80, 57, 73, 85, 65, 65, 72, 63, 73, 66, 77, 74, 70, 14, 50, â€¦ #> $ denom <int> 116, 150, 129, 132, 164, 129, 135, 157, 137, 149, 145, 159, 145,â€¦"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/timeseries.html","id":null,"dir":"Reference","previous_headings":"","what":"Coerce an object to a ggoutbreak compatible time series dataframe â€” timeseries","title":"Coerce an object to a ggoutbreak compatible time series dataframe â€” timeseries","text":"Coerce object ggoutbreak compatible time series dataframe","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/timeseries.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coerce an object to a ggoutbreak compatible time series dataframe â€” timeseries","text":"","code":"timeseries(x, ...)  # Default S3 method timeseries(x, ...)  # S3 method for class 'incidence2' timeseries(x, ...)  # S3 method for class 'data.frame' timeseries(   x,   ...,   date = NULL,   count = NULL,   denom = NULL,   population = NULL,   class = NULL,   declutter = FALSE )  # S3 method for class 'incidence' timeseries(x, ..., declutter = FALSE)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/timeseries.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coerce an object to a ggoutbreak compatible time series dataframe â€” timeseries","text":"x object coerce e.g. data frame ... Named arguments passed .time_period unit length one unit time. either integer number days, specification \"1 week\", another time_period. x time_period, unit different x return rescaled time_period using new units. start_date zero time date something can coerced date. x input already time_period different start_date x recalibrated use new start date. anchor relevant x vector dates, date, \"start\" \"end\" weekday name e.g. \"mon\". vector dates x use anchor find reference date time-series. provided current defaults used. (see set_defaults()) date R expression defining date column (Date - optional) count R expression defining count column (int - optional) denom R expression defining denominator column (int - optional) population R expression defining population column (numeric - optional) class R expression defining class column (factor - optional) declutter logical flag. TRUE unnecessary original columns dropped","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/timeseries.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coerce an object to a ggoutbreak compatible time series dataframe â€” timeseries","text":"minimally case count dataframe dataframe containing following columns: count (positive_integer) - Positive case counts associated specified time frame time (ggoutbreak::time_period + group_unique) - (usually complete) set singular observations per unit time time_period grouping allowed.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/timeseries.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coerce an object to a ggoutbreak compatible time series dataframe â€” timeseries","text":"","code":"utils::data(\"mers_2014_15\", package=\"EpiEstim\")  set_default_unit(\"1 day\") #> [1] \"7d 0H 0M 0S\"  # Use an expression to generate a case count: # N.B. complex column names need to be surrounded with bcakticks like this:  tmp = mers_2014_15$incidence %>%   timeseries(     date = `mers$dates`,     count = local+imported   ) %>%   dplyr::glimpse() #> Rows: 495 #> Columns: 5 #> $ time         <t[day]> -3796, -3795, -3794, -3793, -3792, -3791, -3790, -3789â€¦ #> $ `mers$dates` <date> 2014-08-11, 2014-08-12, 2014-08-13, 2014-08-14, 2014-08-â€¦ #> $ local        <dbl> 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, â€¦ #> $ imported     <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, â€¦ #> $ count        <dbl> 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, â€¦  if (interactive()) {   ip = make_fixed_ip(mean = mers_2014_15$si$mean_si, sd = mers_2014_15$si$std_si)   tmp %>% poisson_locfit_model(ip=ip,window=14) %>% plot_rt() }   # remove columns not needed by `ggoutbreak` outbreaks::dengue_fais_2011 %>%   timeseries(date = onset_date, count = value, declutter = TRUE) %>%   dplyr::glimpse() #> Rows: 57 #> Columns: 2 #> $ time  <t[day]> -4857, -4850, -4843, -4836, -4829, -4822, -4815, -4808, -4801â€¦ #> $ count <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0â€¦   # date column already exists,  could use `onset` or `death` as count outbreaks::ebola_kikwit_1995 %>%   timeseries(count = onset) %>%   dplyr::glimpse() #> Rows: 192 #> Columns: 6 #> $ time      <t[day]> -1.095e+04, -1.095e+04, -1.095e+04, -1.095e+04, -1.095e+0â€¦ #> $ date      <date> 1995-01-06, 1995-01-07, 1995-01-08, 1995-01-09, 1995-01-10,â€¦ #> $ onset     <int> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, â€¦ #> $ death     <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, â€¦ #> $ reporting <lgl> TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSEâ€¦ #> $ count     <int> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, â€¦  # This data set needs grouping to make it a unique timeseries: ukc19::ltla_cases %>%   timeseries(anchor=\"start\", unit=\"1 day\") %>%   dplyr::glimpse() #> inferring extra groups to make `time` unique: code, name #> Rows: 512,050 #> Columns: 7 #> Groups: code, name [381] #> $ time       <t[day]> 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, â€¦ #> $ code       <chr> \"S12000033\", \"S12000033\", \"S12000033\", \"S12000033\", \"S12000â€¦ #> $ date       <date> 2020-03-04, 2020-03-05, 2020-03-06, 2020-03-07, 2020-03-08â€¦ #> $ name       <chr> \"Aberdeen City\", \"Aberdeen City\", \"Aberdeen City\", \"Aberdeeâ€¦ #> $ codeType   <chr> \"LAD19\", \"LAD19\", \"LAD19\", \"LAD19\", \"LAD19\", \"LAD19\", \"LAD1â€¦ #> $ count      <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 2, 1, 0, 1, 0, 0, 3,â€¦ #> $ population <dbl> 228670, 228670, 228670, 228670, 228670, 228670, 228670, 228â€¦  # from an incidence object: if (requireNamespace(\"incidence\",quietly = TRUE)) {    onset = outbreaks::ebola_sim$linelist$date_of_onset   sex = outbreaks::ebola_sim$linelist$gender   inc.week.gender = incidence::incidence(onset, interval = 7, groups = sex, standard = FALSE)    inc.week.gender %>% timeseries() %>% dplyr::glimpse()    d = Sys.Date() + sample(-3:10, 10, replace = TRUE)   di = incidence::incidence(d, interval = \"week\", first_date = Sys.Date() - 10, standard = TRUE)   di %>% timeseries(declutter=TRUE) %>% dplyr::glimpse() } #> Rows: 112 #> Columns: 4 #> Groups: class [2] #> $ dates <date> 2014-04-07, 2014-04-07, 2014-04-14, 2014-04-14, 2014-04-21, 201â€¦ #> $ class <fct> f, m, f, m, f, m, f, m, f, m, f, m, f, m, f, m, f, m, f, m, f, mâ€¦ #> $ count <int> 1, 0, 0, 1, 4, 1, 4, 0, 9, 3, 8, 10, 8, 7, 9, 11, 13, 10, 7, 15,â€¦ #> $ time  <t[week]> -560.3, -560.3, -559.3, -559.3, -558.3, -558.3, -557.3, -557â€¦ #> Rows: 3 #> Columns: 2 #> $ time  <t[week]> 47.71, 48.71, 49.71 #> $ count <int> 0, 6, 4  if (requireNamespace(\"incidence2\",quietly = TRUE)) {   dat = outbreaks::ebola_sim_clean$linelist   x = incidence2::incidence(dat, \"date_of_onset\", groups = c(\"gender\", \"hospital\"), interval=\"week\")   x %>% timeseries() %>% dplyr::glimpse() } #> Rows: 601 #> Columns: 5 #> Groups: statistic, gender, hospital [12] #> $ gender    <fct> f, m, f, f, m, f, f, f, f, f, f, f, f, m, m, m, f, f, f, f, â€¦ #> $ hospital  <fct> Military Hospital, Connaught Hospital, NA, other, other, NA,â€¦ #> $ time      <t[week]> 2310, 2311, 2312, 2312, 2312, 2313, 2313, 2313, 2313, 23â€¦ #> $ statistic <fct> date_of_onset, date_of_onset, date_of_onset, date_of_onset, â€¦ #> $ count     <int> 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 5, 1, 1, 1, 1, 3, 1, 2, 1, â€¦"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/type.time_period.html","id":null,"dir":"Reference","previous_headings":"","what":"Type coercion to a time_period class â€” type.time_period","title":"Type coercion to a time_period class â€” type.time_period","text":"Type coercion time_period class","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/type.time_period.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Type coercion to a time_period class â€” type.time_period","text":"","code":"type.time_period(x)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/type.time_period.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Type coercion to a time_period class â€” type.time_period","text":"x vector coerced time period","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/type.time_period.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Type coercion to a time_period class â€” type.time_period","text":"time_period error","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/type.time_period.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Type coercion to a time_period class â€” type.time_period","text":"","code":"type.time_period(1:100) #> time unit: day, origin: 2025-01-01 (a Wednesday) #> 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/vcov_from_residuals.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Parametric VCOV Matrix from Residuals â€” vcov_from_residuals","title":"Estimate Parametric VCOV Matrix from Residuals â€” vcov_from_residuals","text":"Estimates variance-covariance matrix log-incidence estimates modelling residual autocorrelation exponential decay model.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/vcov_from_residuals.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Parametric VCOV Matrix from Residuals â€” vcov_from_residuals","text":"","code":"vcov_from_residuals(   data,   mu,   sigma,   max_lag = 10,   min_alpha = 0.01,   max_alpha = 2 )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/vcov_from_residuals.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Parametric VCOV Matrix from Residuals â€” vcov_from_residuals","text":"data Numeric vector: observed case counts I_t mu Numeric vector: estimated log-incidence (log lambda_t) sigma Numeric vector: estimated standard error log lambda_t max_lag Integer: maximum lag ACF estimation (default: 10) min_alpha Positive number: minimum decay rate (default: 0.01) max_alpha Positive number: maximum decay rate (default: 2.0)","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/vcov_from_residuals.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Parametric VCOV Matrix from Residuals â€” vcov_from_residuals","text":"List : vcov_matrix: T x T estimated VCOV matrix log lambda_t alpha: fitted decay parameter acf_obs: observed ACF Pearson residuals acf_fit: fitted ACF values residuals: Pearson residuals used times: time indices","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/vcov_from_residuals.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate Parametric VCOV Matrix from Residuals â€” vcov_from_residuals","text":"function generated Qwen3-235B-A22B-2507","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/vcov_from_residuals.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate Parametric VCOV Matrix from Residuals â€” vcov_from_residuals","text":"","code":"T <- 50 mu <- 5 + 0.05 * (1:T) + stats::arima.sim(list(ar = 0.8), n = T, sd = 0.3) sigma <- rep(0.2, T) lambda <- exp(mu) data <- stats::rpois(T, lambda)  result <- vcov_from_residuals(data, mu, sigma, max_lag = 8) dim(result$vcov_matrix)  # Should be T x T #> [1] 50 50"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/wallinga_lipsitch.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the reproduction number from a growth rate estimate and an infectivity profile â€” wallinga_lipsitch","title":"Calculate the reproduction number from a growth rate estimate and an infectivity profile â€” wallinga_lipsitch","text":"function uses single empirical distribution infectivity profile / generation time. multiple provided average central value chosen (.e. propagate uncertainty infectivity profile)","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/wallinga_lipsitch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the reproduction number from a growth rate estimate and an infectivity profile â€” wallinga_lipsitch","text":"","code":"wallinga_lipsitch(   r,   y = i_empirical_ip,   a1 = seq(0.5, length.out = length(y)),   a0 = dplyr::lag(a1, default = 0) )"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/wallinga_lipsitch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the reproduction number from a growth rate estimate and an infectivity profile â€” wallinga_lipsitch","text":"r growth rate (may vector) y empirical infectivity profile either probability vector dataframe format: dataframe containing following columns: boot (anything + default(1)) - bootstrap identifier probability (proportion) - probability new event period. a0 (double) - beginning time period (days) a1 (double) - end time period (days) Minimally grouped : boot (groupings allowed). a1 end time infectivity profile probability estimate (defaults 0.5,1.5,2.5,...). a0 start time infectivity profile probability estimate (defaults 0,0.5,1.5,...).","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/wallinga_lipsitch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the reproduction number from a growth rate estimate and an infectivity profile â€” wallinga_lipsitch","text":"reproduction number estimate based r","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/wallinga_lipsitch.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the reproduction number from a growth rate estimate and an infectivity profile â€” wallinga_lipsitch","text":"","code":"# using a probability vector. wallinga_lipsitch(r=seq(-0.1,0.1,length.out=9), y=stats::dgamma(1:50, 5,2)) #> [1] 0.8524904 0.8882735 0.9247920 0.9620371 1.0000000 1.0386712 1.0780412 #> [8] 1.1181002 1.1588382  # using an infectivity profile wallinga_lipsitch(r=seq(-0.1,0.1,length.out=9), y=example_ip()) #> [1] 0.5949656 0.6805519 0.7759966 0.8821707 1.0000000 1.1304667 1.2746113 #> [8] 1.4335343 1.6083980"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/wedge.html","id":null,"dir":"Reference","previous_headings":"","what":"Wedge distribution â€” wedge","title":"Wedge distribution â€” wedge","text":"wedge distribution support 0 1 linear probability density function support.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/wedge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wedge distribution â€” wedge","text":"n number observations x vector quantiles q vector quantiles p vector probabilities log logical; TRUE, probabilities p given log(p). log.p logical; TRUE, probabilities p given log(p). lower.tail logical; TRUE (default), probabilities P[X<=x] otherwise P[X>x]. gradient -2 (left skewed) 2 (right skewed)","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/wedge.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Wedge distribution â€” wedge","text":"vector probabilities, quantiles, densities samples.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/wedge.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Wedge distribution â€” wedge","text":"rwedge can combined quantile functions skew standard distributions, introduce correlation weight certain parts distribution.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/wedge.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Wedge distribution â€” wedge","text":"","code":"pwedge(seq(0,1,0.1), a=1) #>  [1] 0.5 0.6 0.7 0.8 0.9 1.0 1.1 1.2 1.3 1.4 1.5 dwedge(seq(0,1,0.1), a=1) #>  [1] 0.000 0.055 0.120 0.195 0.280 0.375 0.480 0.595 0.720 0.855 1.000 qwedge(c(0.25,0.5,0.75), a=-1) #> [1] 0.1771243 0.3819660 0.6339746  stats::cor(   stats::qnorm(rwedge(1000, a=2)),   stats::qnorm(rwedge(1000, a=-2)) ) #> [1] 0.06870263"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/weekdays.time_period.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Parts of a POSIXt or Date Object â€” weekdays.time_period","title":"Extract Parts of a POSIXt or Date Object â€” weekdays.time_period","text":"Extract weekday, month quarter, Julian time   (days since origin).  generic functions: methods   internal date-time classes documented .","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/weekdays.time_period.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Parts of a POSIXt or Date Object â€” weekdays.time_period","text":"","code":"# S3 method for class 'time_period' weekdays(x, abbreviate = FALSE)"},{"path":"https://ai4ci.github.io/ggoutbreak/reference/weekdays.time_period.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Parts of a POSIXt or Date Object â€” weekdays.time_period","text":"x object inheriting class \"POSIXt\" \"Date\". abbreviate logical vector (possibly recycled).  names     abbreviated?","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/weekdays.time_period.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Parts of a POSIXt or Date Object â€” weekdays.time_period","text":"weekdays months return character   vector names locale use, .e., Sys.getlocale(\"LC_TIME\"). quarters returns character vector \"Q1\"   \"Q4\". julian returns number days (possibly fractional)   since origin, origin \"origin\" attribute.   time calculations R done ignoring leap-seconds.","code":""},{"path":"https://ai4ci.github.io/ggoutbreak/reference/weekdays.time_period.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Extract Parts of a POSIXt or Date Object â€” weekdays.time_period","text":"components day month year   easy compute: just use .POSIXlt extract   relevant component.  Alternatively (especially components   desired character strings), use strftime.","code":""},{"path":[]},{"path":"https://ai4ci.github.io/ggoutbreak/reference/weekdays.time_period.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Parts of a POSIXt or Date Object â€” weekdays.time_period","text":"","code":"## first two are locale dependent: weekdays(.leap.seconds) #>  [1] \"Saturday\"  \"Monday\"    \"Tuesday\"   \"Wednesday\" \"Thursday\"  \"Saturday\"  #>  [7] \"Sunday\"    \"Monday\"    \"Tuesday\"   \"Wednesday\" \"Thursday\"  \"Friday\"    #> [13] \"Monday\"    \"Friday\"    \"Monday\"    \"Tuesday\"   \"Wednesday\" \"Thursday\"  #> [19] \"Friday\"    \"Monday\"    \"Tuesday\"   \"Friday\"    \"Sunday\"    \"Thursday\"  #> [25] \"Sunday\"    \"Wednesday\" \"Sunday\"    months  (.leap.seconds) #>  [1] \"July\"    \"January\" \"January\" \"January\" \"January\" \"January\" \"January\" #>  [8] \"January\" \"January\" \"July\"    \"July\"    \"July\"    \"July\"    \"January\" #> [15] \"January\" \"January\" \"July\"    \"July\"    \"July\"    \"January\" \"July\"    #> [22] \"January\" \"January\" \"January\" \"July\"    \"July\"    \"January\" quarters(.leap.seconds) #>  [1] \"Q3\" \"Q1\" \"Q1\" \"Q1\" \"Q1\" \"Q1\" \"Q1\" \"Q1\" \"Q1\" \"Q3\" \"Q3\" \"Q3\" \"Q3\" \"Q1\" \"Q1\" #> [16] \"Q1\" \"Q3\" \"Q3\" \"Q3\" \"Q1\" \"Q3\" \"Q1\" \"Q1\" \"Q1\" \"Q3\" \"Q3\" \"Q1\"  ## Show how easily you get month, day, year, day (of {month, week, yr}), ... : ## (remember to count from 0 (!): mon = 0..11, wday = 0..6,  etc !!)  ##' Transform (Time-)Date vector  to  convenient data frame : dt2df <- function(dt, dName = deparse(substitute(dt))) {     DF <- as.data.frame(unclass(as.POSIXlt( dt )))     `names<-`(cbind(dt, DF, deparse.level=0L), c(dName, names(DF))) } ## e.g., dt2df(.leap.seconds)    # date+time #>    .leap.seconds sec min hour mday mon year wday yday isdst zone gmtoff #> 1     1972-07-01   0   0    0    1   6   72    6  182     0  GMT      0 #> 2     1973-01-01   0   0    0    1   0   73    1    0     0  GMT      0 #> 3     1974-01-01   0   0    0    1   0   74    2    0     0  GMT      0 #> 4     1975-01-01   0   0    0    1   0   75    3    0     0  GMT      0 #> 5     1976-01-01   0   0    0    1   0   76    4    0     0  GMT      0 #> 6     1977-01-01   0   0    0    1   0   77    6    0     0  GMT      0 #> 7     1978-01-01   0   0    0    1   0   78    0    0     0  GMT      0 #> 8     1979-01-01   0   0    0    1   0   79    1    0     0  GMT      0 #> 9     1980-01-01   0   0    0    1   0   80    2    0     0  GMT      0 #> 10    1981-07-01   0   0    0    1   6   81    3  181     0  GMT      0 #> 11    1982-07-01   0   0    0    1   6   82    4  181     0  GMT      0 #> 12    1983-07-01   0   0    0    1   6   83    5  181     0  GMT      0 #> 13    1985-07-01   0   0    0    1   6   85    1  181     0  GMT      0 #> 14    1988-01-01   0   0    0    1   0   88    5    0     0  GMT      0 #> 15    1990-01-01   0   0    0    1   0   90    1    0     0  GMT      0 #> 16    1991-01-01   0   0    0    1   0   91    2    0     0  GMT      0 #> 17    1992-07-01   0   0    0    1   6   92    3  182     0  GMT      0 #> 18    1993-07-01   0   0    0    1   6   93    4  181     0  GMT      0 #> 19    1994-07-01   0   0    0    1   6   94    5  181     0  GMT      0 #> 20    1996-01-01   0   0    0    1   0   96    1    0     0  GMT      0 #> 21    1997-07-01   0   0    0    1   6   97    2  181     0  GMT      0 #> 22    1999-01-01   0   0    0    1   0   99    5    0     0  GMT      0 #> 23    2006-01-01   0   0    0    1   0  106    0    0     0  GMT      0 #> 24    2009-01-01   0   0    0    1   0  109    4    0     0  GMT      0 #> 25    2012-07-01   0   0    0    1   6  112    0  182     0  GMT      0 #> 26    2015-07-01   0   0    0    1   6  115    3  181     0  GMT      0 #> 27    2017-01-01   0   0    0    1   0  117    0    0     0  GMT      0 dt2df(Sys.Date() + 0:9) # date #>    Sys.Date() + 0:9 sec min hour mday mon year wday yday isdst zone gmtoff #> 1        2025-12-11   0   0    0   11  11  125    4  344     0  UTC      0 #> 2        2025-12-12   0   0    0   12  11  125    5  345     0  UTC      0 #> 3        2025-12-13   0   0    0   13  11  125    6  346     0  UTC      0 #> 4        2025-12-14   0   0    0   14  11  125    0  347     0  UTC      0 #> 5        2025-12-15   0   0    0   15  11  125    1  348     0  UTC      0 #> 6        2025-12-16   0   0    0   16  11  125    2  349     0  UTC      0 #> 7        2025-12-17   0   0    0   17  11  125    3  350     0  UTC      0 #> 8        2025-12-18   0   0    0   18  11  125    4  351     0  UTC      0 #> 9        2025-12-19   0   0    0   19  11  125    5  352     0  UTC      0 #> 10       2025-12-20   0   0    0   20  11  125    6  353     0  UTC      0  ##' Even simpler:  Date -> Matrix - dropping time info {sec,min,hour, isdst} d2mat <- function(x) simplify2array(unclass(as.POSIXlt(x))[4:7]) ## e.g., d2mat(seq(as.Date(\"2000-02-02\"), by=1, length.out=30)) # has R 1.0.0's release date #>       mday mon year wday #>  [1,]    2   1  100    3 #>  [2,]    3   1  100    4 #>  [3,]    4   1  100    5 #>  [4,]    5   1  100    6 #>  [5,]    6   1  100    0 #>  [6,]    7   1  100    1 #>  [7,]    8   1  100    2 #>  [8,]    9   1  100    3 #>  [9,]   10   1  100    4 #> [10,]   11   1  100    5 #> [11,]   12   1  100    6 #> [12,]   13   1  100    0 #> [13,]   14   1  100    1 #> [14,]   15   1  100    2 #> [15,]   16   1  100    3 #> [16,]   17   1  100    4 #> [17,]   18   1  100    5 #> [18,]   19   1  100    6 #> [19,]   20   1  100    0 #> [20,]   21   1  100    1 #> [21,]   22   1  100    2 #> [22,]   23   1  100    3 #> [23,]   24   1  100    4 #> [24,]   25   1  100    5 #> [25,]   26   1  100    6 #> [26,]   27   1  100    0 #> [27,]   28   1  100    1 #> [28,]   29   1  100    2 #> [29,]    1   2  100    3 #> [30,]    2   2  100    4  # \\donttest{ ## Julian Day Number (JDN, https://en.wikipedia.org/wiki/Julian_day) ## is the number of days since noon UTC on the first day of 4317 BCE. ## in the proleptic Julian calendar.  To more recently, in ## 'Terrestrial Time' which differs from UTC by a few seconds ## See https://en.wikipedia.org/wiki/Terrestrial_Time julian(Sys.Date(), -2440588) # from a day #> [1] 2461021 #> attr(,\"origin\") #> [1] -2440588 floor(as.numeric(julian(Sys.time())) + 2440587.5) # from a date-time #> [1] 2461021 # }"}]
